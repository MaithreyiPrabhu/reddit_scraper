selftext,title,id,sorted_by,num_comments,score,ups,downs
,Data Democratization - Data and Analytics Takes a Step Closer to the Masses | Analytics Insight,9ejtlh,new,0,1,1,0
,43 Plots in R About Earthquakes in Mexico since 1980,9eiys4,new,0,1,1,0
,Using Chaos Search To Make Long Term Log Storage Affordable And Useful (Interview),9eiyd1,new,0,1,1,0
"I've been reading around online a bit as to whether or not employers still stigmatize degrees that have been earned online vs in-person.  While most of what I read seems to suggest that the advent of wide-spread distance learning programs has legitimized them in a way that they weren't previously, I was curious what experiences people on this forum have had with MSDS degrees offered online?  Do you generally feel like there's any stigma around the fact that the degree was earned online?

I'm thinking of programs offered by well established public or private universities with corresponding physical locations (Berkeley, CMU, U-Wisconsin, U-Illinois UC etc...).

Thanks",MS online vs in-person,9eixlt,new,6,5,5,0
,"Mo Data, Mo Problems. Everyone always talks about wanting more data, but they don’t talk about why they need data science or listen to analyst suggestions. If companies want to stay competitive, then they must invest in the resources to do so and treat data like a commodity.",9eimsw,new,1,18,18,0
"Hey all, 
Do people have recommendations for pipeline versioning? 
We have a home-rolled combination of git-branches and ""config"" pythong cripts that version data, experiment (model parameter) and run, but I feel like this problem has to have been solved before ...
I know of commercial tools like Domino and Azure ML, and I did dig into the open source world for a moment .. and then forgot to take notes. 

What are people using to version their work, explore impact of model teaks and all that? ",Pipeline Versioning (Open Source / Free) What are the options and recommendations?,9efk1z,new,2,10,10,0
,Very low cost cloud GPU instances (<$0.15/hr) - Vast.ai (BETA),9ef720,new,6,23,23,0
"[Project Link](https://github.com/HiteshGorana/DataScience365)

&#x200B;

https://i.redd.it/eksfvqscj8l11.png",DataScience365 ( A project started recently to explore the concept of Data Science ),9ee1ph,new,6,65,65,0
,Get free GPU for training with Google Colab - Detailed Tutorial,9ed87s,new,0,0,0,0
" 

My intents are to analyze the results with Excel, Power BI, and/or R and help analytics job seekers (those in college and those who already graduated) have a better time finding work.

I had a very turbulent job search before finding my first analytics role, so hopefully my analyses will help alleviate that for someone else!

Survey link. It should take around 5 minutes:

[https://docs.google.com/forms/d/e/1FAIpQLSd8K9K6CJZMk2cDnXmXzJZhqjFVHjZHmo-kxKlhXUFNRIL6kw/viewform?usp=sf\_link](https://docs.google.com/forms/d/e/1FAIpQLSd8K9K6CJZMk2cDnXmXzJZhqjFVHjZHmo-kxKlhXUFNRIL6kw/viewform?usp=sf_link)

I've only received 10 responses so far, so please take the survey!",Please Take This Survey if You're a College Grad and Working In or Pursuing a Career in Analytics!,9ectjy,new,5,0,0,0
"Hello Folks! I have written an in-depth explanation of a well known Text Classification ML Algorithm : Naive Bayes

I have especially designed it for ML beginners by keeping in mind the mathematical & probabilistic difficulties we usually face when trying to dive deep in to the algorithmic insights of ML algorithms.

I intended to demystify all the intimidating mathematical philosophy behind the Naive Bayes ML algorithm and it's guaranteed to help you to take a step further into your machine Learning Voyage!

[https://towardsdatascience.com/unfolding-na%C3%AFve-bayes-f…](https://towardsdatascience.com/unfolding-na%C3%AFve-bayes-from-scratch-2e86dcae4b01)

I am curious to know your valuable thoughts about it. Let me know if helped you to broaden your ML Conscience! 

[\#NaiveBayes](https://www.facebook.com/hashtag/naivebayes?source=feed_text) [\#ML](https://www.facebook.com/hashtag/ml?source=feed_text) [\#DataScience](https://www.facebook.com/hashtag/datascience?source=feed_text) [\#TextClassification](https://www.facebook.com/hashtag/textclassification?source=feed_text)",Unfolding Naive Bayes from Scratch!,9echsc,new,0,0,0,0
"Has anyone dealt with such a problem statement? If yes what were the steps taken and what packages/code reference are there?

Have been tasked to create 100 clusters with a limit of 30 elements in each cluster as an assignment but I have totally no idea how to achieve this",R clustering with maximum size per cluster,9ec9od,new,6,2,2,0
,How useful is a reference letter from an econ prof. for a MS Statistics application?,9ea76g,new,6,4,4,0
Which tools and packages do you use the most at work?,What tools do you actually use at work?,9e9yt8,new,48,33,33,0
"Since I started as a data scientist, I have been offered several opportunities by professors to collaborate on research papers. In fact, I'm working on one with a professor right now in the area of geospatial analysis.

&#x200B;

I get the impression that a strong publication record is highly valued in this industry in any case - I have seen several job opportunities that ask for research experience if not a PhD outright. As a disclosure, I have a Masters but not a PhD, so I'm always looking for ways to keep myself competitive with people who do.

&#x200B;

In this regard, are research papers useful from a portfolio perspective? For instance, if one doesn't have much work experience in a particular field, a research paper allows a data scientist to showcase domain knowledge in an area, and collaborating with professors on a particular research idea may also lead to good networking opportunities with contacts in industry, etc.

&#x200B;

For a data scientist who doesn't have a PhD and is trying to strengthen their portfolio and research capabilities, is doing independent research collaboration a good idea?",Are independent research papers useful for a data science portfolio?,9e9co6,new,1,0,0,0
"So, I'm trying to build playlists based on values I get from Spotify's API. These are for example ""danceability"",""energy"" etc. The idea is train a recommender with a library of approved playlists and then use it to create similar playlists from a larger set of tracks. I'm using R for this.

&#x200B;

I tried to build standard recommender systems like ALS but the problem is that all the examples I could find use only one rating to recommend items. I tough about using sometging that is distance based but I'm not sure how to implement it or  which algorithm to use. 

&#x200B;

Any advice is appreciated!","How to use recommender Systems with Multiple ""Ratings""",9e8i3u,new,1,7,7,0
,[Cheat Sheet] Snippets for Plotting With ggplot,9e7ye4,new,0,17,17,0
,Feature engineering that exploit symmetries can improve model performance! I made some visualizations of this for decision trees to illustrate why this is this case. Anyone aware of/have thoughts on how to take this to the next step?,9e6rp0,new,9,45,45,0
"Good Afternoon Everyone,

&#x200B;

I was working on  the data camp exercises and I'm am plotting bivariate and multivariate data sets. One of the examples had us plot a correlation matrix in R. The arguments specified  under corrplot( ) allows us to change the method ( ""number"" or ""color"" )

&#x200B;

 ""Color"" shows the circles w/ the size of the circle showing the correlation ( larger the circle the closer to 1 it is) 

It also uses a color chart for correlation

""Number""

Uses the correlation value  and color  

&#x200B;

Is there anyway I can combine the two?

Have a  color circle representing the correlation with the actual value of correlation inside?

 ( the combination of the two images below ) 

&#x200B;

Personally, I think the combination of the two would be better represent correlation visually

&#x200B;

https://i.redd.it/yqzfhdeau1l11.png

https://i.redd.it/pioqddeau1l11.png",Correlation Plot of a correlation matrix ( using R ),9e5urz,new,4,0,0,0
,What are good products for data science on distributed infrastructure?,9e4h42,new,2,0,0,0
"Hi all, this is a followup on [Separated from DS job and taking a month off to make portfolio. What to do about LinkedIn?](https://www.reddit.com/r/datascience/comments/9bnkyb/separated_from_ds_job_and_taking_a_month_off_to/)

I only applied to a few jobs and it gave me some options. There is a remote job where the manager likes me and wants to move quickly for a contract position. I would say it's certainly a step or more down but there are benefits to being remote, having work quickly after separating from a startup, and a normal 40hr/week job that would give me time to build up the skills to get back into a data scientist role again, hopefully. I would still be a data professional but not in tech and not working with programming languages in any substantial way- mainly collection/organization/light analysis from what I hear.

Then, there is another I'm interviewing for that is a permanent with benefits role (although I have them through my SO already) where I would certainly be happy but they are very picky on fit and have been hiring for a long time. It is a small tech company. HR seemed to like me and I will speak with the hiring manager after the weekend but it's only about a half step down from my past DS role. It's a mix of Python, R, and SQL with SQL being the primary language, but I'd still be working with real-time data in my preferred industry. However, it wouldn't give me as much time to work on side-projects, is a longer commitment, and has a commute of \~30-45min by public transit. It would push a DS role much further out (3-4yr?) compared to 1-2yr at most after leaving the contract.

The second role is a normal hiring cycle and would take an extra week to find out about so I'll be in a position to decide whether to risk it and apply to more perm roles or take this contract with nice people at a good firm that is remote. On paper both are data analysts but the contract is a mix of analyst, architecture, and management of data. What would you do in this situation?

&#x200B;

Edit: I have already delayed the contract position by \~3 days and they have a backup candidate, seemingly out of concern for me being too bored with the responsibilities or concern for the above reasons so I can't delay them through the recruiting cycle of the other company.",Step down from Data Scientist in next job- how far down?,9e419g,new,3,0,0,0
"This is maybe not a specific DS question, but I'm sure a lot of you have experienced this scenario: 

I had a rather lengthy interview for a DS position, in which 2 case studies were discussed. 

These case studies were very close to my PhD subject matter, and since I'm still writing my thesis, I came out of the interview in full PhD mode, unable to stop thinking about these case studies and coming up with some great explanations and ideas to solve the problems that were presented to me - ideas that not only made my answers appear inadequate in retrospect, but that are also unlikely to come from other people due to my proximity to the subject matter. 

Now I really want to get back to the team and give them my thoughts, regardless of whether I will get the job, because as scientists, I believe we owe each other (and society as a whole) this type of knowledge exchange. It's the basis of scientific advancement and it's what I would do for any fellow scientist.

How would you handle this situation,, both as an applicant and as a team who is getting contacted outside the application process by one of the candidates? Do you think this would be considered inappropriate, since the selection process is still ongoing? Or could it be taken as a simple exchange of ideas, as is usual in academia? 

Give me your thoughts and experiences!",How do you deal with post-job-interview thoughts and ideas? Share them or let them go to waste?,9e3s9r,new,1,0,0,0
"Does anyone have experience in using either platforms (driverless)? If so, would love to hear about where they excel and what are some of the lacking functionalities. I have been trying to dig a lot, but it's very hard to find first hand information on their pros and cons.

&#x200B;

Thanks",H2O.ai vs Datarobot? Your take,9e3gyd,new,12,37,37,0
"Hey Guys, I've been working on this article for almost a month now. Finally got around completing it and getting it published in [freeCodeCamp](https://medium.freecodecamp.org) . My longest article until now. Hope you guys enjoy reading it as much as I enjoyed writing it. It's usually hard to come up with the few introductory lines of an article but this rad AI rap's starting lines felt like the natural choice to start off my article with!  

**Build it, train it, test it, Makes it denser, deeper, faster, smarter!** — Siraj Raval.

&#x200B;

[https://medium.freecodecamp.org/the-power-of-a-neuron-9b5526c2ed46](https://medium.freecodecamp.org/the-power-of-a-neuron-9b5526c2ed46)

&#x200B;

https://i.redd.it/wyv57bwi2yk11.png

&#x200B;",The Power of A Neuron!,9e1pht,new,0,0,0,0
"Hey Reddit,

&#x200B;

I've been pursuing ML and Data Mining for some time now and have come across multi level association pattern mining. Unfortunately no implementation exists in R which has prompted me to give learning R a proper go. 

Any suggestions for in-depth resources? (textbooks preferred)

&#x200B;

Thanks!",Best Resources To Learn R For Raw Algorithm Implementations,9e1baq,new,5,4,4,0
,Virtual assistant data entry service,9e13le,new,0,2,2,0
,Data Entry Services,9e10kr,new,0,0,0,0
I’d like to dip my toes into machine learning.  I’ve worked as a software engineer for awhile but this would be my first attempt to go into it.  I can’t seem to figure out what would be the best algorithm for something like this.  I believe I need a multi classification.  I know books that people like and the topics and when the book was released etc.  Any direction on what are some algorithms and concepts I should start with?  Thanks!,What would be a good algorithm to use to take a list of books read and then find other similar books ?,9e07i5,new,5,4,4,0
"I'm currently studying for an IT Engineering Master in France (I'm French) due for 2020 and I would like to pursue my studies for a post-master or a PhD in any english speaking university (prefer UK and US). I saw that Johns Hopkins University offered some very good data science programs as well as environmental engineering programs.

So is there anything you know about data science for the environment? Thank you!",Where to study Data Science for Environmental Science?,9e07c3,new,1,2,2,0
"**tl;dr:** Sane defaults for deep learning loss functions and optimizers, followed by in-depth descriptions.

https://www.hergertarian.com/cheat-sheet-deep-learning-losses-optimizers",Cheat sheet: Deep learning losses & optimizers,9dz0gr,new,1,0,0,0
"The context:
I happened to attend a Data-Science Hackathon and after the end when the top solutions were shared, I found that most of the top finalists, end-up using Linear Model for predicting regression, after  feature engineering.

Without this feature engineering it wasn't really apparent that linear model could be applied.","What steps you take to figure out Linear Model as appropriate for Machine Learning? Would appreciate sample to your works in github, supporting your explanation, if possible.",9dxlx4,new,8,0,0,0
"I'm trying to find the right comedian to book for an event. We are looking for an up and coming comedian that will appeal to a young, diverse crowd. I want to find comedians with the largest gain in followers/views in the last 6 months-year.

&#x200B;

I'm familiar with using the twitter API for text mining, but I don't know how to filter and sort by change in views/followers.

&#x200B;

Thank you!",How would you identify top rising comedians from a specific demographic using social media statistics?,9dx9u3,new,0,0,0,0
"Some people have told me that BI is about to grow a ton this coming year. I don't understand why they'd say that. I mean, what is different about BI that wasn't true 1 year ago? Why should it grow even more rapidly now than it has in the past few years? I haven't heard anyone give a good answer for this.",Is the business intelligence market getting flooded?,9dwp1z,new,6,2,2,0
"I came across this gem today and as diversity has been on my mind lately (ok it usually always is), I am curious to see how representative we all think this might be. And not just why this is the case, but how to improve. [(source link)](https://grafy.grafiti.io/facts/19629)

First, this is just a sample of GA class students, not in the entire profession. It's no surprise that traditionally there have been less women interested in being devs, but it's been definitely increasing both statistically & anecdotally. And interestingly more women take data analytics classes. Anyways, would love to hear your opinion.

&#x200B;

https://i.redd.it/l4voyssu4uk11.png",Diversity in Data Science?,9dvhna,new,33,0,0,0
"Messing around with an anonymized sample dataset from a company called Topos (topos.ai) to see if it’d be useful for our site selection model.  They do some awesome stuff to understand the cultural makeup of a city… unfortunately they have some terrible SEO. Like, 4th page of Google when you search for their company name terrible. Sick Medium articles though: https://medium.com/topos-ai/on-dollar-slices-pizza-vectors-prosciutto-zones-and-topping-hyperspace-f163e7ebbccf

Have a meeting later today to see if automated alerts for new production branches performance are actually useful or not.

Going to sit down with some of the combinatorial multi-armed bandit math in https://arxiv.org/pdf/1407.8339.pdf and see if it’s useful to us. Their work seems pretty fucking nuts tbh. We use a neural bandit to handle combinations of prices, which seems to perform pretty well relative to other implementations of combinatorial bandits, but obviously once you move away from pure math strategies and you just let some NN handle everything, you lose the ability to prove mathematical efficiency which scares me a little.

What about y’all? 
",What have y'all been working on recently?,9dvfld,new,0,0,0,0
"Hey all, 

I just want to pick everyones brain on a subject that I've been toying around with in my free time. 

Given a data set - how would you determine, give one entity, which other entity or entities in the dataset are most similar.

I like beer, so the example I usually use is hops: 

Name|Alpha_Acid|Cost per Pound|Aroma|Purpose                        
:--|:--|:--|:--|:--|:--|:--|:--                                  
Hop1|3%|$10|High|Finishing.
Hop2|10%|$3|Med|Bittering.
Hop3|2%|$25|High|AllPurpose.
Hop4|9%|$12|Low|Bittering.

In short, if I feed in HopX - I want to know that (for example) Hop1 is most similar and Hop3 is 2nd most similar based on selected features. 

In my ELI5 mind, the simple way to approach this is going to be assigning the qualitative variables a dummy/quantitative variable and build some kind of predictive model, then probably feed in your control entity and see what is near by. I've been exploring the use of KNN for this - but is this the optimal approach? 

Are there any packages or models in sklearn or anything that would be a better path to explore? How about general theory/whitepapers/articles onthe subject.. 

TY in advance!",Best Practice - Entity Matching/Most Similar Entity,9dveaz,new,4,0,0,0
"Specifically, as AI gets better and better, and algorithms become complex enough so that humans cannot easily understand how data is being manipulated.

&#x200B;

I have read several articles that intimate this is a real issue we will have to deal with in the future.  However, I don't know if this has any validity.  Thoughts?

&#x200B;

Non-data scientist here trying to get an idea of how to make sense of some industry articles I have read.  Thanks.",Is anyone here concerned about eventually putting yourselves out of jobs?,9duy1u,new,11,1,1,0
,Super handy MachineLearning Glossary by Google.,9dus77,new,0,20,20,0
"What is the difference between sklearn.impute.SimpleImputer and sklearn.preprocessing.Imputer?

All I know is that **SimpleImputer** works with strings but when it cames to numerical data is there any difference?",sklearn SimpleImputer VS Imputer,9dur7n,new,0,1,1,0
,"Super helpful cheat sheets for Keras, Numpy, Pandas, Scipy, Matplotlib, Scikit-learn, Neural Networks Zoo, ggplot2, PySpark, dplyr and tidyr, Jupyter Notebook",9duq0l,new,6,359,359,0
,What are the secrets of data scientists who always get job offers?,9duf5f,new,11,1,1,0
"Working as a data scientist, I often find myself saving many tables and graphs over time after running experiments, analyzing results then visualizing the data. But then it's hard to find when I want to refer back to those results weeks later. I've been working on a tool called Reccrd to help with this problem (see [https://www.reccrd.com](https://www.reccrd.com)).

The idea is that when you are doing data analysis/visualization (in a jupyter notebook for example)  you have an API that sends artifacts (e.g. text, pandas dataframes, matplotlib figures and plotly figures) with metadata such as descriptions and comments to a web service. Now you can easily go back to or share analyses done in the past.

Would this be useful to anyone else? Please share your thoughts!",Github (sort of) for data scientists?,9duaok,new,8,4,4,0
"I have a prospective client who’s keen to do some customer lifetime value analysis and data mining on a large database of customers.

I’m well positioned to help and have been asked to quote up the work, but I’ve never done any freelance data science work.

Does anyone here know a ballpark hourly rate for this type of work?

I’m new to freelancing and am still building a portfolio, which means I’m willing to work at a discounted rate, but I have no idea where to even begin... I’m in Australia.

Any advice / thoughts would be appreciated!

Thanks",What hourly rate to charge for a data mining / analysis piece?,9dq2ni,new,4,6,6,0
"Hello all!

I have a final interview for a Sales Ops Analytics/DS role tomorrow morning (just found out about it). Are there any good resources specifically for sales pipeline analytics that I could peruse before my interview?",Sales Pipeline Analytics Resources,9dnnyj,new,2,2,2,0
"Hey all,

I have an interview with Fb for their DS, Analytics role and my first phone screen interview is next week. I know that it has a 50-50 Tech(SQL/Python/R) - Analytics split. I have been practising numerous SQL questions specifically for interview but finding those kind of questions are a bit tough and I was hoping people who have gone through the process or are familiar can post their experience with the type of questions or put sample questions for me to continue working on. I'm not asking to reveal any NDA material, just helpful questions more like an anonymous mentors on reddit. I feel that my SQL concepts are strong but maybe due to less interview experience I trip up during product based SQL questions or am a bit slow, hence I just want more such material to keep practising on. I have compiled whatever questions I could from Glassdoor so am hoping you guys can be of help! 

Any advice on this and even the product analytics related question would be greatly appreciated! Thanks in advance to you all :)

Note - I know a post similar to this exists but that was specifically for onsite and I need advice for the first interview, thanks.","Facebook DS, Analytics Video interview",9dn95h,new,31,54,54,0
"Please shoo me away to the proper sub if I'm asking this in the wrong place.

I'm gathering a time series data that I want to analyze. I anticipate that what I will find is a measurable increase in a specific metric that happens on two separate intervals: every two years and every ten years.

The two year effect and the ten year effect are two different effects. I'm trying to figure out the best approach for measuring which of those effects is greater. This may be very obvious and something I simply haven't thought of, or there may be some unique and interesting way to analyze this. I'm just wondering if anyone can point me in the right direction.",Looking for the right statistical approach to this time series dataset,9dmrro,new,5,1,1,0
,Check,9dl8gr,new,0,0,0,0
,Guidelines For Ab Testing,9dkhbs,new,0,21,21,0
,Introduction to Reinforcement Learning using MXNet 🤖 • r/MachineLearning,9dkgst,new,0,4,4,0
"So here’s a little about me. I’ve been a lead data scientist at a bank going on 2 years now. Leading a team of 6 people. 7 years Python experience. PhD in physics. Knowledgeable about machine learning and software engineering. 

I’ve decided my next goal is to be a data scientist at a quant hedge fund. Ideal scenario would be working for a place like two sigma. I’m confident I can do the job but my impression is the interviews require a bit of specialized studying. Does anyone have advice on studying for these interviews?",Best way to study for quant hedge fund interviews?,9dkeks,new,7,6,6,0
,The many ways to measure economic inequality,9disvz,new,46,70,70,0
"Bayesian Network is a probabilistic graphical model which comprises variables and its relationships. It uses Bayesian inference and learning to develop the algorithm.

[https://info.cloudquant.com/2018/09/bayesian/](https://info.cloudquant.com/2018/09/bayesian/)",Roles Played by Bayesian Networks in Machine Learning,9dinpb,new,0,0,0,0
"What's the best open source (i.e., free) approach/library/tool for unsupervised/semi-supervised\[i.e., with limited to no training data\] time-series \[like this - [https://github.com/numenta/nupic/blob/master/src/nupic/datafiles/extra/nycTaxi/nycTaxi.csv](https://github.com/numenta/nupic/blob/master/src/nupic/datafiles/extra/nycTaxi/nycTaxi.csv)\] anomaly detection.

&#x200B;

&#x200B;

&#x200B;",Time-Series Anomaly Detection,9dffpw,new,4,5,5,0
"I'm looking to make some data science projects regarding hip-hop and music in general, and I'd like to find a good source to mine data from regarding album sales. 

Any suggestions are greatly appreciated. ",Looking for a reliable source for historic and current album sales data.,9dennq,new,3,1,1,0
"Hi, this is my first post ever, so sorry in advance if it is in the wrong place or wrong format.

In addition to being an amatuer redditor, I am a beginning programmer, and have been trying to learn about Data Analytics, specifically search algorithms. I know about things like Binary Search and Interpolation Search but when I look at the big analytic tools like Hadoop or Apache Spark I cannot find out what their search engines are like; I want to know about how fast the most advanced analytic tools are so I can compare it to a simple binary search and get some frame of reference as to where the cutting edge of analytical search engines really are.

It's kinda frustrating not being able to find this out since I am so interested in this, so any help or resources would be appreciated and thanks for taking the time to read this post.",Trying to understand Search Algoritms,9dem66,new,5,0,0,0
"Hi, guys. I have a dataset of different addresses but some addresses pointing to the same location. Those postal addresses that match each other have already been marked,   

e.g., ""5 Avenue, XX building"" is manually matched with '5th Avenue, XX"" (our location is not in US, so it is only an example).

The reason why we have two representations of the same location is that we have multiple datasources.  And given we already know which match, we can perform supervised training in ways that:

&#x200B;

using string A and string B, to form input as X (obviously words in both strings cannot be directly used as input) against binary output Y. 

&#x200B;

say, 

&#x200B;

variable 1: if there is a match digit:  (5 appears in two string, so match): 1;

variable 2: the length difference between two strings;

....

&#x200B;

I am wondering if there is some literatures I can look at or methods that specialise in generating features for NLP problems.  

&#x200B;",NPL problem: building a feature space for ML classification problem,9dejp6,new,0,2,2,0
,Google Introduces New Search Engine for Finding Datasets.,9dcltp,new,16,472,472,0
"Hi Guys, I need some advise or personal experience in what I am going thru right now.



It seems like I am losing focus with a lot of interest I have with this new stuff. I've been reading a lot and collected resources to learn programming (in python). Now the issue lies in me wanting to learn a LOT of unrelated stuff - like I wanna jump right away from basics of python, to machine learning, to blockchain tech. I have this battle in my head that I cannot immediately learn all of these at a nick of time YET my interest to read more about it delays the little steps to unlock my way to fully engage each of them (like I really need to learn python yet I am jumping to learn the math, the visualization, etc)


I wanted to know how do you guys cope up with this issue. I guess I am too hungry and too hard to myself. How do you guys deal with the ""rush"" of enthusiasm?",The feeling of rushing the path/way of learning,9dccrc,new,5,3,3,0
,Putting the Power of Kafka into the Hands of Data Scientists,9db9vl,new,0,3,3,0
"I have one ""master"" classification model, which is composed of two sub-models: one with relatively few dimensionality (input of length 120); another with relatively high dimensionality (input of length 5,000). The latter uses free-text, which is why there are so many input values.

Currently, I build these two models independently. That is, the weights of the lower-dimensionality inputs for model A are developed independently of the higher-dimensionality inputs for model B. However, the inputs really should be considered dependently (or rather, *not independently*) in the ultimate model.

What are some strategies for combining these inputs? My first thought was to just tack the text features (the width-5,000 matrix) onto the lower-dimensional features, but I'm not sure whether that could present problems with the overall modeling exercise. Anyone else have experience with this type of problem?",Combining low- and high-dimensional models into one,9db1v7,new,3,1,1,0
"Cheers everyone! This is my first kernel on Kaggle. Please do not hesitate to spot any bug or any kind of error!

&#x200B;

[https://www.kaggle.com/mrknoot/genetic-algorithms-solving-the-n-queens-problem](https://www.kaggle.com/mrknoot/genetic-algorithms-solving-the-n-queens-problem)

&#x200B;

I truly hope you like it :)",Genetic Algorithms: Solving the N-Queens problem,9dayv2,new,0,2,2,0
"What is your thought on it? How is JupyterLab compared to RStudio?

What tasks would you rather do on JupyterLab than RStudio, and vice versa?

Are we expecting more features and better optimization for JupyterLab?",Anyone doing R stuff on JupyterLab?,9da7vx,new,5,1,1,0
,Dataset search from Google (beta),9d9x3c,new,0,19,19,0
,Deon: an open source ethics checklist tool for data scientists,9d9rtb,new,1,12,12,0
"Hello /r/datascience. TLDR: given the current DS job-landscape, do you think it's more important to have communication skills or tech skills? That's a simplification, here's my full question:

&#x200B;

I'm looking for some advice.  I think I am in a similar position as many data scientists, so I'm hoping people here can relate to my situation.

&#x200B;

A little about me: I'm early in my career (YOE: <5). I work in a large DS department (100+) and we are specializing our department (less ""unicorn"", now more focus on specific skills). As such, I've been given an opportunity to move to a more technical role or a more client-facing role.

&#x200B;

I've always focused my personal development towards becoming the ""unicorn"" --  maximizing the 3 pillars of DS as much as possible: math/stats, computer science, and business/communication. I believe this was the best way to bring value as a DS in the past 5 years (and may very well continue into the future). Personally, I'm strong in communication & math/stats, weaker in programming (R whiz, but everyone here is production-level python & spark). While pushing so hard to become the unicorn, I've learned to love every part of it. My ideal role is building the end-end product/research -- build a data pipeline (CS), build a model (Math/stats), and evangelize the results (business/communication). This is what my role is now! At the end of the day, though, I have a choice to make and must choose between these pillars. One more thing I should note: I personally enjoy these 3 pillars about the same and ""personal enjoyment"" is less important to my decision.

&#x200B;

SO, with that background info, what would you recommend? What would give me the best options in the future? What is the *ideal* career path for someone in my position? I'd love your advice for my situation, but I'm also curious about your thoughts on the DS-industry as a whole and the balance between tech/soft-skills.",The 3 Pillars of Data Science - The Choice to Pursue Communication or Tech,9d9mas,new,3,3,3,0
"I'm finding myself in a position where I may have to make a decision on my career path and I'm hoping you can help provide some thoughts based on your data science work experience.

I work for a mid-size medical device company and we do not have any type of data science department. The most we rely on are R&D scientists who use their typical statistics, a marketing insights team, and a data analyst in the customer service dept (just generate queries/reports for sales transactions). I am in a unique group that does technical support and I generate my own ""projects"" to support internal/external customers. In previous projects, I would create VBA macros and queries to tap into our sales data, SQL databases (production data, returns, materials processing), complaints and thus generate some useful insights (EX: probable return rate of new product launches, medical diagnostics, root cause analysis through data logging).

Most recently a PM asked about a decision to obsolete a feature and I was able to provide a report showing the lack of engagement for it and that eventually got visibility of the higher ups on my skills. Since then, I've noticed more people coming to me for data help. 

**At this point, I'm wondering if I should make the case to our Directors of building a Data team to support the various functions of our company from R&D, Ops, Marketing, and Sales so we can provide them the type of insights that would help us be more innovative and efficient.** 

However, I do not see myself as any type of data scientist, especially when reading about the type of work you all do! I have an a M.S. in Engineering and at a Senior level position, but my exposure to data science has been limited to the Microsoft edX curriculum. I was initially interested in the course to be more efficient at Excel but it eventually spiraled into the Data Science curriculum and I'm currently learning Python/ML.

I wonder if I'm being a bit too hard on myself for simply not having the technical expertise yet, but that my strengths are motivating leaders to buy into the vision of Data. Based on this exposure, would you: 

* Recommend that I continue the data science journey, learn on the fly, and enroll in more formalized courses?
* Say that I'm not really advocating ""true"" data science, but just a glorified data analyst with potential of doing science?
* Suggest becoming a PM to build a group and hire experienced data scientists
* Advise me to Give it up, you're not really doing any of it at all!

It's tough for me to compare because I've never worked for any company with a robust Data Science team. Additionally the structure of a Medical Device company is so different from Tech/Product company so neither of my trusted colleagues would know either. 

I appreciate your comments!","Am I headed towards Data Science, Data Analyst, Product Manager, neither?!",9d9iuh,new,3,5,5,0
,LinkedIn August Work Report: Employers Desperate for Data Scientists,9d8y2w,new,64,97,97,0
"I have been reading a lot of quora answers and see a whole lot about how data science is ill defined. I completely agree **if all you are reading is the job title**.

**Advice:** Read the job description. Read the desired skills.

* If the job posting is looking for someone who has skills in AB testing and visualization. Guess what you will do in the role?

AB testing and dashboards.

* If the role is asking for prediction and inference modeling experience plus experience with techniques like linear regression, NN, and random forest . Guess what you are likely to do?

Prediction and inference.

* If the job ask about bayesian networks and building models to be able to explain observations. Guess what you will likely work on?

Sense a pattern 

* And last but not least. It the job requirement and desired skills ask for every technique under the sun. Guess what you will work on?

Answer: Requirements and building consensus because the organization has no clue what their goals or how to get there .


**Advice 2: Do your research and learn what type of roles are in this field and a job description wont read like foreign language so you wont have to just go on job titles**",Data Science roles are ill-defined? Advice : Read the requirements and skills,9d8lmu,new,4,10,10,0
"What data science course you studied from and found best for you, even if you are complete beginner?",What data science courses/s you found best for you?,9d722a,new,8,5,5,0
I'm looking for a ISO file of a distro that it's Data Science ready (or close to it). I know there are some VM images that I can use. But I would rather not use a VM right now. I've done some Google search but wasn't able to find something I can use. Is this something that exists and that I can leverage?,Is there a Data Science ready Ubuntu (or with another distro) ISO that I can use to speed up the set up process?,9d6d8y,new,12,5,5,0
"PyCM is a multi-class confusion matrix library written in Python that supports both input data vectors and direct matrix, and a proper tool for post-classification model evaluation that supports most classes and overall statistics parameters.	PyCM is the swiss-army knife of confusion matrices, targeted mainly at data scientists that need a broad array of metrics for predictive models and an accurate evaluation of large variety of classifiers.

&#x200B;

[Github Repo](https://github.com/sepandhaghighi/pycm)

[Webpage](http://pycm.shaghighi.ir/)

[JOSS Paper](http://joss.theoj.org/papers/10.21105/joss.00729)",PyCM: Multiclass confusion matrix library in Python,9d6bed,new,0,1,1,0
,Infographics: Who Am I? - Data Scientist,9d4yjp,new,1,0,0,0
"This is my first kernel on Kaggle doing some data analysis, Hope you like it!!

Feedback and Bugs are welcomed:) 

[https://www.kaggle.com/sulabh4/premier-league-analysis](https://www.kaggle.com/sulabh4/premier-league-analysis)

[https://github.com/codexponent/premierleague-analysis/](https://github.com/codexponent/premierleague-analysis/)",Premier League Data Analysis Since it's inception from 1992,9d4rk9,new,14,40,40,0
"I'd like to work on a project where I calculate some data statistics in python (I can write scripts to do this locally) and show a live graph in a webpage. Can anyone recommend some tutorials or packages to get me started on this?

&#x200B;

Edit: FYI the data is scraped online and I can import it into pandas with the requests package. ",Deploying Data Statistics on the Webpage,9d4jv2,new,8,2,2,0
"Hello everyone,

I am trying to predict an event using random forests, and one of my variables has missing values.

The thing is that this variable is the time between today and a certain event. Thus, having a missing value means that the event did not occure before.

As this variable is either NA, or >= 1, I thought that I could replace missing values by -1, given the fact that I'm using Random Forests.

Now I'm wondering if that was actually a smart move.. Should I have replaced missing values by the mean ? Or maybe the maximum ?",Missing value in Random Forest ?,9d4fg7,new,3,1,1,0
,Causal inference using frontdoor adjustment,9d3mxl,new,0,1,1,0
"Let, there will be N events say E1, E2, E3, … E(N)

Also each event will have some soft-max scores (0 to 1). So I will prepare my dataset as E1 have value from 0 to 1, E2 have values from 1 to 2, .. E(N) have values from N-1 to N.

Is it possible to train RNN/LSTM with this.? Or I have to change my input dataset.? How to train LSTM such that it will learn each events with the score and give maximum accuracy.?

I want to do both sequence prediction and sequence classification with that data..

It would be great if someone share good kernels for non text sequence classification/predication using LSTM/RNN's, other than DNA sequence classification and stock predictions",LSTM for non-text data,9d37db,new,1,1,1,0
"Hi there,

I was hoping to find a source that contained a high level description of some of the most common algorithms and their pros/cons for their major applications. 

I know there are a ton of resources out there, but was hoping to see if anyone here knew of a good source.

Thanks!",High level description of best algorithm(s) for particular applications?,9d25sg,new,5,15,15,0
"My company wants to send me to either a conference or a bootcamp to learn the fundamentals of data science. 

&#x200B;

The tricky part is that I've only seen 6 month part time programs that are way over budget. The $2,000 is for both the conference and the travel/hoteling fees. If it's based in Boston, I can cut out those costs and attend a more expensive bootcamp. I tried pitching data science dojo, which comes out to $2,700 but was told no because of budget constraints. 

&#x200B;

I understand that this is not supposed to replace a degree in data science. The intention here is to take a boot camp to get a feel for if this is worth eventually pursuing  a Master's degree in. 

&#x200B;

Any conference recommendations that are in-person, within budget, good for beginners, 1 week full-time anywhere in the US or potentially 1-2 months part time in Boston?  ","Conference/bootcamp to learn data science fundamentals - 1 week duration, <2k?",9d14pc,new,7,1,1,0
"Is there a set of resources that I can not find that can relate the ""employment rate"" and the amount of citizens working multiple jobs. Just curious if employment is actually improving, or just skewed because we're working more jobs per person ",Employment rates vs working multiple jobs,9d0plf,new,2,0,0,0
,Convolutional Neural Networks (CNNs) explained,9d0fnp,new,1,2,2,0
"Going to be starting a project in which will require me to understand and apply these skills for the next 10 weeks. I have a couple weeks until I get staffed, so I wanted to get a good understanding of the concepts and theory. I come from a Python background but the customer requires R to be the language for production. Any guides or help for the theoretical understanding would be greatly appreciated!",Best place to start for theoretical understanding of Natural Language Processing/Text Analytics?,9cznmw,new,6,7,7,0
"[https://medium.com/@joepope44/reddit-com-r-antisemitism-e97df1dc9b53](https://medium.com/@joepope44/reddit-com-r-antisemitism-e97df1dc9b53)

&#x200B;

Would love to hear further thoughts on how to track hate speech on reddit or other sites. Constructive criticism always welcome. 

TLDR: Focus hate-speech classification efforts on authors, not comments. Use comments as labels for  further research. Review in the context of each subreddit. Avoid auto-censoring users, but provide a tool for moderation and human involvement. ",reddit.com/r/antisemitism – NLP and Unsupervised Learning on Reddit,9czks4,new,9,5,5,0
Can anyone recommend some textbooks I can read? Looking for material that assume a strong background in statistics/data-science but with little to no experience in genomics.,Data Science for Genomics?,9cyxm8,new,1,9,9,0
"Plz note I know nothing about javascript, web design, or D3.


Is it possible to create an offline, downloadable document that contains D3.js visualizations? This would be great for a project I'm considering taking on",Is there anyway to access D3.js visualizations offline?,9cysrn,new,8,3,3,0
"Does anyone have any experience with databricks? Or more specifically, uploading models written in R to databricks using the MLeap serialisation? I know that databricks uses Spark integration to handle processes in R, but I'm struggling to find some documentation on how to seamlessly upload a model using MLeap. Any help would be greatly appreciated, thanks.",Databricks - using R & MLeap,9cyp2r,new,1,1,1,0
Rn I'm following andreas Mueller scipy 2017 videos and his notebooks. Shall I slow down and pick up a book instead? Which one's should I pick? ,Fastest way to learn scikit learn?,9cxwyx,new,3,4,4,0
"Some files are related I.e. Joints01.csv and Joints02.csv or Xray01.csv and Xray02.csv, where each of the joints files has an ID to join on and Xray files have an ID to join on. How would you go about combing all the relevant CSVs together to make a more consolidated data frame? Would you write a loop to do this automatically somehow? ",I’ve been assigned a DS project that has 100s of CSV’s with some having a unique ID to merge on. How would you go about making a loop to join/merge all relevant CSV files?,9cxuoq,new,8,0,0,0
"*Reposted here to get some feedback on whether it helps the general public to better understand the difference between cloud computing and the traditional computing infrastructure.*

https://i.redd.it/djfz84lqa9k11.png

The recurrent question in the data-intensive workplace often revolves around which computing infrastructure to use. In the past four years as a bioinformatics Ph.D. student, I have both received and offered solicited and unsolicited advice regarding computing infrastructures using my prior experience in high-performance computing lab and current expertise in data analytics. This blog post covers my experience in using private computing infrastructure as compared to adopting the cloud in bioinformatics/ data analytics, and the thoughts on the advantages and disadvantages.

**What are the main components in computing**

The major challenge I found was that: **The decision-making process of deciding between buying computing infrastructure versus adopting the cloud is very much like buying a car versus renting a car. The main challenge is the unpredictability of user usage pattern.** The moment I walked into the car dealer, all I saw were the shiny cars with a seemingly affordable price tag, and all I had in my mind was to get the car now so that I don’t have to carry groceries back to grad housing for two miles whenever I go to Ralphs. Only till all the bills come then I know I am eating ramen for the next couple weeks and regret why the heck I bought the car. The immediate need of a car rushed me into the purchase without thinking about how often do I need it, and what kind of car do I need in the future.

It is the same game for finding the efficient and cost-effective computing infrastructure. The main problem in the story is that I am a poor graduate student having no money and I need to better utilize the limited financial resources to accomplish this goal. Fast completion time for the whatever demanding task requires expensive hardware, and like Ferrari, fast and powerful computing infrastructure doesn’t come cheap.

Most machines have different RAM, hard disk, CPU, GPU availability. Like cars, certain vehicles cater to a specific group of drivers (Truck if you are loading) and there are types of cars that are close to one size fit all (Honda civic). Of course, there are also people love driving a pickup truck like they need to move every day, burning the double amount of gas without any extra values. Anyway, the point is that a misjudgment on resource usage can cause you extra without gaining more benefits.

&#x200B;

https://i.redd.it/cp604yzva9k11.png

**Renting (Cloud) vs. buying compute infrastructure is like renting versus buying a car:**

For example, identifying the appropriate RAM usage is one big thing, as swapping with disk can slow down the job turn around time significantly. But if you know are going to swap, you might want to have a machine with SSD hard disk instead of HDD. None the less, most machine learning, analytic and bioinformatics programs run within <10GB RAM and some simple memory profiling using unix command *memusg* will tell you what needs to happen.

1. **The cloud is more like renting a car by the hour, achieving immediate goals without commitment.** For example, you want a fancy sports car to impress the girl tonight, and you went on Toru (car renting app) and found that renting a Porsche 911 for one night isn’t too bad, it’s only $200. You got the girl with the Porsche. However, after the first date, the girl expects you to drive her around in the Porsche 911 every day, and after a year, you found out that it cost you $73,000 which can already buy you that car already. The on demand cloud instances can burn through the bank if you are not careful. For example in Amazon cloud (AWS), continuously running an M4.16xlarge on demand elastic instance can cost \~$1,000 per month, which you can buy a similar machine with $10–20k. None the less, the AWS now offers spot instances, cheap availability of idle computing power is slowly changing the game. Some of my colleagues told me that they were able to achieve close to perfect availability with 10X cost reduction using AWS spot instances and 99% availability, where the only time they struggle with availability is during the online shopping seasons.
2. **Cloud computing enables simple and yet diverse configuration of security, network, compute and storage instances.** My experience of using the AWS as compared to traditional SGE and TORQUE computing ecosystem here is that AWS is highly configurable in both how the computing nodes behave together and within itself. For example, I could easily set up a secure virtual private network and file storage in a day, as opposed to negotiating for weeks with the supercomputer center on the logistic of moving the computing nodes into a private network.
3. **Deep Learning Amazon Machine Image + p3.16xlarge = deep learning magic**. For machine learning tasks, the AWS offer instances with up to 16 GPUs and images with the CUDA and common data analytical python libraries preinstalled, like *pandas*, *keras* and *tensorflow*. Those beefy machines alleviate the need for writing distributed code which can take weeks to months, and this turns out to be a huge advantage. Also, the environments issues became much more straightforward. For example, the CUDA static object libraries have versioning extension which screwed up the dependencies when I tried installing *tensorflow-gpu* on shared computing infrastructures. Moreover, all the computing infrastructures I have used so far hesitate to modify the computing environment, which is often the bottleneck in the development process.
4. **Private compute infrastructure maintenance is annoying**: During my years in an HPC (High-performance computing) lab, we used to maintain the cluster ourselves, and the cluster was hosted within the office. And whenever someone submits a job to the cluster we can feel the heat wave from the cluster. We also tried to be smart and save on the all the compute infrastructure except the CPUs and had a ghetto way to stack on machines without much consideration for the heat dissipation. The frequent death of the machines translates into frequent maintenance, which was a huge headache.

**Finally, check your code before checking the hardware:** Aside from computing infrastructure, the other significant problem towards efficient computing in data analytics is the lack of algorithm/software knowledge when people first come in. In the car analogy, if the person wants to go from point A to point B in the shortest amount of time, doesn’t matter how fast the car is if the driver thinks the steering wheel is a gaming controller and the volume up button will propel the car forward. I have come across some data analysts that have a minimal amount of algorithm knowledge, who thought without any software configuration/optimization, simply running on more machines will speed up the process. I have also seen many published data analytical software that could be hundreds of lines but somehow they ended up a hundred thousand lines. I am not trying to say we should stop people who didn’t ace all their algorithms to write code, as I do believe that everyone can learn and I have seen many biologists that could code fantastically. My argument is just the field could save so much time if most people could learn some basic linear algebra and algorithms before they start playing around with Big Data. For example, in the case of table IDs mapping, could be done with a simple sparse matrix multiplication using an existing optimized matrix arithmetic library, instead of writing distributed python to loop over each ID.

These are just my opinions, hope you learned something, feel free to leave comments and thoughts. :)

\-Brian

Originally published on: [https://www.linkedin.com/pulse/buying-computing-infrastructure-vs-adopting-cloud-data-brian-y-tsui/?articleId=6438887571455123456](https://www.linkedin.com/pulse/buying-computing-infrastructure-vs-adopting-cloud-data-brian-y-tsui/?articleId=6438887571455123456)",Buying computing infrastructure vs adopting the cloud in data analytics,9cxtjh,new,0,2,2,0
"I have a background in full stack software development (ruby, node, python) and Cloud System architecture (AWS) and want to dabble into data science. Which language should I check out or start with? Would you guys agree with the data provided in this chart:

&#x200B;

Source: NYC Data Science Academy

Found on: [https://grafy.grafiti.io/facts/15569](https://grafy.grafiti.io/facts/15569)

&#x200B;

https://i.redd.it/45e1xrb6s8k11.png",Background in Web Development and Solutions Architect (AWS) and looking to dabble in data science. Thoughts?,9cwt72,new,2,2,2,0
,From Pandas to Scikit-Learn — A new exciting workflow,9cwddt,new,24,161,161,0
,"Best Online Masters in Data Science and Analytics -- kdnuggets. Ranked by tuition and CIS rank, to approximate Data Science / Analytics",9cvgd3,new,13,22,22,0
"I started the short course of pandas, on the learn section in kaggle,

When I try to run check on my answer it returns false, but my I try to recreate it on sublime and print the results out, it matches exactly, the required outcome, new to kaggle don't know what could be wrong.

this is supposed to be the result 
https://imgur.com/a/MJmUAKr",Kaggle help needed,9cuzog,new,11,5,5,0
"I'm working on a large development project for a major western city. This new project will accomodate 30,000 people and will be built on top of the largest train station in the country.

&#x200B;

I'm putting together a document that showcases how data science can be used to help improve new cities.

&#x200B;

If you were in charge of monitoring a new city how would you do it? What data collection techniques would you use? What problems do you have with your current city and how can data science solve it?

&#x200B;

Feel free to be as open as possible. If this gets adopted by the developer its likely to become a standard in new cities.",Designing Cities for Data Scientists,9cr40l,new,5,4,4,0
"I am trying to decide how to approach comparing different preprocessing methods for model development, but am unsure of how to go about this. 

There are multiple preprocessing steps that I could do before model development. For example, for a regression problem I am working on I am considering taking the log of the target variable as it is heavily right-skewed and for imputation I am deciding between median/mode, kNN, or random forest. I want to do versions of all of these things and compare, but if I use 5 base model types, that leaves me over 20 combinations to compare without even tuning hyperparameters. 

So, my thought is I should decide whether to log transform and which imputation method to use before model development. Is there some convention on how to approach this issue, or what do you personally do?",Workflow when attempting to compare various preprocessing methods?,9cqs5i,new,5,4,4,0
"Hey Data People,

&#x200B;

I have just finished another blog-post. It's somewhat experimental and I am looking forward to some discussion - either here or directly on the blog:

[http://numbersandcode.com/exploring-decision-trees-in-hilbert-space](http://numbersandcode.com/exploring-decision-trees-in-hilbert-space)

&#x200B;

Kind regards",Exploring Decision Trees in Hilbert Space (Blogpost),9cpkml,new,15,10,10,0
,Data Science,9cp62e,new,1,0,0,0
"Here is a little project I've been working on:

[https://github.com/lmeninato/GoFundMe](https://github.com/lmeninato/GoFundMe)

I use python to scrape data from urls I generate by navigating the GoFundMe website with selenium/chromedriver. I think there is some interesting info here. Let me know if you find anything interesting! I provide a raw csv file as well as an .RData file. Let me know if you have any questions about the documentation. There's a cool mix of numerical data and text data. I think it would be interesting to predict which GoFundMe pages receive more funding.",Dataset of GoFundMe urls - interesting text data,9cozge,new,4,48,48,0
,Building A Master Data Catalog Using Machine Learning (Interview),9cou1p,new,0,0,0,0
"Title edit: contractual...not “contractor”

there are tons of examples, (ipynb, documentations) for how to model Customer Lifetime Value (CLV) for:

\- Discrete Contractual customer - Shifted Beta Geometric distribution sBG

\- Continuous Non-Contractual customer - Pareto/NBD

​

Does anyone have any examples in how to implement:

\- Continuous Contractual customer - Exponential Gamma or Pareto Distribution of the second kind

&amp;amp;amp;amp;#x200B;

I am trying to compute CLV probabilistically for these customers using Peter Fader’s techniques. 

​",CLV for Continuous purchases and contractor customers,9comw7,new,0,5,5,0
" Hi,

I recently interviewed Gian-Carlo Pascutto, creator of LeelaZero, the Go Engine based on AlphaZero. I thought I would share it here for those who were interested: [https://blackswans.io/post/14/](https://blackswans.io/post/14/).

Enjoy,

Jack",How a Firefox Engineer is Using A Deep Convolutional Neural Network to Replicate AlphaZero (X-Post r/statistics),9coevf,new,4,4,4,0
"Good Afternoon,

I need some explanation around arima models, specifically differencing random walk models to standardize the data and remove the trend.  I am on the quantitative finance path so if you can explain in terms of finance that would make it easier for me to understand. I need to understand why we are doing this part of it.

In the course they state that weekly oil price data is a random walk, so we must take the difference of the data to normalize it.

 Now how does this apply in a real world application? How does this make me more able to read the data? Or we only remove the trend in order to apply ARMA models? How do ARMA models help me interpret  the financial data better?  Is it just used for predictions?

",Can someone explain ARMA Models to me,9cnxl4,new,12,20,20,0
"**You probably get that a lot so i will try to be brief as possible:**

I am 24 years old, living in Brazil,  working and studying in the IT area about 5 years now, specifically in the fields of Information Security, Infrastructure and Monitoring and i'm looking for advise for where should i start to begin with the whole Data Science thing.   


In those 5 years of i took a basic  look in many other fields and never really found something that makes me attracted until i read about the IA field of research, it was love at the first sight.

&#x200B;

Anyway, is Data Science related to the Field of IA ? Is some kind of requirement or sub field of the whole AI thing ?

Where should i start ?

Should i get an degree in Math or Statistics ?

Should i Learn R ?

&#x200B;

I really need some guidance.

&#x200B;",Looking for a Starting Point in the Field of Data Science,9cnwhe,new,5,0,0,0
"Hello all, 

First of all, please ignore my lack of knowledge, as I did not have a use case to run AWS before. I am using a powerful desktop at work for work purposes only. For my personal toy projects, where  I plan to work on Data Science and Machine learning - which laptop to get, does that matter?  I am considering  a Thinkpad T480/580 and run a dual boot with linux and I am open to laptop/desktop suggestions to run AWS on my personal system. To summarize:


1. How can I learn more about AWS? 

2. Could you recommend a personal laptop/desktop to buy?


3. Thanks for your patience 

Regards,

Passionate newbie :) 
",Which laptop for AWS (for data science and machine learning),9cnvcb,new,16,1,1,0
"Welcome to this week's 'Entering & Transitioning' thread!

This thread is a weekly sticky post meant for any questions about getting started, studying, or transitioning into the data science field.

This includes questions around learning and transitioning such as:

* **Learning resources** (e.g., books, tutorials, videos)
* **Traditional education** (e.g., schools, degrees, electives)
* **Alternative education** (e.g., online courses, bootcamps)
* **Career questions** (e.g., resumes, applying, career prospects)
* **Elementary questions** (e.g., where to start, what next)

We encourage practicing Data Scientists to visit this thread often and sort by new.

You can find the last thread here:

[https://www.reddit.com/r/datascience/comments/9ajry8/weekly\_entering\_transitioning\_thread\_questions/](https://www.reddit.com/r/datascience/comments/9ajry8/weekly_entering_transitioning_thread_questions/)",Weekly 'Entering & Transitioning' Thread. Questions about getting started and/or progressing towards becoming a Data Scientist go here.,9cni2r,new,59,6,6,0
"Hello my fellow redditors! I am interested in getting a job as a Data Analyst and I want to know which software is the best to know how to use.

And also if anyone has a similar job, can you please define the requirements and responsibilities for this kind of job?

I am familiar with Microsoft Power BI but I think it's not the best software for an analyst to use. ",Interested in acquiring a job as a Data Analyst,9cmix3,new,8,0,0,0
"I'm currently learning Machine Learning and have a very cheap, slow laptop. Yesterday I signed up on FloydHub and ran my first code in the cloud - Very exciting! I only ran a 3-fold validation, but I will soon be training neural nets.

I gained 20 hours free use of a ""Standard CPU"" - an Intel Xenon with two cores. This time is highly likely to be used up quickly and I'm happy with spending a small amount of money to use their service whilst I'm learning.

The question is now, how do I chose between extending my hours on a CPU, or upgrade to using a  Tesla K80 or K100 GPU?

Any help would be appreciated, thanks!",How to compare the Performance of GPU and CPU offered on FloydHub,9cmdv0,new,3,4,4,0
,Can you solve a person detection task in 10 minutes?,9cls93,new,1,1,1,0
,Engineers Vs. Scientists: Who to Hire in Data Now?,9cl8j9,new,7,27,27,0
,Load irregular data into Python Pandas 50x faster: build your own C++ module using the xtensor-python cookiecutter,9cl285,new,2,31,31,0
"I'm looking to do some NLP work in Python but I come form an R background and so don't really know what the go to packages are.

&#x200B;

In R, I'd use tm and quanteda when exploring and processing corpuses of text. I have done a few classification competitions using these packages.

The reason I'm moving into Python is because I want to start to use word embeddings. Any recommendations on what the best Python packages for these types of tasks are would be great.

Thanks",NLP packages for Python?,9cl1ne,new,5,1,1,0
"- [Harvard](https://www.edx.org/professional-certificate/harvardx-data-science): this one is a professional certificate program

- [MIT](https://www.edx.org/micromasters/mitx-statistics-and-data-science): this one is a micromasters program


Which one do you think would be better? Im open to any other recommendation aswell.",Would you recommend MIT's or Harvard's data science program on edX?,9ckzw3,new,29,59,59,0
"Hi, I've done my bachelors in Mathematics, Computer Science and Statistics. Now, my base in math and stats is good but not as much in comp sci. I want to know if I'll have to do some advanced programming or can I manage without? Alternatively I can try learning programming from scratch as well. 

TIA","I'm planning to take up a course in Data Science (Masters), wanted to know how much programming is used in this field",9cjtr6,new,8,0,0,0
For example a data scientist working in a retail firm having to work on both marketing and finance problems such as detecting fraud/anomalies and financial portfolio?,Does a data scientist solves problems across multiple business domains?,9cj7pw,new,2,0,0,0
"What is the policy of this subreddit on resume reviews, I am sorry if it is banned or frowned upon, I won't do it again.

If it is not that serious can someone review my resume. I am looking for data science jobs.

[https://imgur.com/gallery/Wtdpir3](https://imgur.com/gallery/Wtdpir3)",Policy on Resume Review ?,9chuud,new,2,1,1,0
"Data Science News, weekly a aggregation magazine  for data science enthusiasts has released its 3rd issue, you may get it here [https://datasciencenews.herokuapp.com/2018/09/02/issue-3.html](https://datasciencenews.herokuapp.com/2018/09/02/issue-3.html) ",Issue 3 of Data Science News has been released,9chuj9,new,0,3,3,0
"I've been working on a hobby project that initially started as a way to make an SQLite like database, but using plain JSON files. Right now the database part is append-only, but you can index existing JSON files that you already have too by creating a JSON index file (so you'll have `data.json` and `data.index.json`). It currently indexes 1.2 million documents (~680MB) in about 2-3 minutes on a 13"" MBP 2016 (tried with [2008 reddit comments](https://github.com/dewarim/reddit-data-tools), indexing the id, author, score and subreddit fields). It doesn't require specifying a schema or anything and you can index arbitrary fields on structured data. Right now it's just an npm library that you can import and use. Is there interest in something like this, and if so, what interfaces might be helpful (eg. CLI, GUI)?

EDIT:

Example code looks like this:

    const db = new Database('data.json');
    await db.index('id', 'author', 'subreddit', 'score');
    const results = await db.find({ subreddit: 'worldnews' });","Is there interest in a fast, indexed JSON database/querying tool?",9chedi,new,4,7,7,0
"Hi all!

Recently I had the idea to compile a lot of my data science side-project work into a single repository that I hope will serve as a one-stop-shop for both learning about and implementing robust forms of a myriad of data science techniques. 

Even though it is still in its very early stages (just a few weeks old) , I wanted to bring it here for your feedback! If you have any code in Python or R that covers these kind of subjects (or others that are generally viewed as data science staples) please do contribute; otherwise, I welcome all constructive criticism! The repository is located at the link below, and if I might offer a recommendation as to what sub-page to visit first, I'd suggest the vignette I wrote up on logistic regression.

[https://github.com/pmaji/data-science-toolkit](https://github.com/pmaji/data-science-toolkit)

PS — check out [this explanatory blog pertaining to this work as well](https://www.linkedin.com/feed/update/urn:li:activity:6442714148005511169)",key components of the data scientist toolkit?,9cflkk,new,10,23,23,0
"Starting a Data Analyst role in 2 months, but currently have no experience in Data Science. What would your suggested crash course (not an actual course, more of a homemade course) be to become proficient in this position?",New Data Analyst Job,9cfk2l,new,2,0,0,0
,Finding the Best Pokémon Types with PageRank and other Methods,9cd37p,new,6,15,15,0
"Hello,

I am hoping for a thorough critique of my resume to prepare for data scientist roles. A little more about me, I have a degree in Biomedical Science with experience in mainly life science-based data analysis except for my most recent role which is in finance/aviation. I have been programming for about 2 years in python, advanced in SQL and relational databases, and just beginning in R. I am taking the MIT MicroMaster degree in Stats and Data Science as a stepping stone to returning to school and hopefully fill in some missing gaps of knowledge of machine learning and statistics. In my current role I am able to freely use ML and have implemented a random forest and k-means algorithm with real data.

Ultimately, my main goal is to transition from data analysis to data science, although I am able to use DS techniques in my current role my main responsibilities are still data analysis oriented. 

P.S. My dream job is as a data scientist/python developer at NASA (I have been taking courses and reading text on astrophysics/cosmology) so any specifics on anything that would help with that would be great, but is not necessary. 

[Version 1 ](https://i.redd.it/p3utqocqutj11.png)

&#x200B;",Resume Critique: Data Analyst Transition Data Scientist,9cc1fy,new,45,50,50,0
"Hey so currently I'm working on my masters in statistics, however at my school there is a data science certificate which requires the following programming courses, SQL, data mining, an accelerated java course (which really just encompasses java 1 and 2 from undergrad).

​

I'm currently taking the SQL, java, and a stat course this semester however I'm wondering if python will be more useful to me in the long run than java. So essentially I'm contemplating dropping the java course to focus on the 2 courses I have currently and focus on learning python on my own time.

&#x200B;

Edit Thanks for the input guys I'm just going to focus on my statistics courses this semester and take a lighter course load next semester so I can knock out this java course. Thanks for all of the input! ",Java or Python?,9ca48n,new,12,0,0,0
"1. Engage in email extraction

2. Engage in email list management

3. Engage in email data generation using different tools

I have been called for an internship interview at an event organizing company which calls the position a data analysis internship and these are the responsibilities.",Are these responsibilities relevant to Data science?,9ca2ip,new,9,0,0,0
"I'm preparing for an interview at a mid-size company. They have a lot of opinionated customers online- across many websites and blogs. I cant read all of it, i am thinking of copying this content from the various sources and running them through a form of NLP or sentiment analysis technique to discover what're the most popular features and most common pain points. Is anything like this possible? Has anyone done anything similar for reference? I haven't done anything of this sort before, but am comfortable with python/its libraries and can take it on if there is some guidance. Also, [https://cloud.google.com/natural-language/](https://cloud.google.com/natural-language/) seems to only have positive vs negative rating. I cant seem to find out to use it to get commonly addressed points from multiple blobs of text. Help?",Looking for a framework or some guidance on extracting most common customer complaints from blobs of customer reviews from across websites and blogs.,9c9v3c,new,0,0,0,0
"I think data science really interests me, but I also may have the completely wrong idea of the skills necessary.

I graduated with a degree in economics, took stats and econometrics and really enjoyed those classes, thought i was  about an average student. The thing is, even 100 level calculus were always a struggle for me. As far back as high-school i had an uncharacteristically difficult time conceptualizing things in math classes, (though I guess i was also kinda lazy at the time).

Now, a year out of college,  I work in excel for 90% of my work day and I love it. Manipulating data sets and creating conditional data flows/ dashboards is by far my favorite part of my job. I've even started learning a bit of VBA and have learned how to work one of those web scraping plug-ins for a few projects. With that said, I know that I'm still garbageo at good old fashion math and that fact scares me as I think about my future career aspirations in a more data-heavy role.

I have no idea if that day-to-day is more similar to writing the  series of conditional formulas i do in excel, or if its more similar to solving equations in an applied math class (not that I've taken one). I know it can be a broad field, but am I headed in the right direction?",can I be a bad mathematician but a good data scientist?,9c7rj3,new,17,15,15,0
"Ok this may come across a desperate plea and a bit of a rant, but I'll try my best to avoid both of those things!

So I recently graduated with a PhD in astrophysics. I've known for quite some time that I want to leave academia and towards the end of my degree I tried to develop as many transferable data analysis/science skills as possible to hopefully make the transition into data science after. But... despite applying for a tonne of both data science and data analytics roles I've gotten zilch. 

&#x200B;

In my degree I spent most of my time coding in C and python, coded a couple of numerical algorithms for the mathematical side of things to get a lot of my results, and used some regression techniques. I also used some bash scripting and Python packages (numpy, pandas) to clean my data, visualise the results etc etc. 

Other than that, due to the nature of the project I was given (which was a shitshow for many reasons, and I was not allowed to change it despite pointing the flaws out many times to my advisor) I didn't do much else in the way of data science/programming/machine-learning/big-data that many astro PhDs can usually boast about at the end of their degrees. 

Of course, my results and conclusions were enough to churn out a couple of academic articles (the requirement to graduate) and hey, presto! 4 years later: PhD. 

&#x200B;

Now I'm at a loss what to do with my career - I didn't do enough stats and probability to go into analytics, not enough coding to go into software engineering, not enough machine learning to go into data science.

Does anybody have any advice on where to go from here? I'm thinking about doing one of those science 2 data science courses where they take in science PhDs and transform them into data scientists in a matter of weeks. What do you guys think of those? And can anyone suggest a good one?",Astrophysics to data science - best way to do this?,9c6oov,new,7,3,3,0
"I am trying to start a project where I do textual analysis of song lyrics similar to [this project](https://www.johnwmillr.com/trucks-and-beer/). I would also like to later incorporate some type of NLP aspect as well (still planning that out). The artists I am focusing on are a multi-member rap group and I would like to compare each of them on various things like most words spoken per album, least words per song, most common words used, etc.

I plan on getting song lyrics through web-scraping but I am not sure how to organize the data once I have all the lyrics. I am not sure if I should separate their lyrics individually, by song, or by some other factor. Is there an optimal way to store and organize this data?",Data organization for textual analysis of song lyrics,9c67me,new,5,33,33,0
"Hey everyone,

&#x200B;

I'm trying to create a model for building's energy consumption based off of data over only a short time period (4 weeks) for each building, an example of what I'm working with can be seen [here](https://imgur.com/a/b6aCwOE). I'm looking into using an LSTM model but I'd like to try and incorporate some of the behaviors that are often present such as reduced consumption on weekends, common patterns over the course of the day etc. probably the most distinct feature is that there are often different consumption 'regimes', for example in the graph linked above there appears to be three different consumption regions which the building works around. 

&#x200B;

I'm planning on trying to do some feature extraction to work out which days the buildings are working and also look into deriving average consumption patterns over the course of a day before feeding them into the LSTM model, adjusting for the daily pattern and running separate models for working days/non-working days. The bit I'm struggling to wrap my head around is how I can work out what 'regime' the building is operating at for any particular time, any suggestions on how I could best do this or generally improve my approach to this problem would be greatly appreciated :)",Techniques for forecasting time series data with different regimes,9c4yt1,new,1,2,2,0
"I am trying to find a way to detect - with relatively few false positives - anomalies on incoming basket items from online sales based on the core features of a basket item (quantity sold, revenue). For example, if someone buys 2 water bottles of brand 'X' for 5$ each then my observation is ( quantity=2, revenue=10 ). The [isolation-based approach](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/tkdd11.pdf) caught my attention and i am curious if it is a path worth exploring.

I would thrilled to know if someone has worked with isolation-based models before and what is his take of the process. In general, i would like to discuss about the model's characteristics, assumptions etc.

\*edit: a typo",Isolation Forests method for detecting anomalies on bivariate data,9c2gks,new,3,3,3,0
,Centralized Government vs. Yet Bigger Data,9c25s9,new,1,3,3,0
"Here is a new masters program offered by Hong Kon University:

https://saasweb.hku.hk/programme/mdasc-index.php

What do people think of it? Does it seem solid? Considering applying there vs UK based masters in machine learning with no clear end goal right now. I have interests in self driving cars, medical imaging and as well as general data science jobs for medium to large sized corporations.

I am UK citizen but the idea of living abroad is appealing :)",Opinions on HKU Masters?,9c228l,new,0,0,0,0
"Please share your success stories at work for modelling related projects. Please share some background. (doesn't have to be complex ml problem but create good business value.) 

I'm hoping this might help brainstorm project ideas. ",Machine Learning successes at work,9c04de,new,34,69,69,0
"Hey all, PhD student in an engineering field here. I would like to get into data science, and I have plans to take on a data-heavy project while taking courses in statistics, data science, and CS. So long as I satisfy the course requirements, I can back out with a master's in about a year. If my end goal is to continue with a career in data science, is a PhD necessary? Would it be beneficial towards advancing my career?",Is a PhD necessary or even beneficial?,9bx7vn,new,22,19,19,0
"I'm pretty new to data analytics. I've spent the last few months studying fundamentals like working with Excel, writing SQL and Python, but my question is: When do I decide to to take my data to another program, and why?

Why exactly do we not ***only*** use SQL or ***only*** use Pandas, or an Excel spreadsheet?","Excel, SQL, Pandas.... What's The Difference?",9bwur2,new,7,0,0,0
,IBM's Watson problem: Is machine learning over-sold as a cure for all problems?,9bwl75,new,8,4,4,0
I currently follow https://www.healthcareitnews.com/ to read about use of data analytics in healthcare.I am interested in learning more about uses of big data in the field of genetics or genomics.Any recommendations ?,Daily or Weekly news source for use cases of data science in genetics,9bvjcl,new,0,3,3,0
"I'm trying to figure out the best way to create a workspace that can move with me.  At work we have many different machines that all have slightly different architectures and data.  What often happens is that someone is consuming all the resources on that box.  

&#x200B;

Just yesterday all 10 GPUs on the box I have all my work on were being used so I couldn't train anything.  Other boxes had free resources but in order to work on a free machine I would need to move all my data, create new branches in all the repo's I work on for my temporary scripts and reset up everything on the other machine.  


Maybe what I described is not that challenging to do, but it seems really cumbersome and requires a lot of bookkeeping.  For those of you who have a similar situation, do you use Docker for this type of problem, something else or just do what I described above?",Docker for environment mobility?,9bvfjd,new,4,1,1,0
"Learn about our Holistics Embedded Analytics feature, which allows our customers to embed their Holistics dashboards into their own applications or web services, using secured iframes (akin to embedding a YouTube video). 

Topic: Embedded Analytics
Date: 4th September 
Time: 4pm (Pacific Time) 
Registration link: http://r.holistics.io/REA

For more information, you can visit here: https://www.holistics.io/blog/webinar-embed/ 

If you can't join us for the webinar, we will still send you free materials for you to look through when you register!",My company [Holistics.io] is having a free webinar on Embedded Analytics!,9bve31,new,0,0,0,0
"Hello folks, I'm senior electrical engineering student. I have only a month left before flying to Poland for internship as research assistant. According to the work description, could you please give me some clear idea of what I should expect to be doing. The work description is very unclear for me. Especially, the term '**Digital data processing and Knowledge extraction'**, I got confused whether they have to do with DSP or more toward datascientist field. Therefore, I can spend my last month to study just one or two things that's actually related to my work.

​

What I've been doing so far were:

* Spent whole summer taking computer vision course and playing with pytorch (not relavant to my work by anymean, just my hobby)
* Coding mostly with python, I can read and code pretty decently. I can do a bit data processing which I've learn from the CS231n course.
* I'm studying DSP, mainly filtering technique (not sure if it's will be apllicable regarding to my work though)

What I'm planning to do:

* Playing with Rasberry Pi and Arduino, probably a crash course because I won't have that much time to build a project for sure.
* Learn Labview and Matlab again. Perhaps just MATLAB, and learn their signal processing and data analytic toolbox.
* Study kalman filter technique and hopefully will be able to code it.
* And yeah there should be the room to fit in specific topic prior to the work.

[Sorry for a blurry image](https://i.redd.it/tiazuodv7gj11.jpg)

Thanks you in advance folks.

​",Is my internship relevant to datascientist field ? If so please give me some insight. (Work detail attached),9buq16,new,3,0,0,0
"UPDATE: The group is complete. Thank you for all those who responded. I apologize if I did not get a chance to respond to you.


Any individuals who are currently and actively working on their personal projects specifically in python interested in forming a small group (~5) for a virtual meetup on a regular basis where we can share and discuss our projects and receive constructive feedback? It doesn't matter whether your focus right now is on EDA and visualization or incorporating a predictive model. Ideally someone who is already comfortable with the python basics and familiar with the common libraries. Some understanding of machine learning would be great! I'm hoping this will not only build our programming skills, but also our analytical thinking, storytelling, and our ability to speak about our code and projects during an interview.  

If you're a python pro or data science expert and would like to join as a mentor, that would be great!  

FYI, I have been learning python and data science concepts for about a year now, on and off, and I consider myself closer to an intermediate level when it comes to python.",Small Group for Learning,9bu3lm,new,8,7,7,0
"Hi all. I am an Assistant Professor in a Statistics Department. I am planning to organize an event like [ASA Datafest](http://ww2.amstat.org/education/datafest/) by the end of October and I need to find a dataset to be analyzed by the students.

I know lots of open data sources on internet (Kaggle, UCI Machine Learning Repository, data.gov and so on), but I am afraid that if I get a dataset from these sources, the students will be able do look for analyses made by other people and simply copy them.

Where can I find lesser known datasets to use in my competition? Does anyone have an idea?
",I need a dataset for a data science competition,9bsmlu,new,6,6,6,0
,Mathematics for Machine Learning,9bsdcu,new,34,212,212,0
"Hello all,

I’m trying to think of the best way of vizualising a nonlinear funnel e.g. a customer can signup and convert without necessarily going through other steps in the process and struggling to come up with a vizualisation that conveys nonlinearity.

I’d prefer this to be in Tableau for interactivity but I’m open to other suggestions, thanks!",How to best vizualise a nonlinear funnel?,9br3rb,new,1,2,2,0
Is it mandatory to use Jupyter notebooks in Data science? I don't like Jupyter notebooks and I'm wondering if it's possible to avoid them. I just don't get what the heck is going on with them. ,Jupyter notebooks,9bordk,new,14,2,2,0
"Hey folks,

Question for the python data science folks.

I'm trying to calculate image gradients using a sobel edge filter for ~800 pictures using the estimate_watermark here: https://github.com/rohitrango/automatic-watermark-detection/blob/master/src/estimate_watermark.py. 

The program runs down to line 34, then (in Jupyter -- broke this out block by blow), kernel dies due to memory issues. I've tried to replace the map(lambda x...) with a list comprehension but still no dice. Images are around 710kb each, and I'd rather not resize and lose resolution. As I understand it, list comps act like generator functions, so I'm not sure if further work there will help.

How might I go about doing this?

",Memory Errors in Batch Image Processing (using OpenCV Sobel Filter),9bno7p,new,3,3,3,0
"Hi all,

After a probationary period I lost my DS job at a startup. They realized they needed more software engineering (not my specialty) and less data analysis (more my specialty). They also weren't all about sales/marketing enablement yet, also a strength. A lot needed to be built. This was a new team and we were pretty much split between software and analysis but then it reached a point where I couldn't keep up with the new direction so that was the end of it. That and a ton of office politics that was poorly timed and took everyone by surprise. That said I loved my work on the analysis side, which included ML, and want to continue. Whether it's DS or a glorified data analyst title, that's what I'm going for.

However, all of my DS work was at this company and I have no portfolio. I lost it all in the sudden separation (not that I could share company work anyway so it's moot). Now I'm not sure how to get hired again without a portfolio. It was nearly impossible the first time. So I've decided to spend a month working on building one up based on all I've learned. Then I'll apply and keep building. As a recent job searcher, I really need a break to focus. However, what do I do about LinkedIn? On a paper resume I can highlight projects but my LinkedIn will just appear as if I have nothing going on. I hesitate to say self-employed because I'm not making myself money through the projects. Is there anything I can reasonably replace my position with to show I'm working productively with my time?

TLDR: Between work, taking a break to work on portfolio, how to show productive work on LinkedIn.

Thanks!

Edit: I will try to reply tomorrow but thank you for the responses so far. I appreciate the advice and it has helped me to frame how I will proceed. Thank you all :)

Also, strength in Business Intelligence, rather than engineering, is what I'm going for. I couldn't think of the word earlier.",Separated from DS job and taking a month off to make portfolio. What to do about LinkedIn?,9bnkyb,new,24,38,38,0
"I'm not sure if I phrased that question correctly or if this is the even the right place to ask, but I'm currently at a loss. For some background, I'm a mobile developer with no real experience in data science, but I'm interested in learning, so I decided to start a side project.

To clarify the question, if I know that weekly, on average, a person watches 21 hours of TV, 25-year-olds watch 20 hours, females watch 23 hours, and white people watch 18 hours. How can I calculate how much television a white, 25-year-old female watches? Is that even possible?

My current thinking is that I find the proportion of each category, compared to the total average ( 20/21, 23/21, 18/21 ), then multiply them all together ( \~.89 ), and finally multiply that by the total average, giving me a value of \~18.78 hours.

Is that right? Or am I completely off-base and making a mockery of statistics?",How do I combine different groupings of the same data?,9bmabz,new,6,2,2,0
"I'm a beginner in data science. I don't have a strong understanding of software architecture or CS in general. I do know how to implement machine learning in python. 

I'm curious if anyone has a link or can recommend a source that shows what a machine learning computational platform looks and works like. All I know how to do right now is bring in data to python, parse the data, apply an algorithm on a training set, apply to test set, evaluate performance, but I figure an actual ML software is much more complex.",Example of ML Implementation,9bke06,new,1,3,3,0
"I've been using R to try and clean up user inputted Addresses.  I've tried regex edits, but there's too many different spellings. I've done geocoding with Google, but it has a 2500 limit per day. I've used the Openmaps API as well, but it doesn't handle the address spellings well. Is there any packages or sites that

&#x200B;

&#x200B;

I'd like to have a mapping of the user input and the corrected address. Once I have the initial list and additional addresses are added, it will check to see if it exists in the listing and if not will run the validation script. Once I have the clean addresses, I'll do geocoding and use distance as a metric for my predictive model.",Best way to clean up user input Addresses?,9bjyog,new,8,1,1,0
"Hi guys,

I'm trying to build a relatively simple recommendation system of sorts for shopping/grocery transactional data, with two use cases:

1. Given a customer has x items in their shopping basket, I want to recommend y items based on their current basket
2. Given one item, I want to see related or recommended items

 A Market Basket Analysis approach seems sensible, to which I've used R and the accompanying packages arules and arulesViz for the visualisation. My problem is, how do I approach building the actual recommendation system? I can use the Apriori algorithm to generate some 'rules', e.g. {butter, milk} => {bread}, based on the parameters support, confidence and lift, but how would I actually *build* a model/algorithm that could recommend items based on a shopping basket I have? What extra steps do I need to take? Or does anyone know of any articles/tutorials that would be easy to follow?

&#x200B;

Cheers!",Market Basket Analysis - Recommendation system,9bjygb,new,4,2,2,0
"(I don't know how to get flair but I am a PhD Economist, Professor in a Business School, and extensive R user for over 10 years)

I have been tasked with designing a plan for a Data Science/Analytics focused major within a business school.  I realize the consensus on this sub seems to be to do CS/Stats as an undergrad major, but we have a large demand for a data focused major (Data Science/Data Analytics) major within the business school and that is the task I have been given.

I have collected a lot of information from other BS, BA, BBA programs, but I want to get some input from practitioners. Where else do you find experts who are passionate about a subject but Reddit?

(If this is against the rules please let me know and I will try to gather information other places.)

Any feedback you can give me will be helpful, however we have a great deal of flexibility in terms of designing new courses or using courses from across our campus so what I would like to hear from those of you out there in the trenches is what topics and or skills you think a freshly minted business major looking for a job in Data Science should have.

\*A little background that may focus the conversation:\*To avoid ""overfitting"" or producing a ""flash in the pan"" major we are creating the program as a track within our existing BS in Economics (not a BBA). So you can assume they will have covered: Calculus 1, basic probability, mathematical calculus based Micro and Macro Theory, introductory applied Econometrics (OLS, Logit, Probit with R). Also we project that \~50% of the students will also be double majors with CS, Math, Stats or Finance.

​

Let me provide a template that you should feel free to completely ignore :)

**Your background:**

Examples: Currently learning, Working as Data Scientist, Hirer of Data Scientist, Trainer, Professor etc... If it is in your flair then skip this one.

​

**Conceptual Topics that MUST be covered:**

Topics and techniques that everyone doing Data Science in a business setting should have. Possible examples:  Regression, Machine Learning?

​

**Conceptual Topics that WOULD BE NICE  to cover:**

Topics and techniques that would be nice to see, but are not deal breakers. Possible Examples: Linear Algebra, Hierarchical Models, Bayesian MLE, Frequentists MLS, Non-Parametic Estimation, Distributed Systems, MCMC?

​

**Practical Skills that MUST be covered**:Skills and tools that everyone doing Data Science in a business setting should have. Possible examples: R or Python/Pandas, Data Mining/Cleaning, SQL?

​

**Practical Skills that WOULD BE NICE  to cover:**

Skills and tools that would be nice to see but are not deal breakers. Possible examples: Hadoop, Spark, Matlab/NumPy?

​

**What would the ideal internship look like?**

We will be requiring internships and we want them to provide real signaling to potential employers.

​

Thanks to anyone who responds to these questions or with any other information or links.

\[Edit: Reformatted after Reddit ate the original formatting\]",Crowdsourcing a University Major: What topics and skills should be covered in a Business Data Science Major,9bjfbu,new,45,48,48,0
"Hi!

I have an NLP problem where I gather loads of emails and classify them based on the written text. A not insignificant number of the emails have a confidentiality notice which I want to remove. I am not sure how because they are not written in the same way. 

The confidentiality notice is in English, while some (not all) of the emails with confidentiality notices are written in Norwegian. 

I am writing in Python using SciKit.

&#x200B;

Any input appreciated!",Removing confidentiality notices from emails,9bidpe,new,14,1,1,0
"I am currently performing text corpus classification using MultinomialNB Classifier and it works well to predict the main category. Now I want to make predictions on which sub category within the main category predicted, does the it belong to. Are there any meyhods to do this? Googling didn't help me much as I'm still a novice. A little guidance from the community would really help me progress in my works.  
Thanks!",Predicting subcategories along with a category while performing text classification,9bhytt,new,5,2,2,0
"Hello

I found a lot of courses online to learn Python. I am interested to learn but not sure which one to choose. I have experience with SQL and bit of R but Python is completely new to me.

Should I take courses with track (like Data Camp Python track) or buy one course (like Python course from Udemy)?

Many thanks in advance.",Questions regarding on Python courses,9bfs6l,new,2,2,2,0
,Python Pandas: Tricks & Features You May Not Know,9bf3qx,new,9,111,111,0
"I'm pursuing the IBM Professional Data Science Certificate on Coursera right now. It has a pretty extensive curriculum on data science as a whole.

Will employers take this seriously on my resume? I don't have a formal degree in anything.

My plan is to become a beast at Stats, Linear algebra concepts, and ml algorithms on my own as well while trying to create a portfolio of projects.

What obstacles will I face and how can I best apply myself once I finish this certificate to land a job? 

Also for background info , I'm coming from the film/TV world.",IBM Professional Data Science Certificate career outlook?,9bewah,new,4,1,1,0
"I am trying to understand better how it works in regards to machine learning.  One thing I am not sure about is if it takes into account when a feature in presence of another feature makes both of them both much more likely.

Example:A basketball player that's tall and large.  If I were trying to predict whether or not a player would be successful I could have in my list of features one for height and one for weight.

Does this automatically take into consideration things like when someone is tall and large they are much more likely to success then tall and thin.  Also when they are short and thin they are much more likely to succeed then if they were short and large.  And to add to that, as each of these are higher, it seems like it would be non-linear in change.",Does Logistic Regression deal with compounding features?,9benxl,new,5,0,0,0
"Hey All!

So I am working on dashboard at work. I have today's sales and yesterday's sales, then I have a metric that shows the difference between today's and yesterday's sales at whatever time I check the dashboard. I set the difference between the two(%) to be red when it is negative and green when it is positive. I want to set a yellow color as well, where it is close to 0% on either side (either positive or negative), but want to avoid using a hard % range (3% more or less on either side of the zero). A friend suggested using standard deviation, but I don't have a clue how to set that up and whether it would be usable.

​

Can anyone shed any light on this or can guide me? It would be very appreciated. Thanks so much!",Standard Deviation and Yellow Caution Range,9bedov,new,2,2,2,0
I'm about to start a project for an open dataset using public data. Where can I find some specific articles for reference? Thanks in advance.,Does anyone know where do I find specific data science articles for study?,9bdvtz,new,3,1,1,0
,Webinar on how online retailer (Rue La La) built their recommendation engine using machine learning models,9bdrrp,new,0,0,0,0
"I'm an undergrad student doing a research project on Datawatch, and it would really help me to know if y'all think it's good or bad. 

&#x200B;

I'd appreciate any insight you could give. Or if you could participate in this poll I'd really appreciate it:

[https://www.strawpoll.me/16362195](https://www.strawpoll.me/16362195)",Has anyone used Datawatch?,9bdbts,new,0,0,0,0
"I'm trying to determine the mean hour of the day when users perform actions, but realise that simply calculating the mean can produce completely inaccurate results. e.g. If a user's actions are normally distributed around 00:00 then the mean is 12:00. Are there any established techniques for analysing data like this? There would be similar problems working with any times/dates.",Accurately determining the mean hour of day / day of week / month of year,9bd5ci,new,11,3,3,0
"I have some big, slow, overly complicated databases I want to move over to SAS, and I doubt the best solution is to rewrite them all.",Are there any tools that will convert SQL queries from Microsoft Access to SQL readable by SAS?,9bcob9,new,1,0,0,0
,I think this is a very important topic that could use some more definitive answers,9bcms8,new,1,1,1,0
,Data Science Competition to Solve the Cold-Start Problem with Energy Timeseries,9bc5tm,new,0,8,8,0
"Hey guys, I am thinking about doing  analysis (just a idea, no specific plan yet) on how music affects culture by utilizing Spotify api, but the problem is that Spotify can only provide attributes of the music and I need more attributes about culture, so my question is that are there any other data source I can look into to do this project? free feel to comment ",How music affects culture with data science ?,9ba96l,new,8,4,4,0
"I'm currently developing a model and I'm facing a huge roadblock. Basically, most variables fit the predictive variable ""y"" very well when I log(y). However, there are some variables that fit better when I leave ""y"" as it is. The question is how do I integrate all of these variables together into one model? Would this be done through stacking, where one model uses ""y"" as the dependent variable and the other uses log(y)?

&#x200B;

EDIT: This model is being used to predict home sale prices (""y"") based off of home characteristics (such as lot size, number of rooms etc.) What I mean by fit is that when plotting variables against ""y"", they will behave exponential in nature, so I need to log(y) so they behave linearly.",Question Regarding Data Transformation & Model Development,9ba8xp,new,28,1,1,0
,Looking to get into data science? Here is an interesting project to put on the resume (python or JavaScript skills required),9ba6da,new,25,107,107,0
"I need to simulate consumption data for a fridge using data in the type of that in the graph (ON periods of the pattern shown with variable levels of consumption, followed by OFF periods of variable lengths).

https://i.redd.it/au7i9n5161j11.png

​

I thought of using seasonal ARIMA to forecast the next values  but, due to the way fridges are used irregularly, I could find no way to model the seasonality of the on/off transition. Is there a way to do this?

I've also considered using an LSTM NN to predict the future timeseries but it really seems like overkill.

​

Do these seem like sensible ways of simulating the data? If so, what are the advantages of doing it this way? Are there any other ways of doing it that might be simpler or more reliable?

Thanks.",Simulating Fridge Consumption Data,9b9292,new,0,1,1,0
"I want to cut a block of text into chunks of 100 words, and then identify the topics of each chunk.

The problem is that every article i can find teaches you how to train a model. I don't want to do this. I want to use a ready built model, much like nltk sentiment analysis. I'm hoping there is an quaker nltk topic analysis but i can't find it. 

Any thoughts on a module in python i could use? Thanks",Topic analysis model for python,9b8rcu,new,10,1,1,0
 Is it possible to import models to Spark from PMMLs using PySpark/Scala or SparkR? I know this is possible using Java ([JPMML](https://github.com/jpmml/jpmml-evaluator-spark)). But I did not find any reference documentation in PySpark/scala. ,How to import PMML model into spark using pyspark or scala or sparkR?,9b5d7t,new,0,2,2,0
"Hi all, working through my first neural network side project. I'm trying to predict which P2P borrowers will default/charge off a loan. 

In the first iteration, I used only my own investment data to create a binary classification of those who paid back their loans (0) and those who defaulted (1). The problem lies in the ratio of available data: 99% of people paid, and 1% defaulted. So the NN has learned to predict that 100% of people will pay their loans and can still report 99% accuracy.

I found a much bigger data set (about 850k items vs. my original 4k) with the hope that throwing more data at the model might help. Unfortunately, the overall ratio is the same: 99% paid and 1% defaulted. This results in the same inaccurate prediction.

So experts, can you share any advice on how to approach this kind of problem? I was wondering if it's a logical approach to alter the ratio of the training set, i.e. use less of the data overall so that 1% becomes 25%. Alternatively, I am only using 2 features in the initial NN. Could adding more complexity with additional features improve the accuracy?

Edit: I’ve learned a lot from everyone’s responses on how to solve this problem and about some entirely different methods to research. Thanks a lot to everyone for taking the time to help me out!","My neural network is 99% accurate, and 100% useless",9b581v,new,74,126,126,0
,My first analytics project - Customer churn,9b3z9x,new,4,6,6,0
"What's going on DS sub?

I'm currently working as a data scientist in the (electric) utility space, thinking about making an industry move.  

Edit: for those asking, our company has a few teams that are doing what could largely be considered DS. That said, I'll talk about what I'm doing specifically. We have electric meters which send us information at the 15 minute level, as well as instantaneous (snapshot) readings. I'm primarily focused on anomaly detection, as there are a ton of ways a meter could fail/degrade in performance. In addition to that, I also look for people tampering with meters/stealing electricity. ",Data Scientists in insurance or retail...what's your day-to-day like? What sorts of problems are you working on?,9b3ah0,new,28,24,24,0
"So I've revisited this a few times and googled it a lot, but can't seem to find a proper answer and the guys are stack can be meanie's whereas you guys are generally nicer. My problem is about email sends, I'm trying to work out if there is statistical significance between the open rates. So for examples if I have:

Delivered emails (A) = 10,000

Opened emails (A) = 100

Delivered emails (B) = 12,000

Opened emails (A) = 130

&#x200B;

How can I work out if there is a significant difference and it isn't down to chance? 

&#x200B;

Alot of the tutorials want to include the sdev but because it is purely opened vs not opened there is no variation. If I use these points as a pseudomean and create a random distribution around it then surely the results will be affected by what I choose the var to be therefore not making it a fair test",calculating signficance levels for a boolean problem,9b2qya,new,5,1,1,0
,Data Structures and Algorithms for Data Scientist Interview,9b159t,new,1,2,2,0
"Hi,

I am looking to do an A/B test where I have a sample size for each group, a conversion rate for 1 group, and I am trying to determine what is the minimum lift necessary to make the results statistically significant.

​

This is the function:

power.prop.test(

n= 6289195,

p1=0.004,

power=0.8,

sig.level=0.05,

tol=.Machine$double.eps\^.8)

​

For power, is the industry standard 0.8 or should I use a different number to find p2?

​

This is my result:

Two-sample comparison of proportions power calculation

​

n = 6289195

p1 = 0.004

p2 = 0.004100341

sig.level = 0.05

power = 0.8

alternative = two.sided

​

NOTE: n is number in \*each\* group

​

If I change it to 0.9, it changes the answer which is why I am asking:

Two-sample comparison of proportions power calculation

​

n = 6289195

p1 = 0.004

p2 = 0.00411621

sig.level = 0.05

power = 0.9

alternative = two.sided

​

NOTE: n is number in \*each\* group

​

​",What is the industry standard for power in the power.prop.test function in R?,9b121c,new,0,0,0,0
"I'm fairly new to using statsmodels ols library for regression predictions.  My question (stated simply) is, do I need to make an effort to remove superfluous data that does not have a strong correlation between it and the responding variable?  Or does statsmodels.ols automatically assign appropriate weight to data series -- based on strength of correlation (thereby eliminating the need to manually weed out week correlation data sets)?",Statsmodels OLS Multi-Variable Regression Question,9b0r18,new,6,2,2,0
"Hi,

I'm taking a Udemy course on how to program in Python with an emphasis on data science.  It's a real good course, but there isn't enough homework/exercises though.  Does anyone have any suggestions on where i might get some (with an emphasis on data science) edit: that would also include solutions as well? Thanks!","Taking courses on Udemy for programming in python for data science, not enough exercises/homework question though. Suggestions?",9b06xt,new,14,4,4,0
"Hi, 

For a while now, im looking for a decent app (android) where i can collect data for day to day nerd stuff... Im looking for something where i can keep track of multiple things in separate projects/maps/sheets. 

I like to gather stats about all the things i do or drink or whatever comes to mind. Any good suggestion?  I prefer free or something i cnab ise with my student card or something. 

Thnx! ",Good Data Collection app,9aytl6,new,5,1,1,0
"Trying to search for a MOOC focused on Python data wrangling and I'm completely overwhelmed. I did find a Python data wrangling book, but it doesn't have the best ratings on amazon. Any help is appreciated.",Sources for Python Data Wrangling,9aydcr,new,3,2,2,0
"I'm thinking about collecting daily scrapes of information from the web and am wondering how many folks in this sub do something similar already. As for tools, am thinking about using a cron job with mongodb.","Are you actively/passively collecting data off the web, right now?",9ayd3w,new,16,0,0,0
,Time traveling with graph databases,9ay6lo,new,0,1,1,0
"Hey hope it’s the right place to post this. Due to my SO I’m considering a move to Finland from the UK. I’m due to finish my MSc in data analytics in December. I have a BSc in physics and worked in web development until I started postgrad studies. 

Does anyone know about what the job market for data science jobs is like there? Is it possible for an English speaker (Finnish is very basic around A2 level) to find decent jobs there? 

Thanks! ",Data science jobs in Finland,9axkt7,new,9,23,23,0
"  

I had posted this question in Cross Validated but did not get any help. I hope to get some help here!

In the course of learning machine learning, I understand that bootstrapping is considered a powerful approach for adjusting for overfitting in measures of predictive ability of a model. Based on information I have gathered, I have tried the following approach for my work (logistic regression to predict binary outcome with 50 predictor variables),

1. Fit the model to full original data

2. Feature selection with backward stepwise algorithm with 100 bootstraps.

(and select the variables that are chosen most frequently)

3. Repeat the following 1000 times;

a. Generate bootstrapped data 

b. Split the bootstrapped data into training (70% data) and test (30% data) sets

c. Fit the selected model (from step 2) to training data

d. Test the fitted model with test data

e. Calculate Area Under Receiver Operating Curve (AUROC)

4. Report average AUROC with 95% Confidence Interval.

&#x200B;

First, I would appreciate if someone could comment on whether there is any problem in the approach. 

Second, do I understand right that I am basically evaluating the selected variables for their predictive ability, but not the model itself. Because during each iteration, the model is fit with different data and thus the model will be different each time with different estimated coefficients. So, can we really say that we are evaluating the model?

I will be very thankful for anyone who could help me out with this confusion!

Best wishes,",Prediction model validation using bootstrapping,9axg8f,new,10,3,3,0
"Hi all,

Last year I started a DS course at my school beside my regular software engineering course where I learn mainly Java and C#. I still need to learn a lot. I practiced with ML and I did use python libraries like sklearn, pandas, numpy etc. Right now I am a trainee at a company that focuses on collecting data from trucks and trailers by using API's or a units they created and installed inside the trucks/trailers. They sell the data to customers by creating custom dashboards.

My assignment is to apply DS with an idea of my own. The goal is to create an informative graph or target that can be included in the dashboard.

I practiced with ML classification models like svm or rf but not that much with models used for regression.  I am planning to predict the fuel usage of a planned trip. Features I can get my hands on are for example distance, altitude, weather conditions, fuel consumption, weight of the truck etc. I am doing some research on models that could be appropriate to fulfill the job.   


I have three questions:

\- Can fuel usage prediction be done and is predicting the fuel usage a realistic assignment for a beginner ?

\- What models are suitable for the job and what is your experience with them? After some research I find out that examples of suitable models are regression tree, random forest, boosted tree or support vector regression

\- I am looking for an idea to do something with the coordinates of vehicles, any interesting ideas?

&#x200B;

Thanks a lot

&#x200B;

&#x200B;",Need help with my internship - transport sector predicting fuel usage,9awxk8,new,4,10,10,0
"I'm looking for data to answer the above question, perhaps some census data based around college degree or business major classifications. I'm primarily looking for a downloadable table or .csv file to work with in R Studio or STATA. Thanks for the help!",Searching for data to answer the question: How much do business majors make per year on average?,9avat2,new,3,0,0,0
"# ShinyR Knowledge Repo
## The **shinyR** curated knowledge sharing platform

I thought I would introduce a new shiny application I have been working on that acts as a knowledge repository, displaying your `Markdown` and `RMarkdown` files listed under the directory. It can even run `python` chunks embedded in `Rmarkdown` files.

##### Links
- Demo: [ShinyR Shinyapps.io](https://jessevent.shinyapps.io/knowledge-repo/)
- GitHub: [ShinyR GitHub](https://github.com/JesseVent/shinyr-knowledge-repo)

Let me know what you think

### Introduction
Built in R with use of the [Shiny](https://github.com/rstudio/shiny) package, this application will list any `RMarkdown.Rmd` or `Markdown.md` that sit under the specified/default directory no matter how many folders there are underneath. By listing all these files you get a true sense of the knowledge collective available to you, and by clicking any of the files listed it will dynamically load the content in a new tab for your viewing pleasure.

Through the reticulate package it can even run embedded python chunks inside `RMarkdown.Rmd` files.

### The Key Principles
-   **Reproducibility** There should be no opportunity for code forks. The entire set of queries, transforms, visualizations, and write-up should be contained in each contribution and be up to date with the results.
-   **Quality** No piece of research should be shared without being reviewed for correctness and precision.
-   **Consumability** The results should be understandable to readers besides the author. Aesthetics should be consistent and on brand across research.
-   **Discoverability** Anyone should be able to find, navigate, and stay up to date on the existing set of work on a topic.
-   **Learning** In line with reproducibility, other researchers should be able to expand their abilities with tools and techniques from others’ work.

### Inspiration
This application is loosely inspired from a mix of the principles of [Airbnb's Knowledge Repo](https://github.com/airbnb/knowledge-repo) and the user interface from [GetGrav's Learn2](https://github.com/getgrav/grav-theme-learn2) with my own spin on my thought's about what a knowledge repo should be, combined with some functionality that **Shiny** brings together so well.

> The Knowledge Repo project is focused on facilitating the sharing of knowledge between data scientists and other technical roles using data formats and tools that make sense in these professions. It provides various data stores (and utilities to manage them) for ""knowledge posts"", with a particular focus on notebooks (R Markdown and Jupyter / IPython Notebook) to better promote reproducible research. [Airbnbs Description](https://github.com/airbnb/knowledge-repo)

### Next Steps
This application is still in it's infancy, but the next major change I want to make is to allow the application to be given a Gitlab project, and allow you to view all the markdown files that sit in sub-projects beneath it.

Happy for any other feedback or thoughts.",Introducing ShinyR Knowledge Repo,9att69,new,0,28,28,0
"Hello,

very newbie here so, hopefully, I am in the right place.

Starting from the spotify charts, I created a dataset including data from the audio features and music genres.

I have music genres stored in a column as a Json. For instance:

|Track Name|Artist|Genres|Date|Streams|
|:-|:-|:-|:-|:-|
|Rockabye (feat. Sean Paul & Anne-Marie)|Clean Bandit|\['dance pop', 'edm', 'pop', 'post-teen pop', 'tropical house', 'uk funky'\]|2017-01-01|71014|

As I would like to do some calculations such as:

* Total number of streams per genre
* Most popular genres in terms of streaming per day
* etc...

what is the best way to deal with the genres in pandas/python? Should I split them in multiple colums (There are a lot of them) or there is a simpler way to do in in panda? Is is possible to do a groupby of values nested inside an array?","Best way to work with multiple categories in an array [Pandas, Python]",9at1vl,new,6,13,13,0
"So I am learning statistics and python from theis book called ThinkStats.It has instructions on how to download the code and solve the exercises. I did everything that was told but am still not able to run the code on jupyter notebook. I am not sure what I am missing.Can someone please help me? here is a list of instructions in the book and the things I did till now.

""After you clone the repository or unzip the zip file, you should have a folder called ThinkStats2/code with a file called nsfg.py.  If you run nsfg.py, it should read a data file, run some tests, and print a message like, “All tests passed.” If you get import errors, it probably means there are packages you need to install""

Till now I downloaded the zip file, unzipped it and got the file named nsfg.py.I opened the file in jupyter notebook, but I am getting an error called"" cannot find module thinkstats2"".This module is specific to the book and from what I understand, the module is in the Thinkstats2 directory.How do I make jupyter notebbok run the file in the ThinkStats 2 directory?",Need Help with running exercises from ThinkStats ( by Allen Downey) on Jupyter Notebook,9asbbe,new,6,4,4,0
[https://www.bouvet.no/bouvet-deler/roles-in-a-data-science-project](https://www.bouvet.no/bouvet-deler/roles-in-a-data-science-project),"Wrote a blog about the roles a Data Science team needs. Pretty obvious stuff, but often overlooked in my experience...",9asavt,new,2,5,5,0
,Using Homomorphic Encryption In Production With Enveil (Interview),9as00v,new,0,2,2,0
"Hi all,

I was admitted as a TDI scholar this Spring with no programming/ML experience. My academic background is a (nearly complete) PhD in Clinical Psychology, but I have always been more interested in research/data analysis than clinical work and recently realized that a career in Data Science could be a good match for me. While I am definitely excited about the opportunity to do the TDI bootcamp, I am hesitant to enroll given my lack of  training in this area and am not convinced I am at the level that I need to be in order to understand the more advanced material and successfully complete the weekly assignments.

After I realized knowing Python was essential to being a TDI scholar/fellow (1 week into the program), I deferred my enrollment and have been learning Python/pandas/data wrangling daily for about 2 months. Now I have to make a final decision to re-enroll or take the partial tuition refund.

Does anyone have experience with TDI , specifically insight about my ability to be successful in this bootcamp given my non-technical, social science background?  Is this program a good fit for me or should I keep learning on my own at my own pace?

Also, I'm wondering what the ballpark job placement rate is for TDI scholars/fellows (especially those w/o preexisting, extensive programming/CompSci skills)? The networking/job placement services were another bonus that attracted me to TDI.",The Data Incubator: Re-enroll as a Scholar to take the Partial Refund?,9ardo5,new,1,3,3,0
"At production level, is it actually necessary to write your own code (your own architecture) for deep learning algorithms. I am still a beginner and have tried using Google APIs for certain small projects. In a commercial setting,  would one work on their own neural networks even if one is already available in the form of an API 

1. In what cases would you write your own code  ? (I am aware of the fact that Google will charge you and it can be expensive in case there's a large amount of data that you're dealing with) 
2. Would you achieve higher speeds by developing your own NN (when dealing with large data-sets or data pipelines)? 
3. How common is it for companies to just use these APIs (any examples of the same would be awesome) ? 

NOTE: I get that most of the projects that we do as beginners can all be done by just using the APIs, but during the learning phase it's important to learn what goes on at the back-end.",Where should I write my own program instead of using APIs,9aqa25,new,5,6,6,0
Which universities accept both the GMAT or GRE as entry requirement ?,Which Data Science/Statistics programs in US accept GMAT as an alternative to GRE?,9aptal,new,6,0,0,0
,Was searching for freelance data science jobs and found this...,9al57d,new,76,143,143,0
"I am pretty new to machine learning and this whole data science thing, but I am making my way through it and having a great time. One place I am having a tough time really understanding and finding a clear answer is with multicollinearity and the dummy variable trap.

I understand the basic case of male/female as outlined [here](http://www.algosome.com/articles/dummy-variable-trap-regression.html): 

y ~ b + {0|1} male + {0|1} female

where the X matrix looks like [b, m1, f1]...[b, mn, fn]. I understand that dropping either a class column or the intercept column will then allow my matric to be invertible. In the link above they use another example for a category of three classes with the same operation.

**Here is my question**: if I combine these two examples and start with two columns, one with two classes (male/female) and the second with three classes (blue, red, green), when I make dummy variables do I need to drop one of the dummy classes for each initial column (one for sex, one for color) or do I just need to drop one of the dummy classes? My thinking on this is that my variable matrix would then look like:

X = [b, m1, f1, b1, r1, g1] ... [b, mn, fn, bn, rn, gn]

And thus removing one column should take care of the problem. Can someone clear this up for me? Thank you in advance!",Can someone help me understand multicollinearity and dummy variable trap?,9akhd0,new,11,2,2,0
" 

Welcome to this week's 'Entering & Transitioning' thread!

This thread is a weekly sticky post meant for any questions about getting started, studying, or transitioning into the data science field.

This includes questions around learning and transitioning such as:

* **Learning resources** (e.g., books, tutorials, videos)
* **Traditional education** (e.g., schools, degrees, electives)
* **Alternative education** (e.g., online courses, bootcamps)
* **Career questions** (e.g., resumes, applying, career prospects)
* **Elementary questions** (e.g., where to start, what next)

We encourage practicing Data Scientists to visit this thread often and sort by new.

You can find the last thread here:

[https://www.reddit.com/r/datascience/comments/98nll9/weekly\_entering\_transitioning\_thread\_questions/](https://www.reddit.com/r/datascience/comments/98nll9/weekly_entering_transitioning_thread_questions/)",Weekly 'Entering & Transitioning' Thread. Questions about getting started and/or progressing towards becoming a Data Scientist go here.,9ajry8,new,82,15,15,0
"https://thuijskens.github.io/2018/07/25/stability-selection/

Hi all,

I've done quite a bit of work on feature selection methods lately, and I've found one method in particular that I've had good results with and I wanted to share back. 

There is another post on feature selection methods as well [here](https://thuijskens.github.io/2017/10/07/feature-selection/), and I've put up a Python implementation of stability selection on [GitHub](https://github.com/thuijskens/stability-selection). The authors of the algorithm have also provided their implementation in an R package on [CRAN](https://cran.r-project.org/web/packages/stabs/index.html).

Any feedback on the blog is much appreciated!",Seeing through the noise with stability selection,9ait67,new,0,1,1,0
What's the most mundane task that you think should be automated in data science profession(other than data cleaning)?,Supporting data science,9aiffu,new,4,2,2,0
"I know there is an overwhelming majority of R users in data science, but I was just wondering if there may be an case in which Excel would be superior given the following premises.

1. Person has the same relative understanding of each. I.e, advanced vs advanced, beginner vs beginner

2. Cost is irrelevant",R vs Excel,9ai2rx,new,14,0,0,0
"Users claim that pipelines make code more readable and the workflow more straightforward, but I find it not convenient that fit_transform() returns arrays instead of DataFrames 

I am switching form R to python and I think that making my own functions would be more productive.

",How often do you use scikit-learn pipelines?,9ai2oq,new,3,1,1,0
"I’m a data science professional with a year and some months of experience. I’ve worked with deep learning as traditional Machine learning methods. I recently switched jobs from a startup to the corporate sector. The new job is a good learning experience, though the hours aren’t so good and there’s not a lot of “innovation”. 

A recruiter from Google sent asked me to send across my resume for the position of a Data Analyst. Should I seriously think about switching jobs from a data scientist to a data analyst? The company I’m currently working with is a good corporate brand and has well respected clients. However, my long term goal is to get an MS in deep learning from US/Canada and my undergrad grades really suck. Should I take the offer of a data analyst seriously (I’m just tempted because of the brand that google is, it would really light up my resume and sort of make up for my bad grades I’m guessing?) 

TLDR; Should I switch from data scientist at an Okayish corporate firm to data analyst at google so I can get a good brand on my resume and hopefully that gets me a good college for MS? ",Should I switch down from Data Scientist back down to a Data Analyst?,9ahgbc,new,36,73,73,0
,"SMU's latest data science review journal is here, volume 3, from their master's program",9ahd5c,new,1,4,4,0
"For example, if I have daily data for the proportion of arrests related to shoplifting in a city for the last ten years, and I would like to predict what proportion of arrests will be related to shoplifting tomorrow based on the data from this year and August 27th data over the last three years, how can I go about this?",How does one make a time series forecast given the assumption that the time series will follow the same pattern as a previously recorded time series?,9agdc4,new,2,3,3,0
"Hello, I am really confused on this, I know python a fair bit, oracle SQL, where  can i see sample data analytics projects and ideas plus datasets.

Thank you in advance ",Data analytics projects ideas,9afw40,new,2,0,0,0
"Hello all,  I am trying to build a neural net in python to classify the iris dataset from Sklearn as a way to learn how neural nets. Currently I have a decent code which has 1 level and can correctly classify 2 of the species but I want to build something that does all 3. I know that mathematically I need to add another level but I haven’t seen a tutorial on how to build it with a second level. Can someone attempt to direct me to some resources which can help me build this neural net?",2nd level of a Neural Net,9afd6j,new,3,0,0,0
"What are the ways to learn data wrangling from basic level which includes web scraping PDF reading etc., preferably in R/python or in both? Is there any free course available online or any good book for learning the process step by step? ",Learning data wrangling,9afa1j,new,17,2,2,0
"Hello to the community. I am a back-end engineer who has recently taken up Machine Learning. I have been exploring the data science for quite sometime now. In past 6-7 months, I have completed 2 courses on ML (both from Coursera) but I'm still not getting hold of the things. I mean, I understand the purpose of the algorithm but still the mathematics is still a thing I want to utilize more efficiently. I have barely touched stats after my bachelors (until these courses) but even they didn't need that much background in stat. I have a comfortable hand with scientific packages in Python, so language is not a barrier. I want to start the statistical aspects of the machine learning. I need to start from the scratch and even if it means a month to get the basics, that's totally fine. But at the end of the day, I should be able to understand the underlying mathematics. Any course material, specific books or talks / lectures recommendations are appreciated. If you guys can nudge me in the direction, that will be very helpful. Thankyou.",Deep Dive in Machine Learning,9af84m,new,4,2,2,0
"Although I only made a reddit account a month or so ago I've been lurking here throughout 2018 while checking out data analysis resources and following advice from other posters - you've all taught me a lot and really helped me grasp the procedural basics of analysis and presentation.

​

The other day I found out that a project of mine using climate data called - somewhat clickbaitingly I admit - [Did Drought Cause the War in Syria?](https://www.kaggle.com/bigironsphere/did-drought-cause-the-war-in-syria-an-r-tutorial) had won the Kaggle weekly Kernel Awards, winning me not only some recognition but 500 big boys as well. I admit I was pretty proud of the animation I made as part of it:


![](https://media.giphy.com/media/24m74PUwE31rzvWQJX/giphy.gif)

​

I want to thank the userbase here for helping me along the way,  it's been a really interesting and supportive environment for learners like me. I'm now having fun exploring neural networks, a topic that has cheerfully enlightened me on the true scale of my ignorance. Best of luck to all other aspiring data analysts and scientists out there!",Just won $500 for a data analysis project - thanks /r/datascience!,9aepcb,new,20,85,85,0
"Hey all!

I am a self learner that, after discovering Kaggle, has started to work on data analysis.

I made a Kernel that analyzes a dataset about the recent history of the Olympics and I will be happy to receive honest feedback and new questions to prosecute with the analysis.

The kernel is here: [https://www.kaggle.com/marcogdepinto/let-s-discover-more-about-the-olympic-games](https://www.kaggle.com/marcogdepinto/let-s-discover-more-about-the-olympic-games) 

Feel free to make any question and/or to give any suggestion!

Thank you!",Want to know more about the history of the Olympic Games?,9adzvo,new,0,5,5,0
"Hi guys, i'm considering taking a part time masters in data science while working to complement my work.

Currently based London and my current finance role has SQL and forecasting involved. 

However, I'm not sure what's the best approach to find the right course. I've come across courses in UCL/LSE, but was wondering if anyone had recommendations or resources that I should look into first.

Thanks.",Courses in London?,9adlog,new,12,1,1,0
"Hello All,

Issue 2 of Data Science News has been released [https://datasciencenews.herokuapp.com/2018/08/26/issue-2.html](https://datasciencenews.herokuapp.com/2018/08/26/issue-2.html) 

Data Science News is a curated list of latest happenings in the field of Data Science, Artificial Intelligence, Machine Learning.",Issue 2 - Curious About How To Be A Data Scientist?,9ac72d,new,1,1,1,0
[SQL on Python](https://www.youtube.com/watch?v=gH66J3H1mOU&list=PLL3Qv26_SCsGWTF5PRaWUY0yhURFvco7L&index=3),Help! Should aspiring data scientists learn SQL?,9abvt4,new,12,3,3,0
Where do you see the DS career and job duties five years from now? Will the career still be in demand and will incomes still keep rising like SWE? ,Data Science 5 years from now?,9abmd2,new,15,14,14,0
,Good for a chuckle : Statistics and Machine Learning in the eyes of /r/coding,9aar0t,new,42,162,162,0
"I am currently a PhD student in Experimental Psychology with approximately 2 years left in my degree. To help my chances in landing a DS position when I graduate, I have taken as many statistics courses as I could and will be taking CS classes in Computational Methods and Data Mining. I do have experience using R, MATLAB, and Python (mostly R).  The problem I have is that I rarely come across individuals who have transitioned into DS with a Psych background. Will it hinder my chances in getting a DS position? Is there niche areas where psychologists are preferred?  Lastly, what other skills will I be lacking when compared to other traditional CS/Statistics/Math graduates?",Possible Options for a PhD Student in Experimental Psychology,9aai2h,new,7,2,2,0
"I hope this kind of post is allowed - if not, mods, please delete this and/or redirect me to a more appropriate place for such posts.

I'm writing my Master's thesis in the next Spring semester, and so, I'm contemplating what to centre my thesis on. Some background info: I'm a business management graduate at a European business school, who's specialised in applied statistics and data analysis (mostly applied econometrics, and none of it industry specific). 

My, very rough, idea is to centre my thesis on the use of 'data science' in the luxury sector, but I'm at loss trying to specify it and eventually come up with a RQ. Does anyone know of any current DS developments within that sector, or have any ideas on what to focus on? If you want me to clarify anything, don't hesitate to ask. 

It should be noted that I am first and foremost a business major, and a (prospective) data scientist second. ",Need inspiration for Master's thesis,9a9ue1,new,3,2,2,0
,"Starting a Data Science blog about some experiments that I am interested in running, looking for feedback on my first post.",9a9qrg,new,9,34,34,0
,Fast Parallel Data Analysis and Processing in Python with Dask Dataframes,9a9jrn,new,0,4,4,0
"I finished reading [End-to-End Multi-View Networks for Text Classification](https://arxiv.org/abs/1704.05907) by Guo et al. (2017). The paper is only a few pages long and it's fairly intuitive. However, the equations are not described very well IMHO and I'm struggling to understand them all.

&#x200B;

Specifically:

1. What does B\[h:h\] means in (1) and (3)? Is it a vector or a matrix? If a vector, what's the shape of W in (3)?
2. Are the s+ and views vectors or matrices?
3. In (5) there's a concatenation, is this vertical or horizontal?",[D] Could you help me understand the math of this paper? (x-post from r/MachineLearning),9a95pk,new,0,6,6,0
"I just recently started learning about ETL and data science in general. I think have a need for a Python workflow/ETL framework. What I'm building (for my startup) won't yet need to support a high volume of data (a few hundred thousand JSON files/month or so). I'm looking to ingest and transform JSON and CSV data and then load it into Neo4j or Elasticsearch.

&#x200B;

After researching Luigi and Airflow, it seems that these are too ""high powered"" for my need and may require a lot of setup and maintenance time. I was wondering if anyone's had experience with other Python frameworks (bonobo, petl, etc.)? Or know of other ones?

&#x200B;

Also, I'm a newbie, so if I'm misunderstanding anything, please feel free to guide me in the right direction.",Simple Python ETL framework?,9a8wgh,new,37,31,31,0
"[https://www.kaggle.com/agrawaladitya/eda-data-preprocessing](https://www.kaggle.com/agrawaladitya/eda-data-preprocessing)

First kernel up on Kaggle! Kagglers here please provide some constructive feedback on it, as I would love to improve and learn from your experience. Also, please upvote if you like my work! 

I am going after the KernelsAward!  :D",Clothing-Fit Feedback Dataset from Modcloth- EDA and Preprocessing,9a8vzx,new,0,7,7,0
How do data scientists stay updated about latest technologies and advances in DS? ,Sources to update new knowledge,9a8sec,new,2,2,2,0
"Hello everyone,

I'm looking for dynamic pricing resources for a rather innocuous experiment. I'd like to have prices of drinks to be adapting to consumers' behavior during an event, for a whole evening, so it must be real-time, or close to that.

Any tutorials, books, courses,... with code I could read and learn from?

Thanks!",Resources for dynamic pricing based on consumers' behavior?,9a8c7l,new,2,1,1,0
"My company has 3 branches, each branch has 10-40 employees that take in forms, identify the purpose of the form, and direct it to the correct team. There are probably \~2000 employees that, among other things, reads the form and manually type the data into our system (things like Name, Date,SSN, Type, etc).

I feel like this would be a great place for me to have an impact (people wouldn't be let go, just given a new set of responsibilities within the company as they all have a lot of experience in the industry and are very much needed).

​

Has anyone ever tackled a problem like this and have any advice? I am not very familiar with projects like this and need some help identifying what to read up on.

I was thinking the process would look like:

​

1. identify the form using image recognition of some sort
2. Rotate and scale image
3. identify the locations of the entered text (would I want to use YOLO or perhaps there is a way to just have an almost fixed set and location of boxes based on the form type?)
4. use some algorithm to extract text (Tesseract OCR?)
5. flag possible data issues (e.g. name and SSN dont match)
6. have a few employees validate  or fix the flagged data

​

I would guess we receive 50-100 forms per minute so a fast set of algorithms would be great.",Form data extraction,9a78fq,new,1,4,4,0
,Clothing-Fitting Feedback Dataset from Modcloth.com and RentTheRunWay.com,9a58cs,new,0,2,2,0
"I'm getting ready to apply for internships/entry level analyst positions, but I don't how when I can say I'm  *proficient* with a language. How can you tell where you stand?

​

I feel pretty comfortable with R, SQL and python (numpy, pandas, matplotlib) in the sense that I can take a dataset and manipulate it however I want with a few stackoverflow searches. But I have no idea how that translates to being able to handle real tasks in a work environment.

​I dont want to oversell myself and be unable to do the job fast enough, but I also don't want to undersell myself and get filtered out of jobs I may be able to do.

​

​",How can you assess your proficiency with a language? Are there any useful standards/guidelines?,9a4er4,new,8,5,5,0
"I'm from an engineering background in the aerospace industry with experience in analytics, python, and BI. I am trying to transition into the data science field with the tech industry. Any advice on how I should approach this? I've been reading a lot of books and talking online classes and trying to translate alot of existing on the job data analytics experience but it feels like the industry and culture is so different.",Advice to Break into Data Science from Engineering,9a44fi,new,3,1,1,0
,The Future of Notebooks: Lessons from JupyterCon,9a3dk6,new,19,44,44,0
"Hi guys, this is my first time here and i've enjoyed the discussions so far, even when my knowledge is far behind my interest in the subject.

I will contextualize my situation. I'm a 21 year old marketing student from Argentina. We don't have a lot of courses down here about data science and machine learning, so i wanted to start an edX MicroMaster taught by the MIT called ""statistics and data science"".

The thing is, i'm a lil bit worried about the prerequisites of the first module of the program, ""Probability - the science of uncertainty and data"": 

[College-level calculus (single-variable & multivariable). Comfort with mathematical reasoning; and familiarity with sequences, limits, infinite series, the chain rule, and ordinary or multiple integrals.]

How hardcore do you think math is going to go? I'm comfortable with learning the basics of each point, but having to go hardcore on every aspect of each topic is a different story.

Do you think this is a viable way to start learning about data science? Would love to hear from you.",Newbie here need some advise,9a37qw,new,4,1,1,0
"I've started to notice lately that I hate being asked to perform ad-hoc or purely-inferential analyses. I've had people come up to me lately and simply tell me, ""Here's a shitload of data. Go find something actionable."" That scenario is a nightmare to me. It might be due to lack of engagement from the data SMEs, but I really seem to like instead the engineering that takes a hypotheses through feature engineering and into a model, and I especially like building the pipelines/applications that serve a model's output.

Anyone else in the same boat?","Love machine learning and engineering, hate analytics",9a2282,new,19,27,27,0
"Care to share your opinion of RF, and in what setting it was used?",Has anyone used Random forest in a professional setting?,9a1qcb,new,61,78,78,0
"This is provably going to sound trivial. I am learning ML using some online guides and have build a few models which use the iris dataset. However, I’m a bit confused about how the model is saved so when I run it on new unclassified data, I can classify that data with a high level of accuracy. For example, when I use neural networks to predict results, I run the script and get a fit/prediction with say 53% accuracy on training data. If I run he script again I get 100% accuracy. Each time I run the script the model gets a new accuracy. Am I doing something wrong, or is there a way to save the model fit such that a good fit could be applied to new data?",How Do I Save A Machine Learning Model Using Sklearn,9a1l4l,new,20,7,7,0
[https://academy.microsoft.com/en-us/professional-program/tracks/data-science/](https://academy.microsoft.com/en-us/professional-program/tracks/data-science/),Is Microsoft's online Data Science program any good?,9a168n,new,9,0,0,0
,"Washington, D.C. gives no fucks",9a0sjg,new,2,1,1,0
"Hey folks. I'm a self-learner and i still haven't worked on any project or on any competition, just studied a bit of theory.   

Is there any way to watch a step-by-step DS project being made by someone, or like a Kaggle competition? As a beginner it would help a lot to get a walkthrough on the most frequent steps in a project.",Following someone making a project,9a07av,new,10,11,11,0
"I'm trying to compare a number of models with CFA using lavaan in R.

I want to include models were the latent factors are not correlated as well, there is a command in the lavaan package to do this, but I get the following error message. any thoughts?

&#x200B;

The cfa() function works fine and gives results if I don't include the orthogonal = TRUE.

&#x200B;

*> BAM.CFA.fit2.ort <- cfa(BAM.CFA2.ort, data = Data2, std.lv=TRUE, orthogonal=TRUE)*

*Warning message:*

*In lav\_model\_vcov(lavmodel = lavmodel, lavsamplestats = lavsamplestats,  :*

  *lavaan WARNING:*

*Could not compute standard errors! The information matrix could*

*not be inverted. This may be a symptom that the model is not*

*identified.*",CFA with orthogonal rotation does not work?,9a04dz,new,0,2,2,0
,CO Network is releasing a Science & Tech collaboration network in collaboration with the Machine Learning Society.,9a03tx,new,0,3,3,0
"Hi everyone. I hope this isn't against any community guidelines but I want to start my first project using python and VSC and a dataset from the DMV about accidents reported. I would like to make a sort of heatmap using the locations that the accidents occured. Are there any resources I can use to help me step by step with this project? Also, how could I see an output from VSC regarding the code i'm attempting to write to see if there any errors so far?

&#x200B;","Super beginner questions regarding Python, VSC, and CSV file",99yz69,new,2,2,2,0
"I always felt I missed a trick with no industry expert guidance/no internship at big company in data science field. Much of what I learnt from ML algorithms to Neural Network models / techniques are self learnt and through Kaggle Kernels.

​

Would like to know are the data science projects, ""challenges"", methods are different in Industry when compared to Kaggle competition experienced developers.","How different are data science projects, methods, and solutions from working on Kaggle competitions vs Industry projects, client side?",99yz1l,new,8,8,8,0
"I am working with a Pandas dataframe with 3 columns containing information about hotels in New York.

* Hotel name
* Longitude
* Latitude.

My problem is that I want to make a fourth column, “city district/borough”, based on the longitude and latitude coordinates. However, this has been a major headache most of the afternoon. I have tried with geopy, but with no luck. Any help is greatly appreciated. Thanks for reading, have a nice weekend. :) I work in python 3 btw.","Make a dataframe column ""city boroughs/districts"" based on columns with longitude and latitude?",99yf5d,new,8,3,3,0
"There are a lot of blogposts and article out there about getting your first data scientist job and breaking into the industry. 

I wasn’t able to find anything about the second data scientist job though. Once you got in, and for whatever reasons, decided to change your job, what was your experience? What are the expectations of the employers? Did any of this portfolio stuff that everyone recommends to have for the first job matter any more? How did the interview questions change between the first and the second jobs?

To give more context to my question, I grew into a data scientist at my place of employment (ie did not have to go though the search of the first job), so I am not sure what to expect when the time to move on comes. 
",How did you get your second job as a data scientist?,99xfzi,new,26,59,59,0
"  

First of all, I am not sure if I posted this in the right place. But, I am breaking my head over this problem, so would be more than happy with your help. I am kind of new to the data science field, so please be gentle. For my dissertation, I am researching the effect of international trade on income inequality at the industry level. I gathered data for the income inequality measurements at the industry level, implying 19 industries, for 12 countries, for a time period of 15 years (see attachment 1 for overview). Furthermore, I collected the international trade variable at the industry level as well. However, my other (control) variables cannot be find at the industry level, but at the country level instead (e.g. education). Implying the following regression specification; 

[regression](https://i.redd.it/bgv1jfufj1i11.png)

The subscripts i, j and t respectively represents sector, country and wave (time).Whereas IIijt denotes income inequality, hence the Gini-coefficient, mean log deviation, Theil-index, Atkinson-index (ɛ =0.5), and the p90/p10 ratio. alpha indicates the intercept. Xijt symbolizes the vector of variables reported at the industry level, including the main independent/explanatory variable for international trade; industry exposure to international trade. Next, Zjt is the vector of the other independent variables, which are reported at the country level; e.g. economic growth, education and inflation rate. Next, D reflects a dummy variable, which are the incidents (e.g. China entrance WTO) “shocking” model. mu signifies the sector-by-country fixed effects and theta the wave (time) fixed effects. And epsilon the error term.

As a beginner in data science, this creates a few problems/questions for me. First, how can I combine data at the industry level and country level in my dataset (see attachment)? Divide the country level variables by 12 or just give it the same value for each industry? Second, how do I construct the panel dataset in STATA? Using *xtset Industry Year?* Or *xtset Country Year?* Third, how do I analyze the effects on income inequality in one regression, thus let STATA run the specified model? And fourth, how do I generate the sector-by-country and wave (time) fixed effects in the model?

Thank you very much in advance from a very stressed economic student!

&#x200B;

&#x200B;

[Wave overview -- Attachment 1](https://i.redd.it/oc2p6e1qj1i11.png)

&#x200B;

[Dataset -- Attachment 2](https://i.redd.it/ab90ndn5k1i11.png)","Creating a panel dataset with time, country and industry -- helping out a very stressed economic student",99xbyl,new,0,2,2,0
,"Da Beave & Faux Reals presentation on ""Bots"" & ""Fake News"" at HOPE conference",99wvgi,new,0,12,12,0
"Hi

I'm studying statistics and economics, but would like a career in computer science. Data science seems a nice mix, but I like CS for the fun problem-solving. E.g. writing my first programs in python feels like solving logic puzzles and fit them together into something that works, which is wonderful. Typical data science tools like SQL don't seem to involve this kind of problem-solving, and don't seem interesting to me (I could be wrong about this, since I don't know a lot about it).
Do you think data science, or any CS disciplines related to statistics/econometrics, involve a lot of the fun problem-solving that I like?

Thanks for any info

PS: I'm currently deciding which degree to pursue (statistics/economics/acquiring good coding skills without an official degree). Right now I'd describe my dream job as: some thinking and discussing about which problems need to be solved; a lot of problem-solving (like coding in e.g. python); and some thinking and discussing about the solutions that I found. (Which is very broad, but the best description I can currently offer.)",Does data science involve a lot of enjoyable coding?,99wq6g,new,33,0,0,0
"Hello Everyone,
one of my friend is gonna appear of the interview.

what kind of the questionnaire can he expect ?

He has already covered Algorithms and data structure type of questions

They have given him one home assignment also

Which is something like this

https://hastebin.com/ovipasiyas.sql

and he has already covered it.

What according to you would be asked in the interview or how he can prepare for it?


Thanks everyone.",Interview Confusion,99wl0q,new,4,0,0,0
r/https://twitter.com/hardmaru/status/1032762806796312576,Exciting new work on conditional video synthesis from Berkeley,99wfhy,new,0,3,3,0
,How an Art Collective Is Using Artificial Intelligence to Make Paintings,99vxnx,new,0,8,8,0
"Hello,
I'm looking for ways how to best work with a data set that is ranked in order. Here is the case:
Lets say, we have a ranked data set of shops, ranked 1 to 100 - 1 having the largest turnover, 100 having the smallest turnover. Only additional information is given - name (brand) of the shop, address of the shop and total turnover for all 100 shops.

Is there a way to reliably work with such data and extract insights regarding shop brand/region based on turnover? I'll be happy to hear any suggestions at this point.",Question: how to work with ranked data,99vja9,new,1,4,4,0
,dbdiagram.io: Free Tool to Design Database Diagram Using Code (DSL),99tp36,new,1,9,9,0
,LinkedIn accepting Economic Graph data science proposals [CFP],99rip3,new,3,18,18,0
"Simplified example of a dataset I'm working on. Assuming there are the following columns.

- owns\_car: No / Yes

- uses\_car\_to\_drive\_to\_work: No / Yes / Does not own a car

- involved\_in\_accident: No / Yes # this is the output variable


Is there any point in keeping the ""Does not own a car"" entries, or they can/should be converted into ""No"", so `uses_car_to_drive_to_work` will have only 2 columns?",Keep categorical variables that depend on other variables?,99ri3m,new,3,3,3,0
Anyone else have this problem? Running as admin and reinstalling 7zip don't seem to help Tried googling but can't find any clear answers.,"Can't install Julia on windows, get '7zip - access denied' message",99ny52,new,3,2,2,0
"What tools do you use, if any, to manage your data science projects and workstreams? Do you do weekly planning, bi-weekly sprints, or schedule your work in some other cadence? 

I’m struggling to manage my tasks and provide visibility to other folks on what I’m working on, so curious to learn what has and hasnt worked for others on here.",How do you manage your DS projects and workstreams?,99m5vv,new,20,36,36,0
"I have users personal information like name,age, company, social profile, payments history then how can i build the model for trust score  for user ",Regarding build a model,99l43k,new,14,0,0,0
I want to help create a solution for the traffic in campus for my capstone in Informatics. How can I measure the congestion of traffic? Object detecting software with camera? Test driving vehicles hrough campus at different times of the day? My idea is to recommend different routes to be taken based on the time of day. The best thing would be to have real time traffic congestion data. It's a year long project we are starting now.,Gathering traffic data,99k9bm,new,10,12,12,0
"This [blog on top tools for datamining](https://bleedbytes.in/top-10-data-mining-tools/) discusses 10 best tools for datamining. 8 out of 10 programs  are written in Java. Does somebody have an  idea about what is the actual usage of Java vs Python? 

&#x200B;

&#x200B;

[Blog:  Top 10 Data Mining Tools](https://i.redd.it/r2ddqztu7rh11.png)

&#x200B;

&#x200B;",Top software tools for datamining,99jl6b,new,2,0,0,0
I work as a data analyst in financial services and am thinking of grad school options down the line. ,Is there a big enough difference between a traditional Stats masters and a Data Science masters for one to be more useful than the other?,99j6s2,new,4,1,1,0
"I feel that unless you go to a school like Columbia for a graduate program in data science or any other elite schools, prestige shouldn't matter. I feel that having internships, personal projects, strong references are much more important?",How important is the prestige of your graduate degree in getting hired?,99ifww,new,36,5,5,0
"[I am trying to build a video like this](https://www.reddit.com/r/dataisbeautiful/comments/997cik/severe_to_exceptional_droughts_2008_present/). [OR like this](https://www.reddit.com/r/dataisbeautiful/comments/99d3ya/one_month_of_monsoon_rains_that_brought_historic/). I have all the applicable data, and a PowerBI pro account. Can I build something like these videos in PowerBI? ",Can PowerBI build this?,99fv3x,new,23,1,1,0
,Logistic regression visualized (League of Legends data science),99ed4a,new,33,93,93,0
"Are there any off the shelf applications that can take a significant dataset & take a first pass at finding all the interesting relationships with a single click?

Let’s say I had a year of process data that recorded everything from raw material batch through every temperature & pressure to the fork lift truck used to ship the product out the door.

Loads of columns & loads of rows.

Are there any tools currently on the market that would allow me to import (or ODBC link) my data and then click some sort of ‘Right, Hold My Beer’ button which would run for (hours?) whilst I went to my various meetings. 

When I returned, I could get a report that tells me every relationship found in the dataset ... not just simple correlation but linear equations with predictive value?

Whilst you were away, application determined:

QA parameters can be predicted by ...

Torque is a function of ...

Raw material A runs hotter than B ...

I ask because I could really do with one!  Sometimes a customer will raise a concern about something measurable but not specified in the sales agreement.  Narrowing down the parameters that can influence these parameters (there are 3000+ parameters measured once per minute) once Occam’s Razor has failed to release any secrets is a pain.

Just wondered what was available commercially to ease the pain.

I know I can learn Python, R ... etc.  I’m a few years from retirement - I don’t want to & I don’t need to.  I’m not under any pressure but I figured there are probably applications out there that would take a gigabyte of data & tell me more about the interdependence of our process parameters than our engineers could.
",Powerful Applications for mediocre Analysts,99e92p,new,5,0,0,0
"Hi everyone!

I was reaching out to request some help regarding geo-localization. I am currently working on a project that requires to suggest, based on several incident locations that I already put on a map using the latitude and longitude, the best location to create a new base (so that the team reaches faster whenever a new incident comes up).

So far I used Pandas library to geolocalize the incident spots using google's API. But I am not sure how to face the challenge of suggesting a new location. Any suggestion or guidance you can give me?

Thanks a million! (and excuse any typo or grammar error, English is not my native language).",How to geo-localize optimums spots in a map,99dhk9,new,10,4,4,0
"Hi, I want to show around 3 thousand points at world map with leaflet heatmap. 

For one point there will be maximum 20-40 stacked points. Most of the points will be maximum 10-20 stacked points.

What is please bet way to set heatmap attributes with this ammount of data? Mainly what intensity, blur and radius to be as accurate as it can be, but still visualy pleasing and easy to see patterns.

Thank you ",How to correctly setup heatmap on map,99d8yg,new,1,6,6,0
,Is my model overfitting too much ?,99d3qz,new,9,0,0,0
"Hello guys, 

I am training a binary classifier to identify pictures of good and bad zippers. The pictures that I am using for this task are being taken from a conveyor belt. I have around 8000 pictures of which 4400 are of good zippers.

One important factor to consider, is that when I was constructing this dataset, I would take 4 pictures every time I passed a zipper through te conveyor belt in order to increase the size of the dataset quickly (I am not sure if this can be the cause to my error)

When I trained the classifier (random forest) using about 30% for testing set I end up getting very high scores in both the training and testing (1.00 , 0.9987). Furthermore, a 5 fold cross validation test with an average of 99%+

The problem I am having is that when I use the trained classifier with live pictures (zippers that I am passing through the conveyor belt to do validation) it predicts all zippers as bad. 

I took 42 individual pictures of good zippers to validate and it predicts all of them as being bad (only one picture per pass this time). I don’t understand how this can be happening if it performs so well on the testing set. It predicts more than 1000 zippers that are good correctly. 

Also when I place the first 20 pictures of the validation set in the training set, it is able to predict about 16 right out of the 22 that are left in the validation set. 

I really do not know what to do. I would appreciate any piece of advise. 

Thanks for the help! 
",Need help with a binary classifier. Getting a weird performance on validation test. PLEASE HELP!,999one,new,7,0,0,0
"I am working on a problem that I am not super familiar with and looking for some advice. I am working with OCRed documents, these records contain multiple smaller documents within them. I am trying to isolate each individual document. Can anyone point me in the right direction of where I could start?",Need help with an NLP question.,998fed,new,4,0,0,0
"First off, I am trying to replicate this paper (don't worry it's short): https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5820689/


I have estimated a ARIMA model as they have done and I have some observed and predicted values for the date ranges they specified (Observed: 2017.01.15 - 2017.04.18 and predicted: 2017.03.31 - 2017.04.18).  My question is: How can I test that  observed values in the predicted date range are significantly larger than the predicted ones?

In the paper it says that ""The ratio of observed and expected volumes with bootstrap CIs were computed"" but it's not clear to me what they did.

Any help would be much appreciated.
",Help with a statistical test,99870b,new,9,5,5,0
"Now this is easier in gensim with my latest commit/pull request. I couldn't find an easy way to use bigrams (phrases) with gensim's Doc2Vec model, so I added that functionality to the source code.

&#x200B;

Enjoy!",Using Bigram Paragraph Vectors for Concept Detection,997q35,new,0,1,1,0
"tl;dr - I'm a professional linux admin with degree in CIS but when it comes to data science I lack the math/statistics knowledge on how to finish my 7 year project.  If you're into news, big data and building your resume we should work together to see what needles we can find in this 2.5 tb hay stack.

&#x200B;

\----  

&#x200B;

In 2011 I started crawling main stream news websites.   The goal at the time was to of course make money and measure sentiment in order to place stock trades.  I never got very far with THAT idea but the crawler has been going since June 2011.  In that time I've crawled the same 20 news sites every 30 minutes to create ""snapshots"" in time.  

&#x200B;

s1 = 00 - 29

s2 = 30 - 59

&#x200B;

There would be 2 snapshots every hour and the crawler attempts to hit every site in a crawl list every hour inside that window.   For example I have [cnn.com/index.html](https://cnn.com/index.html) every 30 minutes going back to June 2011.   This includes a full color rendered image of the home page and the actual HTML file.

This crawler currently has a ""dashboard"" that allows me to punch in any 30 minute window in time going back to June 2011 and seeing what was on the main pages of all these news sites in a grid.  Some very interesting stuff to say the least. 

&#x200B;

Today I woke up and felt driven to refocus on this project and here I am requesting some help or a partner that may be interesting in joining forces to thrash this hay.  

&#x200B;

I suspect there is value here if done right but frankly I'm not sure how to proceed.

&#x200B;

I'm thinking a simple thing would be to take all the link titles <a href='url'>title</a> and process them using R tidy, nlp python, lucene/solr, ELK stacks but every time I start to put things together like this it goes over my head fast. 

&#x200B;

Thoughts or ideas on where to go from here?

&#x200B;

I can share table structure and build some sample datasets if anyone is interested.

&#x200B;

 ",How can we pull needles from this haystack?,997ke1,new,0,4,4,0
I know that being a data scientist is one of the hottest jobs right now. We always here about how great it is but we never hear about the bad parts about it and that's usually I can judge if a certain career path is for me is if I can handle the bad parts of the job. ,What is the hardest part about being a data scientist?,997izp,new,12,10,10,0
"I can't find a good alternative to ggplot2 (R) to Python?
I am diving into plotly but it is too verbose, like matplotlib.
",What is a good ggplot2 equivalent to Python?,996zkv,new,17,16,16,0
"Students who got into Top Data science Masters programs, how well your PS/essay was ? Samples would be very beneficial. ",ML/DS: How your PS/Essay looked like when you applied for Masters?,995gfe,new,7,2,2,0
,Using PySpark 2 to read CSV file having HTML source code,994saq,new,0,2,2,0
I’m working with a large data set (16bn row) and want to understand the pros and cons of using a parquet file format vs generating a hive table. I know with hive I can use Partitions and buckets to help optimize but I am trying to understand if this is better than parquets and why. Thanks!,Is it more efficient to read parquet files or use a partitioned hive table for a large data set?,9945g4,new,0,4,4,0
"I am trying to design and train a convnet to classify images of faces as either smiling or not smiling.

This model (model A) gets 85% test accuracy:

    padded_input -> conv2d -> batch norm -> relu -> maxpool -> flatten -> FC(sigmoid)(1)

This model (model B) gets 95% accuracy:

    padded_input -> conv2d -> batch norm -> relu -> maxpool -> flatten -> FC(sigmoid)(300) -> FC(sigmoid)(1)

However, both of the following models (models C and D) get 50% test accuracy or lower (somehow worse than random guessing):

    padded_input -> conv2d -> batch norm -> relu -> maxpool -> flatten -> FC(relu)(300) -> FC(sigmoid)(1)
    
    padded_input -> conv2d -> batch norm -> relu -> maxpool -> flatten -> FC(tanh)(300) -> FC(sigmoid)(1)

The only thing I had changed from model B to models C and D is the activation function on the second-last layer.

When I look at the literature on convnets, it looks like many of the famous image classification convnets have numerous layers of FC(relu) -> maxpool -> FC(relu) -> maxpool -> ... at the end before a final sigmoid or softmax layer.

Why is it that when I try to use a relu function it completely breaks my model and it fails to learn anything? Is there something I am missing here?

Thanks in advance!

technical details:

1. In the model summaries, where I have written FC(relu)(300) that means a fully connected layer with a relu activation function which outputs 300 nodes.
2. The FC(sigmoid)(1) is the final output of the network. It represents the ""probability"" that the person is smiling. If the value is above 0.5 the person is predicted to be smiling.",Could someone please explain my results? (Choosing ConvNet FC layer activation functions),9941b9,new,6,2,2,0
"## Hey folks! We're the Data Science Path team at [Codecademy](https://www.codecademy.com/?utm_content=redditAMA&utm_medium=social&utm_source=reddit&utm_campaign=redditAMA).

We've been hard at work over the past few months building the [Data Science Path](https://www.codecademy.com/learn/paths/data-science?utm_content=redditAMA&utm_medium=social&utm_source=reddit&utm_campaign=redditAMA) that teaches SQL, Python, NumPy, SciPy, pandas, Matplotlib, Seaborn, and drum roll... Machine Learning (scikit-learn)!

We thought some of you might have questions about Data Science, want to hear a little bit about how the Data Science Path was made, or have ideas about what you'd like to learn next. Feel free to ask us anything.

Answering questions today:

* Laura, Data Science Path Lead (u/teracoder62103)
* Alex, Curriculum Developer (u/jeremey_bentham)
* Noor, Curriculum Developer (u/noorgrewal)
* Sonny, Curriculum Developer (u/sonnynomnom)

We'll be online and answering questions for the entire workday. 

Oh also, [we're hiring](https://www.codecademy.com/about/jobs)!​  

---
EDIT 1: The Codecademy Data team is joining the fun!

* Catherine, Data Scientist (u/naivebayesian)
* Shu-hui, Product Analyst (u/shuhui19)
* Sade, Product Analyst (u/sade-sa)

EDIT 2: Thank you so much for all the questions! We are so proud to be a part of this community and we can't wait for you to see the new content. We will try to come through briefly again tomorrow and answer some more. Signing off for the night\~",We're Codecademy's Data Science Path team. Ask Us Anything!,993jxi,new,115,140,140,0
,Data Science resource feed with personalised library,993jlv,new,0,5,5,0
,"Are there domains in data science where geometry, trigonometry can help?",992zrd,new,11,4,4,0
"And how to know it is worth it to develop?
I'm a freelance senior developer looking for new projects, with ideas in machine-learning field
",How to know an algorithm already exists?,992na8,new,9,2,2,0
"Hi friends,

I’ve got an acquaintance who owns a medical supplies distribution company who has offered me a part-time position of what I can only assume is a entry data analyst position. This offer was brought up when I brought up my desire to change careers and go back for a masters in computer science. (BS in molecular biology). She mentioned she needs someone who can make sense of data and present it in a useful way and if I develop some advanced excel skills I should come work for her to get my feet wet before deciding to whether to commit to a whole career change. 

I don’t have much experience with excel but I’ve got a cursory knowledge of R and Python which I suggested may be better to which she said whatever way works for me. 

My question is which language should I dive into first and what curriculum would be best to be useful in this position?

The company 
As I mentioned earlier, it’s a medical supplies distributor. It’s a small company, with about 10 employees and does a few million in annual revenue. She says her company uses CSQL and Prophet 21.

My background 
My background is in the life sciences, I have a BS in molecular and cellular biology and have taken calc 1-3. I’ve self-studied the basics of html, css, networking (tcp) and only touched R and Python. I’ve taken the online Harvard CS50. ",Need help preparing for this job offer,9926r0,new,19,11,11,0
,HELP: Interpreting R's rpart.plot Decision Tree Visualization.,991ray,new,6,6,6,0
"Hello,

I wanted some suggestions as to course videos from good universities relating to statistics and data science. Would be really helpful if anyone could provide some.

Thanks !",Top Courses for Data Science & Statistics ( Universities only ),990u20,new,7,8,8,0
"With python. I know the question is very broad, but would appreciate to have some practical examples, maybe links.
",What pactical knowledge does it takes to be a data scientist?,990t4g,new,13,1,1,0
,How to create fake data using Python. #ai #bigdata #machinelearning #analytics #artificialintelligence #datascience #deeplearning #python #dataanalytics,990oyp,new,4,0,0,0
"Hi everyone.. I am an industrial engineering grad student looking for data projects that would be relevant to my field. I took an analytics class and want to apply the learnings. 

Are there any data competitions/projects on Kaggle that would be relevant to industrial engineering? Stuff like supply chain, operations planning, transportation problems, manufacturing quality,etc. ? 

I worked on the titanic problem which seems to be quite a common project for beginners and it was quite fun to work on. 

Thank you in advance for your recommendations! ",Kaggle Projects Suggestions for Industrial Engineering Grad,98zo5s,new,2,3,3,0
"I implemented the R stargazer regression reporting library in python because I didn't want to switch back and forth between languages for stats projects and I thought other people might be interested as well. 

It includes many of the customization features found in the original package and can be downloaded using `pip install stargazer.` Check it out if it sounds like something you could use and feel free to contribute!

[https://github.com/mwburke/stargazer](https://github.com/mwburke/stargazer)",Python implementation of R stargazer library,98zdcz,new,1,13,13,0
,Leveraging Python's Generator Expressions and Laziness for Manipulation of Big Datasets,98zcwf,new,0,0,0,0
"For the last few months, Codecademy as been building their ""Data Science Path,"" focusing on instruction in Python, SQL, Matplotlib, NumPy, Pandas, SciPy, Seaborn, and ML/scikit-learn. Responding to your questions will be:

* Laura Breiman, Data Science Path Lead
* Sonny Li, Curriculum Developer
* Alex Kuntz, Curriculum Developer
* Noor Grewal, Curriculum Developer

The AMA will be posted tomorrow morning at 10am EDT (7am PDT).","Tomorrow, we will be hosting an AMA with Codecademy's Data Science curriculum development team",98xg8w,new,6,151,151,0
"
Was wondering about how data science can be leveraged in the area of fitness, movement, physical therapy, nutrition, etc?

Have you seen any good examples?

Given the magnitude of health issues that Americans face and the magnitude of physical dysfunction, I'm surprised that I see few examples of data science applications in the area of fitness, physical therapy, etc.","Data Science applications in fitness, nutrition, physical therapy, mobility, etc domains",98w84q,new,5,5,5,0
,Getting Started with Data Science,98w122,new,0,4,4,0
"I'm a student with a business major and I'm really interested in data science. How would you transition from a fairly non-technical business undergrad to a data science career (entry-level jobs/masters programs etc)?

Thanks so much!",Path from business major --> data scientist?,98vono,new,6,4,4,0
"Hi all,

A friend of mine is involved in a research project at the University of Bristol into the causes of the Syrian Civil War and I offered to help so here's my analysis of precipitation levels across the region. It's a bit sparse on the stats side, but contains a wealth of techniques for students of R.

[https://www.kaggle.com/bigironsphere/did-drought-cause-the-war-in-syria-an-r-tutorial](https://www.kaggle.com/bigironsphere/did-drought-cause-the-war-in-syria-an-r-tutorial)

It can help you with geospatial data, climate data files, animations, making maps, writing functions, usage of the various apply()  functions, rasters, matrix manipulation and more! I hope it becomes a useful resource for other people here hoping to improve their R skills. I make the mistakes so you don't have to! It'll help you make animations like this one:

https://i.redd.it/85o9nr24o9h11.gif

I recently posted a project of mine on \[child poverty across New York City\]([https://www.reddit.com/r/datascience/comments/95hhzq/child\_poverty\_in\_nyc\_is\_my\_first\_data\_analysis/](https://www.reddit.com/r/datascience/comments/95hhzq/child_poverty_in_nyc_is_my_first_data_analysis/)) and got some really good feedback so I was hoping for more of the same. I've probably missed some valuable approaches in my analysis or worded things clumsily or just made a few general mistakes, so any corrections or suggestions you have would be a great help.",Did Drought Cause the War in Syria? A tutorial in intermediate R for data science students,98ul1p,new,2,1,1,0
,Materials for Teaching Applied Statistics,98ugx2,new,0,8,8,0
"I just created a slack group for people who would like to do a slow read of McElreath's Statistical Rethinking. I'm working through all the examples, both in R and the PyMC3 port to python, but I find the statistics confusing at times and would love to bounce ideas off fellow students.

If anyone would like to join, please email me at [pluviosilla@gmail.com](mailto:pluviosilla@gmail.com) (pluviosilla at gmail dot com), and I will send you an invitation to the slack group.

This is a truly marvelous book, best I've found so far for coming up to speed with Bayesian statistics and probabilistic programming.

John Strong",Statistical Rethinking,98u1v4,new,9,55,55,0
,What Skills Do You Need To Be A Data Scientist?,98tw3y,new,9,0,0,0
,"New NLP News: Learning Meaning in NLP, Recurrence in NNs, Q&A with Yoshua Bengio, ML == pseudo science?, ImageNet < 18mins, Where's Waldo?, Frontiers of NLP",98ta8g,new,0,2,2,0
,Vega – A Grammar of Interactive Graphics,98sw03,new,2,13,13,0
"Hey all,

So I started my position as a data analyst about 6 months ago after getting caught up in the buzz around machine learning. I have an educational background in mathematics and work at a small retail Electric company. 

I'd really like to put some data science projects into practice before I start applying for my next position. My problem is that every attempt I've tried so far has been unsuccessful. 

I'm familiar with how to run regressions, decision trees, KNN, etc. But it seems to me that in the real world, coming up with useful datasets and successful models usually requires a litany of models working together and not just a few stand alone datasets and algorithms to run on them. 

Has anyone been in a similar situation and have any advice? Thanks. ",Started a data analyst position and having trouble implementing machine learning.,98skhe,new,9,0,0,0
"I've created several web-scraping python helping scripts for common (and uncommon) websites. Planning on populating the scrapers repository so that beginners get the help they need. Have added other modules and stuff there.

Just created the repository today, so give me time to write documentation for each sub-project. But it should not be hard to do this:

python script.py -h

The above command will provide common script usage help.

I made these to help others and also to learn more by myself. Right now only included Seleinium based scripts. Going to add helper scripts to gather Xpath and all that stuff using complex stuff like RegEx later. If it really helps you noobs out there, will add scripts based of bs4 and request module and/or other site support scripts.

Here is the repository: https://github.com/NyanSniper101/Selenium-Python-Scrapers

Contributions are taken but to be honest, it's better you improve on these and then host as your own project so that you get the sattisaction.",Learn Python & Selenium along with logic!,98sikw,new,0,13,13,0
,"DGraph: A Fast, Distributed, Transactional Graph Database Built For Scale (Interview)",98shrb,new,0,8,8,0
"I am working on a system of building and maintaining a few dozen predictive models, that might increase to hundreds in the next few years. This system consists of programs to build datasets for each model (querying database, building features), building the models using some machine learning algorithm, storing the scorecodes, and running the scoring daily. I also want to be able to easilly re-run the models with newer data. I am familiar with some of the business sollutions, e.g. using the SAS platform, but what is the most common set up for such a ""model factory""? None of the sollutions I have seen offer quite what I want. I picture a web based GUI to keep track of which models that have been built, under which assumptions\datasets, when they were last re-run, how they are performing over time, etc. I can see how I would build it using some front end language like JS to execute programs in sas or python, but there is no use in reinventing the weel if such a comprehensive software already exists.","Do you use commercial business software to keep track of predictive models, or have you built your own system?",98ry9l,new,15,1,1,0
"Hi,

There doesn't seem to be [any consensus](https://stackoverflow.com/questions/37078880/status-of-parallelization-of-pandas-apply) on how this should be done.

However, I'd like to get some feedback on what I came up with for my own needs.

[Here](https://gitlab.com/snippets/1746576)'s the code snippet, I'm convinced it's buggy and non-optimal, which is why I welcome any and all criticism.

Thanks in advance for your time!",Parallel pandas DataFrame.apply() suggestion,98rqzv,new,10,6,6,0
,"Hey Quadrant Protocol Fans, Checkout Quadrant Protocol's Partnership Team in early morning transit.",98qx1o,new,1,15,15,0
,Top 10 Data Science Platforms That Cash the Analytics Code | Analytics Insight,98qw19,new,0,0,0,0
"I'm a student strongly considering a career in data science but I'm questioning whether my pretty entrepreneurial/business-minded and extroverted tendencies would make me go crazy or if my soft skills would be an advantage.

I love math and computer science as well as the lifestyle perks of data science compared to a lot of other careers I've considered but I definitely also love big-picture entrepreneurship and being with people.

Any advice/input?",Is a career in data science suited for an entreprneuerial/extroverted person?,98po64,new,7,2,2,0
"Hi all, I came across the Microsoft Professional Program's, and I'm just curious are they worth doing? I've never heard of them and advice would be appreciated.","Microsoft Professional Program, are they worth it?",98p3y0,new,3,6,6,0
,I wrote a python module that prints regression tables similar to the Stargazer library in R. Please check it out!,98p2zu,new,4,97,97,0
Not sure how to gauge ,How do I know if a personal project is 'high level enough' for the position/internship I'm applying to?,98o6ac,new,2,1,1,0
"Welcome to this week's 'Entering & Transitioning' thread!

This thread is a weekly sticky post meant for any questions about getting started, studying, or transitioning into the data science field.

This includes questions around learning and transitioning such as:

* **Learning resources** (e.g., books, tutorials, videos)
* **Traditional education** (e.g., schools, degrees, electives)
* **Alternative education** (e.g., online courses, bootcamps)
* **Career questions** (e.g., resumes, applying, career prospects)
* **Elementary questions** (e.g., where to start, what next)

We encourage practicing Data Scientists to visit this thread often and sort by new.

You can find the last thread here:

[https://www.reddit.com/r/datascience/comments/96ynxl/weekly\_entering\_transitioning\_thread\_questions/](https://www.reddit.com/r/datascience/comments/96ynxl/weekly_entering_transitioning_thread_questions/)",Weekly 'Entering & Transitioning' Thread. Questions about getting started and/or progressing towards becoming a Data Scientist go here.,98nll9,new,47,11,11,0
"I'm learning it right now, and while just creating plots is simple, the code for formatting can be annoyingly detailed. Is this stress worth it? Unless your job/hobby requires creating beautiful or specialized data visualizations, why not just export the data to Excel?

Edit: Thanks guys. It's always great to have professional advice.","How often do you guys use Python (matplotlib,seaborn,plotly,etc.) for data visualization?",98mwno,new,11,5,5,0
"I’ll be entering freshman year at a mid tier uc studying cs. I’m interested in data science , but most internships target masters/PhD students. Any advice?",Any advice to freshman entering college on how to get a data science or data engineering internship?,98mfjy,new,9,1,1,0
,Are data science jobs at risk of automation?,98m1tu,new,5,0,0,0
"Hi, does anyone know where I can find a dump of a couple thousand company earnings call transcripts? I was going to scrape seeking alpha but I am having issues because of the name changes from ticker to ticker of the url. Any help would be greatly appreciated.  


Thanks!",Earnings Call Transcripts,98l34y,new,4,2,2,0
,"As part of being learning in depth about data science, visualizing is a key, what are some of the useful visualizing tutorials on the internet?",98kq08,new,1,17,17,0
"Having a hard time here. New boss around, not technical at all, but more on the ""consulting side"". Some time ago we developed a small solution to forecast/estimate trends in commodity prices. Not exactly the same as stock market, but very close; the same mathematical properties of the signals. The idea was to have a very approximate and long term view of the trends and the expected average level of prices in +12, +24 months... That was delivered, and everybody happy. 

Now, New Boss sold the idea that we (I!) can predict spot price at a certain date. 

I explained her that it is not possible to do that (at the level of accuracy required), but she insisted and now she expects to see results of everything, from ARIMA or persistence to neural networks. She thinks I am lying or being not proactive. I ran some tests in different technologies to show her that it is not possible to get what she wants, but now the perspective shifted, and now New Boss thinks that the problem is that I am not fine tuning things properly, or working hard enough. 

My mistake: I once said ""sure, I can try and you will see"", but now things are getting worse. She even suggested hiring a new guy just to work on this ""project"". 

I shared with her papers, blog posts, articles, and of course explained her how this works, but in the end, she always end with ""but computers are so powerful! we must be able!""

Now, I'm looking for the most professional way to say no and avoid commitment in things I know I cannot deliver.
:-( ","unreasonable request from boss: ""let's predict stock market!""",98jqtf,new,96,158,158,0
"Got a CSV file of about 10 GB with Webpage_IDs, URLs and HTMLContents.

If you are given a problem of classifying these web-pages, what is your choice of tool-stack and why?

Update:
What my pre-processing looks like today?
Read the CSV in chunks using pandas. For each chunk apply an extractTextContent() function on the HTMLContents column, and add the processed text as value to the new column - TextContents.

This operation alone takes half-day to run on my local machine / laptop. Was wondering if there is a better  way to process about ~80k webpages stored as 'HTMLContents' in a CSV file, that takes up about 10GB of disk space.",What is your choice of tool for processing file of about 10 gb in size?,98jir7,new,9,2,2,0
"I am a mathematics graduate from a good UK university with good grades, I am thinking of doing a bootcamp to get into data science or coding.  I would like to be on campus, I am motivated and will work long hours. I have done a bit of python.

Does anybody know about any data science bootcamps for non phds in London?

Currently I am looking at general assembly data science  [https://generalassemb.ly/education/data-science-immersive](https://generalassemb.ly/education/data-science-immersive) or the flat iron school:

Software Engineering Immersive London. I am not sure if one would be more highly regarded.",Help deciding with bootcamp in London?,98ivrv,new,0,3,3,0
"I am doing the Kaggle competition [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques#) to learn more about data analysis. I would like to apply multiple models to the data(Regularized LR, Random Forests, Neural Networks, and ensemble methods). 

When inspecting the data, I found many fields were ordinal data represented as categorical data. Two examples:

    HeatingQC: Heating quality and condition

        Ex   Excellent
        Gd   Good
        TA   Average/Typical
        Fa   Fair
        Po   Poor
    LotShape: General shape of property

        Reg  Regular 
        IR1  Slightly irregular
        IR2  Moderately Irregular
        IR3  Irregular

I was wondering whether I should keep the fields like this, or whether I should turn encode them as integers(i.e. give each class in the category a number like 1,2,3 or 4) . Since the question probably is 'it depends', I hope you could give me some more general insight in when I should keep this data ordinal, or when to transform it into integers. ",When should ordinal data be represented categorically and when by an integer?,98itmk,new,4,1,1,0
"I want to share awesome insights from an awesome workshop conducted by Netflix data science team. I especially love the DS project arc! 

“Curious About How To Be A Data Scientist? Hear From A Netflix Data Scientist” https://towardsdatascience.com/a-peek-into-a-netflix-data-scientists-day-66bf3dacabb9",Hearing from Netflix data science team,98ic5p,new,14,122,122,0
"Hey all,

Recently I managed to begin dipping my toes in more professional data science/data engineering work after most of my work being mostly limited to personal projects. So needless to say super excited and also a bit nervous.

I am currently attempting to tackle a fairly large project and that is taking my company's existing data and creating some type of formal structure going forward as we begin to actually utilize current and historical information to create product features. This is different from what I'm used to as I've either had a structure given to me to work with or because it was for a personal project I was able to build a structure and pipeline out fairly quickly because It would only be used once.This however will be a standard for other people and parts of a larger application that would be used by a large number of internal staff for data entry.

The company basically does lowest price match procurement for other companies using a combination of people and rule based automation at the moment. This means the data is a lot of price data, both current and historical as well as a lot of free text with product descriptions, names, urls etc. There is also a lot of date information for things such as when something was purchased and delivery estimation as well as internal time tracking for each step of the order pipeline.

I have some idea of what I want to start looking at here but I thought it would also be best to get some advice from people here who have much more industry experience with this first on things like common pitfalls and gotchas to look out for when doing this.

I would really appreciate it thanks!

Edit: So it seems I was not as clear as I would liked to have been when asking for advice. To try and simplify my question as much as possible, I have a lot of text data which prior to now has had no real structure applied to it. For that data what are common pitfalls to avoid when structuring it and what are some good things to do while defining that structure knowing it will be used for like the next decade in my company. Sorry If I was a bit muddled wrote that late last night.","Working to create a data standard for the company I work for going forward, want advice.",98hujw,new,3,3,3,0
"I began working with data by entering Udacity's data analyst program. It provided a welcoming introduction to the field; its lessons softened the edges of what, to someone as uninitiated as I was at the time, was an intimidating discipline. Mentors were unusually helpful. The courses seemed guided by a principle that emphasized clear pedagogy above all else, and the somewhat low-rent production value of the videos actually served this purpose. I didn't sign up for sake of earning the credential, but for the quality of the lessons, and I'm not sure I could have found another program that was as structured and effective as it was affordable. It was a terrific launching pad. (My current job involves a combination of data analysis and editorial work.)

I took the DAND in 2017, and at some point that year, something inside the company switched, which I noticed first in the deep learning nanodegree and then in the NLP program, both of which I was so dissatisfied with I dropped out of. Lesson videos were more visually spectacular but also more pedagogically obtuse. Forum mentors were ruder. The assignments we were given were essentially pre-completed Jupyter notebooks that we simply had to run, filling in tiny bits of code here and there (which, because of the obtuse lessons, were difficult to connect back to any particular moment of learning). Costs went up.

I saw today that Udacity launched a Data Science nanodegree, whose curriculum interests me as a way to sharpen my skills on some algorithms that I haven't worked with that much, as well as build more sophisticated data pipelines.  But I'm inhibited from giving them a third shot at this point, unless someone here has rave reviews of the program.

Maybe the degradation was inevitable as Udacity walks the path to Large Public Company, but it's too bad, because I still haven't found another MOOC as satisfying as the DAND was. ",Udacity was great and now it sucks,98hu7e,new,17,25,25,0
"I think having a hackathon participation on my cv would be useful for job hunting as I'm largely self taught. however I live and work in china and don't speak the language so can't really participate in any local ones.

is there such a thing as an online/remote data science hackathon. are they well rated? do you have any links?

Thanks!",Online Data Science Hackathons,98hdxs,new,6,3,3,0
When it comes to Data Science i find something interesting every week. I decided to collect those interesting stuff and launch it as a weekly so that all would benefit. So I created a magazine called Data Science News. You can get its first issue here [https://datasciencenews.herokuapp.com/2018/08/19/issue-1.html](https://datasciencenews.herokuapp.com/2018/08/19/issue-1.html) ,"Data Science News, a weekly Data Science magazine launched",98gwr6,new,10,19,19,0
,Getting Started with Pandas,98gbe1,new,13,53,53,0
"A [sample](https://imgur.com/a/674BZ7g) of the 5000 images that I have to extract text from and then do sentiment analysis on. 



One solution that have been trying:

Tesseract - this would be an OCR, so it would be best if I feed it only text crops of the images. 

* For that I would need a text detection algorithm (OpenCV).The default (model?)[https://github.com/qzane/text-detection] I guess is doing an okay job.  I also found a [dataset](https://github.com/cs-chan/Total-Text-Dataset) but no clue how to feed that ground truth data into openCV to train a model. I am using a wrapper for it in Python there's no good documentation for that. (Text detection)

* I manually cropped the netflix logo from one of the images - Tesseract said its NETMMX, so the default model won't do, maybe to train a better model and a good dataset to train on??


There seems to be a few similar problems and people have used neural nets, but I am pretty much get lost as to how they work. They seem to extract multiple boxes of a image and then extract text from the right box.

I am looking for some sort of tutorial that has done something similar. 

If not some clarity as to how I can do so. 

If you could point me any image to text tutorial that would be great as well.",Getting started with extracting text from images. Looking for tutorials.,98g038,new,2,3,3,0
"Today, using u/ericmjl's course on DataCamp ""Network Analysis with Python (Part 2)"", I could use his code to recommend merchants to cardholders based on the most similar user found for a given user in a bipartite graph: https://pastebin.com/VptnyJUs

As you can see from the code though, I also weighted each edge using the Number of Transactions, but it is not being used.

My question is: how do I use it to refine or rank the results?

I have read many articles (including u/manueslapera's) explaining recommendation systems, but they are all using ratings and I am doubtful I would still be getting useful results since my weights are not ranged in any way and have a different meaning.",How should I use frequency data in a recommendation script?,98db9d,new,3,3,3,0
"Hi, 

I am working on analytics for a CPG company and wanted to see what datasets you all think I could use. What are some of the best datasets to use when looking at buying food?

Best, James G. ",Consumer Package Goods Data?,98d9ut,new,7,2,2,0
"I have seen plenty of roles related to research in data science and it makes me wonder exactly what would these positions entail. Would data science researchers be involved in developing new algorithms for their business needs? What are some other goals and responsibilities would a data science researcher in the industry have? Would experience in a Ph.D. program be representative of data science research roles?

Equipped with an M.S. in Mathematics, how would I go about exploring this possibility? Is the Ph.D. route the only way, or is it also possible to find research opportunities outside of the academic route? Is the demand high for research in data science?

Thanks!",What is research in data science?,98cxyt,new,3,3,3,0
"I'm scraping an online forum to try and create a reference network based on the universities people list. But the formatting of the forum posts is such a nightmare to work with that I'm starting to think this data is too untidy to handle at all. For reference, the data is [here](http://www.urch.com/forums/phd-economics/160036-profiles-results-2018-a.html), in the ""Acceptances"" section of each profile. Sometimes it's comma-separated, sometimes it's semicolon-separated, sometimes it has extraneous information mixed in like comments... 

I've been trying to format this for almost a month now and it's made me wonder this general question; how do you know when data is too untidy to ever be good to work with?",When is data too untidy to even try?,98bt8d,new,9,1,1,0
,Should data scientists using R and Python switch over to Julia?,98axb8,new,10,0,0,0
,Making 27.31TB of research data available!,989h4s,new,16,138,138,0
"Hello.

Following is the job post for the job position that I am looking at.

> Review and manage structured and unstructured data


> Inventory data received and record metadata


> Transform data using scripting languages such as SQL, PowerShell, C#, or Python



> Perform basic data imports into Microsoft SQL Server


>  Validate imported data and perform preliminary data manipulation and analysis


>  Visualization improvements


>  Machine learning


>  Data science


>  International compliance standards



>  Data privacy laws


I feel like descriptions are rather broad. 

Also, this job position is for an internship.

I learned a bit of Python this past summer and I am reading a book titled Data Science from Scratch. So one can say that I already know very limited amount of Python and data science but I know them only in theory. SQL .. I know what it is and I learned a bit a couple of years ago. 

The company is looking for someone educated in Management Information Systems or Computer Science or anything similar. I come from accounting background and I am strongly interested in doing ""data analyst"" type of jobs because I believe that nothing will be better than showing that I worked as data analyst to convince employers that I have some proficiency in data science along with my accounting background. I believe that will give me an advantage when I look for ""financial analyst"" type of jobs.


Strictly speaking, I don't qualify for most of the qualifications now. How long would it take for me to have enough knowledge to apply for job position as described by the job post above?",How long would it take to be ready for applying for a job position described by this job post?,987dns,new,16,13,13,0
"This is a bit of a hard question, I tried googling and searching within this subreddit and think I'm not asking the right way.

Are there any standards or tools for describing data sets using easy and consistent metadata and then visualizing, organizing, browsing, and navigating through them?

I work for a form that has many large datasets managed in various ways, but have fairly static metadata described using largely project open data [0]. However, I and many team members create small analytical subsets all the time for a particular question or joins or whatnot. They are typically disconnected as the analysis is point in time. Sometimes they are built into database systems like sqlsrver that has it's own metadata and ways to search and describe the set. However, it's usually sas, or R, or csv, or some relatively small file from 100MB to a few gigs. However, this leads lots of difficulty in keeping track, collaborating with co-workers, reusing someone else's work, etc.

Some folks compensate by describing the extracts using datapackages or w3c or whatever individuals choose and storing the file where it can be indexed by an internal search engine (usually SOLR).

I'd like to find an easy or OSS tool that can consistently store metadata and point to the source dataset and allow browsing, searching, visualizing stats like linkages, user activity, etc. But that also works on an individual level to organize personal on individual collections that grow over time.

There are commercial data management products like collibra or socrata has some internal enterprise data products. But they are expensive and require a central install and purchase. I basically want github for data, but can't host externally.

[0] https://project-open-data.cio.gov/open-standards/","What standards or tools for describing, visualizing, archiving metadata for analytics data sets",986oxb,new,2,1,1,0
"Suppose I have two continuous targets (y_1 & y_2) that domain knowledge suggests should be affected by the same factors. I take a group of mostly numeric features (X), scale the numeric ones between 0-1, and build two linear regression models:

1. y_1 = XB + B_0

2. y_2 = XB + B_0

After checking the model's assumptions:

1.  What valid comparisons can I make of a feature's coefficients in model 1 vs model 2?

2. How would comparisons be affected by a feature being significant in one model but not the other? 

Thanks in advance for any help. ",Comparing Regression Coefficients Across Two Targets,985sdt,new,2,5,5,0
"I have been playing with this telco churn dataset from Kaggle. It was my first time analyzing churn and even ""publishing"" my first notebook ([https://www.kaggle.com/larissaleite/basic-telco-churn-analysis](https://www.kaggle.com/larissaleite/basic-telco-churn-analysis)). I have been searching ways to improve the classification for this dataset even after doing some feature engineering, hyperparameter tuning and cross-validation, the accuracy/ROC/F1-score stay roughly the same. Is there something I am missing? Can somebody give me some more insights on this? I had thought about trying downsampling of the majority class, but in the end I thought it wouldn't be worth it as the dataset is not that much imbalanced. Any tips or suggestions are highly appreciated!",Improving telco churn classification,985cuf,new,3,12,12,0
"I started as a ML engineer (first job), and I mostly work on my own. My boss had to take a couple months leave because he just had a kid, so I've been left to my own devices. I have a CS BS with an AI concentration, so I feel quite limited in what I can do, even though I think I understand the basics well. The previous few weeks have been good, and I've been making steady progress in learning about gcloud services and frameworks I didn't use in school. However, I'm at the stage where I need to improve my model, and I feel like 1) I'm blowing money on experiments that haven't amounted to anything 2) running out of ideas to test and 3) have somewhat high expectations from my coworkers in other teams.

I was thinking about this yesterday, but I think I'm not being methodical enough in how I'm setting up my experiments. I've done a research internship before where my supervisor would sit down, do analysis with me, and plan out experiments for me to try, and I'm realizing how much I wish I had that now. My past week has been learning how to use ML Engine and running maybe 20-30 experiments trying different parameters, models, and data distributions to little avail. I feel like I'm sitting in a control room with thousands of buttons that I don't recognize or understand. My plan today is to write out an experiment schedule and take notes on everything. My question is, how do you develop models in a productive way?",how to experiment and iterate productively?,983ppd,new,5,1,1,0
"So I'm attempting to fit and validate a model using the h2o automl function (in R) and running into an issue. Wondering if anyone could help shed some light on this.  
  
automl_models_h2o <- h2o.automl(  
  x = x,  
  y = y,  
  training_frame    = train,  
  leaderboard_frame = validate,  
  max_runtime_secs  = 30  
)  
  
The prediction is binary (1/0) and the y variables are 5 categorical variables which I'm defining as factors and 2 numerical variables which I'm defining as.numeric.  
  
My issue is a separate simple logistic regression model I'm running is out performing the output of the h2o model (looking at the confusion matrices and accuracy score). I think it's because the h2o automl is not playing nice with the numeric variables for some reason...? I've gone through [this booklet](https://www.h2o.ai/wp-content/uploads/2018/01/RBooklet.pdf) and I found this excerpt 
  
""To convert an integer into a non-ordered factor (also called an enum or categorical), use as.factor() with the name of the R reference object in parentheses, followed by the number of the column to convert in brackets.""  
  
Does the h2o.ai only work well if you define all of your variables as factors?  
  
Appreciate any insight!
",h2o automl question (feel like I'm missing something simple),98392q,new,12,3,3,0
"I'm hoping someone here can kindly suggest a data analysis tool for finding patterns in data.

I have no experience at data analysis but I need tool to help me with my work.

Any suggestions?",I need a data analysis tool for finding patterns in credit card transactions,980pa2,new,27,0,0,0
"We're looking to build out an in-house data-curation team to create labelled data for our ML models, and are a bit stuck on what job title to advertise for. I want it to be accurate but also relatable. Possible ideas:

 * Data Labeller
 * Data Curator
 * Data QA Team Member

I'm thinking of steering away from ""data entry"" since the work is a little different (and will possibly require more training) than what people might think of with these jobs ... a previous attempt at hiring from the ""data entry"" tag on Upwork was a major fail...",What job title would you give to an in-house data labeller?,97zggk,new,15,3,3,0
"I’m not sure if this is the right sub for this so please suggest somewhere else to post if not. 

I have a set of data for 10 people who took the same test of 10 questions twice. Each question has a score (let’s say out of 100 for example). They took the test before and after an event, so the idea is to see how the event affected their answers. Each question is significantly different so there is no sense displaying each persons total score for the whole test.

Can anyone suggest some good ways to visualise this? 
I’m thinking of a plot for each person showing their scores for each question, maybe a plot showing average scores for each question.. this could quite quickly turn into many plots or some complex/hard to understand. 

The data is currently sitting in excel but I’m fairly comfortable with python and pretty good with Java/JavaFx if there are better ways to use those? 

Many thanks in advanced.",Visualisation Question,97z3y1,new,3,3,3,0
"I am doing MS in analytics. I have done a good amount of projects on ML. While applying for Data Science jobs, I noticed that almost all of the roles require SQL. I have done a MOOC on SQL but I am missing a project from my resume which I believe is important to showcase my skills in SQL during a interview. I can't seem to find a good project idea and what kind of analysis I can do with it. Any project ideas that might help me fill the gap?

Thanks",Project ideas for SQL,97y7ns,new,15,7,7,0
"I am trying to learn Bayesian and wanted to understand the difference as well. If anyone could lead me to a good resource, would be helpful.",Help Needed: Difference between Classical and Bayesian statistics,97xryc,new,7,9,9,0
"I just saw [these videos](https://www.youtube.com/playlist?list=PL5-da3qGB5IBITZj_dYSFqnd_15JgqwA6) from a conference the guy from Data School made and I really liked the format, looks like a great way to learn how to think like a data scientist. 

Just to be clear, I am not looking for tutorials: I like the format where someone has to analyze a dataset and explains all the steps he follows. Any ideas on how can I find more material like this?",Where can I find some good data analysis videos?,97xn9p,new,2,0,0,0
"Have you encountered a data product that you find useful for your work, play or that you just admire? Google search comes to mind as the epitome of putting data to use but I’m also thinking about Ahrefs for marketing/SEO and Datadog for stack insights. What are some other products or categories of products you’ve seen and been impressed by?",Favorite example of a data product?,97vx2y,new,2,3,3,0
"We always hear about all the things beginner data science are missing but never hear about this angle

**EDIT:** Maybe I asked the question wrong but it seems to have devolved to another generic “what do new data folks don’t understand that experienced folks do” . Although some folks seem to find useful it has been done to death",What are the things you see other experienced data scientist overlook or downplay about work?,97v2as,new,29,9,9,0
Need some personal guidance. ,Anyone having any experience with working on neurological data recorded by an electroencephalograph?,97uykz,new,3,3,3,0
"I'm working on a project where the goal is to automatically update a tableau dashboard hosted on tableau server. 

Currently, reports are created 1am every night and are stored on an AWS server. I want to streamline a process to pull the data from the server, scrub it with R, and upload it to the proper tableau dashboard. 

My idea was to create a small linux server using a raspberry pi and have that run the initial script to pull the data and run a script to scrub the data, and store the raw data and clean data on a server with a date stamp, and then a generic ""Current Data"" that Tableau will read from and refresh. Is that even possible before I go down this rabbit hole?",Automating data pulls to feed into Tableau,97uo4f,new,6,6,6,0
"I just did my first data science internship and don't really have an idea about the industy other than the company I interned with.

So I wanted to know if there are companies that are generally more desirable to work at (Example, in compsci it would be Google, Microsoft, etc) and if those don't really exist in the data science industry then how should I decide which company to work at?

Thanks!",Top Employers in Canada,97uf3o,new,6,3,3,0
I'm looking for a good way to explain this function : [http://igraph.org/r/doc/cluster\_fast\_greedy.html](http://igraph.org/r/doc/cluster_fast_greedy.html)  in a few sentences to an audience who most likely has never worked with networks before. ,ELI5: Clustering based on fast and greedy optimization of the modularity score (network science),97u42o,new,0,1,1,0
"Hey,

I have a linear regression model. I want to see which variables were statistically significant or correlated the most to the output. At first I thought that if coefficients are closer to 1 or -1 that means they have correlation, but upon research I found that that is not necessarily the case. I've also seen that you can see increases in R\^2 as good ways to measure correlation.

I am not using sklearn's LinearRegression, but rather I am using scipy's curve\_fit and made a custom function (I was using a different model before, and am too lazy to switch back). Is there a method that can perform this analysis?",How to see which parameters contributed the most to a linear regession model.,97tz1t,new,25,2,2,0
"Background: I live in New Orleans. For those unfamiliar, it is more like a northern Caribbean city than it is southern U.S. Wild shit happens here daily that would break a normal city's news cycle for weeks. 

ANYWAY, among the many things we offer, we are known for supremely horrible road conditions. New Orleans' potholes have almost won multiple naming competitions for sports teams (look it up). 

Hypothesis: Because of this, I decided to explore the geography of our worst roads compared to our best. I have a theory that the best roads, and those that are fixed the fastest, happen to line the wealthiest Burroughs while those of lower income are neglected longer. 

HOW I NEED HELP: I have found useful data sources on this (http://www.city-data.com/zipmaps/New-Orleans-Louisiana.html; https://roadwork.nola.gov/home/) but need some help in how to best incorporate them for an interactive analysis. 

**TL;DR**: I'd like to test whether/to what degree wealth of an area impacts how likely road projects are 1) to be planned, 2) worked on, and 3) completed (as well as average time of completion by zip code. Finished product would ideally be an interactive graph overlaying zip code wealth and roads highlighted for work. Open to collaboration as a noob. *PLZ HELPPP*

*My background*: have methodological background (PhD student in epidemiology and biostatistics), very knowledgeable of R and importing/cleaning/managing data, not so with mapping or GIS

",Project Idea/Request for Assistance?,97ttxp,new,2,9,9,0
"[Link to article](https://hbr.org/2018/08/what-data-scientists-really-do-according-to-35-data-scientists), it's HBR so has a monthly limit on the number of free articles.

I'm an analyst turned data scientist turned Product Manager turned Manager of a small team of data scientists, all in the tech industry. I've been in the field for a little over 10 years, so what the article said resonates with me a lot.

I've gone from an era where we had to transfer large datasets in CSV through FTP and running our models in a remote SAS server to scalable machine learning in the cloud, but the one thing that hasn't changed is the need to translate complex business problems into data problems and then translating them back into useful insights to convince the suits to make changes.

I see data scientists fresh out of school who want nothing to do with exploratory data analysis, they want to get to ""building models"". To them, the article has an answer that's phrased much better than I could have.

> These days a great deal of machine learning and deep learning is being automated, as we learned when we dedicated an episode to automated machine learning, and heard from Randal Olson, lead data scientist at Life Epigenetics. One result of this rapid change is that the vast majority of my guests tell us that the key skills for data scientists are not the abilities to build and use deep-learning infrastructures. Instead they are the abilities to learn on the fly and to communicate well in order to answer business questions, explaining complex results to nontechnical stakeholders. Aspiring data scientists, then, should focus less on techniques than on questions. New techniques come and go, but critical thinking and quantitative, domain-specific skills will remain in demand.","What Data Scientists Really Do, According to 35 Data Scientists and quips from my 10 years in the industry",97ttot,new,37,173,173,0
"Hello, I'm starting grad school in the fall and will be taking some statistics, data mining, and machine learning classes over the next year. However they generally have pre-requisites of undergrad-level linear algebra and probability and statistics. While I'm familiar with the topics I never took formal classes in either, so was wondering if you all had any recommendations for online resources covering the basics that I could use to brush up for the coming year? Thanks.","Online textbook for the basics (lin alg, probabililty and stats)?",97te1e,new,5,2,2,0
"So I see a lot of posts on here where people worry about how much computer science one must know to develop ML algorithms. Or how much programming is involved in the process. After studying ML (Introduction to Statistical Learning) and learning some Comp Sci terms and getting algorithm practice, there are some thoughts I had.

-I feel like ML programming really comes down to understanding and transcribing mathematical notation to an algorithm written in a language that will be interpreted the same by a computer. For me this personally is not that difficult, and I really enjoy mathematically notating models to describe business processes

- This next thought go’s hand in hand with my last thought. Although it may be easy to transcribe a general ML algorithm, you may need to know the strengths and weaknesses in detail of many ML algos. This will allow you to develop your own algorithms that incorporate elements of many general algorithms to get a ML algorithm best suited for a specific business purpose. This certainly is difficult, and I feel like this more focuses around statistics and math, rather than programming in terms of difficulty.

- I have yet to learn Linear Algebra, so I’m going to sound like a doofus sharing this idea. Basically, it seems Linear Algebra is very focused on dealing with matrices in terms of data science applications. I feel like its good to know linear algebra just so you can incorporate the interpretation of matrices into mathematical notation for the sake of brevity. I would like to know what other uses there are for this topic (aside from matrix multiplication of course).

These are just thoughts Ive had through the learning process, and I would really appreciate any clarification so I don’t develop any bad perspectives.

EDIT: I just want to point out again I’m asking for expert opinions. Some people here I feel like are getting the idea I think I know what I’m talking about, and I don’t know why. I just want to reiterate I’m trying to learn from experts and would appreciate it if people wouldn’t downvote my post. This is a community meant for helping others. I get the feeling that people in this community get looked down upon if they don’t know enough, please correct me if I’m wrong.",I Feel Like ML Programming Isn’t as Hard as People Think It Is?,97svwc,new,16,0,0,0
"I just started using RMarkdown (have been working with R for a year now, so familiar with basic code writing in R); it's really handy but my documents don't look nice and structured. For example:

\- How can you change the color/thickness of line page breaks?

\- How can you change color of certain text pieces (to emphasize a word/sentence)

Any other tips are also welcome :)",Tips for a RMarkdown newby? Especially commands to make the document look nice?,97suwi,new,9,6,6,0
"Hi,

I am planning to do demo for reporting capabilities for an Enterprise customer, but they are not willing to share their internal data into our platform. However, they allow me to join them onsite with their DBA.

Is there a way to run data discovery/profiling on their Postgres 10 within a particular schema? And then use different tools to generate fake data that match those data profiles? With this, we can load that fake data to our reporting platform and address their security concerns.",Profiling Data and Generate Similar Looking Fake Data,97srjz,new,1,6,6,0
"Hi Reddit!

recently, I have written a Java implementation of the fairly new [Anchors](https://homes.cs.washington.edu/~marcotcr/aaai18.pdf) algorithm. 

However, as the algorithm is highly computation-intensive, I would like to add some performance improvements. 

The algorithm's authors formulate finding the best n-candidates as a multi-armed bandit problem and propose to use the pure-exploration KL-LUCB algorithm. 

As the evaluation consists of both repeated perturbation of the inspected instance and subsequent evaluation by the means of a provided model, this is where definitely most resources are being consumed. When an instance gets perturbed, all features not specified by the candidate may get changed. After each perturbation has been evaluated by the provided model, the anchor's precision can easily be calculated by relating correct predictions. This is how the best candidates get chosen.

Therefore, I'd like to introduce a parallel/batch pure-exploration multi-armed bandit algorithm to make use of threading. As there are no open-source implementations, yet and I am no mathematician, this haven proven very hard for me. 

I have found an algorithm called [GP-UCB-PE](https://arxiv.org/abs/1304.5350) which sounds promising. However, I am not even sure whether this algorithm may be applied to the problem depicted above.

What would you say is the best way to parallelize the evaluation? Is there any chance to do this at all?

Thanks!",Parallelizing Pure-Exploration in Multi-Armed Bandit Settings,97rv13,new,2,3,3,0
"I lurk on this subreddit and find most of the posts helpful. I have saved all the interesting posts for when I'm ready to do data science. Thank you for all of that. It's a wonderful community. 

I graduated with a Computer Science and Engineering degree in 2015. And due to the soul crushing pedagogy of my relatively poor college, I switched to art. I made short films, wrote poetry and did everything to avoid regular employment. Sometime, in the turn of this year. I realized I actually loved computer science before college and thought of giving it another chance. Applied to German Unis, got summarily rejected. 

Now I'm self learning. And my progress has been okay. Not got to the Machine Learning part yet. But have been doing EDA and visualization on R. 

My concern is by the time I start implementing ML, the market will have moved on to something else. As we can already see SPSS and other packages offering point and click sales prediction and stuff. 


Is it worth it, objectively? This is not an existential crisis. Just an honest question on whether I should consider academia? Because that's the only field where machines and software can't automate human resources.","I'm self learning data science from the ground up (Linear Algebra, Stats etc). However, I've a sinking feeling that whatever I'm learning is already implementable through UI based software packages. Is it worth it?",97qak5,new,56,69,69,0
"I have a dataframe with 5 columns that are characteristics from people that entered in the sales pipeline from my company, the first 4 columns contain characteristics from this people and the fifth column has information whether the the person has became a client or not(won or lost).

I am trying to use the multinomial naive bayes model to predict the probability of a person with a combination of specific characteristics(combination of 4 columns) to become a client.

My current approach was to used ""Label encoder"" to turn all the columns into integer(they were strings), after doing that, I made a cross validation and used ""predict\_proba"" method to get the probability of each client having the status of lost or won.

My current problem is, ""predict\_proba"" method returns only an array of arrays with the probabilities, I would like to know to which profile(combination of the 4 columns used as features) are related to that probability.

Link to econded data:

[http://www.sharecsv.com/s/f22433a1c92d31de886a68d3bff4a05d/aas.csv](http://www.sharecsv.com/s/f22433a1c92d31de886a68d3bff4a05d/aas.csv)

code:

    
        df = pd.read_csv('aas.csv') 
        
        dfCombined = df.copy() 
        
        ##-------------------------------------  Feature Engineering ---------------------------_##
        le = preprocessing.LabelEncoder()
        def gnumeric_func (data, columns):
          data[columns] = data[columns].apply(lambda x: le.fit_transform(x))
          return data
        
        #Transform string to integers
        intFeatures = dfCombined.columns[0:6]
        gnumeric_func (dfCombined, intFeatures)
        
        
        X = dfCombined.drop(['status'], axis=1)
        y = dfCombined['status'].values
        
        
        ## Naive Bayes ##
        mBayes = MultinomialNB()
        
        
        ## cross validation and predict probabilities
        scoresmBayes = cross_val_predict(mBayes, X, y, cv=5,method='predict_proba')
    
    
    ","scikit learn - Finding features related to probabilities returned by ""predict_proba"" method",97ogpg,new,15,18,18,0
"I'm working with an unbalanced dataset (10% positive), and I could really use some advice.

So, I used a 5M example dataset, did standard normalization of the whole dataset (bad practice, I know), and got reasonably good results with a 256-128-64 DNN Classifier. Something like 75% precision and 20% recall, and for my use case, a weak classifier like this is acceptable.

I decided to move the model to production, except this time I decided to normalize the data with respect to the training dataset only. When I retrained the same model, it became unable to learn anything, and I can't get it to perform better than the baseline (90% accuracy). Does it seem plausible that my results from before were a complete fluke because of how I normalized the points? If not, I must have screwed something else up.

**edit**: I came across tf.nn.weighted\_cross\_entropy\_with\_logits. Would this be worth trying?",Help with unbalanced datasets!,97nacj,new,7,6,6,0
,"Linguists, what's often overlooked by people from other backgrounds when using NLP/text analysis?",97jc5s,new,5,32,32,0
What are the best online courses to learn web scraping with Pyhon?,Web scraping online courses,97il3k,new,16,31,31,0
"My data is like this: there is a choice between two alternatives and the customer chooses one. Each time the alternatives are different. I would like to characterize a desirable alternative. I don't want to use a normal classification algorithm because I don't want to lose the information that one alternative was chosen over the other in the pair. Does anyone have suggestions for ways to do this, or types of algorithms I could research for solving this problem? Thanks!",How do you classify groups when the inputs are paired?,97ih2r,new,4,1,1,0
"Hello everyone!

I aggregated a sample of data from kickstarter and want to **draw insights from best practices of successful projects**. My samples included variables like the number of words in description, images in description or how many rewards the project offers. Of course the funding state (successful or not) and the pledged money is in the dataset as well. The dataset contains only projects from a specific category, where I want to get insights from.   


Im currently looking at the data in R and I can see some correlation inside the scatterplots. My question is, which method can I use to get real insights? What im interest in is to make statements like this: 

""*Projects with more than 2000 words in the description, are 5% more successful then projects with less words*""   


""*The optimal number of rewards for successful projects is 9 rewards""*   


I am a bit lost, so I am happy for every answer!  
",How can I get insights from this kickstarter dataset?,97i4jx,new,3,0,0,0
"I'm working on connecting two data sets together. One data set has coordinate data (lat/long) for each instance, and the other data set has ""multi-polygon"" data for each instance that looks like this:

    MULTIPOLYGON (((-74.07920577013245 40.64343078374567, 
    		-74.07913504647637 40.64333789954809, 
    		-74.07819773831595 40.64211481672276, 
    		-74.07884632409665 40.641995568528166, 
    		-74.0791223401088 40.64194431928626, 
    		-74.07965266950632 40.641855351552806, 
    		-74.08055489346589 40.64169150377349, 
    		-74.08148001617707 40.641550461625826, 
    		-74.08130714145031 40.64074191709323, 
    		-74.08110049694088 40.639922825339106, 
    		-74.08191207797016 40.6398059117602, 
    		-74.08194326513642 40.63993327788856, 
    		-74.0820464807701 40.640338526958104, 
    		-74.08228199570526 40.640600896453016, 
    		-74.08503312179074 40.64019785806871, 
    		-74.0872057798552 40.639895367647135, 
    		-74.08709163679771 40.64033437636213, 
    		-74.087018991146 40.640613790347864, 
    		-74.08682767812013 40.641338023476784, 
    		-74.08667746827268 40.64190963327233, 
    		-74.08652380457303 40.64256408357222, 
    		-74.08575006381034 40.642846120676055, 
    		-74.08496857468032 40.643130075816266, 
    		-74.08414352403344 40.64343089730628, 
    		-74.0820726845645 40.64420760543788, 
    		-74.08237118148979 40.64464507998435, 
    		-74.08028198256949 40.64479321566102, 
    		-74.07920577013245 40.64343078374567)))

As you can see this data basically draws an area. What I would like to do is to determine whether a coordinate is inside this area for each instance. Any ideas?",How to join multi-polygon to coordinate in R?,97h9il,new,4,1,1,0
"I ran into [featuretools.com](featuretools.com). I’m still experimenting myself but its examples looks limited in capability of the module. If anyone has used it for any real world project, is it worth your time? For which kind of data would you recommend? ",Is FeatureTools a good investment of time for NLP related tasks?,97gwsm,new,0,1,1,0
"Hi all, I am recently tasked with making a dashboard for some internal data, which should be an easy task for me. But when I think about how to deploy the dashboard the difficulties kick in. The minimum deployment I can do is using an excel and shared among user but it looks ugly. However if I want to deploy thro the web the difficulty racks up high as there are much more setup needed. Just wanna know how our fellow data scientist typically deploy your work to the end-user? 

Thanks for advice",How do typical DS deployments look like?,97gjt7,new,4,1,1,0
"I've just enrolled into my uni's data science program, and the current class I'm in, I was told we'd be focusing on the Python language. However, I'm also currently taking an online course on Coursera which focuses on R. I've had some experience with Python (Automate the boring stuff) but I didn't finish as it didn't really interest me (the language, or perhaps the IDE). My current school load isn't at all heavy so I will have a lot of free time (gonna do some online part time work). Would it be advisable to drop the coursera course or switch to one that's more python oriented, or are they similar enough (with respect to introduction, as the course I'm taking in uni is an introduction course only) that I can do both?",Bad idea to learn two languages at the same time?,97gcp8,new,5,1,1,0
"What is the current state of the data science field with respect to engineering?

I  am currently pursuing a masters degree data science/machine learning at  a large state university, but my undergraduate work is in biochemistry  and chemical engineering. All three of these fields really invigorate me and I've been poking around to see if a role exists that tackles problems with my understandings of each.

I've talked with advisors in all three fields and there doesn't seem to be much of a verdict. Could anyone lend me some wisdom?",Interface between Data Science and Engineering?,97g0ix,new,1,1,1,0
"Hey everyone thought I would post a little bit about my first year out of undergrad and first year as a data analyst. I previously posted [here](https://www.reddit.com/r/datascience/comments/6znbdo/data_analyst_one_month_in/) about a my background and a little bit about my job. 

In the past year, I have been promoted from analyst I to analyst II and have been accepted to GT analytics program, which my company has agreed to pay for 70% of tuition and 100% of other fees, while working full time.

I work for a natural gas company and continue to do marketing analytics. In my first year, I have gotten very very very familiar with SQL, and cleaning lots and lots of data (shout out tidyverse). I am lucky enough that my team is small and my work requires me to go from pulling the data, to cleaning the data, to ultimately building a model if necessary. 

There are certain things that I have learned through out my year as an analyst 

* Ask questions. Often if you don't know what is going on with the data someone else does. People tend to be helpful especially when you are starting out. 

* Assume the model you built is too good to be true if you are getting some amazing results. Often times there is some data leakage issue that you did not see immediately, but your skepticism will help you catch that. 

* Build things because there is a dollar amount associated with the knowledge created from your analysis. Nobody cares that you have a cool ML algorithm if it does not save or make the company any money. 

* Always have a simple baseline model to compare more complex models to. Losing easily interpreted coefficients should not be taking lightly. How much more accuracy is worth losing that occasional more actionable insight?

* Get comfortable with SQL, like really comfortable and be prepared to clean data and write views for other people... 

* Comment and version control your code. Bitbucket, github, vsts or whatever you use is your friend. 

* Create pipelines to help with reproducible work. Shout out [drake](https://github.com/ropensci/drake) and [airflow](https://airflow.apache.org/). 

Ask to help others on their projects and please please learn about the company, the business' needs, and goals before building some crazy model. Often times a simple approach is just as good as a black box ML model (not saying all the time). Overall my year as an analyst has been great and I have been fortunate enough to have a boss that is hands off and is willing to take the fall for my mistakes. I am looking forward to learning more about data engineering and going to transition into a sort of in between analyst and data engineer role.",Data Analyst One Year In,97exfe,new,38,130,130,0
"I'm trying to find some resources to start learning data engineering, there's handful of resources about data science/machine learning in udemy which I mainly use, but not much for data engineering. Do you guys have any suggestions?",Best resource to learn Data Engineering?,97ex32,new,5,5,5,0
,How to deal with imbalanced data in classification [tutorial],97eetl,new,13,75,75,0
"I'm taking a graduate level CS course (Introduction to Machine Learning) next semester where the professor expects us to implement machine learning algorithms in Python without existing toolkits, such as scikit-learn. I initially decided to take this course due to me wanting to push myself to be able to land a great ML job post grad, but I feel like I might not be adequately prepared for the course.

I come from a mathematics based background (currently doing my graduate degree in Statistics) and the only python knowledge I have is EDX MIT 6.00.1x (Introduction to CS using Python) and some side projects using pandas. The course will be covering nearly all of the well known ML algorithms (ANN, decision trees, nearest neighbors, etc.) I've previously emailed the professor and he has mentioned that he expects students to either be already familiar with Python, or to be able to learn as we go.

Am I in over my head? For those who have experience building ML algos from scratch, is it a difficult task to do?

EDIT: Thank you for all the help! I feel reassured.",How difficult is it to code and implement ML algorithms without using packages such as scikit-learn from a non-CS background?,97e74a,new,7,4,4,0
Hi what is the best click and use (non-programming) data cleaning and analysis software? Must have data merge capability.,Best data analysis software with cleaning capability?,97e0y1,new,7,1,1,0
"Hi all, 

First post here :)

I'm currently in the process of learning R and STATA on my own. I was wondering if there was any place where I could see the code for a full data analysis project? From like, building the data set to cleaning the data set and then the various analyses done. If possible, something in the social sciences that focuses on experiments or experimental design would be great. 

Is there anything like that? Or perhaps a YouTube Channel where someone goes through the complete cycle of a data analysis project? If so, I'd love to find something like this :)

Thanks! ",Finding comprehensive data project code,97cprb,new,2,3,3,0
,How do you become a data broker?,97ccw8,new,0,0,0,0
"Hey all, anyone know of any decent audio podcasts for learning data science /R /statistics?

Would like to make even falling asleep productive. ",Any decent podcasts?,97caae,new,13,28,28,0
"Anyone have any recommendations on books about tuning spark jobs? About executors, Jobs, etc. ?

Thanks!",Books on Tuning Spark Jobs,97c31s,new,2,2,2,0
"I am a rising senior looking for a job as a data scientist/data engineer. I just completed a internship and got an offer but I do not think I will be taking it for various reasons. I was hoping I could get some help touching up my resume so I can start looking else where. I would like specific help on the bulleted section where I summarize and describe what I did over the summer. I have pasted my resume below(I apologize for the formatting issues caused when pasting) and below that I will describe in full what I did for your reference along with reasons as to why I do not like my phrasing and how I could potential solve it. If you have any additional improvements I could make I would greatly appreciate them. Thanks for all of your help and I am happy to answer any questions you have regarding my resume or my internship! 

**start resume**


Objective: A hard working and high performing senior seeking a position as a fulltime employee to use my problem solving skills and passion to contribute to a Software Development Team.

.

Education:
University of Rhode Island, Kingston, RI                                     Expected Graduation: May 2019
Bachelor of Science in Computer Science                                  GPA: 3.69 / 4.0

.
	                      	           
Work Experience:

DW Developer and BI Analytics Intern:
		
Carbon Black						      2017-2018

1100 Winter Street Waltham, Massachusetts 02451

* Designed and built an automated data gathering program
* Cleaned data and created a functional data model
* Delivered analytics to the customer support team and community management, to describe and diagnose customer support performance and community activity
* Worked in a team throughout the entirety of the application development life cycle 
* Received a job offer to become a full time employee

.

Relevant CourseWork:

CSC 392 - Data Science - studied data driven programming in Python; descriptive statistics, data visualization, and foundations of predictive data modeling and machine learning; accessing web data and databases; distributed data management

CSC 212 - Data Structures - Explored run time, memory complexities, and data structures and developed efficient algorithms

CSC 305 - Software Engineering - Studied and practiced Agile software development as well as various software design patterns

.

Awards:|Skills:
---|---
Dean's List: | -   Python	-   Qlik
Fall 15, 16, 17, 18 |-   SQL -   Salesforce 
Spring 15, 16, 17  | -   Visual Studio -   Confluence and Jira
Centennial Scholar |  -   Pandas 	-   SAS

**resume end**

What I did: 

I created a program in Microsoft visual studio that daily calls to the slack web api using zappyssys  to return a list of conversations, users, etc.(where the first bullet comes from). From there I wrote C# programs that converted unix epox times to EST and added missing columns of data to the return of the slack api. Then, I created a producer, consumer, and neutral data model in qlik sense; so that I had all of the desired functionality when creating analytics(where the second bullet comes from). Finally I built analytics though the usage of graphs in qlik sense that displayed and diagnosed the data (the 3rd bullet). 

Why I don't like this:

I feel like it reads like a list and is far too in depth, along with awkward phrasing and the potential to sound like I have no idea what I am talking about. 

Potential Changes:

1. I could turn bullet one and two into one bullet point so it would read like this:
designed and build an automated data gathering program from which I cleaned the data and created a functional model
1. If there is a well know high level process that includes the data gathering, cleaning, and data model creating step I could just include all of these bullets in that process
1. Change the phrasing to make it sound more professional 
1. Leave it alone because I am over thinking everything

Thanks to those of you who have made it this far, it means a lot to have people out there who want you to succeed. Once again if you guys have any questions for me I would be happy to help.  

		         
				        
	                                 
",Help with phrasing the work I did on my internship for my resume.,97bsqm,new,8,33,33,0
"Hi, I am thinking to build a toxic comment analysis model and It should be able to take a user input and classify the comment based on the training given.

Is this a good approach( to test a single user input with a trained set?)

The testing sample here will be only one. Does this mean it overfits data? Is this the right way?

Any tutorials on this?

Thanks.",Sentiment Analysis/Toxic comment analysis for a user input,97bpko,new,3,7,7,0
"For the sake of clarity, I am \*not\* referring to the weekly Python script for analyzing data. Rather, I mean software development at a level comparable to traditional software developers. E.g. you write quality code,  including unit tests, which becomes part of a larger architecture and is eventually deployed to the customers.  ",How much time do data scientists spend on pure software development tasks?,97al54,new,15,9,9,0
"In finance, the term “regime detection” refers to taking a time-series (typically a market indicator) and identifying different periods that are governed by different generative rules. At its most basic, regime detection is used to identify bull and bear markets. The different regimes are commonly analyzed via a H(S)MM, though other approaches like regression and deep learning are also used.

I can find very little about regime detection outside of finance. Is this generally a problem that’s not well studied in other fields, or is it known by different names? I would be particularly interested in resources or pointers on it's use in political science and social network analysis.",Other terms for regime detection,979t4h,new,6,2,2,0
"Hey! I'm trying to understand good ways to impute data into null values in my dataset. Recently I was only using mean imputation, however I know it's not the best way. Do you guys have any ideas or articles about other methods of imputing data?

Thanks!!",Imputation Methods,979nx8,new,27,12,12,0
"Hey everyone,

I'm trying to understand sklearn's [explained\_variance\_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score) but can't find any information online. Is it the relative percentage reduction in std deviation from pre and post modelling? Any recommended texts/blogs to read the equations and understand more fully?

Thanks for all help!

Edit:

For the specific model i'm looking at the r2 score and explained variance score are the same, are they equivalent?",Understanding sklearn's 'explained_variance_score',977nch,new,3,21,21,0
How do someone non-academic find people from academia/industry to collaborate on writing research papers ? Or Where to find potential problems or research topics to write a research paper on ? ,How and where to find people to collaborate on data science?,9762gb,new,13,10,10,0
Should I turn the title of my project into a link or should I just put the link on the bottom of the resume?,How to attach link to my projects on my resume?,975p7r,new,4,5,5,0
"To give a little background on this question...

I'm studying CS and I have a strong interest in data and economics. I'm trying to construct a learning path and I'm running into a wall with the ""learning paradox,"" (a fun term to google). My application for data science is more academic than business oriented, and I can't seem to find basic resources on research methods using data science.

So that all leads me to the most basic question: What category of science does data science fit into?

What I really need is a term for the research methods so that I can find some resources to actually LEARN them. Alternatively, if anyone has wonderful resources to that end I would be eternally grateful for your wisdom!",What kind of research does data science do?,975nsj,new,4,3,3,0
"I am interested in slice sampling and Gibbs sampling to estimate parameters for a complex HMM, and I am seeking a good reference on conjugate prior/posterior relationships to set up the samplers. I'm looking for something beyond the depth of [the wiki page](https://en.wikipedia.org/wiki/Conjugate_prior) on the topic. What's your favorite go-to to look up conjugate priors?
",Bayesian Q: What is a good reference for conjugate prior/posterior distributions?,974ul8,new,22,11,11,0
"Hi all,

This year I will teach Evolutionary Computing and also Artificial Intelligence (although the latter more focused on machine learning). Do you have any suggestions, ideas or examples of  2-3 month projects that could have a positive impact on society? 

I usually like to propose projects based on games, but I would like to spice up things a little this period. Thanks in advance!",Social contribution projects?,973x06,new,2,7,7,0
"I keep seeing this awsome data analyst position for twitch. Dang... i wonder if i can get a hold of some twitch data and do some interesting story telling to get noticed by recruiters. 

You know like how twitter and Facebook have their own public anonymous data.",Is there a way to get twitch.tv data for a data science project,9736ko,new,3,3,3,0
"I've been a Data Analyst for 3.5 years now and I'd realizing that more and more advanced jobs basically require DE skill set. Fortunately, I'm actually really interested in DE more than DS (sorry, posting on this sub since it's the most active Data related sub I know of). I'm currently reading this Medium blog [https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7](https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7) and also looking to go through the Data Engineer path on [dataquest.io](https://dataquest.io), but what else can I be doing? Is it possible somehow to transition to the DE side of things?",How do I transition from a Data Analyst to a Data Engineer?,972pnh,new,4,12,12,0
"Hey everyone. I wanted to post this here because I think this sub is great and what I designed will resonate with your market. I'm a developer/engineer by trade. Building risk management and data processing services which use machine learning and A.I. to interpret massive amounts of data in realtime to look for trends, patterns, and anomalies. I'm an exec today for a massive bank, so I'm off the front line. But I work with many data scientists to build these networks and process billions bits of data for the fintech space. Having just deployed a new risk management platform I've noticed much more new cheap/simple technology has entered the market and it would allow for me to create a prototype on this for super cheap. I'm hoping to get everyone's feedback on this and maybe find some friends to help me churn it out.

The problem I want to solve is the recent problems with Fake News ooccurring on both the left and the right. There needs to be an open source platform accessible to everyone which is owned by the users which follows a formula in order to promote factual news, real news. All the other companies that do this does it as a business and since they need click content they like to take a personal stand on the currrent events to appeal to their user base. I want to avoid that by not condemning fake news, but anonymizing real news and ranking it into an easy to consume news feed that's open source and free of adwords, owners, investors, stake holders.

I started doing some digging for a minute and that turned into an entire day. It's actually fairly doable. Here's the components of it and how to achieve the results needed. Here's the fundamental design and development structure of it along with the business model. Please let me know if there's anything out there that's similar, free, not owned by anyone but the users. I'll keep this brief unless everyone thinks r/datascience can help me build this for the world for just fame and glory. No big deal, just fixing the information in the information world and probably shut down some massive media networks.

>What to Do: Provide a totally unbiased and anonymous news feed to people that analyzes and ranks the top events of the day/week/month/year from 1 to 100 on facts and importance to you baseed on your user behavior and residence. The probability of factual events  
>  
>Where to Play: Digitally. Entire bare bones app provided for free to users on mobile. Also provides a RSS feed for organizations to display in a form field.  
>  
>How to Win: Deliver only factual information to the users using a publicly available formula and data gathering models. Don't make it a business. No financial influences. Only report what is a fact coming from a primary resource.Provide a paper trail for each article so people can see how the platform responded. Become the oracle by which the media validates themselves to the world or condemns another network.

Basically I want to turn the news into a machine. Similar to the 50s. Who, What, Where, When, Why. Its true, because the machine said so. It will be hard to do because it can never turn a profit, no one entity owns it, no one works for it. Data Driven News. Peter Thiel can't fund it. Donations are anonymous. Everyone gets to vote on new features and functionality. The machine operates according to an open source code base and a operational policy. To the layman...a constitution. This needs to happen before someone like a Elon Musk does it makes tons of money. Then again the machine only needs electricity. Its not interested in money, therefore no motives.

Before I share how we can do this on the cheap and keep it simple. Let me know if I should continue with the features/functionality and specs.

EDIT; I'm going to keep this thread open for a while. If you work in data sciences/tech send me an message to volunteer along with your contact info, prior work/expertise.

PHASE 1: Now

\- Opening up this side project to anyone with experience who's also passionate about using data sciences for the good of all.

\- Also looking for validation that the problem we want to solve is being solved in a way that makes it impossible for anyone to influence The Machine.

PHASE 2: 

\- Formalizing the preamble to the machine's archtectural structure and laws

\- Scoping of the public policy ",Fact Checker: Design Concept: Good? or Bad?,972j4g,new,10,5,5,0
"I'm trying to figure out how to calculate some simple dataset statistics (mean, stdv) on a large dataset. Is there an easy way to do this? I tried sitting down and learning Apache Beam, but there is a lot of overhead and the documentation sucks.

**edit:** Thank you for all your responses. I should clarify what I'm trying to do. I know that there are ways to calculate the stdv and mean using numpy, but this isn't scalable if we are dealing with large datasets. In this particular case, I'm using ML Engine and to normalize the dataset, I will calculate the mean and standard deviation for each column so that I can do the normalization in TensorFlow. I want to learn a framework like Apache Beam that can compute this, but I was wondering if there are better methods (for example, sampling as /u/chgrin said).

What I ended up doing was this: Apache Beam has a nice GroupByKey => MeanPerKey function, so I did two passes over the dataset: 1) compute the means per feature 2) compute the squared difference of each value and its mean | compute the mean squared difference per feature | take the square root.",Calculating the standard deviation for a large distributed dataset,972ibt,new,10,3,3,0
"I am a cognitive neuroscience grad student and am using Pandas for the later stages of data analysis. Until recently, I've been hesitant to learn about multi-indices in Pandas, since it seemed like just an extra level of complexity on top of everything else. However, I've been reading about them and they seem quite useful. I had several questions about them:

1. What are some good rules of thumb for which columns should be designated as columns, and which as indices? It seems to me that any columns containing information that contain identifying information for data (e.g., subject name, experiment name, etc.), rather than the data itself, should always be designated as indices, and ideally you should have a set of indices that is collectively sufficient to uniquely index each observation. By contrast, columns should contain the data itself (e.g., subject's response on a given trial) Additionally, indices should never be information that you want to perform operations over (e.g., taking the mean); they should only be used as aids for quick lookup, assignment, and groupby operations. Is this roughly correct?
2. Are there any benefits to hierarchal column labels (i.e., when you have multiple layers of column labels on top of the dataframe when you view it) besides personal naming preference? There doesn't seem to be an obvious advantage to me to having the hierarchal column label like ('prefrontal\_cortex','mean\_activation') vs. a flat column label like 'prefrontal\_mean', besides as a personal organizational aid if you so choose.
3. Finally--I've been toying around with doing groupby operations, trying it with grouping by columns vs grouping by those same columns reformatted as indices. I \*thought\* it'd be faster as indices, since the whole point of indexing is to get the fast lookup times. But instead, I'm finding that it's roughly the same speed for small-to-medium dataframes, only yielding substantial gains for huge dataframes (30% boost for a dataframe with 4 million rows). Is this typical, or are there ways to further boost performance?

Thanks!","Rules of thumb for structuring data (indexes vs. columns, when to use hierarchal columns, etc.) in Pandas?",9725ng,new,3,12,12,0
"I've got some education budget left and am looking to step up my data analysis skills.

Right now most of our ""analysis"" is done utilizing SQL/Analysis Cubes/SSRS.  It's mainly report building more than anything else.

I'm looking to expand my skills in R, more advanced SQL, and Power BI.  I know these fall a bit shorter than a full blown Data Science program but I figured it sets the basis for it and you all may be a good resource to get me started.",Best R/SQL/Data Analysis Courses,971w0j,new,11,3,3,0
,Humble Bundle Big Data: Any good?,9710jh,new,28,58,58,0
,Lessons Learned While Building A Data Science Platform With Airflow (Interview),96zuzu,new,0,1,1,0
"I’m less than 2 years from my 50th birthday.  I’ve always been keen on statistical analysis & through my career I have used everything from Lotus 123 WYSIWYG scripts, LotusScript, Excel & VBA and, along the way, picked up SQL & stored procedures etc.

Now, I think I can get by with these tools but I remember (just about) 25-30 years ago thinking how we could be moving so much faster if the IT manager wasn’t so busy defending his mainframe.

So ... now that I’m the old duffer department head, what can R and/or Python offer our analytics that I can’t get with my tired & trusted toolkit?  If I send my boys off to learn R & Python, except for making them more valuable to the competition (!), what are the tangible business gains?",Learning R & Python,96zu8t,new,4,7,7,0
"I have just come across this:

```python
>>> numpy.array([None, None]) == numpy.array([None, None])
    array([ True,  True], dtype=bool)

>>> pandas.Series([None, None]) == pandas.Series([None, None])
    0    False
    1    False
    dtype: bool
```
(Numpy version: 1.13.1, Pandas version: 0.20.3)",TIL that Numpy's None != Panda's None,96z7uw,new,19,36,36,0
,Behavioral economics and AI-driven decision making,96z6rx,new,0,7,7,0
"Welcome to this week's 'Entering & Transitioning' thread!

This thread is a weekly sticky post meant for any questions about getting started, studying, or transitioning into the data science field.

This includes questions around learning and transitioning such as:

* **Learning resources** (e.g., books, tutorials, videos)
* **Traditional education** (e.g., schools, degrees, electives)
* **Alternative education** (e.g., online courses, bootcamps)
* **Career questions** (e.g., resumes, applying, career prospects)
* **Elementary questions** (e.g., where to start, what next)

We encourage practicing Data Scientists to visit this thread often and sort by new.

You can find the last thread here:

[https://www.reddit.com/r/datascience/comments/956n5i/weekly\_entering\_transitioning\_thread\_questions/](https://www.reddit.com/r/datascience/comments/956n5i/weekly_entering_transitioning_thread_questions/)",Weekly 'Entering & Transitioning' Thread. Questions about getting started and/or progressing towards becoming a Data Scientist go here.,96ynxl,new,52,17,17,0
"I've been searching up and down for dirty/untidy data to practice with in R, and have found nothing so far. Anyone have any ideas about this? :\\ any links,resources? ","Sources of messy, nasty data to clean?",96ylyr,new,32,40,40,0
"I know public policy isn't directly related, but I did some statistical analysis for this prof. as a research assistant.",Asking a public policy prof. for a letter of recommendation for MS Data Science?,96w7uz,new,6,2,2,0
"Hello, I am a college student who is currently 1 credit away from graduating with my bachelor's degree in mathematics. I am afterwards moving on to work on my mathematics-focused MSDS in the spring and need this 1 credit to graduate on time.

I am looking to apply to do a 1 credit independent study through my mathematics department, but am looking for a topic to do it on that would further my knowledge of data science and falls into a mathematics study.

For background information, the data science related math courses I have taken are Linear Algebra, Advanced Linear Algebra, Probability Theory, Mathematical Statistics, and am taking Intro to Statistical Learning in this last semester.

Side Note: I am just looking for a topic and how it relates to data science. I am not looking for a whole syllabus. I just plan on making a syllabus for each good topic and presenting them to the appropriate professors at my university.",Independent Mathematics Study Topic Suggestions? (That is Useful in Data Science),96v5xn,new,4,1,1,0
"Percentage wise, how much of your time do you spend on analysis versus data manipulation/cleansing to get your data ready? Manipulation would include pulling data in my book.

I know I spend 80% of my time on manipulation but was wanting to see if I skew further than others

",Data: Analysis vs Manipulation,96ug5u,new,7,0,0,0
"Having OHLC prices stored with according technical indicators values, how would one analyse the correlation/affection/relation of each indicator or a group of indicators to the price?
Goal is to see which of them could predict the future price, momentum, volatility, patterns etc.
",How to analyse crypto market technical indicators?,96s14i,new,0,1,1,0
,Deploying deep learning with Java,96rnzc,new,1,2,2,0
"Hello,

I live in Europe and I graduated with a master in data science. I am incredible lucky to have received an offer from Google to work as an Software Engineer in a different country from my own, and an offer to do Data Science in a mid-sized (~150 people) company in my country which look interesting and fun.

The cost of living in my country is similar to the cost of living of where Google is located, but Google is paying 70% more the salary for the S.E. as compared to the salary I would receive as a Data Scientist. I really like living where I am right now, and even if the salary is half I would still be able to live reasonably comfortable. 

Most people I talked from my Master's strongly recommend me I go to Google since even If I want to do AI later or a PhD, having Google in my resume its gonna be a big career boost, and additionally I might have the chance to do AI in Google If I am lucky.

Say I work in Google for 2-3 years and then I want to change a company to do AI, how would you evaluate the experience I have in combination with the master? Is the brand name of having worked in Google really THAT important later on in my career, or just cscq ""wrong"" advice?

I appreciate all the feedback.",Data Scientist in mid-sized company vs. SE in Google,96puhm,new,14,11,11,0
"I am trying to figure out the best plan of attack for a certain type of marketing optimization problem I have...

Background: we send out a lot of mail. Certain subsets of customers respond positively to the mail while others aren’t necessarily motivated by it. I want to find pockets of customers based on demographics and buying behavior that we could cut mailing from. 

Data: we have experimental data where 50% of people received communication via direct mail + email while others just received email. 

Desired output: “we’ve found little difference in sales for demographic ABC whether they did or did not receive direct mail. Therefore it’s safe to cut their mailing.”

Long-winded approach 1: running t-test where i split by all different demographics. Example: grab all <25 year olds and run a t test on sales between those who did and did not receive a direct mail piece. If there isn’t a huge difference - then cut mail to this group. 

Multi-step approach 2: run log regression to predict those that’ll shop, then use a regression method on those predicted to shop to see which demographic variables are inconsequential. To be honest I feel like I’m throwing darts blind with this method... and I’m not sure exactly how I’d frame it up. 

Are there any other ideas on how I’d basically answer the question - where can I cut mailing while minimizing risk? Knowing that I have an extensive data set of experiments conducted where folks randomly did or did not receive mailing and we tracked their sales over the course of the campaign. It’s as if I almost need to find the most inconsequential variables. 

Thanks!!!

 ",Looking for some ideas to tackle a marketing optimization problem...,96png1,new,2,2,2,0
,Academic Torrents - Making 27TB of research data available (including datasets),96pkz2,new,12,267,267,0
"I've always had a very hard time understanding these pipes.... %>% 


first question. Does it just put what is on the left of the pipe into the function that is on the right, in the first position? That seems to be what it's doing I see...



Gapminder %>%
Filter( country==China)



so here in this example I'm going to guess that it's automatically putting gapminder into the first argument of the filter function and it's automatically adding a hidden comma... Would that be on the right track? 


but sometimes I see that they chain these together three or more times and then you have a bunch of them one after the other. Is it literally just like a bunch of Russian nesting dolls just putting one inside the first argument of the other repeatedly? ",Some questions about Magrittr pipes in R... Can anyone help?,96pea2,new,4,0,0,0
,A quick and dirty exploration of housing prices in Amsterdam [OC] [x-post /r/dataisbeautiful],96o5gp,new,4,3,3,0
Are there ways to speed this up to down an hour? Or even shorter? Thank you.,Need suggestions: Trying to save Pandas dataframe with 1.7 million rows as csv. It takes hours to finish.,96o4p2,new,14,3,3,0
,The Trillion Dollar Question - Simply Statistics,96mafs,new,1,2,2,0
,UX Design Guide for Data Scientists and AI Products,96llna,new,2,35,35,0
"I'm a physician and clinical informaticist. I've set a  2 year goal for being able to do some small scale projects using machine learning using data from my health system. I'm working my way through brushing up on python and pandas for data wrangling.

I'm wondering if there are good resources that give best practices on how to best prepare Healthcare data for machine learning algorithms.  Specifically how to deal with  diagnoses, icd9 and icd 10 codes, medications (specific med versus med type, dosing).

Is there a book or course you'd recommend or is reading academic papers from medical journals going to give me much detail on how they prepared the data?",Resources on dealing with Healthcare data,96jx58,new,10,3,3,0
currently using datacamp and it has something called gapminder but I don't actually know what that is. Anyone have any idea about this package? Not currently at a computer or I would run some commands to try and figure out what it is. The internet seems to yield no useful result,What the heck is gapminder in R?,96jke6,new,7,0,0,0
,Good resources for text analysis and NLP?,96ji20,new,11,54,54,0
,"Started playing around with Tableau, what do you think?",96iwz8,new,23,10,10,0
"If i'm already competent in Python and Matlab, is there really a need to learn R? Will I be at a disadvantage in terms of employablility?



edit: i should not ask questions i already know the answer to. i was being lazy sry",Is learning R really that useful?,96ilya,new,61,40,40,0
Hi! My group and I will be doing a paper which focuses on Business Intelligence. Any reference/s which will support our topic is greatly appreciated. Cheers!,Credible sources/references for Business Intelligence,96hukg,new,5,0,0,0
As there are too many platforms available online where one can learn DATA SCIENCE but the matter of fact is that no one know whether the stuff u r paying for worth your investment. So can you please suggest me a good platform to learn.. or any other resources . PREFERABLY ONLINE,Can one suggest me good learning resources regarding data science??,96g933,new,2,0,0,0
"Hi, I hope this is the right sub to ask this in, if it's not then sorry about that. I recently graduated with a bachelor's in physics, but now I want to change my field. I'm from India, if that matters.

I've found data analytics interesting and I would like to pursue a career in it. I understand that this might sound a bit naive coming from someone with very little programming experience (a touch of Python, and a bit of experience with C++ in my final-year thesis), but it does look like something I would find engaging enough to not lose interest, as well as something I could be good at.

I've looked into joining institutes near where I live that offer 'complete' programs, but they *may* not be feasible (still looking into it). In any case, I do have at least a year's worth of time on my hands to do nothing but study 24/7. I've attempted to create a list of topics that I've come across, and would like some input. They're compiled from the brochures of the institutes I've visited, as well as some research on the internet over the past couple weeks. I'll mostly be studying from online resources (that I'll have to find) but if necessary I can look for classes for specific subjects. **I would like to know what I actually need to learn thoroughly, from the following list**.

* Statistics and probability (duh)
* Linear Algebra (took a couple courses in my second year but can brush up/study more)
* Python (Numpy/Pandas/Matplotlib/Seaborn/Scikit-learn/other necessary libraries) & R - syntax, predictive modelling, neural networks, regression analysis, bayesian network models, decision trees, SVMs, NLP, data/text mining, etc.) 
* SQL 
* Excel (macros/pivot tables/etc)
* SAS
* SPSS
* Tableau

I've not include some of the things from the various brochures, such as Spark and Hadoop as those were not listed everywhere but if they're necessary then I'll have to learn that too. I've been told IRL to study programming in C++ and Java alongside as well, since I don't come from a programming background, to generally get better. Ultimately, I want to get a job as an data analyst (any position) and keep learning more on the job, to improve my skill-set and advance.

Any advice would be appreciated. Thanks in advance.",Some questions regarding data analytics.,96fccw,new,4,1,1,0
,Big Data Day LA is today (8/11) at USC!,96eqrz,new,1,0,0,0
"## Hello Everyone,

I have been Experimenting with ML5.js for sometime now, I would Like to share my leanings with the community.

[ML5.js Logo](https://i.redd.it/qvn58e4tvef11.png)

**ML⁵.js**  is a recently developed high level Library which aims to make machine  learning approachable for a broad audience of artists, creative coders,  and students. The Library is developed at the **New York University and**  has been publicly released on \*\*July 2018.\*\*The library provides access  to machine learning algorithms ,task and models in the browser,  building on top of  [TensorFlow.js](https://js.tensorflow.org/)with no other external dependencies.So, It can be compared to Keras. [**ML⁵.js**](https://ml5js.org/) is built over [TensorFlow.js](https://js.tensorflow.org/)and it uses the functionality of [TensorFlow.js](https://js.tensorflow.org/)at the backend but makes life easier for people who are new to Machine Learning arena.

https://i.redd.it/mr1ffrkvvef11.png

[**ML⁵.js**](https://ml5js.org/) is built with a Motive to simplify things out for beginners. We can compare this to [Keras](https://keras.io/).  The Motivation behind Keras was to make ML/DL in python so Simple that  it can be used by Beginners. Similar is the case with ML⁵.js..

This  is possible by making a wrapper around the Tensorflow.js library and  use all the functionality at the backend. So Intuitively, It is an Easy  to use API for TensorFlow.js.

## Getting Started with ML⁵.js

We can use [**ML⁵.js**](https://ml5js.org/) by  Referencing the [latest version](https://unpkg.com/ml5@0.1.1/dist/ml5.min.js) of it in our project, by just using a script tag in an HTML file as below:

    <html>
    <head>
      <title>Getting Started</title>
    
               <script src=""https://unpkg.com/ml5@0.1.1/dist/ml5.min.js""></script>
    
        </head>
       <body>
      <script>
           // Your code will go here
         </script>
       </body>
    </html>

That’s all! 💥

You are ready to go..

Please Consider watching this Video for Detailed explanation on ML5.js :-

r/[https://youtu.be/D1jxmyQwM1A](https://youtu.be/D1jxmyQwM1A)

## Promises and Callbacks

[**ML⁵.js**](https://ml5js.org/) supports both **error-first callbacks** and Promises in all methods.

## Using Callbacks

**ML⁵.js** uses a pattern referred to as an **error-first callback**:

**For example —**  if you are using the \*\*imageClassifier()\*\*method, you will need to construct it in the following way:

    // Pass a callback function to constructor   
    const classifier = ml5.imageClassifier('MobileNet', function(err, model) {        
    
         console.log('Model Loaded!');     
     
    }       
    
    // Make a prediction with the selected image and pass a callback function with two arguments   
    classifier.predict(image, function(err, results) {       
     
         // Check for errors. If no errors, then do something with the results       
    
    });

Error first callbacks is a convention common to many JavaScript libraries that is implemented in **ML⁵.js**. The language JavaScript itself does not enforce this pattern. Before implementation, we need to understand that most **ML⁵.js** methods and functions are asynchronous ( *because machine learning models can take significant amounts of time to process inputs and generate outputs!).* 

## Using Promises

[**ML⁵.js**](https://ml5js.org/) also supports [Promises](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise). If no callback is provided to any asynchronous function then a Promise is returned.

With Promises, the image classification example can be used in the following way:

// No callback needs to be passed to use Promises.

    ml5.imageClassifier('MobileNet')     
      .then(classifier => classifier.predict(image))    
      .then(results => {     
           
           // Do something with the results        
     });

## Image Classification Using ML⁵.js - An Example Casestudy

## imageClassifier()

**ML⁵.js**  can use neural networks to recognize the content of images.  ml5.imageClassifier()is a default method to create an object that  classifies an image using a pre-trained models like MobileNet etc.

The **ML⁵.js** library accesses these model from the cloud. 

**Let us build a concrete example:-**

We will use the p5 Library along with **ML⁵.js.** p5 is a Powerful yet simple library to use in Javascript.You can find more details [here.](https://p5js.org/) You can always use Vanilla JavaScript or other frame works of your choice with [**ML⁵.js.**](https://ml5js.org/)

Before we start with the Javascript part,We will need to host a local server using NodeJS. 

**Below is the Code:-**

    let express = require(""express"");  
    let app = express();  
         
    app.use(function(req, res, next){    
          console.log(`${new Date()} - ${req.method} reqest for ${req.url}`);    
         next();  
     }); 
          
    app.use(express.static(""../local""));      
     
    app.listen(8081, function(){   
          console.log(""Serving at 8081"")   
    });

After the Local server is Successfully up and Running, We can start off with the coding of HTML and JS files.

**Index.html**

    <html>      
     <head>   
           <!-- importing p5 library into the project -->       
      <script src=""https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.6.1/p5.js""></script>
        
          <!-- importing ML5 library into the project -->     
      <script src=""https://unpkg.com/ml5@0.1.1/dist/ml5.min.js""></script>   
    
           <!-- importing p5 addons library into the project -->       
      <script src=""https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.6.1/addons/p5.dom.min.js""></script> 
       
           <!-- importing main.js  into the project -->      
        <script src=""./main.js"" type=""text/javascript""></script>       
    </head>  
     <body>       
    </body>  
    </html>

**main.js**

    //initialization of the model object  
    let mobileNet;
    
    //setup function is the Startup function in P5   
    function setup()   {
      //create canvas on the page   
       createCanvas(400,300);    
    
      //initialize the image in a variable       
      img_dog=createImg('./dog.jpg',imageReady);    
    
      //hide the image from displaying it on the Page    
      img_dog.hide();        
    
      //initialize the mobilenet object with a callback       
      mobileNet= ml5.imageClassifier('MobileNet',ModelLoaded);      
    }
    
    //callback function indicating  the image is ready and is Displayed on the Canvas   
    function imageReady()   {
    
           //Displaying the image on the canvas     
           image(img_dog,0,0,400,300);   
    
    }       
    
    //callback function for when the model is ready for prediction   
    function ModelLoaded()   {       
           console.log('Model is ready');       
           
           //predicting the image after the Image and Model is Ready, Its again need a callback because prediction takes time   
           mobileNet.predict(img_dog,result)  
     }     
      
    //callback function to get the results   
    function result(err,res)   {    
    
           //check for errors   
            if(err)       
            {   
             //log the error if any    
             console.error(err)      
            }    
           else
           {   
            //log the result    
            console.log(res);  
      
            //get the label from the JSON result   
           let label = res[0].className;     
       
            //get the probablity from the JSON result   
           let prob = res[0].probability;  
         
           //creation of DOM and printing the label and probability    
           fill(0);    
           createP(label);    
           createP(prob);   
        
          }  
     }

That’s it..We have Successfully Implemented a Image classifier using **ML⁵.js.**

You can go to [http://localhost:8081/index.html](http://localhost:8081/main.html) and check the results. The Screenshot is as below :-

[Screenshot of Web APP](https://i.redd.it/fm7muu41wef11.png)

>Note : This above example  was not focused on UI rather it was focused basically on getting the Basics of **ML⁵.js** clear\*\*. UI can be improved and there is no limit to UI.\*\*

Please Consider watching this Video for Detailed explanation on Image Classification using **ML⁵.js** :-

r/[https://youtu.be/NbGdBp7Dccs](https://youtu.be/NbGdBp7Dccs)

# My Take on ML5.js

This is excellent for coders who are familiar with JavaScript & HTML and are trying to find their way in the ML/DL world!

It  makes things a lot simpler for people coming from a non-ML/DL  background, but who are looking to understand this field.It makes  machine learning approachable for a broad audience of artists, creative  coders, and students.

The use cases for this are many, and I personally think it’s something we need at the moment.

What do you think of ML5? Let me know your views...

**Thanks For reading and giving your Precious Time.**",My Learning with ML5.js - A Beginner’s Friendly Machine Learning for the Web using Javascript,96epcn,new,1,0,0,0
,What are /r/analytics unlogged values?,96e439,new,0,0,0,0
"Are there any guides, resources, lessons learned, or just stories about applying data-scientific methods to Daily Fantasy Football competitions, like those on DraftKings or FanDuel?    


I would like to experiment with these tools and methods on Daily Fantasy Sports as a side project this football season :)",Data Science Resources for Daily Fantasy Football,96e230,new,4,1,1,0
,"Lana Del Rey's discography analysis with frequencies, embeddings and t-SNE",96dsnr,new,0,3,3,0
,"Phys. Rev. X 8, 031039 (2018) - Spreading Processes in Multiplex Metapopulations Containing Different Mobility Networks",96dl85,new,0,2,2,0
"Im curious as to peoples experience with those who work as data scientists but were trained as Economists. I am currently studying Economics at the masters level but wanting to go into data science. I always wonder whether the Statistics/programming from Econometrics is really enough to make it in the data science field which seems to be alot more heavily programming based. I think one advantage of Economics is that it is a very strategic and often different way of thinking of problems and how to solve them... but is that enough? My programming skills are pretty preliminary but I am getting better everyday, but am I wasting my time trying to get into data science with an Econ background without actually being formally trained in high level Stats courses or Comp Sci courses?",Economics and Data Science?,96dgdo,new,9,15,15,0
"Hi guys, been spending some time with ISLR and the Data Science Design Manual lately.

Thought I'd share the cheatsheet that I ended up creating- covers a bit of probability, statistical learning, modeling, and machine learning.

Hope it'll be helpful to those just starting out or those who might need a quick refresher (sorry if it's not particularly math heavy). Feel free to point out mistakes or suggest improvements.

Cheers.

Github Repo: [https://github.com/ml874/Data-Science-Cheatsheet](https://github.com/ml874/Data-Science-Cheatsheet)","Data Science Cheatsheet ""[xpost /r/MachineLearning]""",96cp1k,new,11,181,181,0
" Statistics and Computer Science have their own groups, do people feel there’s a need for a data science association and/or certification? 

Somethings an association would do:

General conferences (already exist under several corporate banners)
Provides standards
Provides ethics
Allows for ‘gatekeeping’ which can be both problematic and good
Certifications
Program accreditation (University/Bootcamp)

Thoughts? 
Do you think this would be useful?
The current system seems hodgepodge to me but not sure if there’s a need. Curious as to what others think. 
",Data Science Association,96c8lb,new,1,5,5,0
"Hello, everyone!
I'm currently pursuing a bachelors in computer science from a fairly reputable private Indian college and I graduate July 2019. I have a GPA of 8 (out of 10). About a year ago, I decided to pursue Data science as my career option simply because its the only thing I won't do just for they money (I fucking love it, actually).

So, I decided to work in R and was able to get a remote summer internship at a London based startup. I have built 2 projects, working on the 3rd, and I'm working for another side project on a CNN (that's pretty much all my CV, even though I plan to finish with 5 projects by the end of August)

I want to pursue Masters in Data Science in Europe right after graduation. I've been preparing for GRE as well - which I'll give by the end of September. 

I simply don't know which countries and universities to aim for/ choose. I'm not considering US because of the political scene and much higher cost across the whole degree.

So, can anybody please advice me on which colleges I'm likely to get into? And which would be unlikely but possible? Everything counts while choosing which countries to go to - finances, expected salaries, taxes, medical costs, standard of living, everything.

I know this is rather long text, so thank you very much for reading it and answering it!",Need advice regarding post grad in Europe.,96btfl,new,0,1,1,0
"I'm currently working through some classes through Coursera, specifically those focused on data science using R (Data Science Specialization - John Hopkins University, Statistics with R - Duke University, etc.). Is anyone else that is moving through related courses open to group learning using Slack? I've heard a number of positive things about Slack and it is very intuitive for collaborative work.
I'm also open to taking a new course (anything programming-related) as long as we're in it together - Let me know!",Anyone interesting in group learning or collaborative projects using Slack?,96bl8l,new,4,2,2,0
"I'm trying to do a data science project to bolster my resume and sharpen my skills. One idea I have is to use the data available at the [London Air Quality Network](http://www.londonair.org.uk/). Specifically, I'd like to allow users to visualize historical data, generate something like the [Tube Heartbeat](http://tubeheartbeat.com/london/), and forecast future pollution levels. On the LAQN website, they do offer forecasts for the next one or two days, but they're [not very detailed](http://www.londonair.org.uk/LondonAir/Forecast/). They just say that the pollution level for tomorrow will be low/medium/high, but they don't break it down into actual numbers or by location.

Would trying to improve upon this by building a more detailed prediction model and more detailed/interactive visualizations be considered a good project?",Improving on work someone else has already done,96bgx6,new,3,3,3,0
"So I currently work as a data analyst. I've been recommended to pursue a master's degree, and I've realized that it's very tough to choose an exact degree to pursue. I found basically three distinct types of master degree programs. Data science, data analytics, and information systems. 


Information Systems is a mix between business and data analytics. Data analytics is specifically geared towards visualizing and working with data in general, and data science seems to be a mixture of statistics and advanced data analytics techniques. So back to my original question. Is it ever a bad thing to major in data science? Possibly because it's too specific? when if ever would it be better to pursue Information Systems, data analytics, or maybe even a masters of Business Administration over a data science masters? ",Can getting a degree in data science possibly be a bad thing? Being to specialized?,96axrv,new,24,0,0,0
"I'm very curious about how data science is being applied in different domains in the industry. I have see many job postings from marketing, HR, product etc hiring for data scientists while it seems to me most of the data science noise has been created by teams doing machine learning and running classic statistical experiments. I am very curious about how different teams are using data science at their work and would love to hear from your experience!","Data Scientists outside of Engineering/R&D groups, how's your day to day like?",969ic9,new,4,1,1,0
"Hi guys,

new to the Data Science world, and having quite some trouble with this particular problem. Didn't find it anywhere so I'm coming to you for some godly guidance.

https://i.redd.it/bhv4e23v0bf11.png

I'm dealing with this kind of matrices, I think they are called Attribute Usage. 1s or 0s, each represent a machine producing a part. 

What I want my cluster algorithm to do is define diagonalized blocks like this: 

https://i.redd.it/2mnfivdf1bf11.png

Anyone worked on something similar?",Clustering in Block Diagonal Form problems,9698q3,new,4,2,2,0
"I have a dataset with a lot of textual sentences. Of course, they are unlabeled and I want to apply clustering on them. Looked into k-means text clustering for a small sample dataset which makes me wonder are there any better approaches to this problem? The problem to be specific, is that I have gathered this data from social media and want to cluster them such that texts with similar topics are grouped in a similar cluster.

I'm applying tf-idf vectorisation while pre processing and then k-means afterwards. Would you like to suggest any other means of performing this task? I'm a bit novice when it comes to machine learning and am only entering the field so please excuse for any kind of clumsiness.

I tried posting this earlier but didn't get any responses due to lack of explanation of the actual problem.

I would also like to ask for any method to convert unlabelled data into labelled one by providing target classes?",Text clustering algorithms. Need help.,96955v,new,7,1,1,0
"I'm doing a course on data analytics and data science. I took up the project idea of Udacity and I am trying to simulate their course recommendation engine. Anyone know where I can get a sample data set(s) for Udacity, Coursera or edX  ?

Any help would be appreciated, Thank you.",Need a dataset,968dfp,new,4,0,0,0
,The importance of the Data Science Community - For Data Scientists,9689d8,new,0,0,0,0
"I finished school last spring and very recently accepted a data scientist position at Booz Allen. Wondering if anyone here would be willing to share their experience? Pros, Cons, how to get the most out your time there, etc. ",Being a data scientist at Booz Allen Hamilton?,9687n1,new,8,2,2,0
"Hello everyone!

I am looking to go into the Data Science feild and was curious what a salary might look like in the feild. Im curious in what starting slaries and  higher up position salaries look like too. If you would like to leave a comment it would be helpful to know 1) what education/background you had to get the job you have 2) how long it took you to get to that position 3) the salary for you position 4) the area you live 5) previous job experience/slaries in this feild. If you don't feel like sharing everything then no worries! But if you'd like to it would be extremely helpful. I k kw some online sites have good estimates as to what a salary in this feild look like but I have heard of friends who get a job in data science in MA making 40k starting and another making 80k. Wanted to hear some other opinions to see what I should expect, thanks!! :)",What Is Your Salary As A Data Scientist (especially in MA/New Englabd area!),9681f9,new,44,6,6,0
,The Democratization of Data Science,966dom,new,3,5,5,0
"I am a machine learning student. I see a lots of research papers, that don't share a link to their datasets.The thing is most of these research papers have no privacy issue for sharing their datasets. I don't get the purpose of a research paper that doesn't shares it dataset.  


So the question is how do I ask them for dataset? Should I mail them or is there a repository where these datasets are uploaded?",How to ask for datasets used in research papers?,965dzk,new,22,27,27,0
"Hi everyone!

[Let ’s find​ out together](https://www.finnoq.com/en/blog/owning-your-data/) how the wisdom of the crowd makes the difference in making better decisions!​

Cheers

Eszter",Owning your data in the third-part oasis,9656dd,new,2,0,0,0
Can anyone help me? Where to get dataset of google search query? I want to analysis.,Data set for Analysis,964wfd,new,1,0,0,0
"I have a 2 identical transactional datasets. One contains transactions after deploying a volume discount model, buy 5 save 10, and the second dataset containing transactions after deploying a volume discount model, buy 3 save 10% and buy 5 save 15%. The changes are deployed at the same stores.

Is it even possible to find an optimal volume pricing model based on the information provided? Any recommendations on how to approach this problem?",Seeking advice on optimizing staggered volume discount model,961d7q,new,3,3,3,0
Reading your comments with open mind :),*Data science is a science*. Change my mind.,9611mk,new,10,0,0,0
,What's the biggest lapse in communication you've had among your team or managers?,9608us,new,0,9,9,0
"Every knows its an employee's market for Data Scientists. I could use some advice with my current situation..

I have been working for my current employer for about 8 months since graduating undergrad from a large technical school with a specialized degree in Data Science. In my role, I mainly do research developing new products using deep learning. My tech stack: Pyspark, Python, Keras, Pytorch, etc etc. I have gained a lot of experience building deep learning models and data pipelines to productionalize them. My current company employees around 1,000 Data Scientists across the globe, but my small team does most of the higher level deep learning work. However, I am at the ""entry-level"" Data Scientist pay grade-meaning my compensation is equivalent to someone who mainly writes SQL queries. 

Now I have been recommended for a role with another company for a salary that is about 25% higher than my own. However, I am in no real rush to leave my current company(I would also have to repay a signing bonus of a couple thousand dollars if I left before a year). Any suggestions of how I could approach my boss about this situation?",How to approach your boss about salary,95zs8m,new,16,8,8,0
"I've read a lot that you ""can't do data science in a GUI"". Well I don't consider myself an expert data scientist, but I am in a large company doing data analysis on manufacturing data, and 99% of our work is done in GUI programs like JMP or in-house analysis software that integrates with data extraction.

I am trying to learn Python and fit it into my workflow, but for the vast majority of my exploratory data analysis when I use Python I keep thinking ""I could do this 100 times faster in my GUI software"". Am I doing everything wrong? Or does anyone else feel that this way? 

I understand the appeal of Python for routine automation, but for exploratory analysis which is mostly one-off actions I can't stand it. In Python I find myself constantly copy pasting things into my code which feels slow messy. Plotting, reshaping data, filtering, those are all actions that I do hundreds of times a day in my GUI by just selecting which action I want to do and dragging in the column names to use from my selected dataset.

Here are some common steps in my GUI workflow compared to Python (apologies for the wall of text)...
  
___
___
___
  
**VIEWING COLUMNS:**  
- As soon as my data import finishes I see a list of column names that I can scroll through and filter by column name using regex in a search bar. I can rename them, hide them, change their datatype, create calculated columns as functions of other columns, etc. All these actions are just a click away.  
- In Python I would do df.head() or df.columns which prints raw text of hundreds of columns to my console that I'd then have to copy paste from. Renaming or rearranging columns, creating functions of columns, filtering, all require copy pasting from the console back into my code (or manually typing column names which for manufacturing data are unwieldy) as dataframe index arguments.

**MANAGING FILES:**  
- All imported datasets (hdf5 usually), plots, pivot tables, filters are shown in a navigation pane in hierarchical folders where I can drag things around. Any time I want to view, reshape, plot, modify, filter or aggregate data I just select which dataset I want to do that for by left clicking it. Filters, plots, aggregation actions, pivots, all exist as files so if I make one I can copy paste it into another folder where it will be applied to the dataset in that folder.  
- In Python all datasets I'm working with are either held in RAM or I have to copy paste the file path (or type it out) in my code. Same for saving files. If my code crashes all variables in RAM that I have reshaped or filtered or aggregated are lost, so it's best to save to a file at each step. That's a lot of copy pasting file paths into Python code which I find very tedious. To view my files I go to Windows explorer, where moving or renaming anything will break my code.  
  
**RESHAPING:**  
- In my GUI if I want to aggregate or pivot a dataset I just click the button and it brings up a dialog where I can search for column names using regex (the list updates in real time as I'm typing the regex) and then drag one or multiple columns to be a key (group by) or data column (where I select what type of aggregation I want to apply from a drop down menu).  
- Doing this kind of thing in Python kills me. I have to do df.columns, then apply some regex to the list and print the result to the console. Then for each column I want aggregated I have to copy paste it back into my code one at a time as dataframe index arguments, putting quotation marks around each column name and separating with commas. Then I have to type out the groupby code and copy paste the key columns there using the same process.   

**PLOTTING:**  
- I can select from a list of around 30 plot types including scatters, bars, heatmaps, paretos, etc. And for each one I get a custom dialog that lets me drag and drop X, Y columns as well as categorical columns to color code, partition into multiple plots by value, or cluster x-axis values, and then I get the plot shown to me and put in the navigation folder along with the dataset file. All plots, datasets and filters are shown in a navigation pane in hierarchical folders. I can copy or move those to other folders containing other datasets (assuming the same column titles exist) and see the same plot for those just by reopening it.  
- In Python, again, print column names, find what I want and copy paste them into my code as arguments on the dataframe index and seaborn functions. Reusing anything means copy pasting blocks of code and modifying manually typed dataset or filepath names.     
  
**FILTERING:**  
- I can use any column to create a filter just by right clicking and selecting filter, on categorical columns I instantly get a list of checkboxes (or a drop down menu, or search menu if I choose) on which I can dynamically toggle values to filter out. On numerical columns it defaults to filtering to a range of values where I choose the min/max. I can create many filters like this and see them listed, and toggle them on and off or modify them, and combine them using boolean logic. All plots in the same folder as this filter+dataset will get updated as I adjust the filters.  
- In Python I have to find the column name I want to filter on, print value_counts to see the possible values in the console. Then I have to copy paste the column name into my code (like for everything else), then copy paste each value I want filtered like df[df['column'] == value] for every single goddamn value I want to consider. This is about 50 times more work than right click -> ""filter"" -> click checkbox beside the values I don't want. And this is something I do hundreds of times a day.  

___
___
___


I've been unable to find any GUI similar to this or JMP that actually plays well with Python/Pandas. I really have no idea how anyone is productive doing exploratory data analysis in a scripting language like this. Am I just wrong?",How do you do exploratory analysis without a GUI?,95z55u,new,11,3,3,0
"Hello everyone, I'm going to be entering the world of data science soon. I've worked amongst data scientists as a software developer. I know that one key frustration for a data scientist is that your experiments may crash after hours/days of performing computationally intensive work. Python, the dominant language for data science, is an interpreted, dynamically-typed language which is highly prone to these types of runtime errors.

In the programming world, a language like Rust allows one to build a very robust system, because it has a ruthless compiler which performs strict type-checking and imposes very hard constraints on memory management. It is very annoying to write a Rust program, because the compiler yells at everything you do, but once you finally make the compiler happy, you are reassured that your program won't fail due to silly errors. At the moment, Rust would be wholly unsuitable for data science since it is designed for systems programming, and there does not seem to be a community for statistical/data science software for the Rust language.

I'm wondering if anyone knows of any languages, software frameworks, or even a development practice/paradigm out there that could help solve this problem for data science. Thanks!",Is there a tool for data science that is robust to runtime errors?,95y8t2,new,4,2,2,0
"Hello everyone,

I am a senior student in college and for a research project I would like to analyse temporal patterns of different pollutants in Rotterdam. I have obtained hourly data of 5 pollutants for 3 years, distributed in 8-10 stations across the city. In addition, I have obtained hourly weather measurements such as wind speed, temperature, humidity...

I would like to ask you if you could advice me which model would be the best fit for the analysis of temporal patterns, such as day-night changes and seasonality.

Thank you in advance for the help :) ",Which model to use to analyse pollution temporal patterns?,95x5zu,new,2,4,4,0
,Julia Language 1.0 Released!,95wibc,new,73,144,144,0
"What are approaches and tactics of a manager that have elevated your work or made your time at a company more productive and fulfilling? Also interested in learning the inverse: what has made a data science manager utterly ineffective in the past?

I imagine many best practices span across other technical roles, but most interested in those specific to data science. ","In your experience, what makes a data science manager effective?",95w7yj,new,14,15,15,0
"Bill Inmon proposes ""textual ETL"" to bring text in an integrated/structured form, so it can be analysed with standard analytical technology (DW2.0 - W.H. Inmon - 2010).
""Textual ETL"" is an ardous task, which involves 

* stop-word removal
* synonym concatenation
* homographic resolution
* thematic clustering
* and many more steps

IMHO this is an extreme waste of resources, because you do all of this preprocessing just to be able to use the standard BI tools for structured data.
This kind of preparation should only be done, if you know that you need it.
Also NLP-Tools and ML are probably more useful than standard BI analytics tools for processing text.

I am interested in your opinion and academic sources.

Thanks for your help!",How useful is preprocessing of text?,95u3tj,new,3,3,3,0
"My company sells tickets to certain events. We have a ton of data that says the time of every sale for similar events in the past. We are trying to use this information to try to predict how much this years events will sell, and we want to be able to update the predictions each day as new sales come in.

No one in my office knows anything about data science, including me for the most part, but I'm trying to teach myself. Previously they were using a moving average, which is obviously terrible and doesn't account for spikes close to the events.

I suggested to use a linear regression, because that's the only statistical model I know. So we record the sales every ten days and use those as the X variables, to try to predict what the sales will be by the day of the event.

So far this is working pretty good, but I know this would be frowned upon by people with statistics backgrounds. So I was hoping someone could suggest a better model that I could look in to?

Ideally it would be something that isn't too complex so I could explain it to my coworkers, and is also something I could implement using pandas

Thanks!",Looking for some help with a small data science problem I ran into at work,95tcza,new,7,3,3,0
"I was hoping that someone could point me to more information on how I can utilize a curve/distribution as a feature in a classification model. 

I am a chemist that has had some limited experience with common modeling methods back in college. I've found that experience in my field has given me a base model on how I attempt to select formulations for different samples. My company has a fairly robust analysis for our base samples that gives me a good starting point, however from that point it is mostly educational guesses. 

I have a personal interest in many of the multivariate methods I learned back in school and thought this would be a good application and help me to get a leg up in my position. I was hoping to use a clustering algorithm to either confirm my preconceived groupings, or find a new way to look at the data I am able to generate to take away some of the guess work. 

I have access to a full data set on ~100-200 samples with a number of analytical information for each. My issue is that the main two metrics I would use in my typical analysis are composition distributions. Typically the shapes of these distributions have been helpful in determining what formulations will be most effective at certain concentrations. I would usually use a PCA type analysis and from there cluster based on the main PCs, however I think this will only consider the individual points in the curve and not the relative distribution. Is there a way to capture this information prior to clustering? If there are any good sources on this it would be very helpful.

TL;DR What methods would account for the shape of a distribution in clustering analysis?
",Using curves as features,95rtbk,new,2,3,3,0
"that's me

* 24 years old
* BS in Biology but took no programming or heavy maths courses other than Statistics and Calculus
* Did 2x internships in Molecular Cardiology and Microbiology labs at University and International research center and hated the lab work
* MS in Biotechnology
   * took a class where I learn how to programme in Python and loved it
   * helped with set-up of a biotech company alongside studies, was fun but not sure if entrepreneurship is my thing...
* Got a job as Molecular Biologist in R&D department in a biotechnology company straight after MS and hated it
   * tinkererd with some Python toolboxes for modelling Biological processes in own time
   * convinced my boss to reduce my hours at work so that I could go to University 2 days a week for two months and work in a bioinformatics lab; learnt how to programme in R and probabilistic modelling -->was not easy but definitely interesting!
   * Developed a Python script for automatizing some data analysis workflows at work that are normally done through Excel

Yes, everybody talks about the sexy Data Scientist position so I have applied for entry level positions as data scientist/analyst for about a year and got no luck!

* Quit the job, after 2 years

What to do now? I would like to go back to academia to learn new things that will allow me to get a more ""quantitative"" career, but I am not sure what kind of degree would be best?  


Computational Science? Bioinformatics? Data Science?  


MS or BS?   
or PhD? (although I am not 100% whether I am ready for it...)  


Any suggestions/opinions are much appreciated!",Advice for biologist who wants to leave the lab and start solving problems with computers,95qmi0,new,4,1,1,0
"I don't mean this in an aggressive way, but from my perspective, the PCA functions in various libraries seem to just be trivial wrappers around the SVD function, which are somewhat more trouble than they're worth.

Can someone weigh in?",Why use a library's PCA functions when you can just use vanilla SVD?,95phsj,new,1,2,2,0
"I've run into this a few times.  

Employer posts a job ad seeking someone with a degree, preferably an advanced degree, in statistics or a stats-heavy field, skills in X, Y, and Z softwares/languages, etc etc etc.

Then you get to the interview and it comes out that the work is all done in Excel at an intermediate level and they're mainly concerned about your experience with pivot tables.  The visualizations are bar and pie charts, and they have doubts that you, despite having a master's degree, will be able to do them.

Is this common?",employers overstating their needs?,95o7ly,new,91,132,132,0
"I have a dataset with a lot of textual sentences. Of course, they are unlabeled and I want to apply clustering on them. Looked into k-means text clustering for a small sample dataset which makes me wonder are there any better approaches to this problem?

I'm applying tf-idf vectorisation while pre processing and then k-means afterwards. Would you like to suggest any other means of performing this task? I'm a bit novice when it comes to machine learning and am only entering the field so please excuse for any kind of clumsiness.",Thoughts on text clustering algorithms?,95o06w,new,5,8,8,0
"All of the references to visualization I've seen on this sub are variants on ""how to use library X to achieve your desired visualization result.""  It seems like there's a huge gap around the question of ""How do I determine my desired visualization?""

The gap isn't unique to the sub.  None of my courses in statistics and machine learning have addressed visualization, other than in passing.  I'm left with very basic questions like: 

  - If my data can be expressed with bar and scatter plots, why would I use something else?
  - How narrow should the buckets be, before you change your bar chart to a line chart?
  - Why is a line plot a *plot*, while a bar chart is a *chart*?

Please don't answer these questions -- they're the first three of ten thousand questions that I think I ought to have defensible answers for.

**TLDR:** What should I read in order to have a better understanding of the conventions, protocols, and goals of statistical visualization?",How to learn fundamentals of statistical visualization?,95nzq8,new,2,2,2,0
"I was just wondering if anyone knew of any good outlier detection methods for strings? Preferably one that takes character positioning/typical structure into account (e.g. where ""A012"" =/= ""012A"").

I'm trying to find a way to help automate the detection of (potentially) erroneous data in our database, and a lot of our fields are strings.

Thanks in advance for any insight you can provide!",Outlier Detection Methods for Strings?,95nzf1,new,20,2,2,0
"Please, explain me, how a few activation functions in neural networks can handle so many problems?  I know some basics theory behind ANN, but I can't get what common have sigmoid function etc. to for example picture classification?",Few activation functions handling various problems - neural networks,95n6xx,new,2,1,1,0
"I'll be doing a take home challenge soon. Anyone know of any free take home style exercises to practice with available explanation? Preferably on clinical or health data using python, but I'm open to any kind of data and tools.",Data and coding challenge exercises to practice?,95mgpc,new,2,9,9,0
"Is there a good source of data for the music industry? I have a project coming up for my DS class and trying to get a bit of a head start. I'm thinking it would be interesting to look at how streaming services are effecting revenue. 

However I'm having trouble finding sources. Is this more proprietary data? Not sure if this kind of data is publicly available. 

Are there any interesting data sets out there pertaining to music?",Music Industry Data,95m2rz,new,3,3,3,0
What are the main issues or problems you've faced in pushing data science to production? Anything you feel could be made easier? Any difficulties training or retraining machine learning models?,Pain points of data science in production,95m1nr,new,6,5,5,0
"Hi,

I'm looking for something that's similar to RStudio, will run on Mac, and is free. Any suggestions? ",Recommended IDE for Python?,95irrr,new,15,3,3,0
"During a recent phone interview with a potential employer, they were impressed enough with both my self-taught skills and formally learned skills in Data Analysis/Science to give me a chance to look at one of their big data sets and make inferences. They said they were more interested in the overall meaning of the data than specific data points. While I have a background in statistics and quantitative analysis, I feel like I have spent only a small amount of time in big data and data visualization.

I know this project is currently vague, and it sounds like they didn't quite know the parameters as well.

Is there any resources for learning you would suggest to help me prepare over the next two weeks for something I have described?",Pre-Employment Screen Data Set - How to Prepare,95hy9s,new,3,3,3,0
"Hi all, 

I posted this project on kaggle a month or so ago and never really got much feedback on it so I'd really like to get some opinions from the users here.

It concerns child poverty in New York City and includes EDA, maps, visualisations, a predictive model and model evaluation. Any critiques would be greatly appreciated so I know where I can improve! What mistakes, procedural or otherwise were made? Is there anything that should have been included?

Many thanks in advance!

[https://www.kaggle.com/bigironsphere/tutorial-maps-eda-and-models-with-nyc-census-data](https://www.kaggle.com/bigironsphere/tutorial-maps-eda-and-models-with-nyc-census-data)",Child Poverty in NYC - is my first Data Analysis project on Kaggle any good?,95hhzq,new,20,74,74,0
"Hello all.  I am really stuck on this problem and have been searching for many hours to find the solution.  I need to fill in a time series with 5 minute intervals where there are no observations.  Attached is my code and error.

Any help would be greatly appreciated.

            while theftIdx:
                #set inx for range of time for samples
                idx = theftIdx.pop()
                sampStart = samples.iloc[idx, 3] - pd.Timedelta(hours = 24) 
                sampEnd = samples.iloc[idx, 3] + pd.Timedelta(hours = 2) 
                
                #Filter samples for date range for graph
                sampDf = samples[(samples['timeOfSample'] > sampStart) & (samples['timeOfSample'] <= sampEnd)]
                #keep columns needed for plot and set index to time
                sampDf = sampDf.loc[:, ['timeOfSample', 'speed', 'fuelLevel', 'fuelVolumeFiltered']]
                sampDf = sampDf.set_index('timeOfSample')
                
                #set sampDf index to DatetimeIndex, create DatetimeIndex to date range and apply new index to sampDf
                sampDf.index = pd.DatetimeIndex(sampDf.index)
                index=pd.date_range(start=sampStart.replace(minute=0, second=0, microsecond=0), end=sampEnd, freq='5T')
                sampDf = sampDf.reindex(index)
    
                #plot sampDf
                sampDf.plot()

https://i.redd.it/pc4mjx4vhre11.png",Python / Pandas reindex problem,95h4nb,new,2,1,1,0
"Hi Friends! I am from India and live in New york city now a days!

Looking for a study partner. Please contact me.

Thanks!",Looking for study partners,95g4uf,new,1,0,0,0
"I was wondering if any data scientists were aware of ways to statistically compare two bar charts which have the same x axis, that is to say, I was to test how similar bar graph A is to bar graph B. I’ve tried modelling both bar charts using high order polynomials but the data is quite volatile. Maybe I could do some sort of different in squares calculation.",Statistically Comparing Bar Charts,95e64a,new,10,2,2,0
"In operations research, there's a technique often used to for linear optimization, it's called the [simplex algorithm](https://en.wikipedia.org/wiki/Simplex_algorithm), Could this be used to find the best weights when stacking different models, has there been an attempt to use it or am I not making sense?

Thanks",Weights for stacking optimization,95dvwd,new,13,1,1,0
"I am trying to find my niche in data science and I was wondering if you guys could recommend any techniques/algorithms heavily used in management of investments.

Is data scientist role in hedge funds any different from a quantitative analyst?",Data science in hedge funds,95dopt,new,7,10,10,0
"I'm a beginning-of-career data scientist (about 2 years on the job), and my company is soon going to be pulling the trigger on a cloud analytics stack.  For those of you who regularly work on these, would you recommend any of the AWS or Azure certs?  If so, which ones were helpful for your career?",AWS/Azure Certifications,95dkou,new,3,7,7,0
"I think some crucial steps in data science projects are data gathering, data preprocessing and not contaminating your test data by leaking information, which is the usual pitfalls beginners fall into. Can you tell me if have you ever been a victim of data leakage in any of your DS project and how much did this cost you, what were the consequences that you had?",Tell me about how you were a victim of data leakage in your DS project.,95cqex,new,8,15,15,0
"Hey all. I'm fairly new to working with representations of text data outside of the standard one-hot format so I apologize if this is trivial. I have a vector for each word in my data, but each record I am dealing with contains multiple words. What ways exist to combine all vectors in a record into one total vector for training a classifier? I was thinking about creating an average vector for each record, but I have to imagine there are more nuanced ways to approach this. Thanks!",Need Help Working with W2V Encodings,95c238,new,5,3,3,0
"I joined a job as a junior data scientist but finding myself taking time to think a lot about the projects; I am still waiting for myself to pass my probation.

I have been working on the same thing (unsupervised learning project) for 1 and half months now. Came up with a couple of visualizations and training some softmax models in TF.

I just wanna know for those who are in this profession, whats a typical day in your work life like for you? What are some helpful habits and routines u have every time u start on a new project or everyday at work? How many hours do u spend in the 8 hours programming? 

I would like to learn those habits that have helped u in your career. Thank you!",Data scientists: Whats a day at work like for you?,95bbgv,new,78,87,87,0
"I'm going to be attending my first data science conference this fall, and my (non-technical) manager has asked me to pick a metric for success similar to ""gather 50 business cards."" Obviously I'll be doing some networking, but I think a more reasonable metric would be something like ""Find three new libraries/techniques that might be relevant to our problem."" For those of you who have been to conferences, what metric would you pick?

If anyone has experience, I'm choosing between [The Data Science Conference](https://www.thedatascienceconference.com/) in Chicago and [PyData LA](https://pydata.org/la2018/) and would appreciate perspective on either of those.","How would you define a ""successful"" conference for you personally?",95b1is,new,5,4,4,0
"I have [this chart](https://imgur.com/c3AuBSI) where you can see some points that are far away the ""trend"" of the curve. The chart represents 5,000 values where each value corresponds to an specific hour of a day, month and year. In this case, it goes from  01/01/18 until 05/08/18 (non-american format) and as you can see at the first lower peak, it was caused because at 12.00 the cost was 20 USD but at 1.00 AM it went up to 51 USD.

I've read that some people just delete those 'peaks' values but I don't know if there's a better solution. This graph shows almost a year but I have in mind on graphing 10 years of this prices so the situation could be worst. Do you know a better strategy? I'm thinking maybe in calculating average costs for every 6 hours but it feels like a cheap solution to me.","How can discard ""peaks"" values from a chart?",95994p,new,8,5,5,0
"Hi all, currently getting a 6 month work from home content writing chance for a ok-ish company. Should i go for it?
Need to know opinions",Content writing internship in data science?,958q5h,new,4,2,2,0
What are the pros and cons of having the titles? (assume the actual work is a hybrid type role).,"ML engineer vs data scientist, from a purely title perspective which is better in what scenario?",958dgd,new,5,1,1,0
"Hi all,

I have the task of finding the right appropriate analytics tool for our department (internal audit function). Since there are so many tools out there, i'm hoping someone can point me to the right direction. 

Our requirements are:

1. Code free (or very limited coding required). Since we're not coders/programmers, we need something along the line of drag and drop :(

2.  We want to be able to connect to databases and perform continuous testing based on a set of conditions. For example, we want to be able to connect to Travel expense data and have any meals over $75 flagged as potential violations to be investigated. Ideally this will be refreshed monthly/quarterly

3. Visualization (Optional): management likes pretty interactive charts. We can always use Tableau for this.

We have Tableau, but not sure if Tableau can do #2 well? I've seen Alteryx demos and it seems to be able to do #2, but the price tag is too high for us. Thank you all in advance for helping me!",Need help finding appropriate analytics tool,957ws6,new,11,1,1,0
"Welcome to this week's 'Entering & Transitioning' thread!

This thread is a weekly sticky post meant for any questions about getting started, studying, or transitioning into the data science field.

This includes questions around learning and transitioning such as:

* **Learning resources** (e.g., books, tutorials, videos)
* **Traditional education** (e.g., schools, degrees, electives)
* **Alternative education** (e.g., online courses, bootcamps)
* **Career questions** (e.g., resumes, applying, career prospects)
* **Elementary questions** (e.g., where to start, what next)

We encourage practicing Data Scientists to visit this thread often and sort by new.

You can find the last thread here:

[https://www.reddit.com/r/datascience/comments/934oxd/weekly\_entering\_transitioning\_thread\_questions/](https://www.reddit.com/r/datascience/comments/934oxd/weekly_entering_transitioning_thread_questions/)",Weekly 'Entering & Transitioning' Thread. Questions about getting started and/or progressing towards becoming a Data Scientist go here.,956n5i,new,64,7,7,0
"Hi /r/datascience,

I have scoured the internet for answers to this question and haven't come up with anything satisfying yet, so I turn here even though this may not be the best place for this question.

I am currently doing a writeup on my website for an analysis project I have done, and I would like to display Pandas output from a JNotebook on my site. I have tried exporting to HTML, but my site's CSS template does not agree with my table. I am no designer, and I really don't want to go in and fiddle with it.

Ideally, I would have it look [just like it looks in the notebook](https://imgur.com/h5LUph9) on my website, but taking screenshots and displaying them just feels unprofessional and inconsistent. I've tried plotting the tables using matplotlib and saving the figures like I'm doing with the graphs I am including in my writeup, but the matplotlib table plot is extremely ugly.

Is there any way to save and export the output exactly as it looks in the notebook, or is there another good way you folks know of for displaying Pandas tables using HTML/CSS/Markdown?",How to best display Pandas output from a Jupyter Notebook on a website?,956f8i,new,6,6,6,0
"I would like to know in which scenario have you applied the Central Limit Theorem to solve a Data Science problem. Another theorem that can be applied in big data scenarios is the Law of Large Numbers. So, have you ever used this to model machine learning algorithms to solve big data problems? How did you do?

Reference:

[http://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter4\_TheGreatestTheoremNeverTold/Ch4\_LawOfLargeNumbers\_PyMC2.ipynb](http://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter4_TheGreatestTheoremNeverTold/Ch4_LawOfLargeNumbers_PyMC2.ipynb)",Have you ever applied the Central Limit Theorem and/or the Law of Large Numbers in your job to solve a DS problem?,956b13,new,6,0,0,0
"Recent events at work make it look like I am going to have to get better at using SAS Enterprise Miner! The version I have access to is 14.1

Can anyone point me to any resources? In particular I’d like something that goes beyond the standard SAS “getting started in ...” guide and also isn’t just the SAS documentation. 

Primary use case is for binary classification, but I will probably dabble in a bit of everything.

Websites would be helpful but I’d love a physical reference as well

Thanks!
",Any SAS Enterprise Miner experts?,955yqu,new,4,1,1,0
,"Apparently Google supports jupyter notebooks, with the option to save to GitHub from the file menu",955wli,new,19,220,220,0
,The 10 best talks on Data Science at SciPy 2018,953kha,new,0,10,10,0
,Data Piques | Quick and Dirty Serverless Integer Programming,953duq,new,0,1,1,0
,Wikimedia Foundation is hiring a Manager of Product Analytics,9539l4,new,0,3,3,0
"TL;DR: is python more efficient than excel in working with huge .csv files in order to graph values inside it? If so, what do I need besides installing Python?

Hi everyone, 
I'm trying to graph, analyze and do some calculations with energy prices from my country's *National Electrical System*, which are changing every hour and I'd like to analyze the last 4 years in order to make a projection for the next 5 years. So, I have the intuition that Python programming would be more efficient in using my laptop's resources than excel, as I just tried to open an 880 MB .csv file and it stopped loading at 29% (ASUS ZenBook 3 non-deluxe).

Any recommendation or alternative would be truly appreciated,
Thanks a lot.","Was told that if learning Python, I could make nice Graphs from .CSV files",9534p6,new,11,2,2,0
"Hey, all! I'm a news writer for TechTarget sites [SearchBusinessAnalytics.com](https://searchbusinessanalytics.techtarget.com/) and [SearchEnterpriseAI.com](https://searchenterpriseai.techtarget.com/). I frequently use reddit to browse news (and to find the best deals on Switch games!), and noticed the amount of community members that post about their personal data science/ML/analytics projects. Looking at all the projects, many of which seem to be coming from members without official schooling/experience in the programming languages, I realized there is probably a really great story in there.

So, I'd love to hear from some of you on what you're working on. We could chat about the project, the software/self-service tools being used, and why you're pursuing this project. The headline for this would be something like ""The amateur data scientists of reddit"", just to give you an idea of where I'd like to go with this.

Feel free to reach out here or over DM. For the article, I'm fine with using either your reddit name or your actual name or both -- whatever you feel comfortable with. Thanks, and hope to hear from you!",Tell me about your data science projects,952zd4,new,10,6,6,0
"I work as a data scientist and have two years of experience. I've recently come to the realization that I'm really not good at this. I could spend lots of time learning more, but I'm really not interested in that. So for those of you who realized that you were below average in terms of DS, what did you do? Go work in another field? Find another job? Etc?

Edit: I'm specifically talking about people who work in roles where their job title is ""data scientist""","For those who realized they weren't good data scientists, what did you do?",952hkl,new,9,3,3,0
"As someone who is entering the job market soon, I just wanted to get an understanding of how competitive it is out there.

What is you job?

How much experience do you have?

Where do you live?

How long did it take to find the job?



",Job Search: How long did it take you?,952gab,new,13,6,6,0
,Learn Foundations of Python Natural Language Processing and Computer Vision with my Video Course: Applications of Statistical Learning with Python,95297u,new,1,17,17,0
"Hi everyone! As a part of my work I've faced with this problem:

We have a complicated system which changes over time and can't be estimated with a function, we can only give the system some parameters as input and after some time it gives feedback, I want to improve parameters gradually as time passes and the system changes. what are some practical solutions to do so?",practical algorithms for this machine learning task?,9518zn,new,7,1,1,0
"Hi! I'm getting started with AI/ML, and I'm looking for some interesting but simple datasets I can use as exercises to practice doing data analysis and basic ML algorithms.

Can you share some good examples?

(I know about Kaggle, but I'm looking for more specific recommendations because I'm not sure where to get started)",What are some good introductory datasets I can use to practice ML and Data Analysis?,94zhv0,new,7,2,2,0
,Write less terrible code with Jupyter Notebook,94zh44,new,47,123,123,0
"After a hopeless electrical engineering entry level job search, I decided a couple months ago to pursue a Data Analysis career. I heard 80% of the job is basically cleaning data and I need more experience with this. If you could offer some tips on where to find good SQL/ excel / Python data cleaning tutorial, I'd appreciate it. ",Practice Exercises for Data Cleaning?,94xpzs,new,10,8,8,0
"In a very large enterprise with multiple analytics teams and multiple BI teams but no single CDO. I feel it's so hard to do anything other than with existing data, then the options are so limited. There is no single EDL and the system is so complex. How to create real value with machine learning in this type of environment? ",Data science in a large enterprise,94vwro,new,14,35,35,0
"When implementing cross-validation for parameter selection, should the same folds be used with each iteration, or should they be randomized each time?  Does it matter one way or the other?",Folds used in CV,94v923,new,3,3,3,0
"I do a lot of analysis type stuff at work and have no problem explaining my insights to someone, but once I try to put it down on paper I feel as if I get writers block.  Then, if I do get it down on paper, I'll spend the next twenty minutes wordsmithing it to the point where I'm not even sure my changes made a difference.  I would really like to improve on this because I feel as if it's really holding me back. Does anyone have resources or tips they can share that I could use to improve in this area?",Resources for improving writing skills?,94v755,new,8,3,3,0
"[https://towardsdatascience.com/predict-employee-turnover-with-python-da4975588aa3](https://towardsdatascience.com/predict-employee-turnover-with-python-da4975588aa3)

In this blog post, Susan is trying to predict the employee turnover. There's a part where she assigns categorical variables, now my question is this. 

**After she assigns those values, she adds them to the columns. Basically she adds the departments to the columns and then starts modelling. If the departments are assigned to columns, why isn't she doing one hot encoding or something else to fill them up?** 

Or am I mistaken, if my question is not clear, can someone please take the time to explain me the categorical varibles and where she adds the columns and she's hoping to achieve. Learning data science without a mentor and teacher is kinda difficult, it would be a great help if you guys helped me here.

thanks in advance

\---------------------------------------------------------------------------------------------------------

IMAGE FROM THE POST

https://i.redd.it/mldcz6a21ce11.png",Need help with this part of the problem,94uubr,new,4,2,2,0
I’m going to be doing a data science internship this Fall and then I go back for my final semester in January. I’m looking for some killer senior project ideas. What is a project you think would make me stand out as a candidate for entry level data science positions? ,Senior Project Ideas,94ubea,new,1,0,0,0
"Let me get the project details out of the way here first, then I will let you guys know where I am at career-wise so you can tell me if this is to big a project to take on and to keep it simple.

Project: Take in data from our live chat provider and return the requested reports and analytics.

My plan: Use C# (Our main backend stack at the company) to pull in the data from their API, do the required data mapping, store the data in a new database, and push it to a service like Kenisis or Kafka to provide real-time analytics.

My reasoning: Our live chat service is our main point of customer support. If we were to integrate that into ""real-time"" analytics we could pull in other logs and data to see changes to our SaaS product is causing an influx of chats. 

My Histations: This would probably be my largest project and I am not a traditional Software Engineer. I am comfortable with programming and working with API's and building small systems and projects.  I am also on a one-man team, so it would take some time.

ANy ideas or does this seem kinds of overkill?",Need help getting started with a new Analytics Dashboard project I got assigned at work.,94so5w,new,9,16,16,0
"Hi guys! 

This is my first post on reddit so, please, forgive me if i miss something. 

I need to compare two different method for object detection (let's say ""Faster R-CNN"" and ""RetinaNet"").  I'm just wondering what actions should i take to get trustworthy results. How to correctly compare methods like these? Should I run then with the same hyperparamethers (learining rate, iterations, backbone, etc)?  Or should I change only some of them? I'm going to use COCO dataset for this experiment. 

It is new field of study to me. I will be grateful any sources or any advice that help me better understand this topic. Thank you.",How to compare different detection algorithms?,94ruk8,new,2,3,3,0
"I want to earn an online certificate in data science/analytics. I know this won't get me a career in data science, I just want it as career enhancer/complement as I work in project management. I found several programs online, but absolutely want to weigh options before committing to one:

1) Temple Univ.: [https://noncredit.temple.edu/public/category/courseCategoryCertificateProfile.do?method=load&certificateId=155191](https://noncredit.temple.edu/public/category/courseCategoryCertificateProfile.do?method=load&certificateId=155191)

This one is extremely cheap ($495.00). But it is so cheap, comparatively, that I wonder if there is an issue of getting what you pay for? I know that no certificate program will be as comprehensive as a degree, but I still want something worthwhile. However, if I am not hinging a career on data analysis - just complementing it- would this really be all that is necessary?

2) Boston Univ.: [https://www.bu.edu/online/programs/certificate-programs/data-analytics/#cost](https://www.bu.edu/online/programs/certificate-programs/data-analytics/#cost)

Of the programs I found, this seems like best middle ground between cost and comprehensiveness. However, they have a stat course prereq I am not positive I meet. I took a standard statistics course in undergrad, however not sure that meets their requirement. 

3) Cornell: [https://www.ecornell.com/certificates/data-science/data-analytics/](https://www.ecornell.com/certificates/data-science/data-analytics/)

I know this has an Ivy league name attached to it, and I am sure it is not of poor quality, but it also does not seem as comprehensive for the cost ($3,600)?

4) UCLA: [https://www.uclaextension.edu/digital-technology/data-analytics-management/certificate/data-science](https://www.uclaextension.edu/digital-technology/data-analytics-management/certificate/data-science)

This certainly seems like the most comprehensive one and most worthwhile. However, also the most expensive ($4700).

Thanks for any input you can provide.",Can you help me weight online Data Science/Analysis Certificate Options?,94rqme,new,4,1,1,0
"Hi all, I was wondering if there were any analysts and/or scientists working in Japan who were willing to share the state of the field over there? I'd be keen to understand how it compares to countries like US, Australia and European Countries.",Data Science/Analytics in Japan,94pf2u,new,18,41,41,0
"Hi, I am building a resnet classifier as a side project and I am in need of a Dataset which has details of anything related to pedophilia, age statistics of internet abuse, abuse by countries and cities...ANYTHING..which has a slight detail about children, bullying, internet bullying, pedophilia will serve the purpose.

Please let me know if you come across or know a similar dataset.",Looking for online abuse dataset,94ou9d,new,2,1,1,0
"We have a dataset that includes Hour, Weekday and the count of values. We want the regression tree to output the regression tree based on both Hour and Weekday. Currently, it is only taking Hour (which is numeric) and not including weekday. I tried changing the Weekday variable to a number of different data types (factor, ordered factor and numeric value) with no luck. Do you have any suggestions on how to proceed?

    set.seed(1)
    offenses <- sample(1:3, size = nrow(data), prob = c(.70,.15,.15), replace = TRUE)
    
    data_train <- data[offenses == 1, ]
    data_valid <- data[offenses == 2, ]
    data_test <- data[offenses == 3, ]
    
    model <- rpart(formula = Count ~ Hour + Weekend,
                   data = data_train, 
                   method = ""anova"")
    
    print(model)

Data:

[https://i.redd.it/n7uewhrlw5e11.png](https://i.redd.it/n7uewhrlw5e11.png)","Running a regression tree using rpart, but the model is ignoring one of the predictor variables. Any idea why?",94nfaq,new,4,1,1,0
"Hey all -

I was wondering if anyone could share their favorite resources regarding ""the business side"" of data analysis and data science. There are a ton of resources out there for learning how to do data science, but I can't find too many coherent resources on how tech companies are actually applying it product, growth, and data analytics. Something that can hopefully lay out some key terminology (""metrics"", ""product lifecycle"" etc), a few key principles, and maybe some case studies too. 

Thanks!

C","Best resources on the ""business side"" of data analysis/science?",94n38m,new,4,11,11,0
,"My first Natural Language Processing Project! Please let me know what you guys think. Looking for all forms of feedback, good or bad.",94m8s3,new,1,14,14,0
"Hi all,

My employer offers an educational budget which I'm pretty much free to spend. It's about 500 euro's each year and money I don't spend transfers to the next year for up to three years. Do you have any good ideas on how to spend this?

I have finished a MSc Artificial Intelligence 6 years ago, but have been working in the information security field. I did however stay a bit up to date by following free online courses. I've decided however to move back to AI and there is even a chance I can do that with my current employer.

Both soft skills and technical skill suggestions are welcome. On the soft skill side, I recently followed  a story telling training, which was quite useful. On the more technical side, I'm only aware of the coursera/udacity etc. and programming sites like data camp.",What are good ways to spend educational budget?,94jono,new,4,1,1,0
,How hard is it to get an entry level Data Analyst position?,94j3uo,new,26,8,8,0
"Hello

I have been trying to use data for historical sales and historical prices, and come up with the forecast for sales based on given future pricing. The problem is not as simple. Not only is sales dependent on price of that product but is also dependent on prices of other products. This makes it very cumbersome as there is a number of products and if I were to find equations for each and every relation every month, it will take ages. I have realised this will be very painful to achieve in Excel. Also my statistics knowledge is very limited. 

Im looking for the easiest way to achieve it. It could either be through a software or some other method or something that someone has made in Excel. There is ""R"" being thrown around, and I am willing to learn if it actually makes my problem easy to solve. I dont want to spend weeks learning it only to find that it is the same as Excel in terms of this problem. 

Can anyone shed some light please? It would really help as I have been trying to get a solution for a long time. 

Thank you.",easiest way to achieve this?,94j3bu,new,1,1,1,0
,TensorFlow now the hottest and highest paid tech skill,94istc,new,30,172,172,0
"Not like the Back/Front classification matters, but I was talking with the data scientist at my firm today and he considers himself a back office employee when I tend to see him with clients more often. This probably differs by industry, but how often are data scientists (non contractor/consultant) client facing?  ",Data Scientist Back/Front Office title?,94fje2,new,2,2,2,0
"I double majored in stats and math and worked with R and some Python in college, but I could really gain from having SQL and excel skills. Every EL and internship position that involves data analytics wants at least some experience, and I am at a loss on getting my foot in the door. Are there any certification programs (preferably low cost) or anything else that would look good for employers? I feel I am in the same catch-22 situation that many graduates find themselves in.",How to gain programming experience after graduating college?,94emew,new,4,16,16,0
"If it was your first week on the job and you go around meeting all your new coworkers and some ask the question in the title, what would your response have been and what field do you work in? If you've been at your position for a while, how has your response changed?","""So you're our Data Scientist? What kind of problems can you solve?""",94ee73,new,11,1,1,0
,How to prepare for a Machine Learning interview,94dnmz,new,13,56,56,0
,Automating Surveillance using Deep Learning (Blog),94c1cr,new,7,7,7,0
"Starting out on my data science journey with support of colleagues along the way, but they all live in the US so finding the luck of physical interaction (checking my code, talking through how to tackle problems) to be a little limiting. Also would love to get some tips and ideas around career progression, key DS methods that need to be mastered, recs for journals/sites, etc. 

Anyone know of a mentorship program or a meetup scheme for data scientists of different levels and industries in London? 

Edit: I’m also a female, so if there’s any female-specific programs, that is also cool (I know that there are “girls who code” type programs, don’t know if there’s anything similar on the mentoring side). ",Mentorship scheme or similar in London?,94boc2,new,7,7,7,0
"Hi all. I'm working on a side project and wondering if it's even feasible. I'd like to use sentiment analysis or number of tweets in order to help predict resell prices of shoes. But I'm not sure how to factor this into a model

I was thinking of using fb prophet to predict this and somehow factor in the sentiment analysis/number of tweets. I read a few projects where people utilized social media and stock prices but I'm not too sure how they're weighing sentiment analysis",How to use social media in predicting sale prices,94b4ku,new,1,4,4,0
"I'm into politics and elections, but just begging to use R, so I decided to try to recreate aggregate electoral targeting in R from a [blog](https://offensivepolitics.net/archive/2009/10/22/aggreate-electoral-targeting-with-r.html) post I found. I would like to recreate it for my local county with data from open elections. I have formatted my [data](https://docs.google.com/spreadsheets/d/1XO4jXIqzoQ08se2NmnhL6Fc5wO520z924BTuqBkKPbk/edit?usp=sharing) in a way I believe should work, and then I recreated the code used in the blog to [this](https://github.com/mwtxw2/R-Aggpol-Boone-Test/blob/master/R%20Data). I decided to use State Senate 19 as my target district because it is county wide, and open elections doesn't have lower county race data.

I have been able to recreate the blogs entire process reliably, until I get to the `hd013s <- district.analyze(hd013)`  
step, then I get an error and I'm unable to move forward. The error is always `Error in aggregate.data.frame(as.data.frame(x), ...) : no rows to aggregate In addition: Warning message: In min(adf[, ""dem_turnout_pct""], na.rm = TRUE) :.`

I have zero idea of why the error is caused, I have looked through the code and I have reformatted my data few different times to include ""NA"" or just leave blanks, but so far none of this has worked.

My knowledge of R is probably too limited to be taking on a project like this, but my goal is to have the precinct level data output by this program to compare election returns to. Any advice you all can give is appreciated.",Help- Election Data Project in R,94adsp,new,1,1,1,0
,"Dataset containing 10,000 images for all Generation One Pokémon.",948g7f,new,16,127,127,0
"I've gotten a timeseries dataset of a piece of equipment with sensor readings (about 40 variables).

I have tried adding some features such as when the machine was on/off based on power readings, and removing extreme values.

But what about values that aren't considered extreme but are definitely outliers? I've tried running STL and it does pick them up but then what? 

---

How do you learn how to deal with outliers and what to do with them? Do I Null them? Remove them? Do I interpolate?

---

I also find myself very out of my depth when it comes to anomaly detection. 

---

Are there any sources you recommend reading data processing / anomaly detection / outlier cleaning that I can read in a few days / a week max.","My first DS internship, struggling with data processing & anomaly detection",948adx,new,9,4,4,0
,Info graphics - An Anatomy of a Data Scientist,947a8u,new,5,0,0,0
"Hello,

I'm working as a data scientist in an internet company, and i've been requested to think about ways to apply machine learning on a website in order to increase conversion rate.  

Is there a known paradigm to tackle such a problem? 

my initial thought was do some personalization, that is, adjust a customized set of components (such as font sizes, number of items in a list, background colors or images) that may have a positive effect on the user behaviour (which can result in conversion).

If it's indeed the proper way to tackle this problem, than i'm not sure how to implement it.

How can i choose the proper set of components that maximize the conversion rate? Should be a recommendation system framework? or i can run a lot of randomized experiments, see what's the ""best"" component, and set it as the target variable and then use some classification algorithms? 

Any advice would be appreciated,

Thank you.

* I'm not a native english speaker, my apologies  for my lame english.",User Interface Optimization Models - how to tackle?,94730y,new,2,1,1,0
"My brother worked at facebook and got this poster there. But I can't seem to find anywhere online to verify this data. Can anyone help?

https://i.redd.it/f5o07lgh5td11.jpg",Zodiac Signs pairing on Facebook. Trying to verify this data.,946msr,new,6,1,1,0
"Two of my biggest passions are entrepreneurship and data science. 

One of the fastest ways we can all become successful data scientists is by identifying useful data. This data doesnt have to necessarily exist in a useful format. We just need to be able to create it. I'm trying to identify what is common within each set of ""useful"" data (defined as data others are willing to pay for).

What is a type of data that you think would be useful for companies?",Useful Data Thread: Whats the most useful data you can think of?,9465ch,new,9,2,2,0
"So I'm doing a data engineering project and it's very straightforward. I'm self-taught using online resources and I've written a Python script (using only built-in modules) that successfully processes small datasets, but I don't yet know how to properly process large datasets and I need to learn this. I'm using Linux, with an i7 processor and 8 GB of RAM.

Basically, here's the project: 

- Read in a .txt file with two columns of data. 

- One column is the name of a product, a second column is the price of the product from some source. The product appears potentially many times, always with a different price. Like this:

        data_input = [['product_name', 'price'], ['bed', '600'], ['chair', '100'], ['bed', '800'], 'chair', '140'], ['fridge', '1000'], ['fridge', '2000'], ['knives', '180']]
    

- The output data should be 3 columns, where each product appears on one row, with the product name in one column, the total price in a second column, and the total count of products in a third column.

        data_output = [['product_name', 'total_cost', 'total_count'], ['bed', '1400', 2], ['chair', '240', 2], ['fridge', '3000', 2], [['product_name', 'price', 'count'], ['bed', '600', 1], ['chair', '100', 1], ['bed', '800', 1], 'chair', '140', 1], ['fridge', '1000', 1], ['knives', '180', 1]]
    
So, like I said, I've already written a Python script that does this for a small dataset like above. But when I expand the input data file so it's in excess of 1 GB and my computer lags with millions of rows, the computer just stalls and won't process the dataset.

What software or other language or Python technique or other method do I need to use to make this work so my code will successfully process massive datasets? And where can I look to learn how to do this?",What can I do to make my Python script process my data more efficiently?,942sut,new,23,6,6,0
"Hi Data people,

I have just finished another post on my blog - looking forward to any feedback and hope you enjoy:

[http://numbersandcode.com/another-simple-time-series-model-using-naive-bayes-for-forecasting](http://numbersandcode.com/another-simple-time-series-model-using-naive-bayes-for-forecasting)",Time-Series forecasting with Naive Bayes (Blogpost),942bhh,new,6,45,45,0
"Let's say I'm building a binary classifier model with a training set of 20k rows. Each of those rows has continuously valued features [A, B, C] available; additionally, 10k of the rows have a continuously-valued feature D available as well. For the rows that have D available, using that value as an input significantly improves performance, so we don't want to simply ignore D. For rows that have D missing, though, simply imputing a missing value doesn't work very well. 

I'm considering using a ""fallback"" solution where a model trained on all 4 variables is used if possible but the 3 variable model is used when necessary. The obvious downside to this is it doubles the amount of work I have to do to maintain both models. Are there other pitfalls I might not be considering though? 
",Pitfalls with using a fallback model?,9429g0,new,9,3,3,0
"So the way you slice a row of a dataframe in R is my cars[5,] but to get a column it's mtcars[5]. this is actually relatively new to me as I learned another way to do it that I've been using to clean data in which I was using mtcars$vehicle. Are these all valid ways to select data from a dataframe, or am I missing something? It seems like there's multiple ways to do everything.... 



mtcars$vehicle <- is the one I'm most familiar with if I want to alter data like performing vectorized operations. Totally not sure if I can do mtcars[5] <- the same way or not. 


Finally, I have no idea why columns and rows are almost identical besides the random comma in rows. ",I'm confused by there being multiple ways to slice data frames in R. Any advice or insight?,9413fu,new,10,0,0,0
"Hi all, I’ve been moving through Northwestern’s MS in Predictive Analytics for the last few years and am pacing to be done in the Spring. I’m also working full time as a business analyst at an ecommerce marketing agency. 

As you may know they changed the name of the degree to MS Data Science. The difference is one additional course. My choice is to either finish in March with the MS Predictive Analytics degree or pay another quarter’s tuition and finish in June with MD Data Science. 

My question is whether any of you think it’s worth the extra time and money for the name change?",What’s in a (Degree) Name?,940zkg,new,14,1,1,0
"What questions do you ask or consider before buying third party data sets or POS data from retailers? Aside from questions regarding frequency and format (etl, csv, etc...).

Many thanks!",What to consider before buying data?,940yji,new,4,3,3,0
"Does anyone knows how is the employability rate for Data Scientists in the sports/e-sports analytics area?  


I am a student of MSc Data Science and also a sport lover. I see often articles about teams making a wide usage of data science techniques to win matches. But I am wondering if it is a good career path.

**Is there many jobs in this area as there are in other fields of Data Science? Or at least half the amount?**

I**s it a promising field for a career path? Would you recommend following it?**

Thanks!",Data Science jobs in Sports/e-sports,940dex,new,19,9,9,0
,On the Suitability of Long Short-Term Memory Networks for Time Series Forecasting,940b9q,new,2,5,5,0
" I have an approximately 300+ excel sheet each has 4000+ variables and i have multiple months of these. I'm looking for suggestion in a outlier detection method to ""flag"" the outlier to brought to attention.  I plan to use RPA as soon as I figure out the initial process . However, I'm not familiar with a method that can tackle each variable by itself  without me spending time investigating each one individually. I familiar with k-scores,z-score, and similar traditional methods #statistician, however I know there maybe a ""smarter"" outlier detection method that doesn't require so much individual attention.   ",Outlier Detection method Dilemma,9409d5,new,11,1,1,0
"Hello, I was wondering if others have run into this in their work place. I’m in a small company that was acquired by an industry behemoth. And we have become “partners” with Google. We are on the google cloud wagon. And as a data scientist I was asked to take a 6 week google ML class that I am told costs 40K + travel + not being billable for 6 weeks. As such I have to sign a agreement that I will work at my company for 2 yrs or pay for the cost within 2 weeks of resignation. I’ve only been at this company a year, and I’m concerned that the acquisition will change it, as well. Has anyone taken this training? Is the training worth it? What is the content covered? Thoughts? Ideas? Suggestions?",Google ML training,9404t4,new,9,1,1,0
"I’m a clinical report writer for a healthcare software company.  Ideally, I’d like to move into doing more analysis.  I’ve written reports using proprietary tools, and by writing extracts and loading the data into R to process and make graphs.  

Currently I’m looking to move back to my home state and I have two job offers.  One is using those proprietary tools for a substantial amount of money.  The fear there is it will be harder to learn new things, although I’d have a fair amount of freedom and I could maybe get a masters in statistics to try and push myself.

Another job pays 30k less, (although roughly what I make now at my current job), but I’d be doing data processing for a research team, get more exposure to analysis, get my name on papers, and the culture is 40 hours and go home, so I could probably get a masters or maybe do part time consulting if I wanted to make more money.

Is the experience from the second job worth the 30k hit?  I’m more intrigued by the second job, but I’m afraid I’ll feel like an idiot for turning the first job down.  The first job seems great too, it’s just like my current job but I don’t want all my value as an employee to be from knowing proprietary software and how to find stuff in their disorganized database.  
",How valuable is the experience from a research job?,940160,new,6,10,10,0
"[https://stackoverflow.com/questions/50051303/what-is-the-package-of-r-function-trim](https://stackoverflow.com/questions/50051303/what-is-the-package-of-r-function-trim)

This stack overflow link is useful, sure. Followed the steps with SOS, and filtering... But there's still 24 packages that have function named 'trim' and half of them say trim leading whitespaces... so I'm really confused.

I just want to trim(df) and pass in my dataframe. I'm unsure which is the true trim that achieves this...

I installed Raster and sensusR, two packages which claim that they trim. Then, I used the following line: 

db2 <- trim(db2)

This turned my df into 'values' and no longer are a dataframe in the environment pane... superrr confused here. ",Simple way to trim all whitespaces in R? Getting lead in circles...,93zjks,new,8,1,1,0
"I'm looking to start doing all of my work in the cloud due to my PC taking a crap. Mainly looking to setup a linux environment with a decent amount of memory with the ability to scale up if needed. I will also most likely use some type of storage for my data (Thinking something like S3).  
  
Cost is the main concern. I don't want to be spending a ton of money just to work on personal projects so keeping under like $100/mo would be ideal. Mainly looking at the big 3 (AWS, GCP, Azure) but open to others too.",What's the best cloud solution for personal projects?,93zhna,new,13,30,30,0
,AI can determine your personality through eye movements,93zhhl,new,0,0,0,0
,Prediction Of World War 3 through data,93yzz7,new,0,0,0,0
"So I have a dataframe named db2 and the data: 

|TYPECAST|VALUE||
|:-|:-|:-|
|DECI|12||
|CHAR|11||
|DECI|10||
|INT|11||
|VAL|11||
||||

Basically, I want to check if the first column has DECI. If it does, add 1 to the value in second column (value). 

Is there a way to do this conditionally? I've looked into an if then, but can't figure it out.. ","Does R have a method of checking contents of a row in one column, and then conditionally performing an operation on a row in another column?",93y33y,new,7,0,0,0
"What do you guys use? And why?

  


I like Spyder and its easily accessible variable explorer and console, but I really miss an autosave feature there like jupyter notebooks have. Also if there is something with a better dark theme I wouldn't be mad either. Is there something Spyder-like with those two features?

  


Thank you for suggestions!  
  
",What's your favourite Python IDE?,93xpbp,new,15,0,0,0
"I broke into the data science industry a few years back but I don't want to be a pure data scientist anymore. Coding, tuning, cleaning, and other parts of the workflows have become boring to me. I could of course keep advancing my skills to eventually become a machine learning engineer or AI engineer but that's not what I want anymore. Plus I feel extremely isolated as opposed to former jobs I had before (marketing, public relations) and I want to transition to a different role. 

I still like the skills I learned but I only want them to be part of what I do, not all of it. Has anyone made the transition from a data scientist to a different role and still utilize their DS skills? I was thinking something in business development or a marketing director might be able to accomplish this. ",I don't want to be a data scientist anymore. Anyone transition to another role?,93wtfr,new,44,67,67,0
"The link: https://soccerpassingnetworks.herokuapp.com/matches/8bfd0a2d-17dc-4548-9a09-c3e637676575/

Recently I've been developing a website for visualizing soccer passing networks. It was largely inspired by this article: [A network theory analysis of football strategies](https://arxiv.org/pdf/1206.6904.pdf). They used standard techniques from graph theory and applied them on passing networks. They used different [centrality measures](https://en.wikipedia.org/wiki/Centrality) to identify the most important players in a network. You can read more about them and how they apply to soccer in the [FAQ](http://soccerpassingnetworks.herokuapp.com/faq/). The most consistent measure that identifies the most important player in a network (IMO) is PageRank. Initially developed by Google to rank websites according to their importance, it works pretty well on passing networks.

Data source: The authors of the previously mentioned article had limited data and only analyzed the teams that reached the knockout stages of the 2010 FIFA World Cup. So, I set out on a quest to find more data and piece it together to form passing networks. I used headless browsing for the most part since most publicly accessible soccer websites are notoriously hard to scrape using conventional techniques (using just Python and the requests library for instance). I scraped many of the popular sites like whoscored.com, flashscore.com, the official league sites and [this](https://www.kaggle.com/hugomathien/soccer) Kaggle dataset. It was not easy and there are definitely some mistakes here and there, but after manually checking a couple hundred of the games it was largely OK.

I'm still working on per-team analysis to find out who is performing the best and using additional techniques from graph/network theory (like community detection) on passing networks.

The tools used here are: Python, Django, NetworkX and SigmaJS.",Visualizing soccer passing networks: Tottenham v. Leicester [OC],93wt0b,new,5,16,16,0
"Hi, I'm new at this, and I would really appreciate any insights. I need to preprocess data for a TensorFlow Estimator, and currently, I have lots of datasets in BigQuery. As I understand it, the pipeline will look like:

- querying BigQuery for relevant data
- host relevant data on GCS as .tfrecords
- use TensorFlow's Dataset API to read in data
- train TensorFlow Estimator
- deploy

I know that the Dataset API allows you to parse the tfrecords into tensors or feature_columns, which can them be inputted into the Estimator nicely, but I need to do some text preprocessing on tf.strings. Ideally, I would vectorize everything from the raw data to the tfrecords in pure Python, but I'm not sure how it would scale. I would like to know when is the best place in the pipeline to preprocess data.",How to preprocess at scale?,93uszb,new,1,1,1,0
"How do you approach investigating new data sets and extracting/engineering relevant features and methods for achieving your tasks? While the classes I’ve taken have stressed machine learning, only some of them discussed data investigation. The closest I came to data investigation was in time series where we analyzed correlation coefficients, stationarity and stability, regression coefficient significance, etc.

When I think of data exploration, I think of first cleaning the dataset (which could mean different things based on the type of data). Next, finding various ways to categorize the data, computing some statistics on these groups and doing hypothesis tests. Groupings can be done categorically or via clustering/PCA. If the data isn’t of the categorical type (let’s say an audio signal), you can extract various features like MFCC, pitch, etc. 

After this is it plug and chug to see how well models perform? How do you choose which models are best suited for your task? Is there a better approach to data exploration? Thanks!",What’s your data investigation workflow ?,93uppj,new,8,30,30,0
"Not a data scientist but I have a lot of flexibility at work and essentially free reign to work with all sorts of data so looking for suggestions on projects to undertake. Also by smaller scale banks I mean regional/state banks.

My strength (and how I make a living) is SQL but I am pretty decent at Python.

Edit: removed duplicate words",Use Cases for Data Science at smaller scale banks?,93uewp,new,7,5,5,0
,Real-Time Credit Card Fraud Detection,93thk6,new,0,0,0,0
"Among all the packages I use in Python, none of them have given me more trouble than NLTK, which is consistently buggy, erratic, and uneven in its output. It's gotten to a point where I don't use it for anything more complex than tokenizing, and even that can more or less be done by simple splitting.

From what I can tell, the library is maintained by a very small number of people and so probably doesn't receive the same attention as something like Pandas. Has anyone else has similar frustrations with NLTK?",Why is NLTK so unreliable?,93tc6i,new,7,7,7,0
"Hi everybody!

I graduated MechE and been working in the Oil and Gas industry for the past 6 years. I like what I am doing, but I am tired of Houston.  I am pretty settled on moving to CO, most likely Denver area. 

So a career change maybe in my future.  I am pretty naive when it comes to big data and data analyst but I recently heard an article on NPR about these data boot camps and it sparked my interest.

Can I get any feedback on your experience?

• Part time or full time

• how long was the curriculum

• where you able to find a job afterwards

• do you feel it was “worth” it ",Taken a Data Analytics Bootcamp?,93t5fp,new,6,0,0,0
"I'm 33. Always loved data, and programming. Thinking of going back to school. I'd like to aim for Data Science—but I'd be approaching 40 before I'd be trained up.

Too old? Or is the demand so good that it won't matter?

*I hear agism is pretty rough in Computer Science related fields. Friend of mine is 52 and already getting hit hard by it.*",Is Agism a significant factor in Data Science employment?,93s95b,new,46,52,52,0
"Hi All!

New to reddit but excited to join the community:

Has anyone's working within or for school districts looked in an Ed-Fi ODS implementation? What other options did you consider? Why did you end up making the decision you did?

Trying to learn about lived experiences for what back end data systems provide to schools districts and are seen as helpful! Please direct me to the proper sub reddit if this is not the place

Thanks!",Ed-Fi Alternatives,93s53e,new,0,1,1,0
"Hello,

I had a meeting with one of the chief at the company I'm currently interning at (Started 3 months ago, about to end in a couple of weeks) and he asked me if I would be interested in working for the company at the end of my internship as a part-time data analyst ""consultant"" (I would have to fill some paperwork, but basically in France, we can create a self-employment company and work as a service provider with a lot of flexibility). The pay is good (especially compared to my intern pay) but next month will be the beginning of my final year before graduation and I'm engaged in an already time-consuming dual master so I'm still reluctant to accept. (But then again, the deal is I take on a project only if I decide to, and they give me a project only if there is one to work on)

He brought an interesting point during this meeting though; the experience I could earn through this might be extremely valuable for my resume. I was wondering if this is really the case IRL, in data science field ? Or is it something pretty common ( especially with more and more people taking on project on kaggle as a student )

And if it's really valuable, how should I highlight it on my resume ? I don't expect to work more than 5 hours a week so I was thinking of emphasizing more on the fact that the company was satisfied of my work as an intern and therefore offered me this opportunity.","Should I take this ""job"" offer as a student ?",93rgul,new,16,1,1,0
"Hi guys,

I'm currently looking for jobs in London, in Data Science/Data Engineering. I have soon a final interview with a small company/start-up that I am very interested in, and I would like to know what range of salary I should come with that would be fair.

**Location:** London

**Company:** small start-up

**Job title:** Data Engineer

**Education:** BSc, MSc and PhD in Physics

**Experience:** in Data Science per se, not much, but I have a good background in maths/stats, data analysis. I have passed the coding interview.

From digging on websites such as payscale, indeed, glassdoor and the like I can see ranges from 40k GBP to 65k GBP in terms of average salary. But I can't come and say 40-65, that's way too large... So how can I evaluate my profile a bit more accurately?

BTW is there any difference in salary between data scientists and engineers? I do understand that the duties are slightly different even though connected of course, I'm just wondering.

Thanks in advance for any insight.",Data Engineer Salary Expectation,93qkgz,new,16,5,5,0
"For this project I'm trying to predict whether certain car services are necessary based on a number of features including the amount time passed since the last service.

Now I'm running into the problem that while there's a peak in the predict probability at a certain distance to the last service (in kilometers), it often drops off again at some point which doesn't rly make sense (as time passes a service should become more necessary, not less)

Any ideas how to deal with this?",Using the time between data points as a Machine Learning feature,93nmdx,new,5,1,1,0
"Hi everyone,

I hope this is the right place to ask this question, if not, please don’t hesitate to advise otherwise.

I am currently building a Chabot for a uni project which uses Reddit comments as a training data set. I found a collection of which here:

http://files.pushshift.io/reddit/comments/

Does anyone know whether Reddit comments are in the public domain and can be freely used for research? Essentially, does using Reddit comments (with no reference to their authors) not break any rules?

Thanks a trillion!",Is using Reddit data fair use?,93nchx,new,2,2,2,0
"Hi, I'm new here, so please correct me if this would be the wrong topic to post this.

So, what do you guys think are some good sources/websites that help data scientists uncover the market ""pain"" in various different areas, in order to apply Data Science and Machine Learning to solve real problems?",How to keep up with market needs if you work as a data scientist?,93mj85,new,3,5,5,0
"I am doing my final year of university. After some networking and good grades, I was able to secure myself a project with the uni itself. So far I have experience in R doing basic EDA(tidyR, dplyR), building some classification models, visualisations(ggplot2), web scraping, basic sentiment analysis. I never wrote complicated functions or anything. It was mostly stuff I learnt while doing uni coursework. This will be my first time working on a real life project with R. I am kind of lost on where I should begin with. I would like prepare myself by getting acquainted with the packages. I have a week before my project starts.  If any of you have done anything remotely close to this please suggest me what packages and tutorials I should look into. Feeling excited and scared at the same time. Below is the description of the project. Thanks

**Predicting the suitability of student applicants from their “Statement of Purpose”.**

This project will take place at the Centre for Data Analytics and Cognition. There are three phases to this project. In Phase 1, the successful candidate will need to manually build a small learning data set to bootstrap the process. The candidate is expected to start with using LDA or other feature construction techniques to create the training data set. 

In Phase 2, the candidate will need to develop a R code to read a text input and predict the suitability of the applicant against the course he or she has applied for. There are two possible ways to approach this: from comparing the LDA outputs, or through traditional classification modelling, or a combination of both. 

Once the model is built, the applicant is expected to build in Phase 3, a Web-based interface to accept “statement of purpose” inputs from the user and feeds this to the predictive model created in Phase 2. The result of each prediction is to be sent to a designated email address.

Students interested in applying for this project should be comfortable working with R and preferably, have knowledge of building a Web-based application from their UG studies. The Web applications skill set is desirable but not compulsory as Phase 1 and 2 are the key aspects of this project.",Finally secured an analytics industry project within my university. Need advice on how to proceed.,93mff6,new,0,3,3,0
,"I've heard of unpaid internships, but this is taking it too far...",93lwhx,new,60,149,149,0
"Hi all,

First time posting in this sub :)

I am working on a problem where I have a time series of sales data. Somewhere in the data, there was a promotion that took place, and lasted for the rest of the time series. My task is to find when that happened.

I have googled very hard, and found techniques such as Intervention Analysis (which works when you know when the promotion happened, and is used to analyze the effect of promotion). There are decomposition methods such as STL, in which we can examine the residuals to see if there are anomalies. However, there appears to be multiple such anomalies in the data I'm working with.

I'm sure this is a common problem in e-commerce or sales in general. So what is the method to be used here? I'm very surprised that there are no posts of this on Google. I'm sure I'm missing something - probably just googling for the wrong key words. 

Any help is much appreciated.

Thanks!",Detecting a Marketing Promotion,93jyue,new,3,4,4,0
"Hi, I'm new here. 

I am trying to get a position in a data-science-based startup. Since I'm coming from a different background, and in this position I will be engaging mostly with data scientists, I was requested to study the work of data scientists and understand their main ""pains"" in their day-to-day job.

I thought it would be best to ask on Reddit first in order to get a grasp and maybe some leads on where I should further investigate. 


Would love to get your help and feedback !
","What are the main ""pains"" as data scientists?",93ii6a,new,13,2,2,0
,Reinforcement learning in business,93iecc,new,0,2,2,0
"I'm working on developing a binary classifier with a pretty small N (~500). The data is pretty skewed (85:15), and optimizing a gradient boosting model without oversampling has been pretty futile. When I oversample twice (I mean copying the minority set of observations twice) however, I am getting in the range of acceptable performance. Is this considered an acceptable application/method of oversampling? ",Question on oversampling and gradient boosting,93i376,new,9,1,1,0
"I’ve just been offered a permanent position as a Data Scientist for a medium sized company. The job is set in three parts: improving the intake of data, analysis of data and presenting the findings to upper management.

This is my first job out of university where I studied Math/Stats, I have done various projects in R/Python working with Data vis, regression modelling and general data management (cleaning etc.).

However, I have never worked with any form of scraping data or anything backend. The first assignment in the job will be to improve, or potentially make from new, dashboards which I have some basic knowledge of. 

My question is, what are some resources that will point me directly towards backend computing? As of right now I don’t know how they collect the data so it’s hard to say how I could improve it.

Any feedback is appreciated.",Hired as a Data Scientist with only analytical skills,93gkw4,new,17,26,26,0
"Just finished his linear regression section and found it was way too shallow. I do have some elementary statistics background but only stuff like MLR, experimental design and anova. 

Can you do any meaningful projects after completing this course or is it just to get ones feet wet?",Is Jose Portilla's Udemy Course Python for Data Science and Machine Learning course too shallow?,93g0xk,new,16,11,11,0
"Hello Everyone,

I have been experimenting on Tensorflow.js for sometime , I would like to Share my Learnings with the Community.

We know that An increasing number of developers are using TensorFlow in their machine learning projects. In March this year, the TensorFlow team at Google announced the arrival of the much-awaited JavaScript framework, TensorFlow.js (which was previously called DeepLearn.js).

Now developers can build lightweight models and run them in the browser using JavaScript. Let’s understand what the need was for the development of this framework.

## History

Before going to TensorFlow.js, I would like to start off with TensorFlow.

TensorFlow was developed in 2011 at Google as their propitiatory library for Machine learning/Deep learning applications at Google. This library was open sourced in 2015 under the Apache License.

TensorFlow is built in C++, which enables the code to execute at a very low level. TensorFlow has bindings to different language like Python, R, & Java. This enables TensorFlow to be used in these languages.

So, the obvious question is: what about JavaScript?

Conventionally, in JavaScript, ML/DL was performed by using an API. An API was made using some framework, and the model was deployed at the server. The client sent a request using JavaScript to get results from the server.

[Client Server Architecture](https://i.redd.it/eduvenp2y7d11.png)

In 2017, a project called Deeplearn.js appeared, which aimed to enable ML/DL in JavaScript, without the API hassle.

But there were questions about speed. It was very well known that JavaScript code could not run on GPU. To solve this problem, WebGL was introduced. This is a browser interface to OpenGL. WebGL enabled the execution of JavaScript code on GPU.

In March 2018, the DeepLearn.js team got merged into the TensorFlow Team at Google and was renamed TensorFlow.js.

Watch the below video for further details:

[https://youtu.be/qa1OXssGBHw](https://youtu.be/qa1OXssGBHw)

## TensorFlow.js

Tensorflow.js provides two things:

* The CoreAPI, which deals with the low level code
* LayerAPI is built over the CoreAPI, and makes our lives easier by increasing the level of abstraction.

## Getting Started

There are two main ways to get TensorFlow.js in your project:

## 1. via <script> Tag

Add the following code to an HTML file:

    <html>
    <head>
      <!-- Load TensorFlow.js -->
        <script src=""https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.12.0""> </script>
      </head>
        <body>
          Hello
      </body>
    </html>

## 2. via NPM

Add TensorFlow.js to your project using yarn or npm.

    yarn add @tensorflow/tfjs   
    npm install @tensorflow/tfjs    

In your main js file:

    import * as tf from '@tensorflow/tfjs';    

## CoreAPI

## 1. Tensors

So, what is a Tensor ?

[Visual Representation of Scalar,Vector,Matrix and Tensor](https://i.redd.it/qex3nvv5y7d11.jpg)

A scalar is a single number. For example, x = 1

* A vector is an array of numbers. For example, *x*=\[1,2\]
* A matrix is a 2-D array => (\[\[1, 2\], \[3, 4\], \[5, 6\]\])
* A tensor is a \*n-\*dimensional array with *n*\>2

TensorFlow.js has utility functions for common cases like Scalar, 1D, 2D, 3D and 4D tensors, as well a number of functions to initialize tensors in ways useful for machine learning.

## Code Examples

**tf.tensor():**

    // Pass an array of values to create a vector.  
      tf.tensor([1, 2, 3, 4]).print();   

**tf.scalar():**

    tf.scalar(3.14).print();    

And so on…

Watch the Below Video to get a deep insight into Tensors in TensorFlow.js:

[https://youtu.be/sZrwxnIfHCo](https://youtu.be/sZrwxnIfHCo)

## 2. Variables & Operations

Tensors are immutable data structures. That means their values can’t be changed once they are set.

However, tf.variable()is introduced in TensorFlow.js. The real use case for tf.variable()is when we need to change the data frequently, such as when adjusting model weights in Machine Learning.

Code sample:

    const x = tf.variable(tf.tensor([1, 2, 3]));  
    x.assign(tf.tensor([4, 5, 6]));   
    x.print();    

## Operations

There are various operations in TensorFlow.js. In order to perform mathematical computation on Tensors, we use operations. Tensors are immutable, so all operations always return new Tensors and never modify input Tensors. So tf.variable()can be used in order to save memory.

Let’s look into some operations:

**tf.add() — Adds two** [**tf.Tensor**](https://js.tensorflow.org/api/0.12.0/#class:Tensor)**s element-wise**

    const a = tf.tensor1d([1, 2, 3, 4]);   
    const b = tf.tensor1d([10, 20, 30, 40]); 
    a.add(b).print();  // or tf.add(a, b)    

There are many operations in TensorFlow.js. You can check the [documentation](https://js.tensorflow.org/api/0.12.0/#Operations)for other operations. I will demonstrate one more operation here: **tf.matmul()**

**tf.matmul() — Computes the dot product of two matrices, A \* B.**

    const a = tf.tensor2d([1, 2], [1, 2]);    
    const b = tf.tensor2d([1, 2, 3, 4], [2, 2]);  
     a.matMul(b).print();  // or tf.matMul(a, b)    

Watch the below video for deep insight into Variable and Operations:

[https://youtu.be/AP1BmP0BZmQ](https://youtu.be/AP1BmP0BZmQ)

## 3. Memory Management

Memory management is the key in Machine Learning/Deep Learning tasks, because they are generally computationally expensive.

TensorFlow.js provides two major ways to manage memory:

1. tf.dispose()
2. tf.tidy()

They both typically do the same thing, but they do it in different ways.

## tf.tidy()

This executes the provided function function and after it is executed, cleans up all intermediate tensors allocated by function except those returned by function.

tf.tidy() helps avoid memory leaks. In general, it wraps calls to operations in [tf.tidy()](https://js.tensorflow.org/api/0.12.0/#tidy) for automatic memory cleanup.

Code example:

    const y = tf.tidy(() => {
        // aa, b, and two will be cleaned up when the tidy ends.
    
        const two= tf.scalar(2); 
        const aa = tf.scalar(2); 
        const b = aa.square();
    
        console.log('numTensors (in tidy): ' + tf.memory().numTensors);
    
        // The value returned inside the tidy function will return // through the tidy,     in this case to the variable y. 
    
        return b.add(two); 
    });
    
    console.log('numTensors (outside tidy): ' + tf.memory().numTensors); y.print();

# tf.dispose()

Disposes any [tf.Tensor](https://js.tensorflow.org/api/0.12.0/#class:Tensor)s found within the mentioned object.

Code example:

    const two= tf.scalar(2);   
    two.dispose()    

## LayersAPI

Layers are the primary building block for constructing a ML/DL Model. Each layer will typically perform some computation to transform its input to its output. Under the hood, every layer uses the CoreAPI of Tensorflow.js.

Layers will automatically take care of creating and initializing the various internal variables/weights they need to function. So, basically it makes life easier by increasing the level of abstraction.

We will make a simple example feed forward network using the LayerAPI. The Feed Forward network we will build is as below:

[Neural Network](https://i.redd.it/u0n7lzmey7d11.gif)

## Code:

**Index.html**

    <html>
    <head>
    <title>
    </title>    
       <script src=”https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.12.0""> </script>
    <script src=”main.js” type=”text/javascript”></script>
    </head>
    <body>
    Tensorflow JS Demo
    </body>
    </html>

**main.js**

    const model = tf.sequential();
    
    //config for layer
    const config_hidden = {
      inputShape:[3],
      activation:'sigmoid',
      units:4
    }
    const config_output={
      units:2,
      activation:'sigmoid'
    }
    
    //defining the hidden and output layer
    const hidden = tf.layers.dense(config_hidden);
    const output = tf.layers.dense(config_output);
    
    //adding layers to model
    model.add(hidden);
    model.add(output);
    
    //define an optimizer
    const optimize=tf.train.sgd(0.1);
    
    //config for model
    const config={
    optimizer:optimize,
    loss:'meanSquaredError'
    }
    
    //compiling the model
    model.compile(config);
    
    console.log('Model Successfully Compiled');
    
    //Dummy training data
    const x_train = tf.tensor([
      [0.1,0.5,0.1],
      [0.9,0.3,0.4],
      [0.4,0.5,0.5],
      [0.7,0.1,0.9]
    ])
    
    //Dummy training labels
    const y_train = tf.tensor([
      [0.2,0.8],
      [0.9,0.10],
      [0.4,0.6],
      [0.5,0.5]
    ])
    
    //Dummy testing data
    const x_test = tf.tensor([
      [0.9,0.1,0.5]
    ])
    
    train_data().then(function(){
      console.log('Training is Complete');
      console.log('Predictions :');
      model.predict(x_test).print();
    })
    
    async function train_data(){
      for(let i=0;i<10;i++){
      const res = await model.fit(x_train,y_train,epoch=1000,batch_size=10);
       console.log(res.history.loss[0]);
      }
    }

Output:

[Output of The code](https://i.redd.it/j9i35qmiy7d11.png)

Pls watch the below videos for deep insight and code explanation:

[https://youtu.be/z2u-s3NzHhY](https://youtu.be/z2u-s3NzHhY)

[https://youtu.be/lKWUSkwOR5s](https://youtu.be/lKWUSkwOR5s)

## My take on this

This is excellent for coders who are familiar with JavaScript and are trying to find their way in the ML/DL world!

It makes things a lot simpler for people coming from a non-ML/DL background, but who are looking to understand this field. The use cases for this are many, and I personally think it’s something we need at the moment.

What do you think about TensorFlow.js? Let me know in the comments section below.

**Thanks For Reading and Giving your Precious Time**",Experimenting with Tensorflow.js for Machine Learning and Deep Learning,93bplp,new,5,8,8,0
"Hi everyone. I am just starting out learning some ML and understand some basic models. One of my upcoming requirements in class is to do a slight ""make-over"" or use a different methodology or approach to solving an existing problem. 

I would love to have a fun and more nerdy implementation involving maybe videogames, anime or comic books etc. Do you guys have any suggestions for good source of data sets or any existing ML studies? (Jupyter would be preferred but not necessary) 

I have been browsing UCI and kaggle for a while now but am not having much luck. Thank you for any assistance :D ",Looking for beginner-friendly geeky or nerdy machine learning implementations,93ax4o,new,0,1,1,0
"Are there any free or open source tools for data governance or metadata management? Data lineage would be good as well.

If there are any paid that's good, I'm also interested. ",Metadata management,939nz2,new,1,9,9,0
,Seven Practical Ideas For Beginner Data Scientists - Written by my friend and old colleague DS.,938xs8,new,6,135,135,0
"Hello r/datascience,

I'm new to data analytics and wanted to work on some projects to add to my portfolio to beef up my application. I've downloaded a few CSV's that I wanted to do some analyses on but don't have my own program to run SQL queries. I've only learned from Udacity and stuff on kaggle. What are some tools that I could use to run queries?

Slightly related, how do employed professionals approach this? I'm guessing if you're working at a firm, there's already tools provided by your company. What tools would those be? Do they run their queries through accessing databases online? Something similar to jupyternotebooks perhaps?",Running SQL queries on local CSVs,938au7,new,7,4,4,0
"I've been looking at how to test if the difference between two categorical variables is significant and have seen Chi squared and McNemar's test mentioned, but I'm struggling to actually apply them. Hoping someone can help.

I'm trying to look at loss aversion in world cup penalties shoot-outs. The book Thinking, Fast and Slow introduced the concept to me and it's that we'll work harder to avoid a loss than for the same gain. Shoot-outs have 5 rounds with one team winning a coin toss to kick first each round. If loss aversion is happening I expect the team kicking second's accuracy to be affected by whether or not the first team scored their kick that round. I expect the second team to be worse at scoring after the first team misses as then they're kicking for a gain that round and not trying as hard.

I had to scrap the data set from Wikipedia ([available here](https://github.com/MarkMacArdle/World_Cup_Penalty_Shootouts/tree/master) if anyone else wants to use it). Analysing it I get the following outputs:

Probability of 2nd kick of round scoring after... 

1st kick of round scored: 71.6% (n=95 - 68 scored, 27 missed) 

1st kick of round missed: 65.8% (n=38 - 25 scored, 13 missed) 

The probabilities of the second kicks scoring are different depending on the outcome of the first kicks of the round (as I'd hoped). But how do I test that this difference is significant and not just noise?

Other info that might be useful is the probabilities of

1st kicks of rounds scored: 70.5% (n=146 - 103 scored, 43 missed) 

2nd kicks of round scoring: 69.9% (n=133 - 93 scored, 40 missed) ",Help with testing if difference significant on categorical data (world cup penalty data set),937yfq,new,11,3,3,0
"Hello everyone,

I was looking for different types of encoding for categorical data and I found this [very nice contrib to sklearn](http://contrib.scikit-learn.org/categorical-encoding/) which implements more encoding techniques.

Basically, I find myself trying all of them and sticking with the one that works best, read the one that gives the best score on validation.

So, I'm trying to understand why would one work better than the other. Internal properties of my data aside, is there a rule of thumb as to what one should use and understand about those encoders. Does anyone have resources to understand them, and the intuition behind them, better?

Thanks!

Edit : the articles linked in the docs go a bit over my head. ",Intuition for different kinds of categorial encoding?,937h6t,new,3,2,2,0
"I have a dataset of about 0.5 mio customers and around 50 items without ratings in 7 categories. I'm trying to build an recommender system, but I could only find algorithms which rely on user ratings.
Can I substitute the rating for number of items bought?

From the users I have demographic information, like age, sex, married etc.
What ist the best way to connect this to an recommender system?

I think an item based algorithm should work better than a user based, since I don't have much user interactions from the customers. Am I right?

Has anyone an idea how to approach this problem?

Edit:
I have data what the customers bought for the last 10 years",Recommender system without ratings,937fd5,new,9,9,9,0
"Hello people of /r/datascience. I'm learning how to build Shiny apps. Can anyone recommend some good resources? Could be online tutorials, blogs, books, and whatever. Right now i'm going through the written tutorials on [shiny.rstudio.com](https://shiny.rstudio.com), as well as the lessons available through datacamp.

Thanks everyone, this community is awesome!",Resources learning Shiny in R?,937ef0,new,3,13,13,0
"I have been teaching myself PyMC3 the past couple of weeks because I think it has potential for a problem I am working on, but the more I think about the exact inputs I'm drawing a blank on how it would work. I'd love some advice from others here. 

So let's say I have 12 samples of 250 individuals. I have 2 data points on them and the outcome of interest is a simple correlation between those 2 data points. This data is typically hard to collect on new samples. 

My main goal would be to use those 3000 data points to create a prior. The issue I am running into the prior I am interested in is the correlation between those two variables and correlations are an aggregate phenomenon. I was originally thinking I could use the prior observations to create a prior distribution and then would theoretically only need to collect 25-40 observations on a new sample and would be able to provide a probability that the two samples come from the same distribution. I kind of see this akin to A/B testing, with an A that is treated as almost equivalent to the true relationship and the B that is treated as the observed relationship. 

Any thoughts on how I could do this at the data point level or would this need to be at the sample level given the variable of interest (correlation). Thanks in advance!",Bayesian Programming/PyMC3,9378xy,new,4,2,2,0
Anytime I'm asked on applications of data science all i seem to be able to come up with is selling people stuff and detection of fraudulent credit card transactions. I want to get into the field but i want to be more knowledgeable about everything out there before i spend too much time on it. ,Recommendation on books that speak on applications of data science that aren't just marketing.,936w9o,new,2,0,0,0
"Hi all I was just wondering if any of you are in a supply chain data science role. I'm interested to hear what your experiences are, what kind of tools you use, and how I might be able to break into this specific field",Supply Chain Data Science,936toy,new,5,2,2,0
"I  am learning datascience and recently completed a datascience track on Data camp.I am pretty comfortable with python and would like to apply my skills in solving real world problems.I am aware of kaggle datasets but as I am still learning, I would like a work on projects with a little bit of guidance.Any advice on where I can find such ""guided real world projects""?",Advice on a good resource for projects.,936ig8,new,2,3,3,0
"## Weekly 'Entering & Transitioning' Thread. Questions about getting started and/or progressing towards becoming a Data Scientist go here.

**Weekly 'Entering & Transitioning' Thread. Questions about getting started and/or progressing towards becoming a Data Scientist go here.**

Welcome to this week's 'Entering & Transitioning' thread!

This thread is a weekly sticky post meant for any questions about getting started, studying, or transitioning into the data science field.

This includes questions around learning and transitioning such as:

* **Learning resources** (e.g., books, tutorials, videos)
* **Traditional education** (e.g., schools, degrees, electives)
* **Alternative education** (e.g., online courses, bootcamps)
* **Career questions** (e.g., resumes, applying, career prospects)
* **Elementary questions** (e.g., where to start, what next)

We encourage practicing Data Scientists to visit this thread often and sort by new.

You can find the last thread here:

[https://www.reddit.com/r/datascience/comments/91c2ij/weekly\_entering\_transitioning\_thread\_questions/](https://www.reddit.com/r/datascience/comments/91c2ij/weekly_entering_transitioning_thread_questions/)",Weekly 'Entering & Transitioning' Thread. Questions about getting started and/or progressing towards becoming a Data Scientist go here.,934oxd,new,84,16,16,0
"My manager has suggested the idea of outsourcing some of our DS work to a 3rd party to help on my DS services related work (eda, segmentation, recommendations). Ultimately it would free up my time to work on DS products that our team is working on which is something I would like to do. 

I'm wondering if anyone has experience working as a DS and offloading/managing consultants effectively. Does anyone have advice on what type of work is easily handed off to consultants in the DS process? I'm newish to the field and feel like a lot of the time I'm doing EDA and don't have playbook prepared for what next to consider in projects. Without knowing how I would effectively use a consultant I'm hesitant to have my boss bring them in. 
 ",How to best use DS contracting,934j2o,new,3,1,1,0
"Hey everyone -

So we hired a remote, hourly resource because we have no FTEs and even if we did, it wouldn't be funded to pay a data scientist and even if it was, anyone decent probably lives in a real city.  Anyway, my use case and data is as follows:

1. A set of meter consumption data.  Roughly 400 meters, with hourly readings going back roughly a year, so roughly 3.5M records.
2. A listing of \~ 50 meters that failed efficiency tests; i.e., run 1000 gallons of water through the meter, and the meter registered 980 gallons, or 1020 gallons)  \[or more/less\].  Metadata on date of test and the efficiency rating measurements is included.  I have given him three reading values for meters that failed in the past, high efficiency, low efficiency, and an average of the two.
3. Measurements at field testing time include a high flow efficiency ratios (i.e., a shit ton of water going through the meter) and low flow efficiency ratios (normal amount of water).  Unfortunately, in the consumption data, we only have a total consumption value; i.e., consumption is not broken down into high/low registers, even though this is how testing is performed.

I tell this guy, look at the consumption records across the entire dataset, use the failing meters as training data set, write a model that can tell me which \*other\* meters are probable failures.   (The existing process for determination of failures is annual, manual inspection of each large commercial meter.  Very labor intensive and subject to extended periods of a meter reporting inappropriately.)

OK.  Anyway, the guy doesn't know the tools that I'd like him to have experience in, so I give him some time to come up on them.  But then, a few weeks in, I say, show me what you have and the shit just doesn't look like he's got half a clue.  So I say, convince me you've got a plan to attack this problem because I am not seeing it.  He sends this response:

>The model with only one independent variable (i.e. AVG efficiency) is prone to underfit and will be biased – we may miss the relevant relations between features and our output variable. So first I will have to figure the ways to balance the bias-variance tradeoff in our use case.

(?) OK, but I also gave him high and low efficiency reading values.

>Second, the consumption data is a tricky part here. There can be various scenarios that may cause the consumption data the way it is right now. For example, the resident can be out for vacation. Meter is installed in a store room etc. Additionally, Daily aggregation isn’t a good idea here because it doesn’t tell anything about the meter’s health, so I am trying out week level aggregation, month level and also quarterly level aggregation. I know that quarterly level aggregation would be too much but there is no harm in testing our hypothesis.

I asked him to explain to a dumb ass like me why we would want to use daily, weekly, or monthly aggregation when we have hourly data available?  \[got no response\]  It seemed to me that we lose a lot of granularity of our data here, making it more problematic to identify changes.  (?)  Note:  These are commercial meters and I don't care about vacations and / or store rooms / they are all stored outside.  I have identified those meters that are irrigation (not too many of them).  I have rainfall data, but he hasn't asked for it.

>Our solution is going to use a classifier to distinguish between cases of legitimate, such as residents on vacation, and illegitimate, as malfunctioning or tampered, zero-consumption meters.

These meters aren't being tampered with, the people running them are businesses, and I have existing processes to determine zero consumption situations.  The whole point is to determine malfunctioning meters and if anyone out there is clever enough to tamper with a goddamn ultra-sonic water meter, I'm inclined to let them have water on general principle.

Ultimately, I can't figure out if this guy has a clue or is just saying stuff to keep on submitting timesheets?  It would be one thing if he could tell me to have a field tech go test meters A/B/C/D/E and we could see how the efficiency ratings came back, but it feels like he's a ways off from being able to do that.  (?)

Thanks

Ninja Edit:  Thanks a lot for all of your replies.  Great community.

Ninja Edit 2:  Yes, I went to great pains to explain my data and expectations beforehand, but I did not want to write a manifesto in Reddit to that level of detail.  Yes, I have had weekly meetings with the contractor and asked, 'do you have any questions?  what else might help you?' and at no point did they mention wanting some of the other data sets mentioned.  At no point has he commented that there may not be sufficient data points to perform an appropriate analysis, which may speak to competence of the willingness to suck the contract dry.  That being said, I \*have\* told him that I have other projects behind this and more contracts could be waiting if we showed success.  Intentionally sandbagging would seem to be a dumb idea given that information.  (?) 

Ninja edit 3:  Failure rates occur at nearly identical 19% rates across the two manufacturer/models that comprise 87% of the commercial meters in question.  I cannot see how this metadata would help a model, but I will supply it to the guy.  Another manufacturer failed 33% of the time, but has only 5% of the meters in the entire system.  Will recommend phase out.  ",Is My Contractor Data Scientist Full Of Shit?,933jv4,new,139,86,86,0
"Hi all!

I was wondering what your recommendations are regarding DS and AI events in Europe?

I stumbled upon [DMEXCO](https://dmexco.com/) for example.

Thanks in advance!:)",DS & AI events in Europe,933exw,new,0,0,0,0
"I am a recent CSE major and am applying for a data scientist position. I don't have too much experience with data science besides a couple of machine learning courses I took, in particularly a class I took called ""recommender systems"". So for my interview project I am given a data set and asked to do a prediction. However they are also asking for some sort of plots or graphs. The prediction part of the project was fairly straightforward given my experience from the classes I took, but I have very little experience with graphs/plots besides the basics. The project is pretty open so they aren't asking for specifics regarding the graphs/plots. 

So my question is what would they be expecting from me given my CSE background, not data science, and what should I do regarding the graphs/plots to make my project look good?

Thanks in advance! :)",Interview Project,931a24,new,8,2,2,0
"Hey all,

Looking at tackling the data scientist career path and was wondering if anyone had a coupon code for datacamp?

Thanks",Does anyone have a datacamp coupon?,9308b6,new,3,0,0,0
"I'm looking for a dataset to perform a multidimensional gender salary gap analysis.
Any help?",Looking for gender salary gap dataset,92zonc,new,2,0,0,0
"Hello,

I have a CSV file with about 3 million rows in it. Here are the names of the columns: INK\_KEY and P\_CODE

I want to isolate rows that contain INK\_KEY numbers from a list. The list is about 1,500 numbers long.

here is the code that I am using to do this but it isn't work. Please let me know what I am doing wrong. Thank you...

`> Install.packages (""dplyr"")`

`> Library(dplyr)`

`> data1 <- read.csv(file.choose(), header=T)`

A system dialog appeared and I selected my CSV file that I wanted to look at

`> data1 <-filter(INK_KEY == 12001367, 12001456, 133344345, etc etc etc....`

But I am just getting an error message here.

Furthermore I am filtering with 1,500 numbers....is there an easier way to do this. I have the 1,500 numbers in a separate CSV file. Is it possible to tell R to match data from the large original file to the other file that has the 1,500 numbers that I am interested in???

Thank YOu",Need help filtering in R,92zbmo,new,12,1,1,0
"Hi, rising college junior here striving to pursue data science. Goals are to land a research/intern position during the school year and an internship for next summer.

I taken enough courses to know how to self-teach concepts and learn how to use packages in R. I'm pretty solid in math and alright in computer science if that adds to anything. My goals for the remaining of this summer are (1) learn Python for data analysis and (2) create 2 data analysis projects in time for fall recruitment. 

My question right now is what kind of project to do? I had in mind to do a text-mining based project, where I will extract data from Spotify's API and examine how a particular artist's music has changed over time, as am I a big music fan. However, there are several similar projects out there and I'm not too sure whether this is the best projects, as I feel like working with numerical data would be better (?). 

Any advice/suggestions? Thanks and much appreciated!",Advice on First Personal Project?,92z46p,new,4,3,3,0
"I work in a hotel. Our systems were in usage when dinosaurs were still around. So I can't access SQL etc, I have to work with provided Excel reports.

I'm planning to scrape a bit of data to modernize our decision making, and I'm wondering what would be the best way to go about it.

We are getting a report every day from our corporate HQ which is like 10 MBs. This is quite a lot. If I want to make a plot with for example one particular day mentioned in all the reports from the past year, to see how the rate / occupancy has been evolving across different segments, I would have to make Pandas read 365 reports and then always append the data into a DataFrame as a new row, which would take a lot of time (even though Jupyter can run on background, I think there has to be a better way).

I was thinking of as a first step letting Python work overnight, and just get the raw data from all the files and convert it into CSV (currently the files are so big because they are formatted XLSM files with graphs, macros, custom buttons etc).

And as a second step, after I have all these CSVs, I can directly access them and plot the data, because I think the individual files should take max few kBs it shouldn't be a problem.

Do you think there is a better / more elegant solution to do this?

I'm a total noob, keep that in mind (about 1/3rd into DataCamp curriculum for Python)",Need advice for smartly collecting a small sample of data from a lot of big files.,92yd13,new,16,2,2,0
"Are there any good book or courses for feature engineering & feature selection?

",Books or courses for feature engineering or feature selection,92y9pn,new,4,7,7,0
,Google partners with NIH to accelerate research,92xzrk,new,4,72,72,0
"So I want to talk about data science / analytics / visualisation to my students. I'm a teacher. Are there good or interesting videos out there?

One example is the Hans Rosling one (https://www.youtube.com/watch?v=jbkSRLYSojo).

Are there other good videos like this?",I would like to teach people about Data Science. What good educational videos are out there that are also interesting?,92uwoy,new,7,43,43,0
"I understand there's the Titanic data set, but I'm confused as what I'm supposed to do with it. Am I supposed to completed all the Kaggle ""Learn"" courses before even starting ? I know python and that's all",How to start using Kaggle as a 100% beginner?,92rqcn,new,23,87,87,0
I’m a Python programmer and started doing data science projects on my own a few weeks ago. My graphs suck and look like something a novice would do. I’d like them to be visually stunning. Any recommendations on packages I could use or any tutorials?,How to make my graphs more beautiful?,92qvq8,new,29,68,68,0
"As a college student, $299 is a steep price for me. I was wondering if anyone here has used it and can share their thoughts on it ",Can anyone here recommend/vouch for dataquest.io data scientist course?,92qe8w,new,7,5,5,0
"Hello,

I have an excel document with about a million rows in it. I am trying to isolate rows via the excel formula VLOOKUP but my computer is not fast enough to do the process. I was told my a redditor here to download R studio and he listed a couple of commands for me to use. I have alot of trouble with that I am seeking help from you guys. In the next paragraph I will detail what is included in my data just so people understand where I am coming from. I appreciate any help.

I have an excel document with about a million rows in it. It has two columns. The first column has a unique identifer (INK\_KEY)  and the second column has a code (P\_CODE) that is associated with that unique identifier. There is also a separate 3rd column that list select unique identifiers (SEL\_INK\_KEY)  that I am interested in. My goal is to isolate rows from the original document if it contains a unique identifer from the SEL\_INK\_KEY column. Here is a link to the online excel document (I removed 99% of the data for the sake of brevity).

Link: [https://knightsucfedu39751-my.sharepoint.com/:x:/g/personal/kailash\_knights\_ucf\_edu/ERbojrpqu1ZFkCMYewUKnqkBnZMUzXsmKSqZ1Gb1V6tKMA?e=uDcA6y](https://knightsucfedu39751-my.sharepoint.com/:x:/g/personal/kailash_knights_ucf_edu/ERbojrpqu1ZFkCMYewUKnqkBnZMUzXsmKSqZ1Gb1V6tKMA?e=uDcA6y)

The redditor I mentioned previously, told me to follow these commands below.

`Install.packages (""dplyr"")`

`Library(dplyr)`

`Dataset <- read.csv(""pathtocsvhere"")`

`Dataset <- Dataset %>% filter(Columnyouwanttofilterby == enterlisthere)`

The typed out the first command and it work but the rest did not. Furthermore, I have zero idea what I am doing in R also.

\*\*Edit: SOLVED. Thank you\*\*",Need help with program R to analyze data set,92ojf7,new,23,5,5,0
,"Are courses covering Introduction to Statistical Learning and Elements of Statistical Learning now replacing ""traditional"" intro stats courses?",92obvn,new,4,4,4,0
,Understanding Tensorflow's tensors shape: static and dynamic,92m7ic,new,2,47,47,0
,Important Unanswered Questions of 2018 in Data Science and Machine Learning,92izkb,new,0,5,5,0
"After a month in my summer internship the lesson I'm coming away with is how in the world do you justify the tools you need to IT and, assuming you get them, how do you share your results with people who only have Excel? I've learned that the business team wants interactivity and real-time data connections but IT doesn't want a business person doing any of those things. Can't blame either side. I would agree with them both but sadly I'm stuck in the middle. If I do throw together an app with real-time data connections I can't share it because no one else has the credentials or software to run it. So I'm just wondering if anyone else out there ended up in a job somewhere between business and developer, misunderstood by both, but somehow managing to get the job done. How do you do it and what tools do you use? 

I ask because I'm debating on investing time in learning the .Net framework to build web applications since it seems to be a nice compromise. The company I work for now has Microsoft deeply embedded in everything from the database to the company intranet with support for all of it. It's an internship though so I don't want to assume it's this way everywhere. Thought I'd ask here before I sink time into something that might turn out to be pointless.",Is anyone else here in a role somewhere between business and developer? How do you handle it?,92ide8,new,8,4,4,0
"Just started it and looking to maximize my experience with it. Wondering if many of you took notes alongside (either in another file or with pen/paper) or if you felt like the practical work was enough for you.

I know that everyone will be a little bit different, but I'm just looking for some opinions :)",Those who have used DataQuest - did you take notes?,92i3h2,new,8,6,6,0
"Im an analyst looking to level up my stats knowledge. 

What are some of the best books out there?

Edit: for anyone asking for more details I work in Sales Operations but do some basic data wrangling in R, SQL, and Excel. I have a finance background and studied basic statistics in college. Essentially looking for a refresher on fundamentals (regression, probability, etc) and to expand my knowledge into topics they don't teach you in a standard stats class. ",Can anyone recommend some intermediate Statistics books?,92i05q,new,28,55,55,0
"Hi,
I have a background in engineering and I'm looking into data science/machine learning. There are so many free resources online to learn but I'd like something structured with a nice progression so I narrowed it down to Udacity's nanodegrees in Data Science and AI and Microsoft Professional Programs in Data Science and AI.

Both seem to require about the same commitment but I'm not sure about the content. Although I can audit the classes for free to get a feel of the content, I'd like to know if anyone has done both programs (udacity and MS) and could tell me the differences or if one is much better than the other.

thanks",Looking to gain more knowledge - Udacity nanodegree or Microsoft Professional Program?,92hkix,new,4,8,8,0
"I’ve learned a lot of Mandarin because my boyfriend is chinese, and I’d like to see if I can leverage it in my career. Given I continue working in the US, do you think there are specific opportunities to use mandarin speaking skills to add value to data science jobs and/or increase pay. Not counting casually speaking mandarin here and there with Chinese scientists I may happen to work with.",Does Speaking Chinese Add Value to DS?,92h851,new,6,0,0,0
"Hello! This is my first time posting on Reddit so do let me know whether I need any types of flair or edits within my post!, Just to give you guys a bit of information about myself, I recently graduated with a Conjoint Major in Commerce and Science with Applied Mathematics, Economics and Finance. I landed a Data Analyst role a few months after I graduated where I honestly did not know what I was going to do (went in the mind set of wanting to get a job).

I've had a great time working for the past few months however I felt I haven't been able to have much challenge within my role. My excel skill has improved phenomenally and I've approached some minor SQL coding (didn't even know what SQL was before I applied for the job) and R but because of the BI tool we use there isn't much opportunity to actually apply what I've learnt in coding and I feel this will hinder my growth.

I've had a look within career development and the most appealing to my interests would be working as a data scientists. My main questions would be:

* What advice would you have in terms of career mapping towards a data scientist from a data analyst role?
* Where would be a great place to practice R and SQL skills? This is more of applying the codes in comparison to learning the codes like on w3school.

I am aware there's no linear way to get to the goal but any insights or life stories would be appreciated :)

Thanks in advance!",Data Analyst Career Progression,92gvfa,new,6,0,0,0
"For everyone's birthday on my team at work we chip in for a gift and I'm completely stumped on what to get our data analyst. The gift is usually something funny, and so far I've gotten a mug that says ""CORRELATION ≠ CAUSATION"" and still have about $45 left in the budget.

Any suggestions would be greatly appreciated...",Need birthday gift ideas for a data analyst...,92euse,new,43,37,37,0
"I have images for just over 100 patients, with an average of 40 images per patient. I need to classify the images as either having or not having a certain disease based on these 4000 labelled images. In the dataset, approx. 3200 images do not have the disease. What's the most valid way of going about this?",What's the most effective way to go about image classification when I have a very small dataset and one of the classes in the dataset is approx. 4 times larger than the other?,92etx4,new,8,16,16,0
"Not a criticism per se but it would be great to hear more from Data Scientists in the UK / Europe, especially those from outside the main tech hubs like London, Paris etc. Anyone have any idea how we could encourage this more?

It's not too much of an issue when it's technical topics under discussion but it's problematic when there are threads about working conditions / job market / salaries etc

Thoughts?",[Meta] This sub is too US-centric,92dhpp,new,7,2,2,0
"Hello! I'm working with a company that has paid a vendor for datasets they are delivering every day via CSV. We can import the data via 

- A website accessed through HTTP or HTTPS.
- An FTP server accessed through FTP, FTPS or SFTP protocols.
- A remote server that offers secure copy through the SCP protocol.
- A cloud drive service such as Amazon S3, Dropbox, Google Drive, Microsoft OneDrive or Box.
- An email attachment to one or more addresses for data export by email.

I'm still learning the field and would love to get some opinions on what option I should choose and why?

Thankya Reddit <3",Where Do I Store Data I'm Importing Daily?,92cjg1,new,12,21,21,0
"Would this course be useful for data science?

COMP9315
Detailed examination of techniques used in the implementation of relational, object-oriented and distributed database systems. Topics are drawn from: query optimisation, transaction management, advanced file access methods, database performance tuning.

Thanks.",Usefulness of this course,92bfo1,new,9,17,17,0
"I want to be able to look on a graph and reach correct conclusions from it without falling into any biases that humans tend to do, but I am unable to find such a course that gets into those details enough; the best I can find are those on Kaggle which aren't enough for me. So, any help?",Any course about properly understanding graphs and data?,92b1px,new,6,13,13,0
"\- I would like to know how to approach highly class imbalanced dataset in Machine Learning for binary classification problem

\- What evaluation metrics do you use for imbalanced dataset for classification task to check model performance?

\- Which algorithms are good for classification problems with class imbalanced dataset?

It would be helpful if someone can provide link to python code which describes the approach to handle class imbalance classification problem.",How to handle imbalanced classification problem in Machine Learning?,92az1l,new,17,22,22,0
"I am an undergrad currently majoring in Math and concentrating in DS from a reputable school. I am also working on side projects of my own accord to get more comfortable with python, R, and some SQL. I honestly am not totally sure what to expect from here. Should I expect getting an internship to be somewhat easy or at all? If I have a degree, personal projects, and a good internship is it likely that I can turn that into a good job right when I get my diploma? Also with only a BS should I expect to just be a data analyst/engineer instead of a data scientist? Will I have to go back for a MS in Stats or similar field to move up in DS?

I'm aware these questions are very much based on how well I can write code and problem-solve as well as my pure knowledge but I am just trying to get a feel of the general climate of how things move.

If it helps at all, I go to UCI so I know Irvine has lots of job and internship opportunities that many other universities don't have due to the many corporate and big business headquarters located here.",How hard is it to enter DS?,929v5a,new,12,0,0,0
"I have a dataframe with 5 columns that are characteristics from people that entered in the sales pipeline from my company, the first 4 column contain strings with characteristics from this people, the fifth column has information whether the the person has became a client or not(won or lost).

I am trying to predict the probability of a person with a combination of specific characteristics to become a client, would I be able to do that with the logistics regression model?

Would there be any other ML algorithm that would help me achieve this?",Classification probability algorithms?,928abc,new,4,7,7,0
"[https://www.kaggle.com/depmountaineer/pandas-idioms-from-common-sql-queries](https://www.kaggle.com/depmountaineer/pandas-idioms-from-common-sql-queries)

A Python 3  Jupyter notebook on Kaggle, a tutorial for someone learning pandas for doing data science with python.  Common SQL queries translated into Pandas incantations.",Pandas idioms from common SQL queries,927los,new,8,30,30,0
"I am currently working with CSV files (excel files) that contain information from about a million patients.  I have a running list of about 1,500 patients that I would like run analysis on. To isolate these patients I am using an excel formula (VLOOKUP). But this process is taking forever on my computer (very CPU heavy task)

I contacted my local university about using their super computer and they said that the interface that they use is linux and I would need some knowledge about python. I have very limited knowledge about linux and python. Is there any I can export this CPU heavy task to the super computer?",Can I use supercomputer for my data analysis?,927hyr,new,12,0,0,0
"Hi guys, I just landed an in person interview for an Associate Data Science position and was wondering what tips you all had. It's with a company that makes machines to help diagnose infectious diseases. They mentioned they use R a lot but are trying to transition over to more python. Any advice is appreciated!

Update: I got the job! Thanks for all the great advice everyone! ","Data Science Interview, advice?",927fvg,new,16,31,31,0
"I'm stuck and I have no idea what else to do. I have a list of more than 30K gyms I want to get ratings and check ins for (if available) on Facebook. But I'm running into some obstacles.

First, 200 calls per application per hour is the limit. Is there a way to get around this limit, and/or is there a way to more efficiently search for all 30K quickly without having to pause my code for one hour? I tried grouping them by zip code, but the Places Search API on Facebook uses a Search Radius and gets all gyms within that radius. One of those places should be my gym of interest, but I'm at a loss of how to check which gym is the one I'm interested in. 

Therein lies my second problem: checking for matches from two different data sources. I'm hesitant to match by address and name, because of inconsistencies between my list and the FB results. I'd probably have to standardize the names/address formats, but given the high variability of names/addresses, I'm not sure how effective that would be. Furthermore, not all the gyms have addresses listed on FB, and some gyms are chains with multiple locations in a given city, so that also wouldn't help. 

I've also tried to search for gyms in FB by making the search radius very small, but FB comes up with nothing.",Help extracting and cleaning data from Facebook Places API,926qbv,new,4,0,0,0
"I searched here but couldn't really find input from data engineers on what their work is like.

The role of course varies from company to company (as most data science related jobs do), though often has to do with working with big data tools, databases/pipelines, and can mix elements of being a data analyst (visualization) and data scientist (ML). 

So my question to the data engineers out there include
-What is it like being a data engineer? 
-Do you enjoy the work?
-What do you think of this career path? Does it set you up well to explore other aspects of data science, or even software engineering (ex. back-end development)?

Thanks!",What's it like being a data engineer?,926b3m,new,12,13,13,0
"I have a tech in home assignment later this week and I was wondering if anyone had a data analysis interview assignments that I can do for practice. Any help is appreciated. The test will definitely involve SQL, Excel and Python/R.",Data Specialist Position,926avf,new,0,1,1,0
"Hey, I am software engineer since the last 8 years, and have been doing a mix of data science/software engineer/bioinformatic for 65k/y in the San Francisco area for a shady company. 

I recently asked them 100k or I would walk away but they countered with 85k, they feel they can do that as I don't have a green card and my boss is telling me only PHD can make more than 100k here. I know it is BS but I am not entirely sure of my value and was wondering how much I am loosing if I decide to stay working for them, as I would be pretty much stuck for another year. 

I tried the glass door estimator and it scored me 150k which I found very high … ",Realistic Salary estimator for data scientist ?,925ee1,new,8,2,2,0
"Data Science is roughly Math + Coding + Experience 

* Does anyone here feel comfortable with hand written notes as a means to learn theory?
* Notes can have capability to give different perspective and intuition which other prominent users might not be aware of : [Link](https://notespace.in/all-notes/machine-learning-gradient-descent)",Handwritten Notes : Gradient Descent,9257a2,new,0,5,5,0
"I was going through a k-means customer segmentation project using rfm(recency, frequency and monetary analysis) Th final image was something as show below. How do I interpret this? I'm fairly new, it would be a great help if someone could explain this

https://i.redd.it/m6cvtvyd8cc11.png",How do I interpret this clustering?,924zh6,new,5,1,1,0
,Eight ways Data Scientists add value to any organsisation,924dz5,new,2,0,0,0
,"Tool overviews for Python (Mask-RCNN, system-design-primer, and Vibora) & R (infer and summarytools)",923vy6,new,0,1,1,0
"**tl;dr:** What's the best way to go about creating an analysis attack plan to propose to a large business that has missed sales forecasts the last two fiscal months, assuming that I have all data that would reasonably be collected by a data analytics team. 

I've landed an on-site interview with a data analytics company, and I was hoping to get some help and/or resources on an interview project. I was given a prompt, and a little over a week to prepare. To give some background on myself, I just graduated 2 months ago with a double major in Math and CS, and my experience with data analytics is about 1 semester of working with R and 2 years of debugging (NOT writing) python (numpy/anaconda) for physics majors doing some quantitative research. I'm not going to give the exact question because I do want to work this out on my own, but some pointers in the right direction would be awesome.  


I was given a website to go look at and gather what information I could. My next step is to act as if the website in question is a client that has missed their sales forecast for the last two fiscal months. It is assumed that I have access to all data that would reasonably be collected by a large business with a data analytics team. My task is to create an ""analysis attack plan"" in powerpoint form to illustrate how to diagnose the recent divergence from sales forecast, what hypotheses I would test, how to validate and what actions to take if any/all of the hypotheses are validated, and what recommendations I would propose to the clients' senior leadership.  


I am a strong public speaker and I tend to do very well with presentations. My main concern is that I've never created an analysis attack plan, and I've never done any sort of diagnosis to propose to a large scale business. What would be the best way to go about learning how to do this the correct way? I am prepared to put in a lot of work over the next week to prepare for this interview, so please don't hold back if you think that the time consumption for a resource might be too long.   


Thanks in advance!",Data Analyst Interview Prompt,922vza,new,7,11,11,0
I am new in data science and learning. I have come across so many algorithms and have tried to implement it in projects too. But are all of these algorithms equally used for real world applications? Is there any preference for a certain type of algorithm if so then why? ,What algorithms are used in real world applications?,922aoy,new,46,67,67,0
,A reminder of how to write a decorator with arguments using a data science example,920erg,new,2,8,8,0
"I'm at a point in my career where I'm not satisfied with my skillset, and I know that I need to learn something new. I have been a data analyst for about 4 years now. 

My main tool is R. I use it to do all of my data manipulation, analysis, and reporting. I have used Python when I have needed something more sophisticated (such as text mining of emails), but I don't see the benefit of doing everything that I know in R and  relearning it all in Python.

The main reason I ended up on this path was because I was sick of actuarial work: a life of poorly formatted and non-reproducible spreadsheets was not for me, I left the field, and I ended up being lucky enough to have had the experience of using R for every analyst position since then. 

I really want to learn how to develop a data reporting pipeline that can adapt to changes in an Oracle database in real time. I don't know where to begin with this. Every search related to real-time reporting in R that I've done on Google always talks about Google Analytics or Adobe Analytics, and I haven't been able to find anything helpful. I have considered enrolling in a masters in computer science program after finishing my stats masters, because I essentially have no computer science background outside of basic programming.

Could someone direct me to what I should be looking for and/or offer an opinion on whether bolstering my computer science background is even necessary for what I'm trying to learn?",I am almost done with a master's in stats. How do I learn how to automate daily reporting or potentially real-time reporting?,91zerd,new,11,10,10,0
,Tips on how to build your own portfolio to get a career in the space of Data Science - For data scientists,91yjmv,new,0,0,0,0
"What book do you recommend to answer that question?

I'm currently reading ISLR (first chapters).",How can I valuate if a model being used is still good?,91y1it,new,3,0,0,0
"I've managed to build up a large-ish corpus of news articles from multiple publications over a period of about a month. What are some good projects related to it? 

One option that I have is a sort of aggregate summarization: Given an article as input (e.g. a NYT article about the royal wedding), find articles in other publications about the same topic and create a summary that uses information from all of the articles that are returned by the search function. 

This might be too hard, though; I think the biggest challenge would be avoiding redundant information when summarizing the group of documents. I'd need some form of novelty detection or something. I liked this neat-looking project on Towards Data Science where the CEO of Machine Box [managed to make a very strong classifier that detected fake news](https://towardsdatascience.com/i-trained-fake-news-detection-ai-with-95-accuracy-and-almost-went-crazy-d10589aa57c). Stuff like that would require a lot of pre-handling the data; for the fake-news project the guy manually marked every article as being fake or real.",A good project using a news dataset?,91xw3q,new,0,1,1,0
"A very nicely put together introduction video on basic decision trees, classification trees, regression trees. 

Well worth 15 minutes of your time (or 10 if, like me, you watch all YouTube videos at 1.5x speed!) 

[https://youtu.be/9w16p4QmkAI](https://youtu.be/9w16p4QmkAI)",How decision Trees work by Brandon Rohrer of Facebook (video),91wdzg,new,0,7,7,0
"We are the home of Summit, the fastest supercomputer in the world, and we are hosting a competition which looks at tackling some of the problems being researched here at Oak Ridge National Lab! [https://smc-datachallenge.ornl.gov/](https://smc-datachallenge.ornl.gov/)

Registration for the challenge is now over, but the datasets will remain available until the competition closes.

If you have any questions about the data, we are holding an AMA session with our data sponsors (ORNL scientists) this Friday, July 27: [https://www.reddit.com/r/smcDataChallenge/comments/91lzrw/save\_the\_date\_we\_are\_holding\_a\_live\_ama\_session/](https://www.reddit.com/r/smcDataChallenge/comments/91lzrw/save_the_date_we_are_holding_a_live_ama_session/)","Looking for real scientific data to test your methods on? Have a look at the datasets provided for our challenge: https://smc-datachallenge.ornl.gov/ Topics include Neutron Scattering, Geographic Information Science, Materials Science, Additive Manufacturing, and HPC",91w0oe,new,0,26,26,0
"I have seasonally adjusted hourly google trend data supposedly representing the selling and buying intentions.

https://imgur.com/a/gV3iKTq
legend: b=buy,s=sell,p=price. smooth lines are moving average.

I would like to see if it can be used to predict returns.

The idea is that after a period of panic selling, the price is lower than it should, and will statistically move back (and the opposite in a period of euphoric buying). Also at the beginning of the euphoric buying period, the price will go up (down in panic selling period). 

A possibility is to find the peaks in sell/buy data. Then for all time interval after the peaks, plot return from peak time to a time in the future (one or two peak widths); do the average of these plots and see if at some time the return is consistently negative/positive. 

I am searching for a collaborator to do this, PM!",Sentiment Analysis Bitcoin,91vm50,new,3,1,1,0
,Recommend the book to learn R in 14 days for medical research to a person that already knows programming and basic statistics.,91vgkt,new,4,0,0,0
"Does anyone know if these streams will be saved? I was looking for the first day, but it looks like it wasn't uploaded on youtube.",Metis Demistifying Data Science Online Conference,91ug3b,new,1,1,1,0
"I have been casually looking at Data Analyst positions (I graduate next May) since I see that as kind of a stepping stone into a data science career path before I pursue an advanced degree.

Though I mainly focus on positions that explicitly mention R and Python, I have noticed that many of these analyst positions **only** require Excel and don't even mention R or Python. This has me a bit curious. Has anyone here ever been hired to one of these positions and predominantly used R/Python in spite of the job posting's emphasis on Excel? 

For example, say the bulk of the job is gathering data, running tests, and creating reports. What barriers would I face to doing this in R and creating said report with RMarkdown? 
    
",Utilizing R/Python in an Excel-based job,91u471,new,11,3,3,0
"I'm interested in ways in which Data Science can be applied in a personal setting. Shoot away! 
Thanks. ","Data Scientists, tell us your personal life Data Science applications and hacks",91t1y6,new,14,10,10,0
,Real World Optimized Non-Stationary Multi Armed Bandits,91stw5,new,2,24,24,0
"I have been collecting a number of images (all same size/format) from Amateur Radio (Ham) operators as part of a web logging project. I've accumulated about 3000 of these images (see examples below).

I'm trying to develop some image data skills but I can't really think of something cool to do with these images. What does Reddit suggest I do with 3000+ random images with lots of static etc?



[image 1](http://hflogs.com/sstvImages/20180725-022608-Scottie-2.png.6qyn_dqhSp07D4gqNWgN6A==.png)

[image 2](http://hflogs.com/sstvImages/20180725-013910-Scottie-1.png.1u2bdO22uZoKalncVs3AgA==.png)

",Ideas for data science project on these images,91s3aj,new,4,4,4,0
"Need some advice here... 
A C-suite Big Boss in the company I work decided to buy a big data platform/visualization tool, very expensive. It's basically a hadoop cluster with a *very* thick skin and many small apps and tools to access and play around with the data. 
The problem is that this Big Boss now wants all the organization to use this platform to run our ML models, even if they are not big/data related. This is: use this visualizations and storage environment to run ml models, originally developed for single node computing, using traditional libraries, scikit learn, Keras, etc... 
We managed to ""open a window"" in this system and now we are allowed to paste (!) some code within this platform, and use the data form there, but of course the scripts have to be translated/adapted/re-written to use the distributed processing capabilities of the cluster. Or, we can just ToPandas everything and just run single node everything, as usual. Of course we do not have any control of the server, libraries, etc. 
Big Boss is really pushing this, and I do not know at what point I should start resisting and trying to explain the absurdity of all this. ",advice needed / wrong tool being deployed and we are forced to use it,91q2a8,new,6,1,1,0
"I'm keen to start a Data Science consulting company.

I want to make it easy for clients by offering a selection of products or services. 

What are some examples of products and services a Data Science firm should be able to provide?",What Products / Services should I offer,91pni2,new,3,1,1,0
"Hi,

I have recently published a new article on my blog - title basically says what it's about:

[http://numbersandcode.com/building-a-strong-time-series-forecasting-model-with-simple-indicator-functions](http://numbersandcode.com/building-a-strong-time-series-forecasting-model-with-simple-indicator-functions)

Looking forward to some feedback and interaction. ",Building a strong time-series forecasting model with simple indicator functions,91p7pq,new,2,6,6,0
"I'm doing an analysis where you make a regression equation to predict IMDB rating. One of the aspects I want to use is Genre So when I look at the broader category of Genre, there are 10 categories. Some are statistically significant, some are not. Do I need to drop the entire category of genre in my final regression equation, only use the statistically significant genre categories, or use all the genre categories no matter the significance? Thanks for the help!

https://i.redd.it/jg2uyea1g0c11.png",Predicting IMDP movie,91o4uq,new,2,2,2,0
"I'll try to explain this briefly as possible. Basically, there is a certain product line our company sells with many different products. We want to classify products into different behavioural product lifecycle groups  for future forecasts. This was a pretty simple problem for me. Glancing over the data, it seems that behavior is mostly attributed to product popularity. Also, the less popular a product is, a more erratic its lifecycle can be.

Since different products can be around the same level of popularity, but still have different levels of sales volume, I scaled the sales data for each product. Then, I plotted each product on the same plot to compare trends. I would start with the most popular product, then add more products in decreasing order of popularity. Most behaved a certain trend, some didn't (which I separated into a different group). If I kept adding products and deviations persisted, I would finalize the sales threshold to establish the certain behavioral product group.

So I show this approach to my boss, and he basically says I'm overcomplicating it. He says I should look at each product individually, and just keep looking at individual graphs and see what trends arise. Bear in mind, I'm comparing over 30 different products, potentially hundreds. So I did that to entertain the idea, and just as I expected, it was impossible to analyze and I didn't learn anything new that my original approach showed me. I don't know what to do. I feel like I cannot communicate with my boss about this because we are from different backgrounds. I literally have proof that ignoring scaling can lead to huge forecasting errors, but I feel like my opinion is disregarded and that I'm ""overcomplicating"" the problem. I don't know what to do, I feel like I'm losing my mind, this approach seems completely valid to me.

EDIT: Just some additional thoughts. I've been continually showing great solutions with R to this problem and various others, and management has recently been shunning R. They say it won't accomplish anything, and that it all can be done with just Excel. This just seems like a horrible mindset. I'm trying to offer them solutions to automate analytical processes and I feel like they just want the simplest solution possible. Of course things don't need to be complicated when unnecessary, but I thought most companies would love to have employees offering such talents to the organisation. If a framework can be implemented to make organisational processes easier, why not implement it?",Having a Really Bad Time at Work,91n07d,new,54,33,33,0
"Hi all, I am not sure if this question belongs here and it's very open ended. I would like to hear your opinions on this though. 

I am a data science intern at a manufacturing company in the semi conductor space. and I have access to the bookings Backlogs and Billing data of this company. There are no other data scientists in this place, so I guess they are trying to figure out if data science works for them through me. I don't have a lot of business experience so I am not able to figure out a problem to apply machine learning and predictive analytics on this data or if it even makes sense to do that. So I would like to know what other data scientists in similar manufacturing companies do and what kind of business problems do they solve? Thanks and sorry if this is in the wrong place, I have researched a lot and tried to talk to people in the company but I couldn't find anything tangible. Off the top of my head I can only think demand forecasting, but is that a good problem to pursue? Are there other problems?  
Thanks and sorry if this is in the wrong place",How to use data science to improve business in a manufacturing company in the semi conductor space?,91midh,new,9,12,12,0
"I am independently learning data science, and I am doing increasingly intensive modeling on my MacBook Pro (e.g. neural networks). Even though my laptop is very new and fairly powerful, I am realizing that some models take ridiculous times (1 hour or more) to train and predict.

Someone suggested I look into GPUs for higher processing power / speed.

Is this the most cost-efficient way for an independent data science learner such as myself (apart from cutting size of data down or adjusting hyperparameters for models)? If so, does anyone have any particular recommendations?",External GPU Recommendations?,91m7fq,new,6,4,4,0
"Assuming, I was able to use YT's Data API to get data like comments, views and likes (which I'm struggling to do now) How to save it in a format that I could analyze it? What are the steps I should take? What kind of things could I know from analyzing something like this?",How do you run a script to get a YT channel info?,91jn0h,new,0,1,1,0
,Breaking into Data Science in Seattle,91j500,new,13,14,14,0
"I think having an education is essential, not only for the piece of paper, but also for being able to develop an understanding of the tools used in data analysis. It seems that there are more and more people who wish to bypass this process and ""get rich quick"" through YouTube or Udemy.   


Honestly, there is no way that a person who learns some basic tools on Udemy is going to be competitive with someone who has a degree in Statistics. Assuming one gets a job, it will quickly become clear that one does not possess an understanding of the models, particularly when one goes to make a presentation in front of people who either do understand them or are trying to.   


Very sad that education is held in such low regard in 2018. ",Why do we see so many daily posts from people hoping to bypass getting an education?,91i1qe,new,162,7,7,0
,Trying to find the best way to set up a scatter plot survey like the NYT's Game of Thrones piece.,91hshh,new,20,34,34,0
"I'm a current Stats major, and am aspiring to be a data scientist in the future.

Looking at articles from around the web, people are always saying that comp sci is the clear complement to Stats in terms of a data science background. However, there is also another school of thought that believes that data science, or in this case I'll narrow the scope to consumers' behaviour, can be paired very nicely with social sciences such as sociology / psychology, to understand the actions of consumers or the society on a different and less scientific level.

What do you guys think? Is there any merit in such a view?

I'm asking because I might want to declare a minor in social sciences, and I feel like this could be an added bonus in terms of helping with my data science aspirations.

Thanks, and I look forward to everyone's replies.",What other kinds of majors / fields of study complement Statistics for aspiring data scientists?,91gzob,new,49,16,16,0
"Hi friends,
Recently I started going to data science competitions and It was quite inspiring. Most of them are conducted online but I want to create on locally with a few friends. If someone has experience with organizing such events, can you give me a few bits of advice from where to start and how process the whole thing?
",How can I make data science competition locally?,91fccn,new,5,7,7,0
"Hello, I am wondering if anyone has links to articles or videos that go into detail about interpreting a linear regression model. I have seen countless resources go into tutorials of setting up a simple or multivariate linear regression models and performing OLS manually or with sklearn, but I'd like to go beyond that. I'd like to look at data that produces multicollinearity, misleading p-values or R\^2 values, data that needs to be scaled, regularization, etc. Details regarding how to interpret MSE or RMSE and when to look at one or the other would also be helpful. 

Preferably in python, but any tool or language is likely fine if well explained. 

I am starting to piece together all the techniques and approaches, but need a little more clarity in a variety of areas first. ",Resources to Help Interpret Linear Regression Models,91du5j,new,8,11,11,0
"## Weekly 'Entering & Transitioning' Thread. Questions about getting started and/or progressing towards becoming a Data Scientist go here.

**Weekly 'Entering & Transitioning' Thread. Questions about getting started and/or progressing towards becoming a Data Scientist go here.**

Welcome to this week's 'Entering & Transitioning' thread!

This thread is a weekly sticky post meant for any questions about getting started, studying, or transitioning into the data science field.

This includes questions around learning and transitioning such as:

* **Learning resources** (e.g., books, tutorials, videos)
* **Traditional education** (e.g., schools, degrees, electives)
* **Alternative education** (e.g., online courses, bootcamps)
* **Career questions** (e.g., resumes, applying, career prospects)
* **Elementary questions** (e.g., where to start, what next)

We encourage practicing Data Scientists to visit this thread often and sort by new.

You can find the last thread here:

[https://www.reddit.com/r/datascience/comments/8z4eeb/weekly\_entering\_transitioning\_thread\_questions/](https://www.reddit.com/r/datascience/comments/8z4eeb/weekly_entering_transitioning_thread_questions/)",Weekly 'Entering & Transitioning' Thread. Questions about getting started and/or progressing towards becoming a Data Scientist go here.,91c2ij,new,76,6,6,0
,"Some exercises related to Logistic Regression, Principal Component Analysis, Linear Discriminant Analysis, Support Vector Machines, the kernel trick, word embedding and constrained optimization. Feedback and stars appreciated :P",91au8m,new,5,83,83,0
,"Fast, Flexible, Easy and Intuitive: How to Speed Up Your Pandas Projects – Real Python",917ktb,new,4,74,74,0
"[Example](https://i.imgur.com/GzbtYKV.jpg) 
 
Trying to make a map like the one above. There are a lot of examples of these kinds of maps for population. ",How would you scale a map by a variable?,916uy0,new,2,4,4,0
"I am software engineer learning data science, and wonder if there are any material I can read on how to analyze code as text data. Specifically, I want to be able to analyze code for possible defects, performance, etc... using data science without having to actually compile and run it. 

When I looked into analyzing code using data science, all I see is how to do data science using code, and that is not what I am looking for. ",Is there a data science resource on analyzing code base?,911q0m,new,4,8,8,0
Hey guys I am using R to make a few data visuals for my company's presentations to clients. Do I need any type of disclosures on the PowerPoints? I have only used free packages.,Using R Graphics in Presentations,910rjx,new,11,7,7,0
,What are some applications for collecting data through qr codes and other scannable IDs? Preferably in the manufacturing industry,90zyn7,new,3,7,7,0
,What sort of model can I use to forecast this sort of trend? Details in comments.,90zt71,new,21,32,32,0
"Hey guys.
Are there any datasets that have been made by body sensors on players to get attributes like
1) Player position
2) PLayer speed
3) Ball position
4) Ball speed
etc

If yes, please help with links. Thanks!",Soccer (Or any sport) player position datasets?,90za65,new,7,19,19,0
"I was just wondering, what's the common career progression at large companies for an individual contributor or for a managerial role?

Junior Data Scientist 
Data Scientist
Senior Data Scientist 
... ??? ",Career progression / DS titles at large companies / FANG,90z0yb,new,7,22,22,0
"Hi, i've recently took a BI developer job (my first analytic job), where I will work with SQL Server and PowerBI. I, of course, passed their SQL test, but before I start the job, I would like to really be advanced in SQL. I've taken several Udemy and Lynda courses, so I understand SQL itself fairly well.

What I would want is actually try SQL queries on different databases - basically to have tasks to find something in a particular database (or different databases), but I don't seem to be able to find anything with Google.

I do have the 3 basic databases (Northwind, WideWorld and Adventureworks) from Microsoft restored in my SQL server, and they do have a lot of data, but I have no idea what to try and find to test my abilities. Do you know of any such sites?

PS I have gone through w3 schools SQL quiz and found it to be fairly easy, I would prefer more advanced queries",What would you recommend for learning advanced SQL?,90yz5d,new,30,53,53,0
"When I think of data science, I think of analytics, statistics, algorithms, and modeling. An MS in Statistics does not cover all of these things, do you just learn the rest on your own? ","If you get an MS in Statistics, where do you pick up machine learning?",90yfic,new,29,3,3,0
,How to optimize stacking?,90xfin,new,3,3,3,0
,Data science is science's second chance to get causal inference right: A classification of data science tasks,90wyfz,new,11,84,84,0
,How to lie with Data Science,90wxel,new,4,3,3,0
"*(Skip over this paragraph to get to the point of my post)* I'm trying to become a data scientist through edx courses over the next year. My father-in-law has a small-ish business (he's an automotive paint wholesaler) and he's saved every scrap of data from his business over the last ten years. The data just sits there and he is excited about me learning about data science and playing with his data and eventually guiding his decisions to get real results. That's my plan for work experience before I hit the job market.

I know the basics of statistics and I am well-versed in calculus up through multivariate, but I don't know anything about linear algebra. How often do you use linear algebra in your data science job, and what should I absolutely know before delving deeper into analytics/DS (past what I'm doing now, which is learning the basics of Python)?",Linear Algebra and Data Science,90wg39,new,5,1,1,0
,Data Analyst to Data Scientist,90w2zi,new,1,1,1,0
"Hi All,

I have recently posted to following article:

[https://towardsdatascience.com/ai-in-video-games-improving-decision-making-in-league-of-legends-using-real-match-statistics-and-29ebc149b0d0](https://towardsdatascience.com/ai-in-video-games-improving-decision-making-in-league-of-legends-using-real-match-statistics-and-29ebc149b0d0)

In this project, I took real match statistics and attempted to model it as an MDP and then apply reinforcement learning in order to find the next best play for long term success. 

I have also posted all of my working in three parts on Kaggle:

[https://www.kaggle.com/osbornep/lol-ai-model-part-1-initial-eda-and-first-mdp](https://www.kaggle.com/osbornep/lol-ai-model-part-1-initial-eda-and-first-mdp)

[https://www.kaggle.com/osbornep/lol-ai-model-part-2-redesign-mdp-with-gold-diff](https://www.kaggle.com/osbornep/lol-ai-model-part-2-redesign-mdp-with-gold-diff)

[https://www.kaggle.com/osbornep/lol-ai-model-part-3-final-output](https://www.kaggle.com/osbornep/lol-ai-model-part-3-final-output)

I will be trying to share with the league subreddit to see how they feel about this kind of idea but would appreciate your thoughts on whether this makes sense and if my model is applied correctly.

Thanks",Using AI in League of Legends to Improve my Team's Decision Making (feedback request),90w1gm,new,2,4,4,0
"This question is part of a project I have at work, but also a question that has been in my mind for quite a while.

Let's say I have a model for leads for a product and my population is quite big.  Since I can't call all of them, just a small portion (say 2% of the population) what clever techniques would you use to train and/or choose the best model?

So far I just been thinking of maximizing the lift curve (percentage of true positives in samples ordered in probability given by the classifier) for the top 2% and just call it a day (also, I would obviously use the same dataset to calculate the leads probability for the different classifier to avoid any misleading conclusions).

Really interested in hearing and discussing of your insights and experiences.",Model selection when only top 5 or so percent mattera,90vo8f,new,4,3,3,0
"https://i.redd.it/1876c2tjlfb11.png

Mainly why do we use equation on line 7 & 8 to update the values of m and c.

used y = m\*x +c equation.

error function is sum of squared error. I know that m_gradient is the partial derivative of the error function with respect to m and c_gradient is w.r.t c.",Someone please explain the mathematical part of this.,90vio2,new,5,5,5,0
"Hello data scientists out there! This might be very basic, but I'm looking to work with a dataset with several csv files which have common ids and variables at multiple levels. It also comes with a 'metadata' file that indexes the variables in each csv. I need to establish the relations the correct way among them and extract filtered informations out of them. Here is a a glimpse of it.  I guess someone well versed with SQL might help. So please pm me so that I can share link to my google drive folder with the data. 

https://i.redd.it/kighjlq98fb11.png",Help needed with a dataset containing several csv files,90v3nv,new,4,0,0,0
"Hi everyone, I have done a couple of Data Analysis projects, a Shiny App, couple of Tableau Dashboards and a blog (planning to add more). I am looking to host all of them on a single platform. Currently I am showcasing them on my google sites website but am looking for alternatives. I know basic HTML, CSS but not much javascript and I am not planning to learn Javascript anytime soon. Here are the options I considered. Please let me know if you have other good suggestions:

1. **Google sites:**  
*pros:*  
\- Easiest to setup. I can upload PDF's, PPT's, Images from google drive and I can embed Tableau Visualizations, or anything with an embed code easily  
\- Google Analytics is very easy to integrate. Not important but it helps when I know that a recruiter has seen my profile  
\- It is free and I don't need to constantly maintain it.  
*cons:*  
\- It shows a default footer at the bottom most part. I feel that this makes my site look amateur. This cannot be removed in any way. Also, the URL is google sites URL and I can only redirect from my custom URL. Again amateurish but I can pay for GSuite and use my own URL, so that's an option  
\- Site format is rigid. I cannot add javscript, etc later if I decide to
2. **GitHub pages:**  
*pros:*  
\- Recruiters will know that I built the site by myself and it adds some credibility to my profile. Also, they can check out my GitHub etc  
\- It is free and minimal maintenance  
*cons:*  
\- I need to take care of design, etc and need to do research whenever I want to embed a new type of object.  
\- Difficult to add google analytics
3. **Medium:**  
*pros:*  
\- Good for blogs. It is free and I can reach out to a broad audience. I am seriously considering this option, along with GitHub pages  
*Cons:*  
\- Rigid format. Not good when I want to show dashboards/apps only on the webpage.
4. **Squarespace, etc:**  
*pros:*  
\- Sites are very polished and look clean.  
*Cons:*  
\- Need to pay. I am okay with paying upto $10 - 20 every month but can't keep monitoring my hosting costs, etc

What do most of you use and is there anything which is easy to setup and customize?",DS portfolio platform recommendations,90v0gg,new,6,2,2,0
"What are (your) good practices to speed up your R code easily? 
I am interested in your experience, code syntax, packages and web/book reference. 
Thanks in advance. ",How to speed up R code?,90rujx,new,26,37,37,0
"I am interested in doing freelance business intelligence / analytic work and was wondering exactly what skills Would be needed and what do people want out of it. 

What I plan on doing is contacting local small and medium businesses. ",What skills would I need to freelance?,90rirz,new,11,0,0,0
"I am doing a data science project and have a list of 100,000 owners of a specific type of luxury item (that is hopefully roughly correlated to the likelihood of them buying the luxury item we are marketing).  The list includes their names and street addresses (and they are all in a single US state).  I want to pull out 2,000 high likelihood leads.

I'm trying to figure out how to (1) sort through the list and (2) find and attach their phone numbers and email addresses.

For (1), my thought was to overlay census tract data on income / other wealth indicators, and select the owners in the highest income areas.  Any other alternative / additional ideas?

For (2), it seems like the Whitepages API is the best option, but I signed up for a test account and it doesn't seem to do a good job of finding their phone numbers (though it generally does find the person, their past residences, and people in their household).  Any other thoughts?

Thank you in advance.",How to narrow down lead list,90pov6,new,2,3,3,0
"Hi everyone, not sure if this is the right place but I am pretty desperate now.

For my Master's thesis, I have the data of all the wind turbines in my state, along with their coordinates. The thing is I need to map them according to the different regions in the state and I have no idea how I can go about doing that. What I meant is there are let's say 30 areas in a state and I would have the latitudinal and longitudinal coordinates of a wind turbine and would like to find out which area they belong to. 

I wanted to try something called qGIS so I downloaded the software from the website and then I just get a black screen asking me to type commands in it. Thing is I am using it for the first time and I don't know what commands to use. 

Does anyone have any suggestions on how I can map 1000 data points with their coordinates according to their respective areas?",Mapping things according to their coordinates,90pn0x,new,5,1,1,0
"I have to create a model to help the sales team in my company have the best leads with the current information avaible.

The problem comes that we only have the information about the persons that purchased and the persons that don't have the specific product, BUT we don't have the information about the persons that rejected when the product was offered to them (it was just not stored).  

How would you go around to build a model with just the positive label (or just a fraction of the positive) and unlabeled data?

What I have been doing is just assuming that my non labeled data are just oart of the negative class (non buyers) and this has gave me some insight in what set aparts the buyers from the rest of customers, but the problem comes when trying to evaluate the model (for example, are FP, persons my model label as positive but are actually negative (I mean unlabeled) truly an error or just potential customers?).   So far I'm really confused on how to evaluate this kind of model.

Thanks in advance for all your insights.",Question about model evaluation: only positive class,90pl0v,new,8,1,1,0
,Word2Vec Meets Trump Tweets — a Visual Analysis,90ou6y,new,9,42,42,0
"If you wanted to use machine learning for something that's financially regulated, or something that a company heavily relies on in its risk management, can you rely on models like gradient boosting that are more or less non-interpretable or is it better to find some more transparent models? Surely this is a common enough problem that there are common solutions for it.

Edited for clarity",How do you justify the credibility of machine learning models when they're basically black boxes?,90mgjp,new,28,0,0,0
"Hi, I am teaching a course in network science next year and trying  to decide if we should use R or python for the programming component. 

I normally prefer R as I am familiar with igraph and some other libraries in statistical network analysis (such as statnet). But many students are more familiar with python and so I could potentially use networkx.

Does anyone have any experience or tips on this issue? How good is python for network analysis? 

Thanks",Pros and cons for network analysis using R vs Python?,90lduc,new,29,28,28,0
"I'm building a predictive model for helping the sales force of my company by giving then better leads for their calls.  I have info of the customers who have and don't have the specific products.  So far everything is going good and my model with minimal tunning has achieved a high AUC (> .8).

However, i realized I created the model using variables i have from the clients in this instant of the time, instead of when they purchased the product.

If it were you, what would you use and why?",Some questions: Predictive model for prodcut selling,90l1pv,new,9,10,10,0
"Hello guys, I've been a luker of this subreddit.

Currently I'm a lab technician, but I grew a personal interest in Data Science, to the point that I'm going to take my second degree in that, from September.

I talked about my passion to a senior researcher in my institution, and he said that he's challenging me.

He gave me a dataset about a 4-years-old experiment on laboratory animals (mice), to see if I can manage to find out any meaning in the data.

The dataset is a set of 72 animals, divided in many cohorts, for a study on a methabolic disease. Half of them are the controls, half are the disease model. There are sub-groups, equally divided for sex(50%M, 50%F), and age (4 different age classes, from 4 to 17 wks). For every animal, many parameters were measured, from weight to hormonal levels that could be correlated with the disease.

By now I just started cleaning the data, creating a single CSV file from the messy XLS I received, exploring the data, creating box-plots and histograms to understand parameters and their meaning in the disease.

Carving out something interesting from this dataset could help my future career, and give a meaning to 72 mouse lives.

For the basics I learnt by now, I'd tend toward trying to correlate the different groups (M/F, healthy/diseased, young/old) with the parameters, but your experience could be helpful. I don't mean to ask anyone to solve my problems, I'd appreciate a hint to the keywords that I need to google to find the tools I need by myself. My math skills are decent, and my aim is to learn.

Thank you in advance for any insight.","New to Data Science, I've got a challange.",90kas8,new,24,5,5,0
"I was asked to find websites that contain raw medical data for analysis.  Where do I look?? Please help.  

Or send links to any kind of raw, unprocessed medical data that I can use for analysis ",Where do I find raw medical data???,90k0bp,new,7,2,2,0
"How do compagnies, especially the american ones, percieve french data scientists. I mean by that, their doctrine about french degrees.

Any kind of information that you might have at your disposition is more than welcomed.",French DS,90ih8c,new,2,1,1,0
,"AI, Education and the Role of Women in Tech and Venture with Ann Miura-Ko, General Partner at Floodgate",90i7mh,new,0,0,0,0
,Finetune: Scikit-learn style model finetuning for NLP,90i7ic,new,1,8,8,0
"I can't seem to find any handwriting dataset that has longer than one single digit like MNIST.

Are there datasets out there that include numbers like: 830, 14, 123.45, 1.00. Primarily looking for multi-digit numbers and potentially numbers with decimal points.

Any help is appreciated!",MNIST alternatives? Looking for handwritten digit dataset that has full decimal values,90hhok,new,1,2,2,0
"Hi Everyone,

I'm a Masters student in a data analytics program, and I'm a bit confused. I have a lot of things going on, and I'm kind of shaky on the processes. The project is a data mining and analysis project. I have a set of customer data and most of the data is textual. (either Yes/No, easily converted to binary/boolean types, or level types) I'm not sure how to go about analyzing the data. (I'm using python/pandas to work with the data) I'm analyzing the data for churn, and I'm not sure how to reduce the dimensions. (PCA needs completely numeric, continuous data.) 

Should I be doing factor analysis?",New to Data Science and Analytics. Not sure how to work with a dataset,90gaug,new,28,17,17,0
"I'm a data scientist and my language of choice is python.  I use it for everything from data handling to viz to inferencial and predictive modelling.

I've just started a new job where the team uses an almost entirely non-python stack.  SQL for all data handling, GUI viz application, and SAS.  These aren't the tools I like, but I took the job because the company's mission is awesome and their's nothing wrong with the output from their data scientists and analysts - it's actually pretty exciting work.

I have no problem transposing my pandas knowledge to SQL or my [plot.ly](https://plot.ly) et al knoweldge over to the GUI application mainly because I haven't experienced a performance impact or a single roadblock I haven't been able to work around after 10 minutes on Google (which has been pleasantly surprising!).

But I'm struggling a little bit with SAS.  It's clunky to me and has so much functional overlap with the other tools that I'm struggling to fit it neatly into my workflow.  

Critically, unlike the other components of the stack, I believe I'm also the only person on the team who currently uses SAS.

So, I want to have a frank discussion with my boss about potentially switching over to python to do the work we would normally do in SAS, and I feel like I can make a pretty good case for python:

\- It's a free solution

\- Certain distributions actually come with GUI tools for those who dislike coding

\- Highly debatable, but for statistical modelling I think Python can do more than SAS.

\- The transition to python wouldn't cause any wasted knowledge for the team as no one uses the program but me

\- For those team members who want / need to learn modelling, I firmly believe python is easier to teach and learn than SAS

\- What's more, python is an awesome skill for data scientists and analysts to have and can inform the other work they do. 

\- Python plays really nicely with the other components of our stack

My hesitancy to have this frank discussion, however, is that I'm a new employee.  So my plan is to become pretty good at SAS and after I've curated some credibility as the SAS authority on our team, to then have this discussion. 

Any advice / suggestions / thoughts?  I'm also open to counter arguments to the case I outlined crudely above.  It would be really helpful for someone to make a pro-SAS case, as that would inform my discussions down the line or could even change my mind entirely.

Cheers!",How to discuss alternative tools with an exec?,90gakc,new,18,5,5,0
,Any recommendations tutorials on choice based conjoint analysis?,90g1ta,new,2,3,3,0
"Hey guys, just wondering, when you first started out a data analysis job, what are some of the fundamental mistakes that you were making. Just hoping to see if I still have a lot of these mistakes.

e.g Ever since I learned some Python, I would strictly try to solve every data cleaning task with Python since I thought Python was better than Excel in everything. I ended up doing way more work for something that would have taken seconds in Excel.

Edit: I didnt mean to make this post Python vs. Excel or examples of defending Excel but a lot of you got my point. I just wanted to list the Excel as a sample.",Data Analysis Fundamentals Mistakes,90g11s,new,26,49,49,0
"Hi,

if someone is interested here is an article describing the differences between the two BI tools:

[https://www.linkedin.com/pulse/power-bi-vs-microstrategy-micha%C5%82-d%C4%99bski/](https://www.linkedin.com/pulse/power-bi-vs-microstrategy-micha%C5%82-d%C4%99bski/)",MicroStrategy vs Power BI,90f6re,new,1,0,0,0
"Hello community,

Long story short,Due to my background with Tableau i had an offer for junior data analyst.I did my study, about the languages and i found that this section is dominated by Python and R.

Although i started to study R (i just liked the syntax more), i can neglect the fact that Python is starting to dominate the market.

Below the google trends:

https://i.redd.it/kx5ak3kd23b11.png

I stated to visit several coursers in various websites and i noticed this trend is somehow passed to coursers structure as well. More specifically, if for example you visit udacity nanodegrees ([https://www.udacity.com/nanodegree](https://www.udacity.com/nanodegree)) you will notice that everything in relation with data analysis,ML etc is combined only with python.

So, my question is if it's good investment to stick with R or switch to Python?

best,

a.",A classic question from a classic newbie (R vs Python 2018 update),90f0lm,new,2,0,0,0
"I have been looking for an entry-level data analyst position and noticed many job postings are asking for intermediate to advanced excel skills. I learn through various online resources (Lynda, Youtube, etc) and it seems easy enough, however, I quickly forget how to do things afterward as I'm not currently using Excel on a daily basis.. 

Does anyone have any resources for an aspiring data analyst to gain more confidence in their excel skills?",Learning Excel for Data Analytics,90e6of,new,9,2,2,0
I want to fit a poisson model to a count variable from real life. But I can't find a good dataset. Maybe one of you could help me.,Looking for a dataset with a count variable (count data),90dg72,new,1,2,2,0
,Data services company in Mohali,90d8jb,new,0,0,0,0
"We are in the process of preparing a model which can price based on incoming traffic demand. I.e according to the surge, the price will go up or down. Think of it as something similar to uber's surge pricing. Can someone please point me some white papers or articles or share your experiences on working with a similar model? ",Model for surge pricing,90d4pz,new,2,3,3,0
"Soon I will have a climate change discussion with my teacher who believes that artificial climate change is not real or significant. He claimed, in my History class last summer, that the reason the earths temperature has been rising is due to its orbit and distance from the sun. I ‘know’ this isn’t the case but I can’t falsify his claims without evidence. -.
",Where can I find studies depicting Earth’s temperature in relation to its orbit around the sun? Since the orbit is not a perfect sphere I believe that the temperature will vary depending on its distance from the sun. The reason why I need this is furthered in the bottom.-.,90d2l4,new,16,7,7,0
"I've recently started trying to learn some data science techniques, primarily in an attempt to implement them within my job. I was just wondering if there was any benefit to using r markdown or jupyter notebook for coding. Currently I use rstudio for all my r work, but I've heard some people talking about using markdown or jupyter to have their code contained in a notebook that also includes plain text. I was wondering how much benefit there is to this and if there was a clear winner between markdown and jupyter?",R markdown or jupyter notebook,90a5ez,new,10,7,7,0
"Is there a way to scrape inventory data from grocery stores? For example, say I want to get all the prices from a local Ralph's or Vons, is that possible? Ideally, I would like to have per item data on prices and nutrition facts. (I wonder how Instacart gets its data.)

",Grocery Stores Data,90a3u0,new,3,1,1,0
"Hello all,

I'm hoping someone can help me here. I can't figure out why the best\_estimator\_ from my grid search is supposedly producing such great results within GridSearchCV, but when I extract it (via grid.best\_estimator) and try it as a standalone on my X\_test the predictions are worse than my baseline. It might have something to do with the randomness of train\_test\_split within GridSearchCV but I don't think that would account for the difference. The test score function inside my common\_pipeline function is accuracy score comparing y\_test and the predicted score.

Am I misunderstanding something with the randomness or how the estimator is scored within GridSearchCV?

https://i.redd.it/f4l66p04gya11.png

Thank you!

Chester",Why isn't the best_estimator_ pulled from GridSearchCV performing as well outside GridSearchCV? (python/sklearn),908vgf,new,10,5,5,0
"I am looking forward to doing a project on predictive time series analysis. Can anyone please suggest me any good, (simple may be..) dataset. I would classify my skills at beginner level.",Time Series dataset for a beginner level project.,908ip2,new,5,1,1,0
"So I am looking for open source datasets where I can give my contribution, because I want to work on real world datasets, do collaboration and also learn some new stuff.

So it would be great if someone could provide GitHub open repositories where people are contributing. Thanks! ",Contributing to open source,908f4k,new,2,1,1,0
,Data literacy project sending out free 'Tips for Effective Data Visualization' wall posters on request,90895t,new,22,115,115,0
,Unpacking NumPy and Pandas: The Book Is Coming Soon!,9083xy,new,0,1,1,0
"Hi everyone,    

&nbsp;  

Over the past month myself and a few other data scientists have started building a little Data Science community over on discord and we're looking for new people to join us.    

&nbsp;

**Our vision for the channel is to gather an active, cohesive group of data scientists from different industries and academia in order to allow everyone to share their domain expertise, discuss problems, explore the many different disciplines of the profession and in doing so build friendships along the way.**  
I personally believe there is a lot to be gained from such a community both professionally and humanly as I feel the medium of instant messaging is conducive to a lot more flexibility in the way we share and discuss things and this channel could be a great tool to use alongside this subreddit.    

&nbsp;

Right now we have about 40 members and we're trying to organize a few channel activities such as a reading group, Kaggle contests, weekly video presentations, etc... and we'd love to get more people involved so, if it seems like a community you'd like to be a part of, come join us over on discord: **[Click to join.](https://discord.gg/UYNaemm)**  

Thank you for reading.  
Etienne
",Join our active discord channel for Data Science practitioners and learners,907j2t,new,0,5,5,0
"In my data analysis workflow I end up doing a lot of my exploratory analysis in Tableau and then mentally translating what I've done into Python Pandas so that I have fine-grained control over the calculations. 

I've been thinking about creating a drag and drop interface like Tableau that generates Python Pandas code that can:

* Be copied and pasted into your own environment

* Possibly be a Jupyter plugin

* Run in a pay per use cloud environment

Additional Goals:

* Wizard to connect to various cloud data sources (like BigQuery)

* Interface to join data frames

* Arbitrary combinations and ordering of pivot tables, calculations, and joins

* Interface for various plotting options (subplots, layout, size, legend, colors, etc) -- this can use both the built-in plotting library as well as something like Plotly

Stretch Goals:

* Generate equivalent code for other languages/environments like:

    * Julia
    * Pandas-JS (to run in the browser)
    * WebAssembly (if someone creates a data frame library for it)

* Pick certain parameters as inputs to expose in a dashboard

    * Appropriate widgets for parameter types (checkboxes, dropdown, sliders)
    * Code generation that includes a web server
    * Possibly upload the data and code to an online gallery (Plotly has some of this functionality)


To be clear, this would be a free and open source tool. 

GitHub: https://github.com/zainhoda/orbgo

Early sample of what I'm describing: http://orbgo.com/


Would this be something you would use? Am I missing anything? What features should I prioritize?",Would you use a drag and drop front-end for Python Pandas?,906v7a,new,11,3,3,0
,AI is getting closer to replacing animal testing,906bnx,new,3,0,0,0
"That is, my primary job duties involve data analysis and machine learning in python. Lots of image recognition. My official title, I believe, is ""Lab Assistant"". What do hiring managers make of titles?",How much weight to hiring managers give to job title?,90654j,new,5,3,3,0
"Hello, I'm in the position of having far too much data and no ready way to select a subset. I have received a very large (>90GB) fixed width flat file and need to get it into a format that I can work with. The data came with a .sas inread file which I have mostly figured out how to use, but can't read in the full file. I have managed to read in the first 500 records and output a subset to csv, but not sure how to handle the full data set? 

So far I'm encountering limitations based on MS SQL Server Express (10GB limit), SAS University (unknown limit, but insufficient to process the full data set).

Is there a way to read the data in record by record instead of the full file? Is there a way to ""chunk"" it, making sure not to divide the file in the middle of a record? Is this a job better done with some other method (R, which I also don't know? or another language?)

Ultimately I need to extract only a subset of this dataset where certain conditions are satisfied, but I still expect it to be extremely large. I will then use other tools for further work with this set. I was planning to load the resulting tables into MS SQL Server Express, but am encountering the size limitations as described above.

Any help would be welcome. I do realize I've bitten off more than I was prepared to chew, and am trying to salvage the project by getting it to a manageable size.","Managing a very large dataset, academic tools only",905nmr,new,23,3,3,0
"Suppose I am in the happy position of having multiple offers.

1. Insight AI fellowship.
2. OpenAI fellowship.
3. A machine learning engineer position.
4. A data science position.

My dream job at the moment is AI research, which makes me inclined to take the OpenAI fellowship. But it's long (6 months). I somewhat feel like I'd just be delaying really getting started in my career for more school-like experiences. And I don't have much information about fellows' outcomes after going through the program.

For the most part OpenAI has more appeal to me than Insight, because it's oriented towards research. Also OpenAI is paid. But I do know that Insight has a good track record with regard to its fellows getting jobs. Also the Insight program is much shorter.

Ultimately what I'm unsure about with the fellowships is whether, even though they are more oriented towards the career I want, whether there's any real advantage of doing them instead of  just beginning working.

Can anyone offer any advice?",choosing between job offers,905gco,new,5,1,1,0
"I decided to learn data science from scratch. Started with python courses. Got some more courses on NumPy, Pandas, Matplotlib and SciPy. I had some projects in mind but then I stopped. I want to get back to it but I keep coming up with excuses. 

I will learn Data Science one way or another. It'll take time for sure. And I want to get rid of those idle time. I thought a study partner would be one of the solutions to the problem I'm having. 

Is there anyone else in similar situation and wants to create a study group? We can share our experience and maybe have some daily and weekly deadlines on mutual projects ?

Thanks in advance.",Study partners to learn Data Science together,9055w6,new,66,81,81,0
"Hey there! Ive got a huge amount of data to analyze and Im thinking about the best way to go about it.

Ive got 160 hours of observation of a sequence that an animal tends to repeat consistently. Lets call it sequence A.

 Then I introduced a disrupting element and have recorded how this sequence has been changing over 20 hours to adapt to the new situation, effectively becoming sequence B.

Ultimately I have 5 hours of observation to see how the animal perdorming sequence B reacts to the removal of the disrupting element.

I havent got enough time to account for every sequence manually, so what kind of stats and program would be best suited to analyze the variation in sequence? Ideally I would like to obtain a graph showing the % sequence A vs the % of sequence B and how this evolves with time.

Thank you everyone!",Sequence analysis,904ls0,new,1,8,8,0
"Has anyone come across a way to print something like this in python? 

Basically, depending on a inputted value place an icon on a scale of 0 to something. 

https://i.redd.it/1tzceirhcva11.gif",Python scale graph?,9046cr,new,3,7,7,0
,"Insights from a one-on-one talk with the co-founder of KDNuggets, Gregory Piatetsky-Shapiro",9044gh,new,0,5,5,0
"I'm thinking about facilitating an internal ""intro to ML"" training course at my work, either using https://bloomberg.github.io/foml/#home or https://developers.google.com/machine-learning/crash-course/ depending on the math level of those interested.

I want to make a proper pitch to pitch to management for some time commitment rather than just trying to cram into into lunchtime or after-work (similar to what we might do for an external training). Was thinking maybe

* One morning/day a week/fortnight?
* Intensive 2-3 days?

Does anyone have some experience or ideas about what might be a good format for this kind of thing?",Good format for internal ML training?,90423l,new,6,0,0,0
"Hi,

I recently got my DNA results back from 23andMe and decided that as a personal data science project, I'd like to figure out which ethnic minority group in China I have the closest DNA match to. I downloaded my SNPs from 23andMe and also found SNP data from different Chinese minority groups through the HGDP. I'm planning on using Pandas + Scikit learn to perform some clustering and create some cool visualizations. 

Does anyone have any advice as to how to approach this problem? My initial thought is to perform some sort of dimensionality reduction on the data that I have and graph and cluster the results. I've also never dealt w/ data this large before, does anyone have best practices for this type of project?

For reference, there's around 450,000 SNPs per sample and 200 samples form the HGDP.

Any help is appreciated!",Analyzing SNPs using python,903ce2,new,7,9,9,0
For each session how many fellows they hire ? How to prepare for interview ?,Did anyone get an interview for insight data engineer fellowship for Sept session,902t1t,new,10,0,0,0
"What are the top alternatives to powerpoint decks to show the outputs and insights of any analysis and modeling results. Eg: Jupyter notebooks ,R markdowns. Outputs which can be shared and understood by clients.",Tools for modeling outputs/insights,902ocn,new,3,3,3,0
"Hey all!
I’m currently going through the data scientist coursework on DataQuest and am having a little trouble getting things to stick, especially with functions (I’m in the beginner stage). Any advice or resources I should look into?

Thanks in advance!",Stuck on beginner Python concepts,9014ll,new,3,1,1,0
"(Posted in /r/pystats but got no replies.)

Hello, Python stats newbie here. I'm trying to get experience with image classification using Python (keras) but I'm running in some trouble.

I'm doing binary classification and I'm saving the data in folders with the structure

    data/
        label_a/
            img1.jpg
        label_b/
            img2.jpg
            img3.jpg

etc. For some reason when I use flow\_from\_directory I get the result  ""Found 10000 images belonging to 3 classes"". The number of images is correct but I don't understand why it's reading 3 classes when I only have 2 folders in the within data.

I've tried playing with this with some dummy examples and I've noticed that flow\_from\_directory seems to consistently ""find"" 1 more class than what I have. I should also note that I'm using a virtual Linux machine.

What is going on?",[Neural Nets in Python] flow_from_directory reading one more class than what I have,900k4n,new,1,0,0,0
"I am looking for a few books in statistics and data science that explain the different characteristics of algorithms and statistical techniques, as well as when they should be used. Most books I have found so far dive too deeply into the mathematical equations (such as The Elements of Statistical Learning), and details are worded in a highly scientific way making them difficult to remember and apply in a daily job as a data scientist.

For example, if I apply an algorithm on a dataset, I want to be able to understand why I am getting the returned results, and from there make informed changes or improvements. Another example is when presented with certain characteristics of data (such as skewed or non-normal), I should know which statistical techniques to apply (for instance apply log transform) and also can explain why.

So far I am struggling to find such materials. The kernels on kaggle sometimes present good explanations for different scenarios, but they are quite scattered and are not complete enough. On the other hand, most textbooks go too deeply into solving matrices and transformations, and the essences of different techniques get lost along the way.

I hope I explained myself clearly enough. With that said, do you recommend any particular title?",Books for understanding statistics and models on an applied level?,9006en,new,14,73,73,0
"Wrote my first scikit learn power classifier, it's not perfect but it's far more accurate than my simple keyword detector for a project.

I think I'm ready for the deep dive into Data Science, I didn't really \_understand\_ what I was doing, but I could apply the techniques to my data.  


I've got almost 10 years of programming experience, what kind of books or courses will help me think in this new statistical way?",Data Science Books/Resources recommended for Software Engineers,8zzzd0,new,13,5,5,0
"My boss gave a task to explore the options for writing automated news stories that take input from a user (things like the area, what time period, metrics to be considering, etc.), and then analyze a data base (containing locations, dates, and other minor details about events across the country) and pull out recent trends, ultimately putting them into a human readable news story.

We understand that this is cutting edge technology only being used at the major publication companies. However, the news stories we want the program to be able to write are relatively simple, at less than 5 sentences (most of which can sound extremely robotic and non-human), with a computer-generated graphic.

What technologies/tools exist out there for the data analysis-to-text part? I've explored PowerBi's Data Visualization options (specifically Narratives for PowerBI) for generating text, but nothing really stuck out as super useful.

I'm open to any advice. Preferably the solution with integrate easily with PowerBI, Excel, or Python. Thanks! ",Getting started writing automated and semi-automated news stories?,8zzmi2,new,9,4,4,0
"Need to create a visualization of which specific activities my university supports on a political worldmap. There are about ~20 different countries, and a max of 4 activities that can be assigned to an individual country. Here is an example: https://www.icf.com/resources/projects/research-and-evaluation/demographic-and-health-surveys

Ideally I would be able to color-code the 20 countries where we are active, and then superimpose different symbols over each country depending on activities. But can't seem to find a (free) mapping tool that will let me do both. Have used Power BI before, but my only two options appear to be strictly color-coding, or using the ""bubbles"" which are not very intuitive.
Does anyone have any suggestions? Would rather not resign myself to MS paint :/ And happy to provide more detail if necessary.",Free mapping tool recommendations,8zzmes,new,2,1,1,0
"I am learning how to use the caret package these days and was wondering if the caret package is going to be outdated soon or already is. I would love to know your thoughts on it. Following are my thoughts on why I think it would be outdated (bear in mind that I am not an expert and I could very well be wrong):

1) There are automated ML packages coming out like h2o which is gaining more popularity

2) I notice a trend of more users of python and tensorflow/pytorch being the go to package for ml and R losing popularity in general

What do you guys think?",Caret ML package outdated or not,8zyuql,new,9,5,5,0
,A Beginner’s Guide to using the DNN Classifier and Regressor in Maple,8zy3mg,new,0,1,1,0
"Hi,

I am trying to set up an environment where I can prepare myself for becoming remote data scientist. And the environment that I want to set up for myself is to practice Spark but with connection to data via S3 and Hive meta store.

Is there anyone out there who has experience with running spark on the cloud for personal purpose?",Running Spark on jupyter with EC2 & S3 for remote data scientist,8zy0g2,new,2,1,1,0
"Hi, I'm trying to build a model that takes in multiple inputs of all the same shape on one axis but not necessarily on another(one hot categorical vector). This is what I'm trying, but not really working. I tried concatenating on different axis.

**def model**(numobj, numclass):  
flux = Input(shape=(numobj,))  
time = Input(shape=(numobj,))  
type = Input(shape=(numobj, numclass))  
merge = concatenate(\[flux, time, type\])  
h1 = Dense(100, activation='relu')(merge)  
h2 = Dense(100, activation='relu')(h1)  
h3 = Dense(100, activation='relu')(h2)  
h4 = Dense(100, activation='relu')(h3)  
h5 = Dense(100, activation='relu')(h4)  
output = Dense(numobj, activation='linear')(h5)  
m = Model(inputs=\[flux, time, type\], outputs=output)  
 **return** m",Keras with multiple input layers of different shapes,8zxqwf,new,3,1,1,0
"I am thinking of making a big project, so would start from collecting data and everything. Also, any other tips and know-how are welcomed.
(Can suggest any other algorithm also)",Any ideas for good college projects using multiple regression?,8zxgtl,new,1,0,0,0
,"Extending samples with rare labels for multi-label classification problems (my first major project, feedback appreciated)",8zwjw9,new,1,3,3,0
"**Goal**

I am trying to run a propensity to buy model for one of our products for every single cusotmer in our dataset.  The output would be a lead list of most likely customers to buy our products.

I know R, SAS, and Python. I am fairly skilled at all 3. as far as skills that i can use to complete

**Dataset**

Our data is b2b sales of retail chains.

The way our data is structured is:

Parent Company: Individual Store

For example,

Subway:  Subway Burlington VA # 3

I would like to predict for each store, not the corporate entity

**Issue 1: Nulls**

I have pretty spotty coverage with my data.   I have tons and tons of different data attributes about my cusotmers, but for each variable, the coverage is only around 30-60%.

The brightside is this is b2b sales and these customers belong to larger corporations and atleast one store in these corporations will have data for all the attributes.

**Example Nulls**

For example,  I may not have store Revenue for a Subway in the southside of Burlington, VA.   But, I will have the number of employees they have.

But, i will have store revenue for a subway in the Northside of Burlington, VA. but, dont have the number of employees they have.

**Issue 2: Sampling**

For some of our products, very few of our customers buy the product.  Thus in my initial model, my accuracy was like 97%.  As it just predicted all of customers would not buy the product.

From my research, this seems to be a sample size issue.

**Questions 1: Nulls**

Would you impute here?  It seems like it would really prevent me from using many machine learning models if i didnt.

**Questions 2: Nulls**

Is imputing based on group averages the best way to go here? Or should i use predictive techniques like mice?

**Questions 3: Sampling**

Would be using some type of over sampling be the best approach to solve this?  If not, why?

Any other feedback you have that you think would be helpful is much appreciated",Running my first model. Two Issues: Nulls and Sampling,8zw6k3,new,9,4,4,0
"Hello,  I'm a developer transitioning into data science, in fact, just got my first data related task :D

**Basically I have a lot of data about everything that goes  through my company's warehouse (Dimensions, Date of entry, Date of exit,  Sender) of each package / pallet.**

Each rack has between 3 and 6 levels (depending of the height set to each level).  The height of the levels of each rack that we use to store the cargo con be graduated.

At this moment the hight of each level of each rack and the amount of levels a rack has been set at a rough guess.

This has proven to be highly inefficient, a lot of space is not being  taken advantage of and for this reason we ran out of space and we will  be moving to a bigger warehouse.

**My task is to find the best rack setup possible ( how many  levels should each rack have and how high each level should be) for our  new warehouse, based on the data of the elements that have been stored  at our warehouse previously** 

I would love to hear how would a more experienced data scientist solve this problem.

My first guess is to figure out for how long each package stays in  the warehouse (I got the entry and exit date), find if there is any  relation between the height of the packages and the time that they stay  at the warehouse, same for height and quarter of the year.

I am not sure if I should treat this as a **multiclass** problem and try to predict the amount of packages that we are gonna be receiving for each rack level height or as a **optimization** problem.

I would really appreciate any kind of guidance, tip or advice that you can provide me to solve this. Thanks a lot for reading.",Optimizing warehouse racks heights based on my data,8zvrdu,new,10,4,4,0
"I apologize if this is a stupid question, but I'm still relatively new to data science.  During an interview recently, I was asked whether adding more data could be problematic.  In particular, we were talking about a model predicting whether a given tweet is sarcastic or non-sarcastic (labeled by the sarcasm hashtag).  It seems to me that more data is always better (except maybe that training and testing would be a bit slower), but are there other reasons why more data could be a bad thing?  Thank you in advance!",Too much data?,8zvmq8,new,17,11,11,0
"Hi guys I work for a credit company and we work with large volumes of debt, essentially money that has gone delinquent, passed recoveries and been defaulted on. We contract these portfolios out to collection agencies and collect on them for our clients.

I've been tasked with building my first baseline forecast, essentially we build a 20 month curve for each segment (as percentage of liquidation - that is percentage of the accounts total initial balance we collect each month).

What I've done is build 20+ variables which may or may not have an influence on dollars collected, what I've found is that the initial account balance as well as 4-5 of the date differentials are the most significant predictors. Since I have to build these out into segments, I can only do a reasonable amount (10-15 max). What I've done is create 3 top segments, never paid before default, paid last 6 months before default and paid 6+ before default, and split these 3 top segments into balance bands (>500,500-1000-,1000-1500 etc.). I then averaged out their performance month by month to create curves.

I've built these curves on the historical 2017 data and forecast them out into the first 6 months of 2018. What I've found is that with this segmentation my training data over approximates total $ collected so far in 2018 to be 4% higher than it really is. This is OK but since 4% actually amounts to a good deal of profit for us it ideally needs to be +/- 2% to get anyone to sign off on it.

What I'm wondering is if anyone has any suggestions on how to possibly solve this. The only things I've thought of so far are:

1. Get more predictive variables, we have requested more data from the client
2. Create more segments with other predictive variables, we already have 12 segments though so another classification layer would potentially bump this up to 24-36 segments no bueno
3. Scrap the segmentation plan and build a model that approximates individual account liquidation month by month, I' built a random forest and it was 6% out on $ collected in month 6 - however, building 20 random forests that predict month 1 to 20 may yield better accuracy?
4. My random forest wasnt actually too bad, but I visualised it the predicted vs. actuals and the 0,1 abline through it was skew, low values were over predicted  by 5-10% and high values were underpredicted by 5-10% on average

This is my first job and I want to impress my boss/co-workers, one other thought we had was to build a neural network using an R package and see how that predicts. Anyone who has more insight, is further along their studies or career than I I would truly appreciate insight from. I have a B.S. in stats and I do a lot of reading into data science but I'm still learning a whole lot when it come to finance.",Creating Segments in order to Forecast a Baseline,8ztq85,new,3,1,1,0
"Hey all,

I'm sure that I can't be the only one experiencing issues when converting a Jupyter NB to PDF. HTML conversion looks great, but having my notebooks in PDF form would be awesome (if anyone knows of a good resource to convert HTML to pdf that would also be appreciated).

The main issues I'm facing are:

• long lines of code do not wrap in the PDF
• plots and tables show up super tiny even though they look great in the HTML

Any insight would be appreciated, I've tried using nbconvert as well as just converting straight to PDF through the Jupyter browser window.

Thanks!",Jupyter Notebook To PDF Issues,8zsoni,new,6,6,6,0
,The Beginner's Guide to Dimensionality Reduction,8zsejf,new,4,111,111,0
,Using sklearn with AWS lambda to build a model service,8zs6qb,new,12,37,37,0
"I'm working at a startup and I was looking up ways to perform text classification. I don't have the data for all the classes right now(only about 3) but later on, the classes might increase upto 30. Was looking for advice on which text classification techniques would be best for serving huge dataset with those many number of classes?  
My data consists of paragraphs of texts with labels.",Production level text classification model,8zoiky,new,15,8,8,0
"hello everyone,

I have an excelsheet that has records of all excavation damages to gas pipelines in half of state of Washington. It shows each day, which location have been damaged by which contractor( not everyday damages happen)

I am trying to add some features to it such as rain and weather conditions and based on that predict where will be the next damage in future( using future weather forecasts)

Considering the fact that I only have data for when excavation damage has happened, do you think it would be possible for me to predict the future?I asked my cousin who is am ahcuine learning engineer and she said the model wil be very biased as we only have the data for when and where it happened and not for when it didnt happen.

I was thinking to build a database qwith GIS software that has all the locations in our territory and then add the excavation data to that database in order to be able to build a model.

Can you please do me a favor and help me what do you think is the best approach?

https://i.redd.it/803s3zkgsja11.png

thanks",Excavation damage,8zngax,new,6,0,0,0
"I have 5 different CSV files. Each csv file has {Date,Metric,Class1,class2,class3}. 1st csv is describing ranking of webpages, 2nd is describing reach, 3rd is describing  time spent and as such. How should I use this different CSV to create a proper dataset. The following is the image of the dataset, I need to use this different dataset to predict best website.

Thanks

https://i.redd.it/6vemd8eesja11.png","Hi, Please help me to create a proper dataset (explanation is in description)",8zn5oy,new,21,1,1,0
,What is the best notebook to work with AWS? Jupyter or Zepplin?,8zn23e,new,2,0,0,0
"The basic skills needed to be a data scientist are stats, programming and domain knowledge. But how does a great Data scientist set themselves apart from the rest? What do they do that makes them worth more? ",What makes a great Data scientist great?,8zmsmq,new,10,5,5,0
,Stock Data Analysis with Python (Second Edition),8zm39z,new,1,4,4,0
"x-post from r/excel by u/OCData_nerd  
[Machine Learning + Mr. Excel: How to build a Netflix movie recommendation system that predicts what you’ll like](https://www.reddit.com/r/excel/comments/8xp2xg/machine_learning_mr_excel_how_to_build_a_netflix/)

  
To all my spreadsheet homies out there…I actually tend to agree that Excel is not a bad tool for learning how algorithms work (obviously using small datasets).  Thoughts?  


Found this quote funny haha:  
“I don't think computer scientists are going to drop Python and become Excel wizards any time soon, but I would argue Excel is the most popular programming language :)”  


I doubt the bean counters I work with consider themselves programmers, but it’s probably true now that I think about it. ",Machine Learning + Mr. Excel: How to build a Netflix movie recommendation system that predicts what you’ll like (x-post r/excel),8zl0vb,new,8,9,9,0
Do you use inline SQL? Stored procedures? Object-relational mapper? I can't help but feel all three of these options are imperfect for my use cases.,How do you handle SQL queries in production systems / ETL processes?,8zk8o0,new,6,7,7,0
,A great guide to K-Means Clustering + tutorial,8zjxgm,new,7,103,103,0
AFAIK python is the more popular choice but R is fine for ML methods too. However is there actually anything one language can do that the other literally can't?,Is there anything Python can do that R can't or vice versa?,8zjrsy,new,21,4,4,0
"Hi everyone, I'm new here and to data science field so the question might be too basic. I've been reading an article about predictive methods, and there was a comparaison between least squares method and Nearest neighbour method. The point I do not understand is describing least squares method as stable and nearest neighbour as not. If someone could explain for me this stability notion it would be really helpful. 

Thanks.",Stability of a predictive method,8zj6bo,new,2,2,2,0
"I need a laptop for school while I pursue a degree in data science. What laptops are good best pc or Mac ect?

Edit: I ended up getting the HP Elitebook X360 1030 G2 13.3
It's pretty much if a macbook became a Pc.",Best laptop recommendations for Data Science?,8zghh1,new,24,6,6,0
"Hello /r/datascience!

I'm currently working this summer as a machine learning engineer intern and was hoping to stay **consistent** with my self study in the evenings.

I know that having someone to share progress and encouragement with helps tremendously, so I was looking for someone who was also learning data science / programming / math to keep in contact with. Perhaps we could message each other on reddit twice a week?  I've done this before, but sometimes things just fizzle out (and that's okay). 

Feel free to PM me if interested or post here if you are also looking for an accountability partner! I was hoping to start right away, so if you want to get into it send me a message with what you are or hope to be working on and we can set up a schedule (I was doing wednesdays and saturdays before) for messaging each other to check in. ",Accountabilibuddy,8zfh8y,new,0,6,6,0
"I'm interested in setting up simple http endpoints (sometimes with forms or just to handle json), processing messages from queues, batch processing, and easily listening to streams of data from social media and rss feeds. Also the more features that can be added on, like [creating dashboards from data](https://github.com/node-red/node-red-dashboard), is a plus.


Has anyone used both and have opinions on how Node Red and Apache Nifi compare? I've been testing both of these for the past two days, and it feels like Node Red is easier to use but Apache Nifi has marginally more processors. 
Node Red seemed to have a lot more fun toys out of the box but Apache Nifi processors seemed to have more configuration options in case scaling ever becomes a priority.

Node Red's message passing the the `msg` json objects was really intuitive, and even though it's only been a few hours working with Nifi I still haven't really figured out how to read, manipulate, and write flow files, or how to set up an easy debug console to debug flows as easily as Node Red.

I've been doing some research on Node Red vs Nifi for the use cases I mentioned before, and I haven't seen Node Red mentioned on this subreddit before. It seems most people who would fall in the ""big data"" space use Nifi, so I would like to like it too but now I'm skeptical if that's the right choice since Node Red was ridiculously easy to setup install and make something productive within minutes. 

Any thoughts appreciated!",Node Red vs Apache Nifi? [x-post /r/bigdata],8zf0fk,new,0,2,2,0
"Hi everyone!

I've crawled out of the lurker shadows to become a first-time poster and am hoping I can make a decent post, but let's get to the point!

I work in the Business Intelligence field in Healthcare for a multi-state organization.  Our executives have finally caught the data science bug and there is top-level movement now to create a data science position and team.  The major problem is that no one really knows what to call it or what data science is about - they just know they want it.

Enter me.  My management team is aware that I have some skills in this field and that I've expressed interest in pursuing further education in this field.  They've asked me to flesh out what our org would call a Data Scientist, what the role would look like and how it would interact with other roles, research some use cases, and put together a presentation in case this needs to be shown to the execs.

In case some of you are wondering, here's an overview of some of my skills, knowledge, education, etc.:

* B.B.A. in Management Information Systems
* 2+ years in BI as an analyst/developer
* Data architecture and integration
* Data wrangling
   * API calls to web scraping
* Data visualization
   * Tableau Dev
   * Simple to complex dashboards and vizzes
* Geospatial analysis
* Semantic layer development
* Web and mobile app development
* Analyzing disparate datasets with python
* Union contract analytics
   * How to quantify normal to weird questions during negotiations that typical analysts can't answer
* Completed DataCamp's ""Data Scientist with Python"" track plus a few other courses on the site
* Machine learning experience:
   * Participated in a Kaggle competition hosted by Home Depot (awhile ago)
      * Text mining and prediction with XGBoost
   * Did a POC model to demo some of Tableau's capabilities with their python integration via TabPy
      * Trained a model using GBM to predict if an employee would term within their first year of employment based on user input from a dashboard
   * Personal project using NLP packages to conduct sentiment analysis and topic identification of Twitter data.  
      * Still not sure on the entire direction of this though
* Primary languages:  SQL, Python
* Secondary languages:  C#, Java, Javascript, R

I've (hopefully) made it clear to my team that at best, my experience is closest to the bottom of what some other orgs with DS teams would consider a Junior Data Scientist, but that I would try me best to provide valuable input on what I think this role would look like.  My main benefit from this is getting my foot in the door to this career field - I would potentially be occupying a membership role on this team instead of moving up in my current role later this year.  Plus the experience of starting an initiative like this from the ground-up is an invaluable learning opportunity.

Enter you.  I want to hear from any people involved in the DS community.  Yes, I've done research looking for what other orgs are calling Data Scientists, but most articles are filled with buzzwords and junk that makes it seem the author has little idea beyond what everyone else, and every other article, is saying about the DS field.  I'm hoping to gain some opinions from industry professionals or even those who operate with DS teams.  I have some broad questions below and I'll include any quick thoughts I have on it as well.  Any answer/comment, however specific, general, or off-topic they may be, would be useful for me.

**The broad questions are:**

* **What would your dream wants of a DS role be if you were in a position like me that had some control of the creation of the role?**
* **How would you describe the field of Data Science?**
   * I think of it as a thought process when interacting with data, mainly because I don't think the end-goal is to always have a predictive model, but could be something more simple like correlation analysis to gain an understanding of drivers for a metric.  It's the science of how to tackle and solve/investigate specific to abstract organizational problems with data.
* **What do you call a Data Scientist?**
   * A person who can take the above problems and transform them from business problems to workable DS problems, wrangle needed data, clean it, transform it, model it, present it, and not only provide answers to the problem, but help determine where and how to change a process, test the change, and assist with implementing a ""full circle"" solution where any data/model is a driver of that solution so impact and success/failure can be measured.
* **What should a DS role do vs NOT do? IE:**
   * A DS might need to scrape some data from the web for a given project, but shouldn't deal with typical ETL processes
   * A DS needs to be able to visually present findings, but shouldn't be the fullstack production dashboard developer - leave it to the BI team
   * This question mainly comes from seeing numerous articles where a Data Scientist was hired for a job where they thought they'd be doing job X but ended up doing something that fit another role/department doing job Y

Also, my current thoughts on recommendations for the team are:

* HIRE A SENIOR DATA SCIENTIST ASAP
   * This team will fail without experience
* Find the low hanging fruit and start at a crawl
   * Tons of potential use cases already
   * It's a matter of finding the one(s) which are definite wins, within the team's current capabilities, that will demonstrate the value of a DS team

TL;DR

I've found myself in a position where I can help define a Data Scientist role at my organization and possibly step into it.  I'm reaching out to the community for ANY input on what they call Data Science and what the dream wants of the Data Scientist role would be if you were in my position.

If anyone has questions, wants to chat, or do a massive brain dump on me then let me know!  I'd be extremely happy to make some time to talk.",How would you define a Data Scientist role if you could do it from the ground up?,8zew81,new,7,4,4,0
,Docker for Data Scientists,8ze8u3,new,7,89,89,0
"http://minimaxir.com/2018/07/imdb-data-analysis/

Following up on my [previous post](https://np.reddit.com/r/datascience/comments/8w4zlj/in_5_minutes_ill_be_starting_a_data_analysis/) with a lot of upvotes where I did a livestream of my first pass through the data, here is a full writeup w/ code if you want more detail.

If you want to see some really cool R and ggplot2 data science work on real world data, this post is for you!","By popular demand, I wrote a very detailed post about using R and ggplot2 to analyze IMDb data the intended way.",8zcow5,new,3,16,16,0
"Randy Zwitch of MapD and Jason Thompson of 33Sticks have written a blog post on utilizing the EPA's AQS Data API to analyze air quality in Utah. 

 [https://33sticks.com/analyzing-utahs-air-quality-connecting-epas-aqs-data-api/](https://33sticks.com/analyzing-utahs-air-quality-connecting-epas-aqs-data-api/)",Analyzing Utah’s Air Quality: Connecting to the EPA’s AQS Data API,8zc7sr,new,0,4,4,0
"Hello everyone,

I am currently working on clustering (k-means) a big dataset (several millions of individuals). Due to its size, I had to create a sample to run my clustering fast enough.

Now that I obtained my desired clusters, I would like to apply my model on the whole dataset i.e. assign each point of my dataset to a cluster. 

What method should I use ? Should I see to which center of cluster my point is the closest to, or should I run a KNN ?

Due to the fact that I used K-means for the initial clustering, I think that the first option seems to be the most appropriate.

What do you think ?",Clustering on a sample,8zb2gl,new,1,1,1,0
"Hi,

And sorry about the maybe misleading title. I remember seeing a list of collaborative projects (NGO like) for data science, but I haven't been able to find it using the search option. Anyone knows of anything? I am not talking about kaggle but more like volunteering in the field of DS. 

Thanks!",Data science to help people,8zavem,new,13,9,9,0
,"Using Ceph For Highly Available, Scalable, And Flexible File Storage (Interview)",8zak7z,new,0,1,1,0
,"How a Kalman filter works, in pictures [xpost r/MachineLearning]",8zaglm,new,1,3,3,0
"I'm interested in colour theory in sports and wanted to see what effect colour has on world cup matchups. The effects, if any, would be small, so it requires a bit of analysis to find. I gathered data on what colour jersey teams wore in each world cup match going back to 1930 (and got to watch a lot of great highlights doing it) and analysed the effects.

# Methods

The biggest determinant of a match outcome will be skill. To look at other effects you have to (attempt to) remove that from the game. To approximate skill I used the team's Elo ranking at the start of the tournament. As expected, higher ranked teams [score more goals](https://imgur.com/Cj8y4Us) against lower ranked teams.

Taking this relationship, you can add goals to the lower Elo teams, and/or subtract goals from the higher ranked teams and [create a ""fair"" matchup](https://imgur.com/a/9m71KG4). This is similar to having them play with a spread. This is rough, but it does a decent job of removing the effect of team skill from the matchups.

Once adjusted, you can rerun the tournaments and see where teams end up with these new scores. We're still having teams that won in reality but lost in their adjusted games go through, so it will still bias the best teams, but we can see that [things look a lot more even now](https://imgur.com/gallery/olZrZXz).

# Results

Let's look at [what impact colour had](https://imgur.com/gallery/1HBpY1w). The unadjusted line shows how good teams that wear that colour are. Teams that wear green are not good at scoring goals. Teams that wear black are good at scoring goals. This doesn't have to do with colour yet, it just happens to be that way. When you adjust for skill most colours even out and move towards the 1.5 goal mark. Green and orange basically have the same effect. There is a small detrimental effect of wearing white, but the effect is small.

The notable exception is black. Though the best teams wear black, and it does adjust downwards when you adjust for skill, it still is a massive outlier. Skill-adjusted teams wearing black score almost a whole goal more per game than they're expected to.

In fact, the team wearing a black jersey have[ won every match they've played](https://imgur.com/gallery/O45Qf8O) in the world cup! Note: counting draws as neither wins not losses. Their record is 12 wins, 0 losses, 2 draws.

Granted, there have only been 14 such matches, but that's still an impressive feat. When controlling for skill that record goes to a still impressive 7 wins 6 draws, and 1 loss (South Africa - Mexico 2010).

# Conclusion

So what's going on? Does wearing a black jersey give teams a competitive advantage? It really seems to, but keep in mind only 1.72&#37; of games have been played by teams in black jerseys, [and only recently](https://imgur.com/gallery/EhcAWAU). Good teams tend to wear black, but even when you give them a disadvantage to the point where a game is a ""fair"" 50/50 chance, they still win way more than chance. Hopefully more teams will play in black and we can see if this trend bears out.

[Bonus chart](https://imgur.com/gallery/eJ9DI3F) showing specific colour matchups.

Tl;dr: Wearing black seems to give a [distinct advantage](https://imgur.com/gallery/O45Qf8O), but a small sample size means take that with a pinch of salt.",X-Post /r/soccer The effect of shirt colour on world cup matches,8za3r4,new,5,0,0,0
,Practical Apache Spark in 10 minutes. Part 4 — MLlib,8z9tuc,new,11,37,37,0
,Intuition for polynomial transformations and feature engineering?,8z8r1k,new,4,5,5,0
,KubeFlow: Pythonic Machine Learning at Scale on Kubernetes | SciPy 2018,8z7j1d,new,0,21,21,0
"I guess I’m a somewhat advanced Spotfire user and I want to start learning either Python on R. My company uses Blue River Analytics and they recommended learning R first. 

Just wanted to reach out to y’all and see if you guys agree? And if R is the way to go, what are some good resources? Seems like there is a lot more online training for Python. 

Some of the things I’d like to do:
- be able to append a spreadsheet with new data at the end of each month 
- embed links that create specific visualizations when clicked on
- export visualizations to a PDF and be able to specify name (or have it pull from a calculated/column value)
- be able to create a list of wells within 1 mile of a specific Well

",R or Python for Spotfire?,8z6c9j,new,7,1,1,0
"**TLDR:**

The Georgia Tech OMSA MicroMasters program starts on 8/20. I want to transition into a data role. Is this program enough to get my foot in the door?

**Background**

Working as a junior systems analyst with weekly travel requirements for the last 2.5 years. My current contract is coming to an end in a few months and I am not keen on doing the same type of work or traveling anymore. 

Data analytics has had my eye for a while now. I like statistics and math, absolutely loved my Database courses in college, and I like writing dumb little programs in Python. Working with data seems like a good cross section of things that actually interest me.

That being said, I'm pretty rusty and need to brush up/learn a few more skills in the month leading up to the program.

**Plan**

Self study efforts end up half-hearted by work and travel requirements. I'm considering taking some time off after my contract ends to hunker down and focus on this program and learning. This won't be any immediate financial risk, but it means explaining a 3-4 month employment gap in an interview. I get mixed responses for how serious that gap is.

Is the OMSA MicroMasters program enough to get started? Is the quality of education enough to justify a gap in employment to an interviewer? Am I overthinking how hard it is to get my foot in the door?

Reddit, what is your opinion on my Transition 1.0 plan?
",Plans for edX MicroMasters -> Junior Data Analyst. Can I get a sanity check?,8z5dhn,new,7,3,3,0
"Hey guys,

I ended the MOOC on PGMs some time ago and I would like to practice the techniques presented there.

What would be a good way to start applying and feel comfortable with PGMs? Implementing them by myself in a language? Using toolbox or a framework on this? Playing a little in a kaggle challenge?

Also, I would like to use this  thread to know: what are some good applications for PGM that, in general, is a best option using them than using the deep learning framework?

Cheers",Best ways to learn and apply PGMs after Daphne Koller Coursera's course?,8z4tig,new,1,17,17,0
"**Weekly 'Entering & Transitioning' Thread. Questions about getting started and/or progressing towards becoming a Data Scientist go here.**

Welcome to this week's 'Entering & Transitioning' thread!

This thread is a weekly sticky post meant for any questions about getting started, studying, or transitioning into the data science field.

This includes questions around learning and transitioning such as:

* **Learning resources** (e.g., books, tutorials, videos)
* **Traditional education** (e.g., schools, degrees, electives)
* **Alternative education** (e.g., online courses, bootcamps)
* **Career questions** (e.g., resumes, applying, career prospects)
* **Elementary questions** (e.g., where to start, what next)

We encourage practicing Data Scientists to visit this thread often and sort by new.

You can find the last thread here:

[https://www.reddit.com/r/datascience/comments/8x1wz1/weekly\_entering\_transitioning\_thread\_questions/](https://www.reddit.com/r/datascience/comments/8x1wz1/weekly_entering_transitioning_thread_questions/)",Weekly 'Entering & Transitioning' Thread. Questions about getting started and/or progressing towards becoming a Data Scientist go here.,8z4eeb,new,81,9,9,0
"I'm using the Orange library to help identify associations in a transactional dataset. My users will want to be able to control the dataset that feeds into the FP growth library. For example, modify date range, filter specific attributes...etc. I can build functions to accept parameters to filter the dataset however, I'm at a point where im kind of lost as to how I should go about deploying the script. Also my users would like to view the data in PowerBI.

I was thinking I will probably need to set up a REST API and call the API from PowerBI with the parameters as inputs. Is this the right approach, or do you have a better way?

Thanks!",How would you go about deploying models/scripts?,8z4cd9,new,1,1,1,0
"Hey Everyone,

I found this course/syllabus (https://cims.nyu.edu/~cfgranda/pages/DSGA1002_fall16/index.html) that is taught at NYU and the curriculum is perfect for the topics that I want to learn. It seems at one point that all the material for this course was ""open"" to the public online. The lecture slides, readings, HW, other problems, and solutions seem to all still be hosted, but the video lectures seem to be removed from techtalks.tv. I came up empty searching on google and youtube and was curious if anyone might know where I can find them? 

I expect that the answer to this question is probably no, so I am hoping someone can guide me to a similar course, series, or books?

Thanks in advance.",Statistical and Mathematical Methods Video Lectures,8z466i,new,0,2,2,0
"Does anybody have advice on how to break into the industry? I have been searching for a full-time salaried position since mid-September last year to no avail. Although I'm confident that I have the skills to do the job, my lack of 'industrial experience' or an advanced degree has been holding me back. 

The last 2 jobs I applied for, I went through the technical interview and was very confident in my answers. However, I received the following feedback afterwards:

""Your interview left us with no doubt of your strengths and abilities. You have taken the time to use varied approaches in multiple projects, and you possess a critical skill in understanding how the methods you've used perform and yield specific results. We did have some concerns regarding your fit for our team, given somewhat light experience with unsupervised anomaly detection and custom algorithm development. While such experience is not necessary in every data science position, we've found it is critical for analytic development at.......""

 - and -

""Technically we think you are qualified as the data scientist position. Our concern is that since this will be the first data scientist our team hires this person will lead the project relatively independently so we are looking for someone who has worked on some industrial data science projects before. 

I believe we will have more openings after the project takes off, and we will definitely keep you in mind...""

Summary of my background: B.S. Mathematics, may 2017. Data science bootcamp, sep. 2017. Ad-hoc hourly data analysis work, Sep. 2017 - present. TA'ing for said data science bootcamp, Apr 2018 - present

I have a very strong statistics and math background and I'm a strong coder. I know I can do the work, but even junior data science positions seem to all want advanced degrees and previous job experience. My goal is to get an M.S. in comp. sci., but I will have to take some undergraduate comp. sci. classes to get into the program I want, so it will be a couple years at least until I can get that degree. ",Data Science Positions,8z4282,new,42,30,30,0
"I specifically just want to learn those two things as it would advance my current career. There is just SO much stuff out there that it is hard to choose. Anytime I think about doing a course I get worried that I will learn stuff I don’t really need to learn and thus wasting my time.

If anyone could recommend something that would be great, I am willing to pay up to $25/course. ",Best sources to learn statistical analysis with R and web scrapping using Python?,8z1bvs,new,18,65,65,0
"I'm working on a project that began as a simple app for me to track my weightlifting progress. It's a  web app where I input the exercise, weights/sets/reps, rate of perceived exertion,  it's datestamped, and all this goes into a mysql database. Much better than writing notes and putting it in a spreadsheet when I get home. 

Getting stronger is a pretty simple process that is well understood, and there are established guidelines for creating a program. The programs change over time based on how much progress you are making. 

It starts with high frequency full body training (usually with squat, bench, deadlift, overhead press, rows, and chin ups done 2-3x per week) and linear progress. 

Eventually this progress stalls and you have to switch to a periodized program that is based on percentages of your one rep max. Progress is slower, but stable. Some weeks you make progress, sometimes you miss numbers you hit previously. This is where the RPE (rate of perceived exertion) comes in. If you hit the numbers but it was very hard, you lower the weights 5-10&#37; and work back up. There are a few more tenets of strength training like this.

I think it would be useful to create a program that tells me what workout I'm doing today and adjusts my program based on my progress. I think this could be done with some tedious if/then statements, but I was thinking that a ML algorithm might be able to learn how to make these adjustments with enough data. I have a few friends that have asked to use the app and once I get it to support multiple users I will let them.  With the data I might be able to gather over the next 6 months-year, I was thinking it may be enough to train a ML algorithm. 

Is this a feasible use case for ML? I dont really know what I'm talking about here.  ",Would machine learning be useful for this project? Weightlifting related.,8z0hug,new,6,5,5,0
,Running Zeppelin Spark notebooks on Kubernetes,8yws3i,new,0,1,1,0
"Does anyone who has been accepted into data incubator have examples of what they used for an interesting visualization? 

What are good examples of non-trivial plots. I've got some ideas but I'm unsure if I'm just over thinking this. My project idea is NLP focused.",Data Incubator 'Interesting' Visualizations.,8ywc65,new,0,4,4,0
"Hi there, hope you  fellow redditors are doing good at this sub.  I am getting into field of analytics. Sorry. Just hear me out  on my short journey towards becoming an analyst.

I graduated last year with bachelors in cse with 3.0 gpa with no job/internship since september until now. I have managed to learn python, R, ML algos, Tableau,SQL, deep learning from the courses on udemy website. Most of these courses were from the author named Kirill.

Now that I have managed to land internship at a company who are into constructions designs (civil + structural + site). They want me to try to optimize their business processes using the skills I have acquired. I barely have any clue on how I can accomplish this task, what data should I request. So in meantime I have created simple dashboards for their old balance sheets using tableau. But right now I need to figure out what to do. So I have come here to ask for advise.

Thanks for reading out my post.",Data/Business analytics for building consultant (need advise)!!! appreciated,8yv8o0,new,2,3,3,0
"See the title for the overall generic question. When do you think it is optimal to move on? (Outside of situations when you are fired or laid off). At your current position, what would make you consider a different option? What amount (or &#37;) of increase in salary? A job with more/less responsibilities? Better commute? Managing title? 

Now a little bit about myself. I have a decent job that I have been at for a few years now, after I had switched from academia. Overall, I quite like it. Very have pretty relaxed athmosphere, good management, decent pay, great perks. But I am a little tired of everything here. I am not in love with the industry, a little bit tired of coworkers, my learning curve has started to flatten out. So I've started looking around. Now a have two offers, both nice, but I am not sure wether they are worth the move. In both cases I am getting a modest salary bump, a new industry and lots of opportunities to learn. But I am afraid to leave something that is familiar, my relatively short commute, flexibility and perks. ",When do you think it is time to switch jobs for a data scientist?,8yv15s,new,7,5,5,0
,Number Comparison Challenge - Hard,8yuhj4,new,1,1,1,0
"Hey folks, I recently wrote this post describing the process of building a real-world data-science-driven product/system.

[Building A Data Science Product in 10 Days ](https://tech.instacart.com/building-a-data-science-product-in-10-days-d2f4688567b0)

I'll answer questions related to the post or general questions in using data science for solving business problems. This is also my first blog post - feedback is appreciated.

Note: It is in the logistics domain but I tried to make the learnings applicable to data science projects in general.",A blog post about using data science to solve a real-world problem,8yugj7,new,4,14,14,0
"Hi r/datascience!

My wife and I moved to New York a while ago. After some discussion she decided to pursue the career in Data Science, as maths & statistics were always her passion. Prior to our relocation to US, she used to work as a Senior Audit analyzing financial data, looking into Data Science and Machine Learning in her spare time. Given that none of us has actual experience in the field, I thought that it could be really helpful to get an advice from the experts and people working with Data for life. After some iterations we came up with [the following version](https://imgur.com/a/swwoUAp). What do you think? What could be added or removed? Appreciate your opinion and time.",Looking for advices on my wife's DS entry-level resume,8ytuhy,new,15,27,27,0
"One of the central assumptions of many probabilistic Customer Lifetime Value models is that the inter-purchase time obeys a Poisson distribution. This seems a very poor assumption for seasonal businesses, for example travel, where transactions from a single customer may be sparse but exhibit a high degree of periodicity (e.g. booking a yearly holiday around the same time of year). Are there any adaptations that can be made to these models to account for this, or perhaps alternative approaches?

Edit: I should specify that I am modelling on an individual level and I'm interested in calculating quantities such as expected number of transactions in some arbitrary future time period. Currently I am using an ML approach as this time period is fixed so I can train from historical data, however I'd like to make a comparison to a probabilistic approach. The conventional BG/NBD model for doing this has a poor performance which I suspect is partly due to the Poisson assumption.",CLV models (e.g. Pareto/NBD) for high seasonality?,8ytlrw,new,7,6,6,0
"So we're looking for speakers for a data meetup and we've been through the usual suspects, we've had local researchers who have cool ideas in progress to people who've been responsible for some cool public projects etc. But we sat down to a beer the other night and asked ourselves, who are the worldwide rockstars when it comes to data science? We were drawing a blank. I mean we all know people who are doing some awesome stuff, but is there an Elon Musk or Stephen Hawking of Data? Are we perhaps just missing the obvious? The best I had was Hans Rosling because of his TED talks (also Andrew Ng just because yeah he's cool), internet searches were coming back with Mark Zuckerberg and Eric Schmidt which I'm not sure I'd class as data scientists just because they have massive data companies. Perhaps it was because we were drinking, but if you have any suggestions I'd love to hear them. Not that we can afford to fly in all of these people, but we might be able to get an awesome speaker for a large-scale hackathon sometime which would be cool. Crap, I just remembered Nate Silver (unless he lost his coolness factor after the last US election?).",Who are the rock stars of data science?,8ysaq9,new,35,2,2,0
"Hey, I was wondering if anyone knew of ways to get CCG bank for free  and/or get a free LDC membership for personal use and/or for completely unpublished trial research",LDC is expensive,8ys9c5,new,0,0,0,0
I completed my MS in Statistics two years ago and recently was promoted in my bank to a position using more machine learning. What online classes would you recommend someone who has experience in machine learning but wants to move to more modern R packages?,Looking for Online Class Recommendations for someone with an MS in Statistics and R experience,8yr5cu,new,5,8,8,0
I recently created a new post on my blog that tries to explain how to become faster in RStudio by making use of their hotkeys. Here is a link where I share it on [Kaggle](https://www.kaggle.com/general/61080#latest-356608). I appreciate any feedback!,Becoming a faster data scientist in RStudio,8yps30,new,3,0,0,0
I’ve been practicing a lot of data structure questions for interviews. However I haven’t gotten to dynamic programming yet. Are there normally asked in data science interviews?,Are dynamic programming questions important for data science interviews?,8yp79z,new,8,3,3,0
,"For people currently employed as data scientists: did you go right to data science? Or did you work your way up from a ""lower"" related job, like analyst? Or right to DS from something else entirely?",8yp6zy,new,19,11,11,0
"As per the title, is anyone familiar with how I would install a third party package (specifically lightFM) onto a databricks server?

",Installing the LightFM Package on Databricks,8yokne,new,1,1,1,0
,Tame Jupyter notebooks for production systems,8yok94,new,2,1,1,0
"I know R, Python, and SAS.

What actual things would java allow me to do, that the other 3 languages do not allow me to do?",Any reason to learn Java?,8yo303,new,32,37,37,0
"I'm trying to identify the qualities of objects through their adjectives and want to use a pretrained word2vec dataset. I'm wondering if anyone knows of any attempts to locate the closest object to a given adjective in either word2vec or any other kind of coordinate space of word vectors. For example, given the coordinates for ""disgusting"", the closest noun might be ""disgust"". But how would one find the nearest non-abstract noun, such as ""worm"" (a highly improbable result, but you get the idea)? 

This seems like something of sufficient heft that it felt worth throwing to folks here before blindly coding my way to frustration. One solution would be a dataset of trained words that differentiate concrete from abstract nouns, but I'm not sure if such a thing exists. ",Finding closest concrete noun to given adjective in word2vec?,8yo1ff,new,6,8,8,0
"Lets say that I use a bunch of features and trains an accurate ML model (like a ensemble tree learner or ANN, something complex) to predict how productive a factory is using historic data about many input factors.

Then I see that the output of the model says there is a drastic reduction in productivity and I want to see which features caused this to happen, so that I can plan an intervention. 

How does one approach this? The most naive way i can think of is to change one variable at a time, but some input features are correlated right?","How to make a ""prescriptive"" model using machine learning, not just a good predictor?",8ynyi6,new,7,1,1,0
"I have data that is a list of cities across the world and a count for each city. I would really like to investigate if there are any geographical patterns. Are there any tools you guys can recommend to visualize data like this? 

More generally, what visualization tools do you use for geographic data?",Tools for Visualizing Geographic Data,8yndr0,new,8,1,1,0
,"Weekly Digest for Data Science and AI: Python (Prophet, tweets_analyzer, PythonRobotics) and R (gganimate, gghighlight, paletteR)",8ymw2u,new,0,2,2,0
,UMAP for Supervised Dimension Reduction and Metric Learning,8ymj4g,new,2,31,31,0
"Hey all,

Apologies if this question is out of the scope of this sub. Please feel free to direct me to a more appropriate place to post if necessary.

I'm in the process of familiarising myself with Hidden Markov Models so that I can apply them to a few engineering problems. I have a pretty solid, but not quite rock solid understanding of the theory behind them, but enough to get the gist of what is going on. This may or may not be enough in the context of machine learning engineering, but I'd like to understand the theory behind them at a deeper level to satisfy my own curiosity.

What I'm trying to do right now is derive the formulas for the forward and backward variables both analytically and graphically. I've scoured multiple resources that might walk through the derivations at a more fundamental level but I haven't found any.

I have a few questions and the best way for me to describe where I'm having trouble would be to draw out my thought process and provide that in an imgur link. Before I do, though, I thought that I would use this post as a feeler to see if anybody out there is willing/able to help out.

Thank you all in advance!",Any Hidden Markov Model Experts?,8ymifz,new,14,27,27,0
"Hello guys,

I’m working on a problem for a friends factory. Basically they manufacture zippers and I am trying to estimate the probability that a damaged zipper might come out of the production line. 

I have a large sequence of events in which a good sample is represented by a 1 and a bad sample is represented by a 0.

[11111110011011110001...]

At first I thought of using a two state Markov chain in which I would calculate the transition probability matrix by counting the number of instances that occurred in the last n samples. 

In other words, number of ones followed by a one, number of ones followed by a zero and so on. 

But now I’m staring to think that my approach is not the correct one. Anyone knows how to approach this problem? 

Thanks in advance for the help!",Manufacturing probability problem,8ymg07,new,9,5,5,0
,"Defying Death, Living Forever and Coming Back to Life with Dennis Kowalski of Cryonics Institute",8ymdbi,new,0,0,0,0
,How to scale the machine learning community to 1 Million researchers,8ymbac,new,1,1,1,0
"\[Main Question\] Anyone who got an entry level job or internship in data science or as a data analyst, do you learn on the job or do you think that having a good foundation prior to the job is essential?

\[About Me\]  I'm an undergrad with one year left and I have my major courses in this last year where I suppose i'll learn more about SQL, Python, data visualization etc. I feel like I have a lot to still learn and explore. I don't want to enter the job market with such little knowledge and no experience at an internship so far. 

Thanks in advance for all replies! ",Question for entry level jobs/internships (Not looking for one here just asking for experiences),8yl2ts,new,8,9,9,0
"I am working on a problem in which I have several instances that have predictors that have activity over various different time periods (i.e. <3 months to well over 20 months.) Originally I attempted to use knowledge I have about this problem (it is an opportunity to sale conversion model) and learned that the average time for a deal to close is about 9 months, so I broke my predictors up into three month intervals. However, I took another look at the lengths of these deals and see that there are a variety of instances that have durations that are not even close to 9 months so this idea does not make sense.

The only idea I have gotten is just creating a duration column where I subtract the start and the stop date and then just do the summation for each predictor. However, I feel that the instances might get incorrectly labeled because some might have an overwhelmingly higher amount of activity than another due to the duration of the deal. Has anyone else encountered such a problem. Not sure if this is a common problem but a quick glance at google/reddit did not come up with anything (I could be asking the problem wrong.)",How to aggregate data for instances that occur over very different time periods,8ykxay,new,4,1,1,0
"I'm using the Prophet package in Python 3.6 to evaluate the effects of a campaign on sales, product margin, and other ecommerce variables. I am training a model on daily data from the pre-period before the intervention (holding out a subset of the data at the end before the intervention and validating that it makes good predictions on that period and has reasonably calibrated uncertainty intervals), and then using it to forecast the counterfactual of how sales would have trended without the intervention accounting for trend/seasonality/holidays. 

Someone has advised me to take MCMC draws from the posterior predictive distribution of the counterfactual sales trend and cumulate the actuals against those to get a distribution of lift attributable to the campaign. However, I am completely lost as to how to do this, and need some serious help. I tried looking at pyMc library, and it sorta went over my head.

If using prophet to make a prediction, how would I then get MCMC samples from the predicted distribution?",How to do MCMC sampling on the posterior predictive distribution created by Prophet Library (python),8yknw0,new,5,4,4,0
,Teaching R to New Users - From tapply to the Tidyverse,8ykk7q,new,0,67,67,0
,Technology Detox and its importance in our lives,8ykchd,new,0,0,0,0
Hi! Anyone knows where one can find free soccer/football data online?,Data Science for soccer (Free),8yjxw5,new,7,9,9,0
PS : as data science is a new field there are so much lower jobs in DS than SE and other related fields I have heard jobs for DS & ML(AI) are going to increase in future and we will need more DS because DS are less in number but history showed us there were times when prediction became false ( Just applying Bayesian thinking) and also which one is more paying?,Which one is better data scientist vs Software engineer?,8yjvft,new,11,0,0,0
,Zero to Hero Series- Business Analytics & Statistics using Excel- Part 1.,8yjugj,new,0,1,1,0
"Hi all!

Wanted to use time since last purchase as a possible variable. However, my data set contains lots of new customers as well, and I do not want to drop them

Thought of coding a dummy variable and interaction it with new customers, but how do I interpret this.

All ideas welcome!",Beginner question: how to inpute time since last purchase for new customers,8yj0x6,new,4,5,5,0
"Finding it hard to get suggested HIT recommended payments. Lot of old (2014ish) information. 

Per minute, what is most people recommended payment to HIT(s)?  I've seen everything between 0.05 and .50 cent. ",Recommended Mturk HIT payment?,8yiug8,new,0,2,2,0
"Hey folks, i'm writing here looking for suggestions for which laptop to buy, considering that i'll start a Master's degree in Data Science in September.  

My two options, as of now, are the new Macbook Pro 15"" (sadly, with touchbar) or the Surface Book 2 (i'm fine with both Windows and MacOS).  

Taking into account all the software that i'll use, what is, in your opinion, the best choice? (my main one would be the Mac, but the high price and the keyboard are two big problems).",Laptop suggestion for a future DS,8yidju,new,18,2,2,0
" I've been interviewing people for my team. Was wondering if you guys ask any ""dealbreaker"" questions. As in, if the candidate gets it wrong, then that's an automatic ""no"". Kind of like fizzbuzz for data science. ",Dealbreaker Interview Questions,8yhzk0,new,4,2,2,0
"I have built 4 of regression models to predict 4 binary dependent variables based on a single independent categorical variable. I am using a training testing split of 80-20 for testing overfitting and am getting anywhere from 97-100% accuracy on all my models. Now, granted that my data does not pose too many complications and is pretty consistent (one can see obvious relationships just by looking at the spreadsheet) but I cannot help but feel suspicious, especially because my dataset only has around 230 datapoints. How should I proceed? Should I bother with bootstraping or cross validation or just use my results as is? I have not tried any other classifiers and planned to start with logistic regression and move on to decision trees and svms. But seeing as I am already getting this kind of accuracy, I am not sure how to proceed. Please advise and thanks!

",97-100% accuracy in binary logistic regression using a single categorical predictor. Should I be suspicious?,8yhysg,new,4,1,1,0
So I got in undeclared to my college. I decided to switch to the data science major(intended to get CS). I want to try getting into an internship by my 1st year summer(I know it is hard but I will still build towards that goal). But I am slightly new to the data science. I have a couple of months free and I want to get some basics down and start working on projects to build into a resume. Can someone recommend the most efficient way to start on this. Also apart from projects is there any other way to build my resume. And any tips to land internships?? Thanks in advance,Need help deciding what to do from now on,8ygg35,new,0,1,1,0
"So I’ve recently been trying to get better at data science over this summer and as I advance further and further into the field I’m starting to deal with larger and more complex data sets. 

The main question that I have is how do you begin working with extremely large data sets? Thus far, I’ve had very few problems analyzing, visualizing, and making models from smaller data sets that have less than 100,000 observations and very few independent variables, but as I progress in my skill and knowledge I’m beginning to feel overwhelmed with the sheer size of some sets. 

Are there any books, videos, or other resources that I can use to help me get over this problem? I know it will become easier to work as I gain more experience but I would still like some advice. 

Any advice is appreciated! ",Help Dealing with Large Data Sets,8yga9k,new,12,3,3,0
,What would be an absolute beginners course on data science you would recommend a friend??,8yg957,new,9,9,9,0
,A quick overview of Robotics Process Automation (RPA) and how it is going to explode the whole market,8yg7qf,new,1,5,5,0
"Hi All

I'm looking to transition into the Data Science industry in Sydney Australia. 

I have a background in Electrical Engineering and have recently enrolled in Monash Universities Grad Dip in Data Science.

Would anyone have any links to a data science community centered in Australia? I’d love to get in touch with people in the field nearby.

Also is anyone able to comment regarding the state of the industry in Sydney?

Thankyou!
",Data Science Community In Australia,8yfrbk,new,1,1,1,0
"Hi guys, just needed a bit of advice. I am starting grad school at Columbia University where I’ll be studying data science in September. I studied Financial Engineering at Carnegie Mellon and so my background is in finance and haven’t really recruited with tech companies before. 

I’ve spent this summer improving my programming skills and building a portfolio of projects in anticipation of internship recruiting. Just wanted to know when recruiting for data science internships normally begins. 

I was looking at companies like LinkedIn, Microsoft and Facebook that have internships listed on their job portals but no deadlines. Does recruiting for summer internships normally take place after full time recruiting is complete in September/October or does it occur side by side with full time recruiting? 

Would really appreciate your help!",Looking for advice on data science internships and when to apply,8yfq8u,new,3,12,12,0
Looking to see if there are any blogs or websites I could look at where data science is used in eCommerce.,any blogs or tutorials for data science in ecommerce?,8yfcc0,new,2,6,6,0
Check out the gallery: [http://www.scikit-yb.org/en/latest/gallery.html](http://www.scikit-yb.org/en/latest/gallery.html),New Release of Yellowbrick (Open Source Python Machine Learning Visualization Library),8yf2mv,new,5,100,100,0
"I’m an Econ grad and have a masters in Econ as well. Have done tons of econometrics and would love to do a masters in data science. I am a viable option for a data science program? I’m really passionate about data. 
Thank you DS community. ",Looking for advice from the community,8yepyk,new,6,2,2,0
,List of Winning solutions of Kaggle competitions.,8yeoiu,new,0,2,2,0
We’re looking to bring on a data science consultant and I was wondering if anyone had a template that they’ve found or willing to share for this. Thanks!,Data Science Consultant Statement of Work,8ye597,new,1,0,0,0
"My apologies in advance if this post comes off as a nuisance; however, I'm very much in a state of existential dread. I'm about to finish my double-major in Physics and Astrophysics from a large university (expected GPA ~4.0 if that means anything). I entered this major with the intent of pursuing a Ph.D. in Astrophysics; however, as my senior year approaches, I'm having second thoughts. I do love astronomy, but academia has become increasingly unattractive to me (worryingly high rates of depression among grad students, gross underpayment of grad students, imposter syndrome, etc.), so I'm looking into other options.

I frequently hear of Astronomy PhDs ending up in data science, and oftentimes loving it. And I suspect that I could find a great deal of enjoyment in data science as well. I say this because my favorite part of my research projects has always been in the nitty-gritty of using Python to reduce and visualize data for analysis (the analysis is a lot of fun too!), especially with particularly large datasets. Broadly speaking, I suppose I enjoy using tools like Python to reduce data into an interpretable format in order to constrain the answers to some big questions.

So my questions for anyone in this subreddit are:

* **In your own experience, do you enjoy your job as a data scientist? i.e. Does it keep you interested?** My main--and perhaps naive--concern about pursuing data science is that I might fall into a boring, unexciting job. I don't suspect this would be good for my own mental health.

* **Do I even have a shot at this career without a degree in CS, stats, etc.?** My loose plan is to become proficient in Pandas and SQL before graduation, and then apply for paid internships after graduation. Hopefully these wouldn't reject me on the basis of my non-CS background.

Again, I'm sorry if I'm annoying anyone with this perhaps hackneyed post. I'm certainly under a great deal of stress right now because I was so sure of what I wanted to do for so long. I'm by no means ruling out grad school entirely... I just don't think I'm ready to make that huge commitment quite yet, and data science is looking very attractive from my perspective. Thanks for reading!","Will graduate soon with Physics and Astrophysics B.S. Very interested in data science, but unsure if this is viable. Advice appreciated!",8ye3eq,new,5,0,0,0
"Thought in the interest of speed I'd use bullet points for my situation

* Starting a part time Master's program this fall
* Nov 2020 is expected graduation date

* Currently in sales - job is stressful, time consuming and not very relevant to future career

* Most internships seem to be part time and looking for a grad date no later than 2019 - but they also pay better per hour


So my question is what should I do over the next two years?

 Hands on experience is important and I want as much as possible and a big meaty portfolio, but is it too soon to apply for these internships?

 Would companies be willing to hire me full time as an intern or share me with another company?

 I wouldn't mind working part time, going to school part time and doing something like bartending on the side to make ends meet. ",Just got into grad school for the fall - career advice needed,8ydw7z,new,2,3,3,0
,Intuitive Ensemble Learning Guide with Gradient Boosting as a Study Case,8yd2pr,new,0,2,2,0
"I currently work as a data engineer for a large company using not so interesting tech. Think SQL, SSIS, etc... I do a substantial amount of on my own python programming and data science work for the fun of it. However, it does not seem to be enough to bridge the gap to getting hired as a data scientist or even as a data engineer in a data science shop.

One option i have is to work for a actuarial firm for 2-3 years as a data engineer. This firm is using new technologies that are in demand by data science/engineering teams for processing, analyzing, and visualizing data. During that time i will also be encouraged to take and pass the actuary tests. I am also heavily considering beginning an online masters program in computer science since my BS is in a non CS engineering field. I feel that i could likely complete this in 2-3 years.

My 3 questions are:

\--Will completing 2-3 actuary tests make me a more competitive candidate for a data science position. The tests largely involve probability, statistics, and finance. In my eyes this could be viewed as almost a stats B.S.

\--Are online CS masters degrees with focuses on data science from reputable institutions well respected among data science hiring managers?

Ideally my resume could look like the following. Would this be competitive?

\--5+ Years as a data engineer (with relevant tech)

\--2-4 Actuary tests passed (this guy knows statistics and probability)

\--MS in CS with a focus in data science (perhaps at the same time setup a public portfolio)",Data Engineer aspiring to be a data scientist evaluating my career path.,8ycv9r,new,2,5,5,0
"The video details using Pandas, Numpy, and Matplotlib to analyze many files at a time. The purpose of the video is to help students in data-heavy fields handle significant amounts of data with relative ease (for me it's a physics senior lab).

My goal is to make a bunch of videos including fundamentals in Python, intermediate statistics concepts for lab work, and possibly some introductory machine learning. If you have the time to watch the video, I'd really appreciate some constructive feedback. :)

[Check it out!](https://youtu.be/SmG3N_NM18U)",Looking for feedback in my first Python tutorial video,8ycv59,new,3,7,7,0
"Hi, I recently had a phone screen with a big tech company, which I did not clear. I answered all the sql and coding questions, and the third part was an open ended stats question - I failed because of this. The question is :

The company X makes thousands of SQL requests everyday. The data is stored in the format:
Date; Number of successful queries, Number of failures

How will you qualitatively and quantitatively find out if the variations is just due to normal fluctuations or there is a real change?

part 2:
There was System 1 in place till June 25th.  A new system was installed from June 26th. How will you determine if the new system improved performance or decreased or did not have an effect?",Phone screen question - Answers?,8yci5w,new,5,5,5,0
"Goal: to proactively identify potential computer network latency.

Approach: Given a contrived dataset like the following,

time (minutes)|Network IO|Factor X|Factor Y|Factor Z|
--:|--:|--:|--:|--:|
1|200|42|3|55|
2|250|19|12|46|
3|201|15|100|69|
4|204|11|60|63|
5|275|58|20|12|
6|350|74|58|40|
7|700|38|26|12|
8|655|16|94|51|
9|400|20|67|93|
10|200|100|73|96|

predict network I/O at a given point in time.

I think this lends itself to a multivariate forecasting problem, where changes in factors X, Y, and Z are assumed to have some impact on network I/O.

Since the goal of this project is to be **proactive**, wouldn't it be a good idea to ""lag"" the `Network IO` dependent variable to better identify combinations of activity for X, Y, and Z that lead to higher network I/O? By lagging I mean something like this:

time (minutes)|Network IO|Factor X|Factor Y|Factor Z|
:--|:--|--:|--:|--:|
1|200|NULL|NULL|NULL|
2|250|42|3|55|
3|201|19|12|46|
4|204|15|100|69|
5|275|11|60|63|
6|350|58|20|12|
7|700|74|58|40|
8|655|38|26|12|
9|400|16|94|51|
10|200|20|67|93|
||100|73|96|

Where the X, Y, and Z values have been shifted forward in time in order to learn a function that accurately maps input feature states at time *t-1* to output states in *t*.

Or might a better strategy be to somehow roll-up the X, Y, and Z features historically, e.g. `stddev_last_5_periods_Factor X`, `mean_last_3_periods_Factor Y`, etc., and keep the original input-ouput alignment?",Lagging dependent variable for multivariate forecasting,8yca5k,new,2,1,1,0
"Our 300+ person bureau is seeking to hire Sr. Data Architect/Scientist to assess our current data situation, design a new data organization and storage environment and direct the implementation of the new infrastructure.  We seek to move from our siloed legacy systems into an up to date environment utilizing  modern tools and data management practices.  This project has funding and senior management buy in.

Any advice where to post this project?  Ideally we'd like a 3-9 month engagement, with a follow on contract.  We are interested in working with an academic institution.",Seeking to hire Data Architect/Scientist for Large Data Project,8yc9dq,new,1,0,0,0
"When scouting companies and interviewing, how do you tell if it has a highly collaborative culture or not? 

By collaborative, I mean there’s ideally an effective reward/discipline system for individuals and teams that actively collaborate vs those that don’t, and overall willingness of teams to share knowledge, data, techniques, etc. with one another",How to identify a collaborative company,8yba9k,new,3,9,9,0
"Hi everyone. 

I was wondering if anyone on here has come from a humanities background. Things like History etc and made the switch across ? Data science fascinates me but my background is not in maths etc so be good to get people's thoughts. 

Thank you ",Humanities Background,8yan1p,new,14,12,12,0
,How to build an end-to-end deep learning GitHub discovery feed,8yag6g,new,0,10,10,0
"I've actually worked for many years in the financial industry doing quantitative analysis work but never really found it interesting. I loved building models to gather financial data, automate and test existing processes and using machine learning to make new predictions on the stock market. But i was never very excited to hear about the latest corporate acquisition, news and political events affecting the financial markets, the latest stock to drop or pop double digits, etc.

Back when i first started, there was no ""data scientist"" position but nowadays, it seems countless industries are embracing the same skillset that i used to build quantitative models for financial firms, now in data science positions.

I honestly don't feel any passion or preference for any particular industry. I'm just passionate about data science. Given this, would i be able to succeed as a data scientist in most industries? 

I don't mind and may actually enjoy learning some domain knowledge of other industries in order to get the job done but for me, what gets me excited ultimately is building machine learning models that make fast, accurate, and innovative positions rather than the industry or business's bottom line (even though the latter is what gets me paid.)",I don't really have any passion for any particular industry but I love machine learning and working with data. Can I still make it as a Data Scientist?,8y9s7n,new,20,42,42,0
"Does anyone have thoughts on this article? From what I gathered, he is arguing that data science will change due to the increased availability of ways to gain the skill set. I'm not sure though.

DATA SCIENCE DEAD IN 5 YEARS or LESS
https://www.linkedin.com/pulse/data-science-dead-5-years-less-justin-b-dickerson-phd-mba-pstat-",DATA SCIENCE DEAD IN 5 YEARS or LESS,8y8ii4,new,7,0,0,0
"I work as a consultant data scientist and I'm looking for recommendations for books to give to clients.

The type of reader might be a commercial manager or director who is interested in applying AI to their business unit and has data scientists or machine learning engineers in their company but wants to better understanding what is and isn't possible, what language to use, and get an intuitive overview of DS practices.

Does such a book fit the bill that you've read?",Recommended data science/AI books for managers,8y7xg5,new,4,6,6,0
"College freshman aiming for the Data Science major at my school.

Was kind of surprised to see Calc 3 wasn't a required lower-division math course at my school. (Just Calc 1+2, Linear, and Differential)

Do you think taking Calc 3 is a good idea for a career in data science and machine learning? I'm studying Calc 2 right now and enjoy taking math, but I also don't want to take a non-required class that doesn't have too much real-world value for me.",Is Calc 3 useful for a Data Science Career?,8y7p8s,new,11,3,3,0
"So, I'm trying to create a service . Currently, the backend that I have is using ARIMA models to predict.

What I'm struggling with is how to create an automatic method to select parameters that take into account seasonality. I'm running a grid search using 80&#37; of the data to train and testing it against the remaining 20&#37;. Whichever parameters return the least RMSE, I'm using those in the model. But this is computationally intensive and could result in overfitting, any idea how to go about it?",Generic forecasting model with ARIMA,8y7aje,new,9,1,1,0
,An Introduction to Causal Graphical Models,8y6zyp,new,0,2,2,0
,Welcome Wagon: Classifying Comments on Stack Overflow - Stack Overflow Blog,8y6t5n,new,0,1,1,0
"Hi everyone,

Currently try to create a linear regression model (market mix modelling) and seeking some guidance on how to organise this data.  I'm doing this in Python

Essentially I would like to create a model to look at multiple variables and how it contributes to ‘sales’ – and looking at this by day.

One set of data looks like this:

|Date|Sales|Vists|
|:-|:-|:-|
|01 July 2017|294|1432|
|02 July 2017|312|1907|
|03 July 2017|673|3451|

Second set of data looks like this:

|Date|Channel|Spend|
|:-|:-|:-|
|01 July 2017|Facebook|$103|
|01 July 2017|Ads|$139|
|01 July 2017|Google|$345|
|02 July 2017|Facebook|$94|
|02 July 2017|Ads|$207|
|02 July 2017|Google|$564|

Do I need to transform my data so that each date is only ever on a single row? That is, change the second set of data so that it looks like:

|Date|Facebook|Ads|Google|
|:-|:-|:-|:-|
|01 July 2017|$103|$139|$345|
|02 July 2017|$94|$207|$564|

And if that is the case, what is the easiest way to do this (in Python)?

Thanks",Market Mix Modelling (Python) - how to structure data (if there are multiple lines of the same date),8y5iwi,new,2,4,4,0
"For anything memory-intensive, like using Pandas with sizeable datasets, you probably want to uncomment the lines in the Vagrantfile for setting up the virtual box's memory and CPUs.   Choose values appropriate for the host machine.  It is left commented out for maximum installability.

  
Repo: [https://github.com/Deplorable-Mountaineer/VagrantDataScience2018](https://github.com/Deplorable-Mountaineer/VagrantDataScience2018)

Blog post: [https://www.deplorablemountaineer.com/tutorial/mathematics/data-science/a-vagrant-data-science-virtual-ubuntu-18-04-box/](https://www.deplorablemountaineer.com/tutorial/mathematics/data-science/a-vagrant-data-science-virtual-ubuntu-18-04-box/)",A Vagrant Data Science Virtual Ubuntu 18.04 Box,8y5c0y,new,2,3,3,0
"So due to some lucky breaks and a few hijinks, I was looking at being able to graduate a year early from UT Austin for a while. However, the fact is that I think doing so would be wasting my access to the university's resources, so my solution was basically to get involved in the co-op program to supplement my degree by working full time in industry for 9 months before graduation, but I'm also doing something called academic enrichment which basically lets me take a certain number of classes outside the ECE department and still have them count towards my degree (in my case I have seven classes I can take). Here's the long and short of what I have planned so far:

Elective Data Science Classes: [Software Design and Implementation II](http://www.ece.utexas.edu/undergraduate/courses/422c) , [Multicore Computing](http://www.ece.utexas.edu/undergraduate/courses/ee-361c), and [Concurrent and Distributed Systems](http://www.ece.utexas.edu/undergraduate/courses/360p)

AE Advanced Math: [Intro to Stochastic Processes](http://catalog.utexas.edu/search/?P=M%20362M)

Of the seven other courses I have room for, three need to be usable for academic enrichment (so any kind of upper division classes outside of Engineering), and the rest can be whatever (more Data Science electives, for example). Does anybody have any suggestions on what kinds of classes would compliment my degree, specifically with a bent towards human data on a large scale (think international company or domestic/foreign intelligence type data). Any help is appreciated!",Data Science Major looking for advice on extra classes,8y4uov,new,1,0,0,0
"Besides college a couple years ago I really have no rdbms experience.  I have understanding of SQL and it really isn't hard for me to pick up on the more advanced commands within a weeks time. 

I'm in a cyber security background and went through the help desk route.

I enjoy the thought of data, but I cant really figure out what day to day life is like for SSIS ETL worker.  In my mind it's just going to be really reclusive and boring/ frusturating when commands are wrong and things don't execute.

I have an interview tomorrow, but after refreshing on relational databases, visual studios, and SQL I thought, ""damn, would I just be doing this stuff non stop all day?""

One thing nice about cyber is it's all very logical based and different minds can solve issues different ways. Where data seems more white and black. 

just looking for work experience reviews for people who did ssis work. ",Anyone coming from cyber security or cyber field? SSIS experience?,8y4ldd,new,1,0,0,0
"I have been working as a data scientist for a few years, and recently decided it was time to move on to another company to advance my career as a data scientist, but the recruiting and interview process has been very tough. The interview process is a different set of skills, and I have gotten less rusty and better over the past few months. I have had bad interviews and good interviews. I don't think I have had a great, home-run type of interview. I have also run into not so great, or just plain bad interviewers. All these things are expected. 

I do think the gap between my interview skills and my actual work performance is quite large. I don't think the interview process is a good proxy for future performance as a data scientist and as a process is inconsistent at best; I don't expect data scientists to be good interviewers and they usually aren't. But the process is starting to bother me since I keep getting rejected. Obviously one reaction is to just keep going, since rejection is an inherent part of the process, and keep on working on my interviewing skills. But I am starting to ask myself if it even makes sense anymore? I have read about people spending a year interviewing and practicing their interviewing skills for hours every day. Is it crazy to think *that* is crazy? I have a family and some other difficult circumstances (which I will not state here, but it's something very few people have to deal with) that make something like that quite unreasonable; and I am pretty exhausted trying to do so. 

A few things I have noticed in my interviews, this is purely anecdotal. Some people have been surprised to see me. My assumption is that they were expecting something different from what they envisioned. Perhaps it is because I am older older? I don't know, most people think I am much younger than I actually am. Maybe more intimidating (I don't think I am)? I went to good schools but definitely I don't really fit the image of the type of people I run into at these companies. I come from a combat sports background (since I was a kid), so scars above my eyes and cauliflower ears. One person could not look me in the eyes, which threw me off. I don't think I am hideous to look at, at least my wife says so! It's hard to describe.  But I have yet to run into an interviewer who I could say, ""oh, this person is like me."" And, on their end, they may be thinking the same thing about me.  I don't think that should be important, but I know that empirically it is a factor. 

So, I have been thinking about quitting the field the past few days, since it has become extremely, extremely frustrating. I think that feeling will go away since I hate quitting. But also wondering if it would be actually more reasonable to find something else to do. I am not sure what given the skills I have; which include:

ETL pipelines

Machine learning models. End to end into production.

Deep learning models. End to end into production.

Natural language processing (document classification, entity recognition)

Econometric modeling (I went to grad school for this)

Statistical analysis

Geospatial analysis

I also did a couple of Udacity Nanodegrees (Deep Learning and Artificial Intelligence). So, computer visions tasks (CNNs), sequence models (RNNs). Though I have not had the use case to use those models professionally. 

Any insight or advice would be great. Or just commiseration.",Anybody consider quitting data science?,8y3h97,new,19,6,6,0
"I'm currently doing a project that requires record linkage/ identity resolution. I'm using the python package `recordlinkage` but I find it very memory intensive when indexing the data. For example, I'm using a block such as first letter of persons first name and first 3 letters of surname but when I run this on my dataset (approx 1.6 million records) the memory runs out (60Gb aws server). I cant do any kind of sorted neighbor hood blocking which would be nice too.

My question is does anybody have any experience or strategy on how to tackle a problem like this. ",Record linkage/ Identity resolution with python and memory issues,8y34z0,new,1,2,2,0
"I'm confused how to handle large data sets in python. Currently I have multiple tables that I filter, join, sort in SAS. Tables range from thousands to millions of rows, columns from 10 to hundred.

We're moving towards python and pandas. However are we really supposed to load each table into memory for processing? I would think that is prohibitive. How do you use python/pandas with larger data sets?

My idea was to keep the tables in SAS and use python to tell sas what to do, but I don't see the benefit of that.",How to handle large datasets in memory?,8y2trw,new,11,3,3,0
,Intro to optimization in deep learning - How to chose an activation function for your network,8y2jiv,new,0,1,1,0
I have been looking for an actual informing data science meetup that is not hosted by a bootcamp? Does anyone have recommendations? ,Genuine Data Science Meetups in NYC,8y23n8,new,0,1,1,0
"Several months ago, Kaggle released a dataset of homemade beer recipes. This was my first data science project outside of my regular 9-5 and I'm looking for advice/recommendations that the larger community of Data Scientists can give me in my continuing DS journey. 

The goal: predicting beer style based off the recipe. 

Link: https://github.com/gclarkjr5/HomeBrewAnalysis

Thanks again to those who check it out and provide feedback!",Beer and Data Science,8y14cl,new,8,85,85,0
"I'm looking at product margin over 3 years. According to dicky Fuller test, the time series is stationary (p<.005). Do I still need to control for seasonality and trend if running a multiple regression analysis to determine the effects of various campaigns?

Edit for clarity:

Looking to evaluate the effects of a treatment on a time series data set by comparing mutliple dependent variables to a prior time period without treatment in effect. I have various dependent variables for which I must conclude if the effects of the treatment significantly impacted those variables. Data is e-commerce based and dependent variables include sales, product margin, average order value, etc.

Questions:

1) Treatment period lasted 25 days. Dataset is composed of 4 years of data (at the day level). When controlling for seasonality and trend, should I base the trend and seasonality off of a 25 day period (because that's how long the treatment was in effect), or should they be calculated using the complete 4 years of data, while holding out the treatment dates?

2) one of the dependent variables I'm looking at is product margin, this is stationary according to dicky Fuller test. Does this mean that I should not include trend in the model and only include seasonality?

3) I'm having difficulty determining the frequency of seasonality and trend. For example, my data is daily, so I can view seasonality based on a 7 day pattern or trend based on the 7 day rolling avg in order to control for weekly fluctuations in the dependent variable. Similarly, I can extend this to 30 days for monthly fluctuations, 90 days for quarterly, 365 for yearly etc. The extracted seasonality and trend will be used as additional predictors in the model to isolate the treatment effects. I just don't know how to decide this frequency.

","If a time series is stationary according to dicky fuller test, should i still decompose? (E-commerce)",8y0wec,new,6,2,2,0
"At work, we now have close to 20 data scientists. We want to grow that number to 50 in a year, and will need to put in place a good platform for all to work together. We are moving fast, but needs to ensure reproducibility and good collaboration, and ability to deploy and maintain many models concurrently.

Most of our models are built with scikit-learn, XGBOOST/LightGBM, and Tensorflow. Data store is Cloudera Hadoop.

By ""platform"", I am thinking of common access to data, productionized feature calculation, feature quality monitoring, model version control, ongoing model performance monitoring, etc.

What are the commercial or opensource solutions people are using? In my search, I have found Domino Datalabs, Databricks, Dataiku, DataScience.com, KNIME. If you have experience using these, I would be very interested to hear about the experience, as well as which of these or other I should prioritize in my research.",Data science collaboration platform for 20-50 data scientists,8y08pd,new,25,34,34,0
,Datathon competition: develop an app using Open EU Data in 4 different challenges,8xzam5,new,0,3,3,0
"Hi all,

I've been tasked to explore any possible solution for  HMO/Healthcare Insurance companies. So far we've worked on the following:

- Causal Analysis for Increase/Decrease in Claims
- Regression models to predict Claim Amounts

Wanted to know if there are other effective use cases we can look into. Have thought about customer segmentation and risk scoring, wanted to know how these would work for this specific industry. My experience for applying this thus far has been for banks and retail companies. 

Open to any and all suggestions! 
",Use Cases for HMO/Healthcare Insurance,8xxaj3,new,6,1,1,0
,"Why preliminary data report not counted in BI and Why reporting with visuals and creating dashboards counted in BI? What are the meaning of: Preliminary Data Report, Reporting with visuals, Creating Dashboards",8xx0s5,new,1,0,0,0
"I'm working on breaking into data science with R (no related formal education, 7 years reporting/analytics experience), and would like to start building a data pipeline and interest with our org's leadership.

We are a medium size real estate development company, and I'd like to pitch that we could start building models and answering questions like which variables best explain a successful deal closing (geographic region, land size, project lead, etc.). Timeline would be to start working on projects by end of year (allows time for my education and building better data warehousing).

Am I setting impractical expectations? I'm not sure what other possibilities there are with R and DS in general, aside from the basest of explanations that it helps identify relationships between variables.",Setting proper DS expectations to executive leadership?,8xw4nn,new,2,1,1,0
"I am a first year undergraduate of Math and Physics. I am comfortable with Python, sklearn and all other remaining libraries. I am also comfortable with many machine learning techniques. I want to get an internship next summer and I would like to know 
1. What more should I learn
2. What kind of projects should I do, so that I have it on my github account.",What kind of projects should I do ?,8xvc94,new,9,1,1,0
Are there any good courses or training sessions you've been to other than the obvious AI/ML conferences?,what do you guys spend your training budgets on?,8xv4ii,new,29,51,51,0
"Data Science Advice is Broken.  
You don't become a Data Scientist by reading textbooks but by DOING.  


**Our Goal:**   
**Learn Through Practice NOT Theory**  


0 *to Data Science Will Have  2018 !Hack a Week!*

For 3 months (July 15 - September 28) 📆   
We will create 1 project a week 👷  
ANY tool is allowed: from Excel to Python 📈   


We will build weekly projects with the help of our community and  [Fernando Hidalgo](https://mc.us18.list-manage.com/pages/track/click?u=925db8bec0c0df647916cdacd&id=006b7a3713), Data Scientist at Discovery Communications.

[**Sign up here to join the community**](https://mailchi.mp/fernandodata.com/0-to-datascience-hackathon)",We Are Building 1 Project A Week,8xtw9u,new,16,15,15,0
"Hope this is an appropriate question for this sub. I just started using AWS. The console just seems really over-whelming and not super easy to use. Is it advisable to jump straight to learning how to use the the Command Line Interface ? That way I'm not blindly going through setting things to default preset values without knowing what's happening.  If anyone knows how I could approach using AWS (RDS module), I'd appreciate if you could link to courses, materials or relevant documentation.",AWS - Should I learn to use the command line interface directly,8xtusz,new,7,9,9,0
"My colleague and I are trying to figure out what the heck these categories mean on a spreadsheet (analyzing populations for health risks). The categories are set up as one would normally expect their respective **departments, last name, first name, sex, etc.**.. What has stumped us, is a category titled ""**RL**"" the fields are populated with these types of answers **MS, BC, NS, PS, E, C.** We are thinking relationship?

*Any suggestion are most welcomed!*

Happy Tuesday!","Need some help on identifying what ""RL"" means",8xtgpp,new,17,8,8,0
Is such a thing possible? Only to experienced professionals? What about fresh graduates?,Data Scientist H1b Sponsorship,8xswmu,new,7,1,1,0
"Everywhere I read, everyone says ""Build the model off the training & validation sets, then see how well it performs with the test set"". So what happens if the test set results are bad, and what if the model's performance is variable based on the data selected for the training/test set? Currently, I'm working with a data set of only 24 observations, and I'm using 5-fold cross validation to hyper-tune parameters. Depending on the seed I set (to split the data), I could get phenomenal Test set RMSE's or really bad ones. My goal is to find the best ML Algorithm and features to use building my model.

To resolve this issue, I built a loop that, given a certain ML algorithm, will take a list of feature combinations and use sampling to determine each model's mean RMSE & its standard deviation. Given the algorithm and list of features, the loop will go through 30 iterations, in which a random seed is generated (to create the training/test sets) and a model is fit to the training data using grid search. Then, the RMSE for that iteration is computed with the test data. The mean is calculated for all 30 iterations, and a table is created where you can see the Mean RMSE and SD for each combination of parameters.

I have no idea if this is a good idea, but given the lack of data I have, this is the only solution I can think of to be confident in the best model to reduce bias and variance as much as possible (analyzing the mean Test RMSE's and SD's). I just wanted to get everyone's thoughts on this procedure. For XGB Tree, the computational time is god awful, but it's fine for using Random Forests and Linear Regression.",Is This Good Practice for Model Selection?,8xrw99,new,12,2,2,0
,New article from Distill: Feature-wise transformations,8xpoqe,new,0,29,29,0
,Self Service Data Flows With Apache NiFi (Interview),8xns6g,new,0,2,2,0
,Help understanding Yifan & Yehuda's Netflix Prize paper: Collaborative Filtering for Implicit Feedback Datasets,8xmnf6,new,0,2,2,0
"Recently, I've been asked by a recruiter if I have a public presence as a data scientist when looking at new opportunities. Clarification usually leads to a discussion on whether I have a blog, active twitter, or public portfolio / open source presence. I got my present job (as Data Scientist) through a professor who took me under his wing in grad school and never had a reason to have a public presence for career purposes.

I won't deny self-marketing is useful. But I often refrain from being public about work-related matters due to most of what I do being under heavy NDA. This maybe a bit of a weak excuse since I have some old grad school projects I can share after sprucing them up a bit.

For established data scientists - does having a blog, twitter, or well kept github account really help you find new  quality opportunities? Or is it more of a headache than benefit?",Public Presence as a Data Scientist,8xk1sj,new,13,29,29,0
,Tableau Prep Vs. Altyrex--Hands-On Comparison,8xjogh,new,0,3,3,0
,"List of data science models, techniques and tools shared on Kaggle kernels.",8xjg54,new,12,200,200,0
"As the title implies, I am looking for a dataset in context of blood glucose levels if anyone has a dataset they're willing to share or point me in the right direction it would be much appreciated. Additionally if there are any datasets that have both blood sugar and other metrics such as ( sleep, meal frequency ) along those lines that would be great. The problem that is trying to be solved is abnormality detection of blood glucose levels, thank you in advance.",Looking for blood glucose data set.,8xj8ww,new,10,5,5,0
"In a manufacturing setting, a certain round, cylindrical part is to be fed into an equipment to be assembled. It's small (roughly 1cm in length, and 5mm in diameter). It's feed via a conveyor with a groove so that the axis of the part is parallel to the conveyor direction. The parts are not necessarily equally spaced.

Sometimes these parts have cracks which can cause quality defects or machine stops. It's desirable to inspect each part for cracks or fragments before feeding into the machine. Bad parts can be blown off the conveyor at a certain point.

What is the easiest way (algorithm) to inspect this using computer vision? If you can install cameras that can take photos of each part at different angles, what algorithm would you use?

Thanks",need advice on an industrial application of machine learning.,8xiewr,new,4,7,7,0
"Currently feeling Atom + Hydrogen with an IPython kernel and autocomplete-python powered by Jedi.

A friend suggests PyCharm.

Would love to hear your thoughts!",Python Data Science IDE preferences?,8xhb9k,new,28,6,6,0
"What are your strategies re: leaving in or taking out features with zero or very low importance? I could go either way – on the one hand, I like the parsimony of taking them out; on the other, since their importance values are so small, it is probably the case they aren't being used for any significant splitting and thus don't have much (if any) impact on performance.",Removing zero-importance features in a decision tree,8xggdr,new,3,3,3,0
"Sorry, if the title wasn't as clear as it could have been. But I'm looking into modelling the number of days a sow (i.e. female pig) takes from weaning her litter until being bred again. The sow's backfat (millimetres of fat on a specific area of her back) is measured using an ultrasound tool at three points: at farrowing (giving birth to the litter), at weaning (nursing off her litter) and 30 days after weaning.

For now, the backfat at farrowing (sometimes called 115-day, as the gestation period for sows is around 115 days) is the most important item to look at.

Here are some graphs I made in my initial analysis. I simply used the plot() and abline() functions in R. I fit a linear model - lm() - on the data.

[Farrowing backfat](https://i.imgur.com/vL6nwWt.gif)

The above image should give you an idea of the structure of the data. Basically, the goal is to have as many sows as possible bred within 7 days after weaning.

As you can see, for the sows bred within 7 days seem to have little relationship to farrowing backfat and form their own sort of flat group. For the sows bred more than 7 days after weaning, a trend seems to exist.

So when I fit my basic linear regression model it doesn't seem to express the data very well. So, I am looking for help in identifying other modelling techniques that might be useful for this data.

From the reading I've done, it looks like performing some data transformation or trying to fit some non-linear model to the data would be my best options. However, when looking for specific techniques, it seems difficult to me to find a direction to go in. Without a good knowledge of non-linear distributions it seems somewhat arbitrary in what model to choose. It seems to require some intuition.

So I am looking for some help in what methods/techniques to go for with this data.

**TLDR**
**Given [this](https://i.imgur.com/vL6nwWt.gif) data, can you suggest some modelling techniques more robust and applicable than my simple linear regression?** ",Advice in modelling techniques where one group of the data seems to follow different trend than another (TL;DR included),8xfwi6,new,3,1,1,0
"We’re conducting a market survey for HPC data center managers and others who make decisions about data management systems. Two focus areas for the survey - 1) Cloud v OnPrem specific to HPC work to be done and, 2) impact of hardware architecture / specs on overall performance. 

There is a lot of information about choosing cloud for biz ops and ""regular"" computing needs - not so much for HPC demands and requirements - access, security, cost, etc.

If you manage your organization's system, please consider taking the survey - as well as encouraging colleagues to do the same.

Here's the link: https://www.surveymonkey.com/r/BigDataHPC
Your consideration is much appreciated! Message me with questions.

- E Scott",HPC Market Survey,8xfmxh,new,0,2,2,0
"I'm using PCA for dimensionality reduction to simplify a machine learning model I'm working on.  It's worked great.  3 of my variables account for like 80% of the variance and I can get over 99% with only half my variables, so I can throw away like 11 of the measurements I'm taking... but how can I tell which measurements correspond to which principle components?

Specifically, I'm using sklearn.decompositions.PCA in python if that makes a difference.

I know what PCA does, but in the actual implementation, I can't seem to figure out which inputs go with which principle components.  Any ideas?",Used PCA for dimensionality reduction and found I can explain over 99% of my variance with 11 of 22 measurements... but which measurement correlates with which principle component?,8xeeja,new,15,28,28,0
I came across [this SO post](https://datascience.stackexchange.com/questions/20075/when-would-one-use-manhattan-distance-as-opposite-to-euclidean-distance) and glanced at the paper one of the answers links to and still am not quite grasping the intuition behind using Manhattan distance over Euclidean distance for high dimensional space. Why is it preferable in certain situations?,Why is Manhattan distance superior for high dimensional data?,8xdzb5,new,9,64,64,0
"I want to get the community's thoughts on this idea: assertions for expected input values. Consider the following dataset:

height|gender_male|gender_female|
--:|--:|--:|
67|1|0|
54|0|1|
50|0|1|

Where `gender` has two discrete values that have been one-hot encoded, ""male"" and ""female.""

Suppose I have an ML model I built, and I want to deploy it as a web service that processes incoming requests. The `gender` field comes from a massive upstream system, and I have no control over whether additional values for `gender` will be added in the future.

What are your thoughts on tying-in assertions to the web service in this type of scenario? Something like this, in Python:

    gender = request['gender']
    possible_gender_values = {'male', 'female'}

    assert gender in possible_gender_values, 'Unexpected value for gender, ""{}""'.format(gender)

I think there are two schools on thought on this. One would be to let error pass silently (i.e. provide a null result back to the requestor). The other would be to count the number of errors that occur in the web service and alert after a critical point that the model should probably be retrained, taking into account the new discrete levels.

Thoughts?",ML web services: thoughts on assertions for expected input values,8xbhp4,new,1,1,1,0
"I'm looking for an approach to resolve the subjective questions. 

The images below shows post services data. Here, I want to analyze the data and segment the quality team questions into different categories like unnecessary question/unrelated question/insufficient info from Engineer. 

The quality team questions the Engineering team based on their input (Engineer column,Action taken  and test column).The overall idea of this analysis is to stop the quality team questioning the Engineer/ to provide Engineering team a feedback to fill the log properly so that the issue opened is closed asap(TaT time).

Please suggest what kind of analysis I should be doing in order to achieve the end result. 

Manual read-through is tough as there are hundreds of records. 

[Sample Dataset-1](https://i.redd.it/pibh9t0u2x811.png)

[Sample Dataset-2](https://i.redd.it/2zrr3lps2x811.png)",An approach to resolve quality team subjective questionnaire,8xb99j,new,2,1,1,0
"According to [the documentation](http://reference.wolfram.com/language/) it seems like it has quite a range of modules for data science work. It also comes bundled in with a Raspberry Pi.

That said, I don't recall ever seeing it being used 'in the wild'. 

Any input on the subject?",Does anybody use the Wolfram Language for data science work?,8x97ig,new,23,8,8,0
I'm a bachelor degree student learning data science apart from my carriculum. I have an inclination towards working in the above sectors. I'm just trying to know about the domain knowledge I need and data science problems I need to gain experience in. How are the career prospects in this area?,"What are some good applications of data science in business, finance and stock trading sectors? Anyone in such a career?",8x8ybf,new,11,1,1,0
"Some optional background info:  

I'm a data scientist for an electric company. I've been working since May 2017, but have been seriously contemplating leaving for the last couple months or so. I very much enjoy the duties and core components of a data scientists work (or at least what I believe to be core components), but I don't really care for the specific work I'm doing (much was left over work from the person I took over for unexpectedly). ",Data Scientists in corporate: What was your first position like? Was it what you expected? Are you still there?,8x8huv,new,8,3,3,0
,How to Build a Data Science Portfolio,8x4x1x,new,23,251,251,0
"The [sklearn LinearRegression class](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) in Python uses ""Least Squares"" to determine our coefficients.   


This can be calculated with a little linear algebra, no gradient descent needed ([see here for math details](https://economictheoryblog.com/2015/02/19/ols_estimator/)).   


So here is my stupid question: where is our y-intercept (w\_0) coming from?   


Looking for a mathematical explanation, with proof, please. ","Another stupid math question, re: linear regression in python sklearn",8x326o,new,4,0,0,0
"Going to be a new grad and I'm currently working as a Data Engineer for a consulting company and staffed on a project with a small bank. While this bank I'm working on doesn't seem to need much more analytics besides basics visualizations in Tableau, I'm interesting in working in the Finance/Banking industry after this project.

I do plan on finishing my Masters and working towards a Data Scientist role. In the meantime, any advice on skills to learn etc that's the most beneficial to secure a job in that industry?

Any advice would be great!",Advice on Data Science in Financial/Banking industry?,8x2mvr,new,16,8,8,0
"**Weekly 'Entering & Transitioning' Thread. Questions about getting started and/or progressing towards becoming a Data Scientist go here.**

Welcome to this week's 'Entering & Transitioning' thread!

This thread is a weekly sticky post meant for any questions about getting started, studying, or transitioning into the data science field.

This includes questions around learning and transitioning such as:

* **Learning resources** (e.g., books, tutorials, videos)
* **Traditional education** (e.g., schools, degrees, electives)
* **Alternative education** (e.g., online courses, bootcamps)
* **Career questions** (e.g., resumes, applying, career prospects)
* **Elementary questions** (e.g., where to start, what next)

We encourage practicing Data Scientists to visit this thread often and sort by new.

You can find the last thread here:

[https://www.reddit.com/r/datascience/comments/8v7y88/weekly\_entering\_transitioning\_thread\_questions/](https://www.reddit.com/r/datascience/comments/8v7y88/weekly_entering_transitioning_thread_questions/)",Weekly 'Entering & Transitioning' Thread. Questions about getting started and/or progressing towards becoming a Data Scientist go here.,8x1wz1,new,142,30,30,0
"I’ve tried Google’ing the topic but most sources does not go into detail of how the actual detection is done. For example Apples Face ID, i’ve only found out that it uses ”biometric” methods, IR cameras and comparison to a users face. 

I’m interested in how the faces are actually distinguished given a bulk of information. 

Are we just creating massive NN’s and pray for them to capture features or are we using them in more sophisticated ways? 

I’d be super greatful if someone could recommend some recent papers on the subject! :) ",Question: How does modern face recognition work?,8x1bpy,new,4,4,4,0
,Using Reddit API + Python to find the most popular domains (urls) posted to a given subreddit,8wwx9i,new,1,29,29,0
"The modin project provides a concordant pandas API, while using a scalable, parallel backend. It makes pandas faster by changing just one line of code!

[https://rise.cs.berkeley.edu/blog/pandas-on-ray-early-lessons/](https://rise.cs.berkeley.edu/blog/pandas-on-ray-early-lessons/)

[https://github.com/modin-project/modin](https://github.com/modin-project/modin)",New project targeted at scaling and parallelizing pandas,8wuz7e,new,6,79,79,0
,I've made a replacement for Kevinformatics' excellent GraphTV!,8wuj5k,new,0,3,3,0
"Hi all, I'm super new to Reddit (and data science for that matter) so I'm sorry if this post is ill-placed, and please let me know if theres somewhere better to post!
I'd love to hear some ideas about what to do with data collected from a psychology practice that I work at. 
The dataset is relatively comprehensive and contains individuals' diagnoses, test scores (IQ, autism, behavioural etc.), severity, and potentially relevant demographics (birth weight/length, comorbidities, siblings, age, gender etc.).
The data is mostly numerical scores for different sections on different psychological and behavioural tests, with some categoricsl demographics and what not dispersed throughout. 
I dont work as a data scientist and I'm not sure exactly what data to collect, so I'd really appreciate some help with what you'd think would be good to look for or what data to collect. 
I'd love to chat to anyone who's interested.
If youd like to see the dataset as it exists so far, let me know:) ",Ideas wanted for analysis of Psychogy Practice Autism & ADHD Dataset,8wtitb,new,8,5,5,0
"I've had a couple of DS interviews with various companies and I always seem to be unsure about how to answer product metric/experimental design questions (AB test related). Are there any resources to help me pass these type of interview questions? 
Much appreciated. 

As an example: Suppose you want to conduct an AB test on 3 different page load speeds. What metrics would you track? What are some external factors to keep in mind? Novelty factors? ",Product Metric/Experimental Design Interview Questions,8wtfz5,new,1,1,1,0
"Given a single x feature, it is possible to calculate the parameters of our regression line deterministically by minimizing the squared error function (see also [Khan Academy tutorial on linear regression](https://www.khanacademy.org/math/statistics-probability/describing-relationships-quantitative-data/more-on-regression/v/squared-error-of-regression-line)).  


I was under the impression that most linear regression methods use an algorithm like Gradient Descent in order to find the optimal solution, and had to use iteration to get there.  


Some questions: 

1. Is it possible to deterministically find the slope and intercept of a linear regression given 2+ x features by simply minimizing the squared error across all dimensions? Specifically, I am looking for a proof that takes us through the entire optimization process, e.g. Khan Academy.   

2. According to [Andrew Ng via his Coursera](https://www.coursera.org/learn/machine-learning) on ML, there also exist forms of linear algebra that offer deterministic solutions to this. What are they? Where can I learn more about them?  

3. According to Ng, we use Gradient Descent, instead of a deterministic approach, because it is ""more efficient"" when training on larger data sets. I would like to understand this better. Can anyone point me to some benchmarking or more specific comparisons between these methods?  

4. The  [SciKit Learn Linear Regression model](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) uses Ordinary Least Squares by default, not Gradient Descent. Why? Which method do you use when training a LR model? Why? Where can I go to learn more about the math behind Ordinary Least Squares? Looking for something in-depth, e.g. Khan Academy.   


Thank you in advance. ",Please help me understand linear regression better,8wnfle,new,10,1,1,0
" I have created a pickle file using 

    joblib.dump()

I earlier used 

    pickle.dump()

but it gave me memory error so i switched to joblib. So the file was created successfully but when i try to load it using 

    joblib.load()

it gives me following error - 

    ValueError: reading array data, expected 1200 bytes got 0

so my code looks like:

    from sklearn.externals import joblib  with open('conversation.pickle', 'rb') as f:     x,y = joblib.load(f) 

The full error log:

    File ""model.py"", line 16, in <module>     vec_x, vec_y = joblib.load(f)   
    File ""C:\Users\acer_pc\AppData\Local\Programs\Python\Python36\lib\site-packages\sklearn\externals\joblib\numpy_pickle.py"", line 568, in load     
    obj = _unpickle(fobj)   
    File ""C:\Users\acer_pc\AppData\Local\Programs\Python\Python36\lib\site-packages\sklearn\externals\joblib\numpy_pickle.py"", line 508, in _unpickle     
    obj = unpickler.load()   
    File ""C:\Users\acer_pc\AppData\Local\Programs\Python\Python36\lib\pickle.py"", line 1050, in load     dispatch[key[0]](self)   
    File ""C:\Users\acer_pc\AppData\Local\Programs\Python\Python36\lib\site-packages\sklearn\externals\joblib\numpy_pickle.py"", line 341, in load_build     self.stack.append(array_wrapper.read(self))   
    File ""C:\Users\acer_pc\AppData\Local\Programs\Python\Python36\lib\site-packages\sklearn\externals\joblib\numpy_pickle.py"", line 184, in read     
    array = self.read_array(unpickler)   File ""C:\Users\acer_pc\AppData\Local\Programs\Python\Python36\lib\site-packages\sklearn\externals\joblib\numpy_pickle.py"", line 135, in read_array     
    read_size, ""array data"")   File ""C:\Users\acer_pc\AppData\Local\Programs\Python\Python36\lib\site-packages\sklearn\externals\joblib\numpy_pickle_utils.py"", line 646, in _read_bytes     
    raise ValueError(msg % (error_template, size, len(data))) 
    ValueError: EOF: reading array data, expected 1200 bytes got 0 

If you have any knowledge about this please help.","Reading pickle file using joblib gives error: ValueError: reading array data, expected 1200 bytes got 0",8wnaq6,new,5,1,1,0
"Hello everyone, I've been challenged with wikipedia [pageviews](https://dumps.wikimedia.org/other/pageviews/) analysis. For me this is the first project with such amount of data and I'm a bit lost. When I download the file from the link and unpack it, I can see that it has a table-like structure with rows looking like this:

  `1  |                 2             |3|4`

`en.m The_Beatles_in_the_United_States 2 0` 

I struggle with finding out what exactly can be found in each column. My guesses:

1. language version and additional info (.m = mobile?)
2. name of the article

The biggest  concern I have with two last columns. The last one has only ""0"" values in it and I have no idea what it represents. I'd assume then that the third one show number of views but I'm not sure.

I'd be grateful if someone could help me to understand what exactly can be found in each column or recommend some reading on this subject. Thanks!",Wikipedia pageviews analysis,8wn2yb,new,1,2,2,0
,Top 100 Data Science Skills scraped from Indeed.com 7/6/2018,8wmgu3,new,57,245,245,0
Does studying CTCI and LeetCode work just as well for both?,Data Scientist vs SWE interview differences?,8wlz8n,new,3,0,0,0
"I'm working on a project where I need to gather information about common (and cutting edge) use cases for data science/analytics in the fasion industry, particularly e-commerce. 

For example, some things I've already thought about are recommendation stystems, price elasticity, promotional forecasting, and some newer stuff being done in trend forecasting with image recognition.

But I need a lot more, with a way to justify ROI if that's possible...

I'm looking for data use cases that help answer certain questions like:

Customers:
-how to increase the number of new and existing buyers
-how to ehnace the customer experience
-how to increase basket size
-how to increase new and existing customer revenue
-how to optimize customer lifetime value
-how to enhance customer loyalty

Merchandising:
-how to determine new styles to introduce
-how to price luxury apparel
-how to reduce overstocking 

Supply chain:
-how to determine what products to stock
-how to reduce backlogging 

Marketing:
-how to reduce customer aquisiton costs
-how to create more effective campaigns
-when to start a sale
-when to end a sale
-sale optimization in general

Business:
-data use cases in HR
-data use cases in accounting and finance (eg, revenue forecasting)


Any and all help would be greatly appreciated!! ",Data Science Use Cases in Fasion e-commerce?,8wl7zs,new,4,1,1,0
"Say you’re trying to predict the total number of times a customer buys your products. Some customers buy your product once, some twice, others fifty times. They can buy different types of your product, but ultimately we’re counting counting how often they buy any product. Your hypothesis is that certain types of products being bought is predictive of how many times someone buys. How would you best incorporate the type of item someone bought without leaking information as to how many times they bought any of your products?

It makes sense to be that, if a customer buys any of your products twice, but it’s the same product both times, that you could include the fact they bought product X as a one-hot indicator. This wouldn’t be a 2: 2 mapping, which is cheating. My concern is with customers who buy twice, but buy different products. I think it would be easy for a model to learn that, in a world with product cardinality of two, their buying product X and Y at least once is predictive of their having purchased twice.

I wonder if the better route to go, given a history of visits to your store, some rows indicating the lack of any purchase, others indicating a purchase, would be to roll-up previous purchses for each product type prior to each visit and predict the likelihood, on the customer’s next visit (who knows when that could be), that they purchase again.

Any thoughts?","Predicting number of times event will occur over lifetime, given previous history of event's occurring?",8wl0ua,new,12,2,2,0
" On July 19th at the Tobacco Dock in London we’re organizing a free one day conference focussing on reproducibility and data provenance in data science.

RAPIDS 2018 (Reproducibility and Provenance in Data Science) will feature 4 talks in the morning from leading lights in the space followed by a hands-on workshop in the afternoon.

[https://dotmesh.com/blog/rapids-2018/](https://dotmesh.com/blog/rapids-2018/)",RAPIDS 2018 London - Free one day conference on reproducibility and data provenance with afternoon workshop,8wkwaq,new,0,2,2,0
,Understanding Neural Networks by embedding hidden representations,8wkqkr,new,1,2,2,0
"[https://medium.com/ravenprotocol/comparative-analysis-raven-protocol-v-s-conventional-methods-a94b795c2f8c](https://medium.com/ravenprotocol/comparative-analysis-raven-protocol-v-s-conventional-methods-a94b795c2f8c)

Coming right to the point, Deep Learning is the most advanced and still mostly uncharted form of Machine Learning that many are apprehensive of applying, owing to the simple non-availability of, wait for it… **Compute Power**.

Consider the non-availability or compute-demand that is hard to meet, of GPU resources to train a model, or a very huge requirement that requires abundant compute resources to train the models. This calls for innovative methods to perform DL training. Traditional methods involve Data and Model Parallelism, which partially quenches that demand, with distributed systems. *Raven takes both Data and Model Parallelisation approaches to form a different model of distribution.*",Comparative Analysis of Distributed Training of DNNs- Raven Framework vs Existing,8wkday,new,0,1,1,0
"Hello, 
My co-worker and I are building a multiple regression model to predict rent. Our Y input range  is the current rent of all our homes and our X range is beds, bath, sq feet, median income per zip code (2010 census), population density per square mile in a given zip code, total population per zip code, and cost per square foot given the current rent. To account for seasonality we have weighted averages for each season, Summer weighed 1.025, Winter .975, Fall .9875, Spring 1.0125 and then we create a range for any given property. 

However, I noticed an issue last night in terms of x input range. Should I even include cost per square foot if I am trying to predict rent? I previously did not do so because we are trying to predict the rent. However, when we attempted to run the regression without cost per square foot our rent estimates they were off by a few hundred dollars when we checked them out to the current rent we have on them. We were testing the model to what rent we already have on the homes. But when we included cost per square foot in the next regression test the rent estimates came out much more accurate than before. 

Im sure someone may mention you may want to include school ratings and crime, but I was unable to locate a spreadsheet that had a crime index matched with zip code and the same goes for average school ratings in a zip code. 
",Am I running this multiple regression test correctly to predict rent? (Real Estate),8wjwih,new,10,1,1,0
,Play Your Charts Right | An Illustrated Collection of Mistakes People Often Make When Visualizing Data,8wj1nr,new,34,320,320,0
,Updates to the XGBoost GPU algorithms,8wilhb,new,2,28,28,0
"I have a background in software engineering and recently made a move to a very data-focused company. My work is in Python mostly and deals with parsing huge datasets but barely involves much stuff like Pandas etc. I would like to learn more about data visualisation using it. I registered on Kaggle and used Plotly to play with datasets but I struggle to come up with a larger project idea. Any help with that, please?",Struggling to find projects to work on,8whz23,new,10,2,2,0
,Infographic in SSRS,8wh8ou,new,0,5,5,0
Hi I'm studying data science in my undergrad and am buying a new computer which will probably be a dell xps. I was wondering if 8gb of ram will be enough. We mostly run r and python with datasets around 1000 data points.  Thanks,How much ram do I need in undergrad?,8wgyhm,new,13,0,0,0
"I have the following structure right now which allows me to display my simple app on my local machine (Dash local URL).

1. Scrapy - scrape data from web (running locally)
1. Store scraped json data in a few PostgreSQL tables (hosted locally)
1. Use dash to render my application using that data (delivered locally)

As web development is totally not my forte, I'm now having a hard time even knowing what tools to use to get it online. I've looked at Heroku to deploy the app, but I'm having a hard time understanding what I need to do to arrive at a finished product.

My ideal finished product would run items 1 and 2 above each night in order to update the data available in item 3. I'm ok spending up to ~$30/month right now on hosting/storage etc if need be. I have <500MB of data in my db, my largest table is around 20k rows of data.",How to set up backend for a simple web hosted data tool,8wgoqv,new,3,5,5,0
"Hi everyone, I'm just starting out in a Data Science career.  I'm finally moving up form ""generic Business Analyst"" to ""Data Analyst"" which involves a bit more rigor and a glimpse at the more advanced parts of Data Science and Machine Learning.  Looking at career progression, it seems that the big employers in this area in the US are the big internet tech companies (Facebook, Google, Amazon, Twitter, etc) on the west coast and government agencies (NSA, NGA, NRO, DOD, etc) on the east coast.  To my (admittedly naive) eyes that leaves me with two major careers paths: helping companies get people to click things on the internet, or helping the government 'fight terrorism'.  
  Since I'm not particularly interested in either of those paths, I was wondering what other career paths are out there.  Are there any big employers or sectors hiring analysts and Data Scientists that are doing more than getting users to click more or buy more stuff? Anything with a more obvious benefit to society at large? 

Thanks
",Data Science for Good?,8wfzyl,new,33,70,70,0
,(X-Post from /r/MachineLearning) Analysis of the Relationship between U.S. Congressmen’s Tweets and Their Political Party,8wfhe5,new,3,0,0,0
"Udemy has one of their sales going on and I'd like to get an R course so I can scrape web data. However, as I'm ignorant, I'm not sure I'm asking the right question .A lot of the data mining on udemy seems geared to a specific platform, eg, Twitter or Facebook.

I'm looking to grab game data from nhl.com, which would require basic web scraping knowledge... Any idea of what words beyond data mining I should be looking for?

Apologies for the semi coherent begging.

",Grabbing Web Data in R,8wefdj,new,12,3,3,0
