selftext,title,id,sorted_by
"**This is the question I'm stuck on.**

I understand how to use the rest of the functions, but I don't understand how to use \^2. I keep getting errors.

Using the functions sqrt(), sum(), \^2, length(), and mean(), but not var() or sd(), calculate the sample standard deviation median value of owner-occupied homes in $1000’s. Report the R code and number to two digits.

Also, do you think I'm supposed to run them all at once? Does that make a difference? (I'm one day into RProgramming.) I have them set as so:

    sqrt(housing\_df$MEDV); sum(housing\_df$MEDV); \^2(housing\_df$MEDV); length(housing\_df$MEDV); mean(housing\_df$MEDV)

Thanks! :)",What is the ^2 function?,9d0d2w,new
"When indexing into something, how do you know when to use `[[index]]` vs `[index]`?

I'm a bit confused by the difference, since there isn't really a programming language equivalent of this type of operator. I think `[index]` means ""return a list of results"" whereas `[[index]]` means ""return one result"", but I'm not sure.",Beginner question involving `[[ ]]` vs `[ ]`,9cwrza,new
"I have a dataset in which one column represents monthly Date:from 02/01/2004 to 09/01/2008, i have to create a dummy for the Dates in 2008. I tried to use:

\*\*dummy <- as.numeric(Date >= 01/01/2008)\*\*,

but R said me that: ""\*\*>= is not meaningful for factors\*\*"", hence i tried to transform the factor variable Date in a numeric one, but all my Dates disappeared, substituted with some random numbers.

I am a noob using R, hope somebody can help me.

Thanks to all",Dummy for time series in R,9ctvxd,new
"So, I've been using R for a few days now.

​

Here's my code:

​

salario<-c(25,35,40,45,55,65,85)

​

homens<-c(3145,2465,4675,11220,9180,8160,3655)

​

mulheres<-c(2664,2640,2196,2808,996,516,180)

​

tabela<-data.frame(Salario = salario, Homens = homens, Mulheres = mulheres)  (it's working so far)

​

barplot(mulheres,salario)

​

[The \\""salario\\"" variable isn't showing in X](https://i.redd.it/iebb9q9t05k11.png)

​

​

i'd like to have the x axis label of each bar to be \[25,35), \[35,40) etc (those ""salario"" values).

how can i do that?

thanks!

also, sorry for my bad english!!",Beginner question on graphs.,9crv29,new
"I'm working through a survey I made. For several of the columns I've got TRUE/FALSE questions and have been using for example 

student<-as.logical(student) 

to convert them one by one, is there a faster way to do this where I don't have to work through the inputs one by one? 

Note: only about half the questions are T or F questions (about 50 of them) 

Please help","""x<-as.logical(x)"" for multiple variables",9cqj82,new
"Hey everyone, I'm a grad worker that is converting some econometric problem sets/answer keys from Stata to R. Stata allows you to save the output in its own separate file (including plots), which can then easily be printed and turned in by the students. 

Basically I'm really hoping to be able to find some way for all of the output that shows up in RStudio's console to be exported into a file that can be saved separately and printed. If there is a way to include the graphs into that file as well, that would be nice but it isn't crucial. 

Note: The scripts are simple (summary statistics, creating new variables, and running regressions); the most complicated output is basic plots.

Thank you!",Creating an output file for a script in R.,9cohof,new
"I have to make many individual API calls by replacing one set of numbers in the API URL. 

But the GET request only allows for a ""length of 1"". Any ideas?",GET function for many URLs.,9cm80h,new
"Who can help me through this excercize?

&#x200B;

 

>This exercise is somewhat more challenging. We are going to repeat the previous exercise but this time order my\_df  
 so that the states are ordered from least populous to most.  
>  
>INSTRUCTIONS  
>  
>Create variables states  
 and ranks  
 to store the state names and ranks by population size respectively.  
>  
>Create an object ind  
 that stores the indexes needed to order the population values, using the order  
 command. For example we could define o <- order(murders$population)  
>  
>Create a data frame with both variables following the correct order. Use the bracket operator \[  
 to re-order each column in the data frame. For example, states\[o\]  
 orders the abbreviations based by population size.  
>  
>The columns of the data frame must be in the specific order: state, rate

The excersize needs the dslab package about murders in the US. it has $state (names of all 51 states), #abb (abbreviation), #region (factor with 4 levels, northeast, south....), #population (obvious) and #total (amount of murders in the state)

Here is what I got. 

>\# Define a variable states to be the state names from the murders data frame  
>  
>states <- murders$state   
>  
>  
>  
>\# Define a variable ranks to determine the population size ranks   
>  
>ranks <- rank(murders$population)  
>  
>ranks  
>  
>  
>  
>\# Define a variable ind to store the indexes needed to order the population values  
>  
>  
>  
>\# Create a data frame my\_df with the state name and its rank and ordered from least populous to most   
>  
>my\_df <- data.frame(states,ind)

&#x200B;

I've got no idea what they mean with ""Define a variable ind to store the indexes needed to order the population values"", and what to do next. I do know I need to use the ""order"" code.

&#x200B;

Any ideas? The difference between the three seems to be very small.","Beginner question: sort, order and ranks",9cdou6,new
"I'm running a meta-analysis for risk differences using the metafor package in R. When I plot the figure using forestplot, the risk difference is presented in the right column as a decimal. Does anyone know a way to change this into a percentage (ie, the first row -0.011 \[-0.052 to 0.030\] would become -1.1 \[-5.2 to 3.0\])?

[https://imgur.com/a/AXE2YaE](https://imgur.com/a/AXE2YaE)

&#x200B;

Edit: added link!",How to get forestplot to show risk difference as a percentage?,9cape6,new
"Ugh. I haven't programmed in a while. 

If I have a some vector

     myVec<-c(""Apple"",""Banana"",""Cantaloupe"")

What's the best way to create three empty vectors with the names apple, banana, and cantaloupe",Create a new vector for every element in a vector,9c8lob,new
[https://cran.r-project.org/web/packages/GGIR/GGIR.pdf](https://cran.r-project.org/web/packages/GGIR/GGIR.pdf),Anyone familiar with the GGIR package in R? Any tutorials?,9c7uoa,new
"I'm trying to run a model for a nonlinear regression. Specifically, I have a change in an x-parameter that induces a change in a y-parameter. I'd like to generate a model with a fit line so I can fill in the gas between the known x-variables to predict the resulting y-variable. I have the starting point, so I don't need to estimate it using a self start. 

I've been messing around with the NLS() function, but embarrassingly enough I'm not sure how to build my model. 
If anyone knows of a tutorial for building a nonlinear regression model for a known data set that would be awesome! ",Help Needed: Equation for Nonlinear Regression,9c5ru4,new
"I'm using this code to plot points and paths from two different datasets:  

`ggplot(data=XYZ, aes(x=XYZ$X, y=XYZ$Z, label=XYZ$SysName)) + geom_point() + geom_text_repel(size=2.5) + geom_path(data=gates, aes(x=gates$X, y=gates$Z, group=gates$inSystem_outSystem))`  

I get this error though: `Error: Aesthetics must be either length 1 or the same as the data (27588): x, y, group, label`  

I'm not sure how to tell R that it is supposed to label the points and not the paths. There's no label aesthetic for geom_point, so I don't know how to specify the labeling be only for the points?",ggplot error when labeling points in 2-dataset plot,9c0xaq,new
"Whenever I specify columns etc like c(""Age"",  ""Weight""), ....... it's a bit slow.

I've seen this done before on a Udemy video but am unsure how to do it. Anyone know?

&#x200B;","Shortcut for inside apostrophes to comma? Example: ""from in here"" -> , to here",9bz6kz,new
"I am looking to have a script create files in a directory and then zip them up afterwards. I have been trying to use 'zip' from the 'utils' package, but I seem to be messing something up, even though I seem to be using the right syntax.

so, I would set the working directory to the location where I want to save the zip folder, which is the same location as the individual files.

&#x200B;

Just as practice, I would do one file: 

zip(""[test.zip](https://test.zip)"",""test1.txt"")

if i wanted to do two files, I believe I need to do:

filestozip<-c(""test1.txt"",""test2.txt"")

zip(""[test.zip](https://test.zip)"",filestozip)

You can view the function at ?zip

Let me know if you can help, or if my understanding is wrong. Thanks a bunch!",How to zip up files,9bykl6,new
"I was reading up on this function on the [Tidyverse reference](https://dplyr.tidyverse.org/reference/all_equal.html#examples) and the example the documentation gives for the behaviour of the `convert` parameter is unclear. Both examples evaluate to `TRUE` so it offers no insight into why the parameter is needed since it appears that the function converts similar classes even when the parameter is on its default of `FALSE`. 

&#x200B;

Does someone have an example of where setting `convert = TRUE` gives a different evaluation to the default?",What does the convert parameter of dplyr's all_equal() actually do?,9bx195,new
"I'm creating dataframes for each student using our online course website. We have 375 students. 

I have a data mining and wrangling script that starts with a GET request to a website. That request is for a single user because the API only allows certain data to be collected individually. By the end of the script, the student gets a dataframe object that is named after their username.   

But I can't imagine doing this for each and every user!

Do any of you fine people know some fundamental strategies on how to automate the creation of each script?",Automate data wrangling... specifically the assigning of objects.,9bwiby,new
"Hi R'ers,

First time poster and 2-months-old R user!

I have a dataset that records **subject number**, **dose in mg**, and **time**, plus things I don't need. I need to calculate **dose over time,** with the results stored as an array.

I can post the code I'm using, but I am not sure about how efficient that whole train of thought is. I hope it's ok to leave this question open for ideas as I suspect this is probably pretty simple. (also, the code is in a virtual machine environment that's impossible to copy paste from).

Thanks!

​**Edit1:** There is actually more to the matter. I need to calculate dose over time, *but each subject may have any number of visits* (when dose is measured and the day of the visit counting from baseline is recorded).

**Edit2:** The following table is representative of the data I want to use.

|subject\_id|dose|day|
|:-|:-|:-|
|subject1|25 mg|7|
|subject2|25 mg|7|
|subject2|37.5 mg|49|
|subject3|25 mg|7|
|subject3|37.5 mg|49|
|subject3|50 mg|98|

​

​

​","How to work (sum, max, min...) with values that were recorded with their units of measurement?",9buagx,new
"If I create a map (using Leaflet or some other package) and place markers, is there a way to shade the map according to which marker or class of markers is closest?  For example, I show every McDonald's restaurant (in red) and every Subway restaurant (in blue).  Can I display the polygons around each restaurant that show which area is closer to a McDonald's and which area is closer to a Subway?",Shade a map in R based on proximity?,9bu4h5,new
"I have some points plotted via geom_point, but I'm wondering if I have a two column list of line segments I need to add by point (e.g. column 1 is departure city and column 2 is arrival city), can I add that with native ggplot2 somehow or will I end up needing another library like ggnetwork?",geom_segment functionality in ggplot2?,9br4yr,new
"I've been trying to figure out how to change all the character values in one column in a data set from an ""A"" to a 4 as per the assignment given by our instructor using this line

\>biosub$grade\[biosub$grade==""A""\]=4

I got this to work exactly one time, but every other time I try it returns this error message:

\>Warning message:

In \`\[<-.factor\`(\`\*tmp\*\`, biosub$grade == ""A"", value = c(4L, NA,  :

  invalid factor level, NA generated

And, like it says, it replaces the ""A"" with an ""NA"" instead.

Any ideas?",How to change character values to numerical values in one column in a data matrix?,9bq9xh,new
"Hi!

I am building an rfid time tracking software for our local sports club.

I want to capture data as fast as possible so I just pipe everything to a textfile. Since the reader reads the chip multiple times, and I don't wish to have the code constantly checking if a chip has recently been read, I get a long text file of times and chip ID:s. Something like this:

    ​1927;S6181E
    1973;S6181E
    2053;S6181E
    12548;S6181E
    12612;S6181E
    12692;S6181E

The first three rows are all from the first time the chip passes the reader, and the last three are the second time the chip passes the reader.

Can I, in R (or perhaps Excel), filter out so I only keep the first entry and remove all that comes within 10 seconds from it. And do this for each group.

If not, I guess I can write code in python or something to filter this out, but I see this as an opportunity to start learning some R.

Thanks!",Removing all but one record within a certain time frame,9bd5hk,new
"I'm using dbplyr to push work into the database, rather than having my computer churn on it here.  But I am trying to get a weekdays calculation.  I know that certain things are dbplyr aware (i.e. they will be converted to a sql statement) and others are not.  I am guessing that ""weekdays"" is not a dbplyr aware command.  I was trying to add a ""%>% mutate(WEEK_DAY = weekdays(TIME_KEY))"" to a command, and it doesn't translate right.  Does anyone on this sub have familiarity with dbplyr to that level that they could help me send this over?  If not, I can collect the data and do the weekdays local, but it is 6+ gigs of data once collected.",probing for DBPLYR familiarity,9bbdax,new
"I  have two time  series,  they  respectivley describe    the  performances  of   a tennis  player, in  two separate  matches.

I want to merge the time series  togheter  and  get   a unique time  serie  which  describe the best the performance of the tennis player. 

Should  I run a regression fit  line, or  there  is another method to  merge  both time series  togheter?  Which are the methods  that I can use?

Thank you.",How to merge two time series?,9b1dud,new
"Hello R Programmer, Newbies here i want to learn about R but my background is Networking. I dont know much about coding and algorithm. Today i started with installation of R and R studio and run some basic program about adding, variables and vectors. A friend of mine said the future is Data science and AI.

Please advise me how to move forward? Any resources? What kind of projects will done in R?
",Want to learn about R,9az4t5,new
"Here is a reproducible example
library(ggplot2)
library(scales)
a <- rnorm(1000,0,1)
colnames(a) <- c(“test”)
ggplot(a,aes(test)) + geom_histogram(aes(y=(..count..)/sum(..count..))) + scale_y_continuous(labels=scales::percent) +
stat_function(fun=“dnorm”)

As you will see the distribution hits 40% instead of 4
My real numbers are around the same as rnorm. I do use the number’s mean and sd as args in stat function(the values are close to mean 0 as 1) and the distribution is way off

For other values were the mean and sd were higher (eg mean 4 sd 5) the distribution looked more normal",How to plot normal of histrogram with y as percentage,9au2m0,new
"I have a dataframe that look something like this,

    df 
    month year ID   location pin  amount
    1     12   xx1  1        1    123
    2     12   xx1  1        1    456
    3     12   xx1  1        1    789
    1     12   xx2  1        2    10123
    ...    

The data goes on for monthly amount from 2012to 2018for 5 locations and 6 pins and some 500 IDs. plotting amount against dates shows a variation of amounts across different months but similar, steady increase throughout the year. So, I am trying to get a linear regression model training sample representative enough to get a good R^2 value for one pin in a one location, so using month and year as variable. So I added a date column into df; and basically what I am looking into is this:

    training <- df[df$date >= ""2012-01-01"" & df$date <=""2017-12-01"", ]
    lm.fit <- lm(amount ~ month.sequence, data = subset(training, location == 1 & pin== 1))


but R^2 is not beyond 0.35. Any idea what is a good practice into choosing a sample size for linear regression model training dataset?
",Representative testing data for linear regression,9atxs6,new
"So, I have a data frame:

       state sex  diag death status T.categ age
    1   NSW   M 10905 11081      D      hs  35
    2   NSW   M 11029 11096      A      hs  53
    3   NSW   M  9551  9983      D      hs  42
    4   NSW   M  9577  9654      A    haem  44
    5   NSW   M 10015 10290      D      hs  39
    6   NSW   M  9971 10344      D      hs  36

Let's say I want to find what percentage of the men have status D. I did it manually by just storing the number of men with that status and the number of all men in another variable but wondered if there was a more natural way to do ir.",How to get the percentage of a subset of a data frame?,9ar2em,new
"Is there any packages or way I can speed up Neural Network training than just using the base NeuralNet?

&#x200B;

My training size is only 1500 observations with \~24 predictors (5 continuous and 19 binary) however I have a lot of these to run.  Any suggestions to anything better than NeuralNet?",Faster Neural Networks than NeuralNet,9apn9g,new
"Hi folks, 

I'm working on a CV in RMarkdown and I would like my sections to reflect the following format (attached picture).   


My code is as follows:

    # Education
    \noindent\makebox[\linewidth]{\rule{16.5cm}{0.4pt}}

This adds a line break between the word ""Education"" and the horizontal line.   


How can I eliminate the line break?

https://i.redd.it/319yya90ghi11.png",Eliminate the space (line break?) above horizontal line?,9aid2g,new
"Hi, sorry  could you help me  to write this simple thing   in R?

I  have   as hobby  the tennis  matches analisis  and  I  want to  get the correlation and  the  causes between  winning  matches  and  losing  matches  for a  given tennis player.  

&#x200B;

What  do you suggest me?

&#x200B;

I  was  thinking to make a  linear / non linear  regression,  but first  let's  start  with somenthing simple:  Let's  suppose  I  want to  start  out analizing  the  number (the percentage)  of first   points made  at service  by a tennis player  (X)  and  the number of  winning  matches :

X=  30%   Yw=    20

&#x200B;

X = 10%   Yl=   40

&#x200B;

This  is  an  example, where  Yw  are the matches won and   the Yl  are the matches lost.   

&#x200B;

With  a  30%  of  first point made  at service  the tennis  player  won 20 matches,  with 10%  he  won the 40% of  the matches

&#x200B;

What   can we assume?  The  first  point% is  not relevant  and  it is inverse correlated to the number of matches won,  but how  to  find if this   is a  statistical significant  result?   Do  I need  to make a  Z-test?

&#x200B;

ALso  how  doI find  if  the relationship is  linear  /  non linear?

&#x200B;

Thank you

&#x200B;",R and correlations,9adz7j,new
"I have XYZ coordinates for spatial objects and an edgelist for which objects 'connect' to each other. The coordinates are measured in meters, but the overall area is light years in size. (e.g. one object's XYZ coordinates are -88510792599980600, 42369443966878900, -44513525346479700).  

I've tried mapping them in ArcGIS and QGIS with little success for a few reasons: both had labeling issues; I couldn't figure out a good scale for symbology; they require a coordinate reference system that is Earth-based (my objects are measured in XYZ meter distance from a point in space, there is no projection to account for).  

My question is if I can 'map' these in R but calculate a scale for doing so where neither the dots representing each object nor the labels for each object overlap each other or the connections between them (from the edgelist of connections)?  

Size isn't a big issue but the final proportions for printing should end up being around 3ftx4ft with all the labels being legible at like an 8pt sans serif font.",Plotting/mapping space objects?,9a8ghh,new
"I have a shiny app that uses a fairly long function that periodically prints updates to the console. I would like to renderPrint() these to a shiny window so the user knows that work is still being done. I have been able to get this system to work on macOS High Sierra 10.13.6 and shinyapps.io as expected. 

But, when trying to run this on my Mint Linux or Ubuntu 18.04 Shiny Server, the logging does not update in real-time, instead printing all at once after the function call is complete. My thoughts are that this is an OS issue with file locking because multiple processes are accessing one temp file, but it is also my understanding that shinyapps.io uses Ubuntu so I do not know if there is a permission setting I can change to allow this app to work as expected.

I don't know a ton about Unix file permissions and file locking so if someone has any suggestions they would be greatly appreciated, thanks!

edit: It appears after some more looking that this only works with `plan(multicore)`

Below is a minimum working example confirmed working on macOS High Sierra 10.13.6 and shinyapps.io:

ui.R

    library(shiny)
    
    fluidPage(
      mainPanel(
        actionButton(""run"", ""Run""),
        div(id=""outDiv"", verbatimTextOutput(""consoletext"")),
        tags$head(tags$style(""#outDiv{overflow-y:scroll; max-height: 100px;}"")),
        tags$script(
          '
          Shiny.addCustomMessageHandler(""scrollCallback"",
          function(color) {
          var objDiv = document.getElementById(""outDiv"");
          objDiv.scrollTop = objDiv.scrollHeight;
          }
          );'
        )
        
        )
    )

server.R

    library(shiny)
    library(future)
    library(promises)
    library(rprintf)
    plan(multiprocess)
    library(Rcpp)
    sourceCpp(""test.cpp"")
    
    tmpfile <- tempfile()
    
    function(input, output, session) {
      observeEvent(input$run, {
        sink(tmpfile, type=c(""output"", ""message""), append=FALSE)
        future({
          test()
           }) %...>% 
          (function(x) {
            print(""Complete"")
          })
        sink()
      })
     
      log <- reactiveFileReader(50, session=session, tmpfile, read.delim, sep=""\n"")
      output$consoletext <- renderPrint({
        try(
            suppressWarnings(print(log())), silent=TRUE)
        
        session$sendCustomMessage(type = ""scrollCallback"", 1)
      })
    }

test.cpp

    #include <Rcpp.h>
    #include <unistd.h>
    using namespace Rcpp;
    
    // [[Rcpp::export]]
    void test()
    {
      for (int i=0; i<5; i++) {
        Rprintf(""Step: %i\n"", i);
        usleep(3000000);
      }
    }

sessionInfo()

    R version 3.4.4 (2018-03-15)
    Platform: x86_64-apple-darwin15.6.0 (64-bit)
    Running under: macOS High Sierra 10.13.6
    
    Matrix products: default
    BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
    LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib
    
    locale:
    [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
    
    attached base packages:
    [1] stats     graphics  grDevices utils     datasets  methods   base     
    
    other attached packages:
    [1] Rcpp_0.12.17   rprintf_0.2.1  promises_1.0.1 future_1.8.1   shiny_1.1.0   
    
    loaded via a namespace (and not attached):
     [1] codetools_0.2-15 listenv_0.7.0    digest_0.6.15    later_0.7.2      mime_0.5         R6_2.2.2        
     [7] xtable_1.8-2     jsonlite_1.5     magrittr_1.5     rlang_0.2.1      stringi_1.2.2    tools_3.4.4     
    [13] parallel_3.4.4   httpuv_1.4.3     rsconnect_0.8.8  compiler_3.4.4   globals_0.11.0   htmltools_0.3.6 ",[Shiny] Capturing Future Rprintf() calls and displaying them in Shiny verbatimTextOutput,99zz7q,new
"So, I use both R and Python at work.

&#x200B;

I notice anaconda allows you to install both rstudio and spyder.

&#x200B;

Is there any disadvantage in using anacando to run rstudio vs downloading rstudio by itself?",Anaconda R studioq,99zpgg,new
"A while back I made a post asking about a cheat sheet for R Shiny (under a different account) and while I did not get that, I given some great advice on how edit my Shiny programs using CSS without actually learning CSS. It's actually a very easy concept and doesn't take much additional coding at all.

I decided to create a small tutorial/cheatsheet to help anyone else that wants it. It includes images and gifs to help you get started. Then it has a handful of examples you can use and a small template to quickly edit your progams.

​

[Here](https://github.com/thomaskellough/Personal-Projects/tree/master/shiny-css-cheatsheet) is a link to my Github with it! Let me know if you have any questions.","""Cheat Sheet/Guide"" for CSS to Shiny",99zkmy,new
"First of all, if this is not allowed the please delete this post or let me know and I'll delete it.

I just recently finished my first R Shiny project and I'd love some advice on how I can make it better. This is my first major R project, having come from doing a few Python projects. I'd love any kind of advice on the code style/format, how I can improve the code to make it run smoother, making the app prettier, features I should add/remove, or really just anything I haven't thought of. My degree is in Biology so I may be lacking on the programming, design, and statistics side of things. But I want to get better.​

This project is a student grade analyzer specific to the school I will doing my apprentice teaching at start on Monday. I don't know if I'll be able to use it during my apprenticeship, but when I eventually get my own classroom I plan to use it and share it with any other teachers that want to use it as well. My Github for the project is [here](https://github.com/thomaskellough/Personal-Projects/tree/master/grades-analyzer). I'll also take advice on how I set up my Github if anyone wants to offer anything. [https://tkellough.shinyapps.io/grades/](https://tkellough.shinyapps.io/grades/) is a direct link to my project, but you will need a CSV/Excel file to run it (I've included some in the Github).

​

Thank you in advance!",Would someone be willing to review my code and give me advice/suggestions? RShiny Project,99zbzl,new
"So, my goal here is to create an Shiny application which takes user's input, changes it into a matrix, then uses a pre-saved Keras model (basically saved weights) to predict a certain variable of his (and prints it). I am new to Keras and Shiny, so I'd appreciate any help.

    server <- function(input, output) {
      hisdata <- matrix(cbind(input$VK_001, input$VK_002, input$VK_003, input$VK_004,input$VK_005,input$VK_006,input$VK_006, input$VK_007, input$VK_008, input$VK_009,input$VK_010,input$VK_011, input$VK_012, input$VK_013,input$VK_015, input$VK_017, input$VK_018, input$VK_021, input$VK_022, input$VK_024, input$VK_025, input$VK_027, input$VK_028, input$VK_030, input$VK_031, input$VK_033, input$VK_034, input$VK_036, input$VK_037, input$VK_039, input$VK_040, input$VK_041))
      test_data <- hisdata
      model <- load_model_hdf5(""my_model_bft_003.h5"")
      test_predictions <- model %>% predict(test_data)
      output$oid1 <- renderPrint({x <- test_predictions[ , 1]
      print(x)
      })
    }
    ui <- fluidPage(
      
      # App title ----
      titlePanel(""Shiny + KEras!""),
      
      # Sidebar layout with input and output definitions ----
      sidebarLayout(
        
        # Sidebar panel for inputs ----
        sidebarPanel(
          
          # Input: numeric----
          
          numericInput(""VK_001"", ""Value:"", 10, min = 1),
          numericInput(""VK_002"", ""Value:"", 10, min = 1),
          numericInput(""VK_003"", ""Value:"", 10, min = 1),
          numericInput(""VK_004"", ""Value:"", 10, min = 1),
          numericInput(""VK_005"", ""Value:"", 10, min = 1),
          numericInput(""VK_006"", ""Value:"", 10, min = 1),
          numericInput(""VK_007"", ""Value:"", 10, min = 1),
          numericInput(""VK_008"", ""Value:"", 10, min = 1),
          numericInput(""VK_009"", ""Value:"", 10, min = 1),
          numericInput(""VK_010"", ""Value:"", 10, min = 1),
          numericInput(""VK_011"", ""Value:"", 10, min = 1),
          numericInput(""VK_012"", ""Value:"", 10, min = 1),
          numericInput(""VK_013"", ""Value:"", 10, min = 1),
          numericInput(""VK_015"", ""Value:"", 10, min = 1),
          numericInput(""VK_017"", ""Value:"", 10, min = 1),
          numericInput(""VK_018"", ""Value:"", 10, min = 1),
          numericInput(""VK_021"", ""Value:"", 10, min = 1),
          numericInput(""VK_022"", ""Value:"", 10, min = 1),
          numericInput(""VK_024"", ""Value:"", 10, min = 1),
          numericInput(""VK_025"", ""Value:"", 10, min = 1),
          numericInput(""VK_027"", ""Value:"", 10, min = 1),
          numericInput(""VK_028"", ""Value:"", 10, min = 1),
          numericInput(""VK_030"", ""Value:"", 10, min = 1),
          numericInput(""VK_031"", ""Value:"", 10, min = 1),
          numericInput(""VK_033"", ""Value:"", 10, min = 1),
          numericInput(""VK_034"", ""Value:"", 10, min = 1),
          numericInput(""VK_036"", ""Value:"", 10, min = 1),
          numericInput(""VK_037"", ""Value:"", 10, min = 1),
          numericInput(""VK_039"", ""Value:"", 10, min = 1),
          numericInput(""VK_040"", ""Value:"", 10, min = 1),
          numericInput(""VK_041"", ""Value:"", 10, min = 1)
        ),
      
      # Main panel for displaying outputs ----
      mainPanel(
        h4('Predicted values'),
        verbatimTextOutput(""oid1""))
        
      )
    )
    shinyApp(ui = ui, server = server)

​",Using Keras with shiny,99z53v,new
"Does somebody have experience, knowlande or sources which can be useful in building cryptocurrency exchange platform?",How to Build a Cryptocurrency Exchange?,99o73r,new
"Hello there! I want to simulate queue (M/M/1, M/M/C etc etc.) with poisson distribution, mean arrival/service rate. 

I have been told that R-programming is very good for this. I have have very low experience with this, so I would be quite happy if somebody could help me getting started with code, and get some results out. 

&#x200B;

Could somebody please help and assist me? :)",Queueing simulation in R-programming,99munj,new
"Hi all, am new to R and I've been working on RMarkdown though I struggle to understand the difference between this and a notebook or script. Some enlightenment here would be helpful.

Additionally, I'm unsure why the 'Preview' button only shows up sometimes and other times, it's replaced by the Knit button. They produce the same(?) results but could anyone help explain why this 'Preview' button isn't there some times?

Edit: As for the preview button thing -> it only appear when your output is a notebook!",Knit vs Preview,99kb86,new
"Hi everyone,

​

How do I do this in R.

​

Need to find what model best fits this data. Most likely a exponential model. It is S curve project cost estimation data. Y is the percentages and X is the months.

​

​

Y: 0.9	0.9	1	1.05	1.15	1.25	1.4	1.65	1.8	1.95	2.15	2.35	2.55	2.75	3	3.25	3.5	3.75	4	4.25	4.55	4.85	4.95	4.8	4.7	4.55	4.35	4.05	3.65	3.25	2.85	2.5	2.15	1.8	1.4	1

​

X : 1	2	3	4	5	6	7	8	9	10	11	12	13	14	15	16	17	18	19	20	21	22	23	24	25	26	27	28	29	30	31	32	33	34	35	36

​

https://i.redd.it/lmczu6x8vxh11.png",Looking for S curve model,99a8fd,new
"I am trying the predict revenue of a firm. I ran a regression on a few variables giving me :

    Returns = 239216.9 + 10705*X1 + 23.3183* X2 - .7468334*X3

Variable X3 is a one period lagged return variable. I would like to simulate two quarters out and was wondering how one would do that in R. Any help would be appreciated. Essentially I want to take the returns generated from the first simulation and then run one more...

​",Two stage simulation,999rkr,new
"I'm an absolute noob with regards to R and even though I've taken two classes on it, I can't make heads or tails of it. I'm not even convinced that the title makes sense. Doesn't help that I'm really struggling with even the simplest concepts of statistics. However, it's not an unwillingness to learn.

For a small project I'm doing right now (in historical linguistics), I have two columns I'd like to use. One is called ""Gender"" and one is called ""Language"".

""Gender"" has the possible values ""yes"", ""no"", ""unclear"", ""ungendered""

""Language"" has the possible values ""English"" and ""French"".

What I would like to is to get a table where I can see how many entries ""English"" has for each value of ""Gender"" and how many entries ""French"" has for every value of ""Gender"". 

I'll try to illustrate what I mean in a quick mock up table.

|*#*|*Entry*|*Gender*|*Language*|
|:-|:-|:-|:-|
|1|of þis boc|yes|English|
|2|and eft iþet ilke luue boc |yes|English|
|3|þene nexte sunendei |no|English|
|4|iðe deofles kurt|ungendered|English|
|5|þeos riwle is imaked|no|French|
|6|þis manere |yes|French|
|7|his spuse|unclear|French|

The result I'm hoping for would look something like this, even though a list would be fine as well, of course.

||*English*|*French*|
|:-|:-|:-|
|*yes*|2|1|
|*no*|1|1|
|*unclear*|0|1|
|*ungendered*|1|0|

I know some Python, so if I'd have to write a loop that would be fine, but R is somewhat confusing me and I can't figure out where to start.

Any help would be greatly appreciated!",ELI5: Counting instances of string combinations,9923uq,new
"I'm not sure if something like this exists, but I've been googling and can't really find anything.

I'm not good at all with CSS. I've been learning R Shiny recently and I want to stylize my UI. I went through a bunch of bootstrap themes that you can download and use as a source file, but I still want the option to edit specific things. I don't mind going through the bootstrap.css file and changing the colors/size of things as needed, but I'm actually having a hardtime understanding what is what.

Is there a cheat sheet somewhere that shows a widget/label or whatever in R Shiny and then says what it's called in the CSS file?  Or is there an easier way to stylize with having zero styling experience? 

Thanks in advance!",Looking for a CSS cheat sheet that can help me with R Shiny,98xmom,new
"I want to write a function that finds comparison text between User Generated Text and The Office TV show lines that have been said. The program would allow for anyone to type in any text and the R program could find Office lines with similar words. 

Solution:
User Generated Text:
 ""I'm interested in buying a paper shredder from the Steam Town Mall"" 

Output:
 ""Let's go to the Steam Town Mall to see if there is a sale, anyone interested?""  -Michael Scott, Season 4 Episode 5 (as an example)

The data: 
https://docs.google.com/spreadsheets/d/18wS5AAwOh8QO95RwHLS95POmSNKA2jjzdt0phrxeAE0/edit#gid=747974534 


This is the code I have so far. 

    library(plyr)
    library(dplyr)
    library(tidytext)
    library(googlesheets)
    library(bindrcpp)
    library(stringr)



    # get key for data sheet
    sheet_key <- gs_ls(""the-office-lines"") %>% 
      pull(sheet_key)

    # register sheet to access it
    reg <- sheet_key %>%
      gs_key()

    # read sheet data into R
    raw_data <- reg %>%
      gs_read(ws = ""scripts"")

    #removing funky stuff fixing typos
    mod_data <- raw_data %>% 
      filter(deleted == ""FALSE"") %>% 
      mutate(actions = str_extract_all(line_text, ""\\[.*?\\]""),
         line_text_mod = str_trim(str_replace_all(line_text, ""\\[.*?\\]"", """"))) %>% 
      mutate_at(vars(line_text_mod), funs(str_replace_all(., ""���"",""'""))) %>% 
      mutate_at(vars(speaker), funs(tolower)) %>% 
      mutate_at(vars(speaker), funs(str_trim(str_replace_all(., ""\\[.*?\\]"", """")))) %>% 
      mutate_at(vars(speaker), funs(str_replace_all(., ""micheal|michel|michae$"", ""michael"")))


    # Creating the comparison function between sentences
    compareSentences <- function(sentence1, sentence2) {
 
       # split everything on ""not a word"" and put all to lowercase
       x1 <- tolower(unlist(strsplit(sentence1, ""\\W"")))
       x2 <- tolower(unlist(strsplit(sentence2, ""\\W"")))
  
      commonWords <- intersect(x1, x2)
      #add word beginning and ending and put words between ()
      # to allow for match referencing in gsub
      commonWords <- paste(""\\<("",commonWords,"")\\>"",sep="""")
  
  
      for(x in commonWords){ 
        # replace the match by the match with star added
        sentence1 <- gsub(x, ""\\1*"", sentence1,ignore.case=TRUE)
        sentence2 <- gsub(x, ""\\1*"", sentence2,ignore.case=TRUE)
      }
  
     numberofwordsmatch <- str_count(sentence1,coll(""*""))
  
 
     return(list(sentence1,sentence2, numberofwordsmatch))     
     }

        # Getting a specific The Office quote
        TheOfficeLine<- mod_data %>%
                filter(id ==1, 
                   episode ==1, 
                   scene ==1, 
                   season ==1 )%>%
             select(line_text_mod)


    UserDefinedText <- ""all right Jim so this quarter look good""

    compareSentences(TheOfficeLine$line_text_mod, UserDefinedText )


If we run the function `compareSentences` we will see that five words match between the two different texts -- This is awesome. What I want to do next is loop through the entire series and see how many words match with my User Defined Text. 

I decided to make a loop to try and complete the next step:

    scenerange <- 1:100 # just pick the first 100 lines 
    for ( i in scenerange){
  
      TheOfficeLine <- mod_data %>%
        filter(id ==i)%>%
        select(line_text_mod)
    
    print(TheOfficeLine)
      }
  
This will work printing first 100 lines. The next bit is when I have trouble. I cannot seem to understand how to combine a loop and a function. 

This does not work: 
    
     for ( i in scenerange){
  
      TheOfficeLine<- mod_data %>%
        filter(id ==i)%>%
        select(line_text_mod)
  
      UserDefineText<- ""all right Jim so this quarter look good""
  
     compareSentences(TheOfficeLine$line_text_mod, UserDefineText)
 
    }

And I'm not sure why -- the loop works and the function works as well. I've used loops before but I have a hunch this has something to do with global environment not existing inside the function? maybe... 

Does anyone have an idea on what I should try next? 

",Requesting Help - Working Code -- Data is publicly available. Comparing between different text strings,98env2,new
"[Hadley ](https://adv-r.hadley.nz/R6.html#controlling-access) And other sources have used this notation but I can’t tell why. I think it has something to do with trying to access the object and not the field but I’m guessing. 

Could anyone explain why the dot is necessary?",R6 and use of dot in private$.age,98e0a2,new
"if ur interested in the data here is the post 

/r/CryptoCurrency/comments/988lxb/i_have_5_years_of_coinmarketcapcom_crypto_price/

I mainly so far want to look for peeks and bottoms as they have occured throughout the time series. 

I'm familiar with stats, just did stats 101 at uni, and brushed up again years ago when i built a simple trading bot for stocks. 

So a tutorial that focuses on c# would be great, there are a few around but if there is a really good one you guys could share, id appreciate it

thanks","I have 5 years of historical crypto price data i want to do some analysis on, new to R, using c#. can someone provide me a good tutorial to get started?",988ws6,new
"I'd like to know whether Microsoft R Open will give significant performance improvement as compared to the standard CRAN R. The platform is Windows 7 (64 bit), my computer is an average desktop. I'm mostly interested in machine learning tasks such as random forests, boosting classification, SVMs etc. My datasets are of medium size (3-5 Mb).",Microsoft R Open,983ae5,new
"#SOLVED

Hi friends,

I created a package of R functions and thing I've found on the internet and a few I've written myself. I've done a package before and had no issues. Typically, what I do is create the package in RStudio then load it into github, then use `devtools::install\_github("""")` to install the package (it just keeps everything up to date and consistent across computers). 

today, though, I went through and added documentation for my personal package for future me. After installing the package, I've had all kinds of errors. Rstudio couldn't create a folder for my package so I had to make one by hand and install it there; it won't download from github; it won't install itself; file is corrupted; etc. 

I'm at a point now where the package is installed and will successfully download itself from github. 

however. 

None of the functions work. I load the package and call any of the functions and rstudio and R console both act as if they've never heard of them. There's gotta be something wrong with the namespace? or something else? 

Does anyone else wanna give it a shot? 

    devtools::install_github(""McCartneyAC/mccrr"")

    library(mccrr)

    coinflips()","trouble with a package not loading functions, et al.",97ywf5,new
"I have the following string:
asdasdasd (987REM {CS} [029292920] (123203020200)
i want to extract what is in (), i use rm_between, but he detects the first parathesis and dont stop until the last one. I want to be able to tell him to start from right to left. Any ideas? any other function that can do this? 

This will be done to a lot a of strings with different sizes",Searching string from right to left,97w25f,new
"Lately, I've been practicing with Python and creating GUI's and freezing them so non-programmers can use them. Now I want to create one that can analyze grades from students and classes. I've been trying to learn matplot, but it seems so much more difficult than using R and ggplot. I'm much more proficient with R when it comes to graphing. So instead of trying to learn matplot, I'd rather learn how to create GUI's and how to package scripts with R.

Does anyone have any recommendations on what libraries I should look into for these accomplish this? With R, I'm currently only familiar with R Studio, mainly using ggplot and tidyverse. ",Looking to create a GUI with R and packaging it,97tt6o,new
" I just started using RMarkdown (have been working with R for a year now, so familiar with basic code writing in R); it's really handy but my documents don't look nice and structured. For example:

\- How can you change the color/thickness of line page breaks?

\- How can you change color of certain text pieces (to emphasize a word/sentence)

Any other tips are also welcome :)",Tips for a RMarkdown newby? Especially commands to make the document look nice?,97t1mn,new
"I've collected a dataset which details tweet sentiment as a categorical variable (good, bad, neutral) across the course of one year, and I want to graph these to show variable frequency compared against time. Is there a clean way of doing this in R? ",Plotting categorical variable frequency over time,97s6jz,new
"I cannot for the life of me seem to find a way to efficiently add lines to denote p-values and significantly different groups in a comparison of multiple groups. I am using the ggpubr package, however the multiple comparison option allows me to run ANOVA and display the results, however it conducts a t-test instead of offering Tukey's test.  Is there a way to do this in R? How come both ggpubr and ggsignif run a t-test instead of Tukey's for multiple comparisons?",How to add p-values and lines to compare significantly different groups,97mxj8,new
"Could you help me please?

I am  analizing tennis  matches.  

In this case I  want to  spot  if there is a  correlation between  the double  faults  and  the  winning (or losing) matches.

I  have  labeled  the variable  ''WON match''  as   1 ;   I have labeled  the  variable  ''LOST match''  as  0

Here  the number  of  double faults  on the  left  and  the 0  and 1  on the right

https://i.redd.it/7l6lrdeth4g11.png

And  thos  are  the  results  (ragroupment for  coloumns)

https://i.redd.it/gn2d6hpji4g11.png

Colonna is  ''coloumn''

I am  doing  this  with  the  excel  in Ubuntu (LIbre Office).   Well, now  what  I  do not  understand  is:  are those values inversed correlated?  the  number of faults and won/lost  matches  are  not correlated? 

What is  the code  to make  a correlation like this  on R?

Thank you",Correlations,97c6y2,new
"R was the first programming I learned (as an Econ/stats person, it was a natural choice). And sure, learning how to program didn’t happen overnight. But I just don’t see why people say R has a “steep learning curve.” As I’ve started to delve into other languages like Python, I actually think learning R is far easier. Maybe I’m just weird though. So, why exactly does R have this reputation?",Why do people say R has a steep learning curve?,979ebq,new
"Hi, I am about to get more into serious football analytics stuff and therefore I'll use r/Python a lot for my work. The problem is that I have data in PDF's and I need to extract it so I can tidy it up and work magic afterwards. 

Also, I want to automate this process as I'll get every week data report. What's the best and the most painless way to do it. And, should I use R or Python after all.

Thanks!",[HELP] From PDF to tables in R,976y70,new
"My area (finance) is slowly adopting other applications beyond Excel in data analysis and predictive analysis - R and Python are the top two that have emerged.  In order to sell these applications to business end-users, I think it is absolutely imperative that they integrate with Excel and spreadsheets.  Otherwise, no one will feel comfortable with our models, especially if they can't interact with it in a spreadsheet.

I've been learning more R and Python simultaneously from scratch. I've gotten more accustomed to using Python and having it called from Excel via xlwings.  As I get more experienced in it, I can see it being a powerful tool in data, automation, and modelling tasks that I can transfer to others fairly easily via Excel and xlwings.

I've been asked to assess the feasibility of using R in the same way with Excel, and I'm honestly not that familiar with integrating Excel with R.  Does anyone have any experience integrating Excel with R?  How did it turn out?  Is one language more advantageous over the other in terms of working with Excel?  We eventually would like to use these languages for predictive analysis as well - is there any advantage to one language over the other in this regard?",R vs. Python for operationalized processes?,9744ot,new
"Hello, sorry not  familiar to R could  you   explain me somenthing and  help me  a littlebit, please?

I  was reading  this  article  which  talks  about  Amazon stocks price   modelling using AR (autoregressive  model)

There are  some terms  I don't  understand.

This  is  the article:

[https://www.quantstart.com/articles/Autoregressive-Moving-Average-ARMA-p-q-Models-for-Time-Series-Analysis-Part-1](https://www.quantstart.com/articles/Autoregressive-Moving-Average-ARMA-p-q-Models-for-Time-Series-Analysis-Part-1)

## Simulations and Correlograms

## AR(1)

Let's begin with an AR(1) process. This is similar to a random walk, except that *α*1

does not have to equal unity. Our model is going to have *α*1=0.6

. The R code for creating this simulation is given as follows:

\> set.seed(1) > x <- w <- rnorm(100) > for (t in 2:100) x\[t\] <- 0.6\*x\[t-1\] + w\[t\] ''''

Why  did  he set  the  *α*1 = 0.6?  Based  on what?

And  what is  this coefficient?  What  does it  rapresent?  (In simple words)

**question 1:**

He goes on with the simulation:

Notice that our *for loop* is carried out from 2 to 100, not 1 to 100, as

    x[t-1]

when *t*=0 is not indexable. Similarly for higher order AR(p) processes, *t* must range from *p*

to 100 in this loop.

We can plot the realisation of this model and its associated correlogram using the layoutfunction:

\> layout(1:2) > plot(x, type=""l"") > acf(x)

The  loop ''for''   from 2  to 100..... what  is  that?  Is it  the  number of  simulations?

**Question number 2:**

(He plots the  ACF graph)

We can plot the realisation of this model and its associated correlogram using the layoutfunction:

\> layout(1:2) > plot(x, type=""l"") > acf(x)

[https://s3.amazonaws.com/quantstart/media/images/qs-tsa-armapq-ar1-plus-six-x-correlogram.png](https://s3.amazonaws.com/quantstart/media/images/qs-tsa-armapq-ar1-plus-six-x-correlogram.png)

**Realisation of AR(1) Model, with** ***α*****1=0.6**

**and Associated Correlogram**

Let's now try fitting an AR(p) process to the simulated data we've  just generated, to see if we can recover the underlying parameters. You  may recall that we carried out a similar procedure in the article on [white noise and random walks](https://www.quantstart.com/articles/White-Noise-and-Random-Walks-in-Time-Series-Analysis).

**My  question is  WHAT IS  THIS  ACF  graph?  How  to read  it?  What  does it mean  with  LAG?  What is  LAG?**

I see only  some lines....  but  what  are they?

As it turns out R provides a useful command arto fit autoregressive models. We can use this method to firstly tell us the best order *p*

of the model (as determined by the AIC above) and provide us with parameter estimates for the *αi*

, which we can then use to form confidence intervals.

For completeness, let's recreate the *x*

series:

\> set.seed(1) > x <- w <- rnorm(100) > for (t in 2:100) x\[t\] <- 0.6\*x\[t-1\] + w\[t\]

**Question number  3:**

why  do we  need  to  find out the  ''*αi*'' parameter if  we already knew it  is  0,6?",Autoregressive in R,96yxis,new
"When I hit enter it goes to a new line, but the cursor moves forward as though I hit the tab button.  
Have looked at the R shortcuts and tried googling but no luck.   
Any advice as to how I can undo this?",Issue starting a new line,96uj9h,new
"What is the easiest/best way/package to plot 2D and 3D vectors and do basic linear algebra activities? Something where I can easily manipulate axis lengths, change the perspective etc?

",3D vector plotting,96sxu4,new
"Hello Team!

The question at the end is very open ended so please bear with me.

Lets say I have the below data frame which represents my quarterly forecast and how it changed over time:

    library(lubridate)
    
    forecast <- data.frame(Date = c(010118, 010118, 020118, 020118, 030118, 030118, 010118, 010118, 020118, 020118, 030118, 030118),
                           Concept = c(""Toyota"", ""Toyota"", ""Toyota"", ""Toyota"", ""Toyota"", ""Toyota"", ""Ford"", ""Ford"", ""Ford"", ""Ford"", ""Ford"", ""Ford""),
                           Opportunity = c(""Tacoma"", ""Supra"", ""Tacoma"", ""Supra"", ""Tacoma"", ""Supra"", ""F150"", ""Focus"", ""F150"", ""Focus"", ""F150"", ""Focus""), 
                           Month1 = c(10, 10, 15, 15, 20, 20, 30, 30, 40, 40, 50, 50), 
                           Month2 = c(15, 15, 20, 20, 25, 25, 35, 35, 45, 45, 55, 55),
                           Month3 = c(10, 10, 15, 15, 20, 20, 30, 30, 40, 40, 50, 50))
    
    forecast$Date <- mdy(forecast$Date)
    forecast

The date column represents the day that the forecast for the quarter was received. Given that my real world data has hundreds of opportunities and \~30 customers, how would you track the change in forecast over time given that the concept and opportunities, for the most part, will remain the same as we step through iterations of the forecast?

For example: the forecast for the Month1 forecast of the Toyota Supra changed 3 different times. Starting on 1/1/2018 it was 10, then increased 5 units to 15 on 2/1/2018, then increased 5 units to 20 on 3/1/2018.

Is there any simple and effective way to go about this?",Track changes to forecast over time,96iglm,new
"Could  you help me   with this problem?

In a tennis match player A has 40% chance of winning, while player B has 60% chance of winning.

It   has been calculated (from previous games) that if player B does not   close the set within 1h his chances of winning decrease on  average by  5% for every 5 minutes of game, while the odds of winning  for his   opponent increase by 4% for every  point in a row   he makes. Calculate  what  are  player B's chances of winning after 1h and  20 minutes,  knowing that  player A  made 5 points (in a  row).

Should I use the conditional probability in this  case or  am I wrong?

How could I do?  I don't  know  how to write E1  and  E2 (events).  They  are dependent  each other

How  can I write this in R?",Conditional probabilities,96fqqf,new
"I am trying to use calcStringMetric to get the width of a string. When defining a property like cex during viewport creation I get the desired results 

    grid.newpage() 
    pushViewport(viewport())
    get.gpar(c(""cex"")) #1
    calcStringMetric(""Hello World"")$width #0.864
    
    grid.newpage() 
    pushViewport(viewport(gp = gpar(cex=1.4)))
    get.gpar(c(""cex"")) # 1.4
    calcStringMetric(""Hello World"")$width #1.212

But how do I update these values on the fly? e.g. maybe now I want to calculate the lenght for cex 2 without creating a new viewport.

According to the help of **calcStringMetric**

>The metric information from this function is based on the font settings that are in effect when this function is called. It will not necessarily correspond to the metric information of any text that is drawn on the page.

And **gpar**

>The default parameter settings are defined by the ROOT viewport, which takes its settings from the graphics device. These defaults may differ between devices (e.g., the default fill setting is different for a PNG device compared to a PDF device)

so I assume that **calcStringMetric** falls back to the properties defined in the current viewport. 

    #Empty initialize but re define
    grid.newpage() 
    pushViewport(viewport())
    current.viewport() # and now how do I set a new custom cex to call calcStringMetric
    # .....
    get.gpar(c(""cex"")) 

TLDR: How do I set a fontsize for caclStringMetric?",Setting gpar for calcStringMetric,96fem2,new
"Hi everyone,

I'm back with an other question. I'm so close to being done, I can smell the weekend. I'm having an issue with ""lapply."" I'm using it to pull information from an API. Some of the responses appears to be coming out in an unusable format or there is something wrong with the function itself. If it is the former, I was wondering if there was a way to have ""lapply"" skip errors and move on to the next object. The following is a trimmed down version of my code:

    #Testing function with a subset of data
    testdata <- requestdata[1:32, ]
    
    #Function for URL requests
    
    scrape_json <- function(ein){
      #API request
      url <- paste0(""https://projects.propublica.org/nonprofits/api/v2/organizations/"", ein, "".json"")
      resp <- GET(url)
      
      if(http_status(resp)$category==""Success""){
        
        #Raw data which is not structured and readable
        cont <- content(resp, as=""raw"")
        
        #Raw data to character
        char <- rawToChar(cont)
        char
        
        #Convert to workable list
        data.flat <- jsonlite::fromJSON(char, flatten = TRUE)
        class(data.flat)
        
        #Covert to data frame
        results <- data.flat[[""filings_with_data""]]
        
        print(class(results))
        
        #results
        return(results)
        
      }
      else{return(NA)}
    }
    
    
    data <- lapply(testdata[ ,1], scrape_json) %>% 
      rbindlist(fill=TRUE) 
    

This works well for some of the data. For example if I subset the testdata object to \[1:30, \] of the full dataset, it works fine. However, on the 31st data point, there appears to be an issue. It spits out the error:

>Error in rbindlist(., fill = TRUE) :   Item 31 of list input is not a data.frame, data.table or list

However, the print() command says that all the objects are data frames or lists. Is my if-else statement poorly written or is this an other issue? I was wondering if there was a way to have lapply log the error but move on to the next data point while saving my results? I've tried using tryCatch but that didn't work. However, I may not have uses it correctly.

Once again, thanks in advance for any and all help.",Skipping an Error when using lapply and piping?,96aoj8,new
"set.seed(357)

Ng <- 100 # number of cases per group

group.a.x <- rnorm(n = Ng, mean = 2, sd = 3)

group.a.y <- rnorm(n = Ng, mean = 2, sd = 3)

group.b.x <- rnorm(n = Ng, mean = 11, sd = 3)

group.b.y <- rnorm(n = Ng, mean = 11, sd = 3)

group.a <- data.frame(x = group.a.x, y = group.a.y, group = ""A"")

group.b <- data.frame(x = group.b.x, y = group.b.y, group = ""B"")

my.xy <- rbind(group.a, group.b)

\# construct the model

mdl <- lda(group \~ x + y, data = my.xy)

\# draw discrimination line

np <- 300

nd.x <- seq(from = min(my.xy$x), to = max(my.xy$x), length.out = np)

nd.y <- seq(from = min(my.xy$y), to = max(my.xy$y), length.out = np)

nd <- expand.grid(x = nd.x, y = nd.y)

prd <- as.numeric(predict(mdl, newdata = nd)$class)

plot(my.xy\[, 1:2\], col = my.xy$group)

points(mdl$means, pch = ""+"", cex = 3, col = c(""black"", ""red""))

contour(x = nd.x, y = nd.y, z = matrix(prd, nrow = np, ncol = np),

levels = c(2), add = TRUE, drawlabels = FALSE)

This creates a scatter plot of all the (x,y) points, different colors if group A or group B. However it also makes a singular contour line. This is the part where I am confused. The lda model predicts that either the (x,y) point is in group A or B, so there is only two possible z values. I understand that it should only be a single line, as it is the discriminant line that separates group A's from group B's. But every single point is a 1 or 2, how does R know to plot only a single line?",Can someone explain how this creates a contour plot?,968bp6,new
"I  am doing a  Montecarlo simulation to predict the the price  of  a stock over 100 days.

I have  its  chart  and  its  historical data

I  want to add  this  parameter  to the  model, to make  it  more ''robust''

The parameter is this one:

''If a   stocks  pumps  x300% , it's  likley it  will  drop at its pre-pump  levels +  20% (from stock's pre-pump level), at  the next session.

I don't know how  to write this  into a  Montecarlo simulation in R.

Can  you help me?",Montecarlo simulation in R,965kf4,new
"In matlab you can do array(3,end) to get the third row, final column. What is the r command for this? Google hasn't turned up anything useful",How to index for last value in array?,961yhi,new
"Hi guys, I need saving.

I need help figuring out how to improve a for loop. It doesn't necessarily needs to be an apply, I just thought it was the best way after researching it on stackoverflow. I tried following the guides I found on stackoverflow, but i'm a newbie and  believe i'm not getting a good grasp on the apply function.

This is a reconstruction of the snippet i'm trying to change:

    for (j in 1:NROW(teste2) {
      for (z in 1:NROW(teste2)) {
            if(is.na(teste2$DATE[z]==Sys.Date()+j-1) | z==NROW(teste2)){
              teste2$SALDO[z] <- 0
            }else{
                if(teste2$SALDO[z]!=0 & teste2$DATE[z]==Sys.Date()+j-1){
                  teste2$SALDO[z+1] <- teste2$PREVISAO_FINAL2[z] + teste2$SALDO[z+1]
              }else{
                teste2$SALDO[z] <- teste2$SALDO[z]
              }
            }
    }

i tried doing the following:

    for (j in 1:NROW(teste2) {
    rows = 1:NROW(teste2)
    saldo_fn <- function(z){
      return(if(is.na(teste2$DATE[z]==Sys.Date()+j-1) | z==NROW(teste2)){
        teste2$SALDO[z] <- 0
      }else{
        if(teste2$SALDO[z]!=0 & teste2$DATE[z]==Sys.Date()+j-1){
          teste2$SALDO[z+1] <- teste2$PREVISAO_FINAL2[z] + teste2$SALDO[z+1]
        }else{
          teste2$SALDO[z] <- teste2$SALDO[z]
        }
      })
    }
    teste2$SALDO <- sapply(rows, saldo_fn)
    }

but when i run sum(teste2$SALDO) it gives a different value.

What am I doing wrong? how do I fix it?",Need help with a complex model that runs on a bazillions of for's,95zpdc,new
"I've created a Bayesian model in runjags that I've used to predict which habitat covariates have an impact on burrow density on an island. The interaction between tussac (a type of plant used for nest building) and slope has come back as significant. The following graph shows that increases in both variables leads to an increase in burrow density:

[https://imgur.com/a/vScDqL4](https://imgur.com/a/vScDqL4)

The axis have negative values as the data has been standardised (mean = 0, SD = 1).

Does anyone have any suggestions for a way in which to present the information that is easier to understand and would be appropriate for a published paper?

Thanks for any suggestions.",Modelling - best way to plot an interaction between two variables,95waa2,new
"across the web I can read that I should use data.table and fread to load my data.

But when I run a benchmark, then I get the following results

    Unit: milliseconds
    expr       min        lq      mean    median        uq        max neval
    test1  1.229782  1.280000  1.382249  1.366277  1.460483   1.580176    10
    test3  1.294726  1.355139  1.765871  1.391576  1.542041   4.770357    10
    test2 23.115503 23.345451 42.307979 25.492186 57.772522 125.941734    10


where the code can be seen below.

    loadpath <- readRDS(""paths.rds"")

    microbenchmark(
      test1 = read.csv(paste0(loadpath,""data.csv""),header=TRUE,sep="";"", stringsAsFactors = FALSE,colClasses = ""character""),
      test2 = data.table::fread(paste0(loadpath,""data.csv""), sep="";""),
      test3 = read.csv(paste0(loadpath,""data.csv"")),
      times = 10
    ) %>%
      print(order = ""min"") 

I understand that `fread()` should be faster than `read.csv()` because it tries to first read rows into memory as character and then tries to convert them into integer and factor as data types. On the other hand, `fread()` simply reads everything as character.

If this is true, shouldn't `test2` be faster than `test3` ? 

Can someone explain me, why I do not archieve a speed-up or atleast the same speed with `test2` as `test1` ? :)",read.cvs faster than data.table::fread,95vjd8,new
"Hi Everyone,

I'm a 2nd year grad using R for some research. I'm definitely a noob. I need to extract data from an API. The httr package is working well to pull the requests as a JSON but I can't figure out how to turn that into workable data. My code is as follows:

    # This package is required for Accessing APIS (HTTP or HTTPS URLS from Web)
    library(httr)
    #This package exposes some additional functions to convert json/text to data frame
    library(rlist)
    #This package exposes some additional functions to convert json/text to data frame
    library(jsonlite)
    #This library is used to manipulate data
    library(dplyr)
    
    #http request
    resp <- GET(""https://projects.propublica.org/nonprofits/api/v2/organizations/10549867.json"")
    http_status(resp)
    http_type(resp)
    
    # Shows raw data which is not structured and readable
    jsonRespText<-content(resp,as=""text"") 
    
    # Structurised data in form of R vectors and lists
    jsonRespParsed<-content(resp,as=""parsed"") 
    
    # Access data element of whole list and ignore other
    modJson<-jsonRespParsed$filings_with_data vectors
    
    #Using dplyr to format list to data frame
    modJson %>%
      bind_rows %>%
      select(filings_with_data$tax_prd_yr,
    filings_with_data$formtype,
    filings_with_data$totrevenue, 
    filings_with_data$totfuncexpns, 
    filings_with_data$totassetsend, 
    filings_with_data$subseccd, 
    filings_with_data$ein)
    
    

I get the error:

>""Error in bind\_rows\_(x, .id) : Argument 4 is a list, must contain atomic vectors""

I've tried other solutions from Stack Overflow all day but nothing has worked. I have tried removing the index to look as follows but still no bueno:

    #Using dplyr to format list to data frame
    modJson %>%
      bind_rows %>%
      select(tax_prd_yr,formtype,totrevenue)

My modJson object is a list containing 4 elements (lists). Each element is a list of 47 values (each for a different year of data). I need to extract only some of those values into a data frame as listed in the last batch of code. Am I indexing it incorrectly or is this the wrong approach all together? The modJson object is below:

[modJson object](https://i.redd.it/ms3r1prs9ze11.png)

Any tips?  

Thanks! And I'm sorry if this is in the wrong format, I'm happy to change it to something more general if needed.",Need help transforming response JSON data to data frame.,95sib4,new
"Example  
df2 <- subset(df1\[conditions,\])   VS    df2 <- df1\[conditions,\])  


Is it simply that the subset function offers more options and either is fine? Or is there something else to this I should maybe know. ",subset() vs [],95qrje,new
"Hello, are  those one (DSE)  used  mainly  for Montecarlo / random forest?  ",Differential stochastic equations,95kdby,new
"I am not the best when it comes to writing things in a very R-like style, but I've gotten better since learning data.table.  However, and interesting problem came to mind this weekend (while I was in Vegas of course).  Many problems I've encountered with production data, at least for the questions I'm asked, are similar, but a simple challenge came to mind.

What would be the most code efficient way to determine losing and winning rolls for a series of craps rolls:

1) assuming the data is in some sort of data frame
2) assuming that the first roll begins the series
3) assuming we're just looking at ""pass line"" betting (don't would be extra credit)

simple data set for testing would be:

    Obsnum = 1:10000
    roll <- replicate(10000,sample(1:6,1) + sample(1:6,1))
    DF <- data.frame(Obsnum,roll)
    DT <- data.table(Obsnum,roll)    # (if you speak data.table)

For those unfamilar with the rules of craps, here is how winners would be determined:
The dice are rolled on what is called ""the come out"" roll.  if the dice show 7, WIN, if the dice show 2,3,or 12 , LOSE.  If the dice show any other number, a POINT is established.  Then, for the next ?? throws, a loss or a win is determined by either making the POINT again (WIN) or a 7 (LOSS).  Since this can take an infinite number of throws, herein lies the problem.  (Perhaps there's an easy solution I don't know about and then I'll feel like an ass when someone posts ""hey, just use xxx"").  After a WIN or LOSS, the game ""resets"" back to the ""come-out"" roll.

Since 7 is important, I'm using `set.seed(7)`

Here's a baseline non-R-esque code for benchmarking:

    flags<- rep(""ROLL"",100000)
    come_out <- 1  # 0 is ""point cycle""
    point <- 0
    for(i in 1:length(DF$roll)){
      if(come_out){
        if (DF$roll[i] == 7 | DF$roll[i] == 11)
          flags[i] <- ""WIN""
        else if(DF$roll[i] == 2 | DF$roll[i] == 3 | DF$roll[i] == 12)
          flags[i] <- ""LOSE""
        else{
          flags[i] <- ""POINT""
          come_out <- 0
          point <- DF$roll[i]
        }
      }
      else{
        if(DF$roll[i] == point){
          flags[i] <- ""WIN""
          come_out <- 1
          point <- 0
        }
        else if(DF$roll[i] == 7){
          flags[i] <- ""LOSS""
          come_out <- 1
          point <- 0
        }
      }
    }
    DF <- cbind(DF,flags)


comments welcome, if I did anything wrong for the set up, let me know.  If I can find a savvy solution, I'll post it.

EDIT:  Please note that the data should be generated before your code takes over.  Imagine that you're handed the data-frame by your supervisor or something, not that you're generating the rolls or probabilities in your code.  This is a question about optimization of things that aren't simple ""shift""s or otherwise basic vectorization. (unless, like I say, I'm the idiot and missed something basic.)",R-esque code challenge?,95ffml,new
"Has anyone had success putting R on an openshift pod? We're trying to do this for the first time, but not having any luck finding an up to date docker image for R.",How to get R on openshift,95eluf,new
"I am working on a industry project within my university trying to build model that will take in a large body of text such as a statement of purpose and a categorical variable (Accepted/Rejected). I have been trying to model mine based on the tweets experiment [this blog post](https://www.r-bloggers.com/sentiment-analysis-with-machine-learning-in-r/). My question is how big of a text body(about 400-500 words) can the NaiveBayes function in the e1071 package handle? Are there any other packages that you guys are aware of that can efficiently handle such large texts for sentiment analysis machine learning.

I am required to manually build a small learning data set to bootstrap the process. I am expected to start with using LDA or other feature construction techniques to create the training data set. Then later develop a R code to read a text input and predict the suitability of the applicant against the course a student has applied for. There are two possible ways to approach this: from comparing the LDA outputs, or through traditional classification modelling, or a combination of both.

Any help would be appreciated.",Need help building model using Sentiment Analysis with Classification model,95do6v,new
"Hi,

Grad student learning R for the firs time here.

What is the detailed explanation of the difference between recalling subsets through a list\[\] or list\[\[\]\]?

I read that list\[\[\]\] will break the list structure, so that length(list\[\[\]\]) would give you ""How many elements/vectors(?) are within that list""

vs.

length(list\[\]) will give you length of 1 (Because the length of that new list is 1?)

Is there an easy way to understand this?

Currently going through Arrays, Matrices, Lists, Factors and Data Frames.  I'd like to get a concrete / strong foundation of how their characteristics before beginning to work with them.

Thank You!",list[] vs. list[[]] subsetting,95d4z1,new
"What  should I put  into link function and  WHEN  to choose gamma, gaussian, binomial, quasi-binomial before making a regression? How to choose  one or oneother?

**glm(***formula***, family=***familytype***(link=***linkfunction***), data=)**

  **Family**				  **Default Link Function**				  

 binomial (link = ""logit"")    

gaussian (link = ""identity"")    

Gamma   (link = ""inverse"") 

  inverse.gaussian (link = ""1/mu\^2"")    

poisson (link = ""log"")    

quasi   (link = ""identity"", variance = ""constant"")  

 quasibinomial (link = ""logit"")    

quasipoisson (link = ""log"")",Generalized Linear Models,9552w0,new
"I have been using the rvest package to limited success on the website [transfermarkt.com](https://transfermarkt.com)

There is one page, however, which makes it incredibly difficult to use the SelectorGadget and create/grab usable CSS elements. This is the page: [https://www.transfermarkt.co.uk/arsenal-fc/ausfallzeiten/verein/11/plus/1?reldata=GB1%262016](https://www.transfermarkt.co.uk/arsenal-fc/ausfallzeiten/verein/11/plus/1?reldata=GB1%262016)

My biggest issues is that some of the squares in the matrix are color coded (not picked up by the selectorgadget) and other times have a URL embedded in them. A solution I suppose is to say IF a square has a URL, the player was involved in a game in some aspects. Another example of this is when they do not feature due to injury, and the injury is provided through a hyperlink.   


I am wondering if there are other packages which can look at CSS elements in terms of color or other widgets which grab more CSS elements. Or if rvest/selectorgadget which can work in this case. there might be an attribute ( html\_attri() ) which would work which I am unaware of. ",How best to scrape this web data,9511vj,new
"
A person goes through a maze made of 32 T-intersections. At each intersection they can decide to turn either left or right; each time, on one side there will be a wall, while on the other side the maze will continue to the next intersection.

Their goal is to arrive to the end of the maze as soon as possible.

At each intersection, the person is aided by two cues, a visual cue and an auditory cue. **The cues are not always correct and not always in agreement**. Specifically, the cues can have different level of reliability. For example, in one maze the auditory cue may be correct 50% of the times, while the visual cue may be correct 25% of the times.  

The cues may be reliable at three different levels: 25%, 50% and 75%.  The reliability of cue does not change within one maze, but may change from maze to maze. Each new maze is a completely different situation. 

Since we have three different reliability levels, combining all of them we have a total of nine mazes.

I would like to model this maze in R. 

First I would need to generate nine mazes, with auditory cues and visual cues randomized according to their reliability level.

Then I would like to model the outcomes of a subject going through the maze according to a decision rule.

For example, let's say that subject A has the following decision rule: if in the first 10 trial one cue is correct more often than the other, he will always follow that cue for the rest of the maze.

Once the decision rule is set, I would have the subject go through the nine mazes and count how many times he made the correct decision. After that I could model a different decision rule.

I am a bit at loss on how to simulate this process! Any ideas or resources I could refer to?",Maze simulation in R,94ntt9,new
"Hello, 
I've written a script in R and using ggplot2 I've generated a series of graphs that my employer would like to put on our website.  

I'm repetitively new to this, so I'd like to get some information on what is required to make this happen before I contact our IT department.  I'm aware that I could just use R Markdown and generate an HTML document, but I'd like to take it a step further and add controls so that the users can modify the visualizations as they see fit.

In addition, once this is set up, would I be able to just refresh the dataset (a single file), in order to get new data or is there something else that I'd need to do?

Thanks for any tips! ",Posting Visualizations on the Web? What's required?,94mz3q,new
"Hi,

I'm working with a dataframe that does not include complete observations, that is to say 1700ish observations with 250ish variables and everything observation is missing at least one variable. 

I'm following the following procedure:

Define the lm() model

stepAIC()

But I am having trouble with lm() since na.omit or na.exclude will both empty out the dataframe. 

Please advise on ways to treat lm() with so much missing data, and wehater that will negatively impact the stepAIC() portion. 

Thanks! Here is a joke in return:

My social life. 


Zinnnng",lm() model in stepwise regression with no complete observations,94i8o4,new
"I am  trying to  make a  montecarlo simulation on T-test  student, as described in this  article:

[https://www.r-bloggers.com/introducing-the-montecarlo-package/](https://www.r-bloggers.com/introducing-the-montecarlo-package/)

As  you can see,  the summary  out put  is  this:

    # generate table: MakeTable(output=MC_result, rows=""n"", cols=c(""loc"",""scale""), digits=2, include_meta=FALSE)
    
    ## \begin{table}[h] ## \centering ## \resizebox{ 1 \textwidth}{!}{% ## \begin{tabular}{ rrrrrrrrrrrrrrr } ## \hline\hline\\\\ ## scale && \multicolumn{ 6 }
    {c}{ 1 } & & \multicolumn{ 6 }{c}{ 2 } \\ ## n/loc & & 0 & 0.2 & 0.
    4 & 0.6 & 0.8 & 1 & & 0 & 0.2 & 0.4 & 0.6 & 0.8 & 1 \\ ## & & & & & 
    & & & & & & & & & \\ ## 50 & & 0.05 & 0.30 & 0.83 & 0.98 & 1.00 & 1.00
     & & 0.05 & 0.10 & 0.28 & 0.55 & 0.79 & 0.94 \\ ## 100 & & 0.05 & 0.51
     & 0.98 & 1.00 & 1.00 & 1.00 & & 0.07 & 0.16 & 0.53 & 0.84 & 0.98 & 1.00
     \\ ## 250 & & 0.05 & 0.89 & 1.00 & 1.00 & 1.00 & 1.00 & & 0.05 & 0.35
     & 0.90 & 1.00 & 1.00 & 1.00 \\ ## 500 & & 0.05 & 1.00 & 1.00 & 1.00 
    & 1.00 & 1.00 & & 0.06 & 0.58 & 1.00 & 1.00 & 1.00 & 1.00 \\ ## \\ ## 
    \\ ## \hline\hline ## \end{tabular}% ## } 
    ## \caption{ decision } ## 
    
    \end{table}

Well, I don't  know  what it means. It's  like  an alien language.   How  can I  red this? Any help please?  Why  the output is so complicated?  How  can I  show it in a readable  way?  Any istogram?",Montecarlo simulation in R,94ghuj,new
"My data is separated into two different tables with the same column headers. I need to run a linear regression (or maybe non-linear regression, I don't really know for sure yet) on each pair.  

Is there an easy way to do all the linear regressions at once instead of me typing out each lm(table1$boise ~ table2$boise), lm(table1$atlanta ~ table2$atlanta), lm(table1$losangeles ~ table2$losangeles) ?  

Is there also a way to capture the output into another table so I can easily plot all the lines later?",Running multiple linear regressions?,94gdsd,new
"x-post from r/statistics

i have 12 independent events occuring, and need to figure the probabilities of X number of events. This is for a sports schedule, so basically after 5 games the probability of being 0-5, 1-4, 2-3, 3-2, etc.

What would be the quickest way to calculate this with some type of loop to figure this out without manually doing all 4095 possibilities by the time I get to week 12.

Thanks!",I need to find a loop to find the probability exactly X independent events occur,94cd5x,new
"I have a list, that is a string. In this string, the characters are separated by either a "";"" or "","". So I have to use a ""strsplit"". With this, in this example, I end up with 3 list, where 2 of those lists have 3 elements and the last only will have 2 elements in the list.    

    mylist = c(""ac*, be, cd*; daa, efae*, fge*; gefa*, h"")
    Liste <- strsplit(strsplit(mylist , "";"")[[1]], "","")

The reason for, using ""strsplit"" like this, is that when I have a "";"" in my string and "","" as a logical OR, then it acts like a logical AND, that means I have to use one element from each list, later in my code. 

So the output of Liste will be

    [[1]]
    [1] ""ac*""  "" be"" "" cd*""

    [[2]]
    [1] "" daa"" "" efae*"" "" fge*""

    [[3]]
    [1] "" gefa*"" "" h""

What I am trying to avoid, is the use of the double for-loop, and maybe make the code faster, if it is possible.

so now I am using a nested for-loop, to look at each element in mylist.

    for (c in 1:length(Liste)){
      for (d in 1:length(Liste[[c]])){
        # Extracting last character, matching if it is a wildcard
        # Liste[[c]][d] Prints all elements from the list
        # I need the double for-loop for this check
        if (stri_sub(Liste[[c]][d],-1,-1) == '*')
            DO SOMETHING
      }
    }

What else can be done here?",Trying to avoid nested for-loop,947tv7,new
"I currently have a data frame like this:

|x|y|category|
|:-|:-|:-|
|149.5 |150.5|1|
|140.5|172.5|1|
|149.5|377.5|1|
|174.5|157.5|2|
|146.5|153.5|2|
|141.5|169.5|2|
|149.5|377.5|2|
|174.5|157.5|3|
|146.5|153.5|3|
|158.5|169.5|3|

My goal is to compare each x-y coordinate to another one in its own category. I need to replicate **each row**, in each category, and then **replicate the whole category**, binding them together to get the difference between each coordinate pair.

So the goal would be for the resulting data frame to look like this:

x|y|category|x1|y1|xdiff|ydiff|
--:|--:|--:|--:|--:|--:|--:|
149.5|150.5|1|149.5|150.5|0|0|
149.5|150.5|1|140.5|172.5|-9|22|
149.5|150.5|1|149.5|377.5|0|227|
140.5|172.5|1|149.5|150.5|9|-22|
140.5|172.5|1|140.5|172.5|0|0|
140.5|172.5|1|149.5|377.5|9|205|
149.5|377.5|1|149.5|150.5|0|-227|
149.5|377.5|1|140.5|172.5|-9|-205|
149.5|377.5|1|149.5|377.5|0|0|
174.5|157.5|2|174.5|157.5|0|0|
174.5|157.5|2|146.5|153.5|-28|-4|
174.5|157.5|2|141.5|169.5|-33|12|
174.5|157.5|2|149.5|377.5|-25|220|
146.5|153.5|2|174.5|157.5|28|4|
146.5|153.5|2|146.5|153.5|0|0|
146.5|153.5|2|141.5|169.5|-5|16|
146.5|153.5|2|149.5|377.5|3|224|
141.5|169.5|2|174.5|157.5|33|-12|
141.5|169.5|2|146.5|153.5|5|-16|
141.5|169.5|2|141.5|169.5|0|0|
141.5|169.5|2|149.5|377.5|8|208|
149.5|377.5|2|174.5|157.5|25|-220|
149.5|377.5|2|146.5|153.5|-3|-224|
149.5|377.5|2|141.5|169.5|-8|-208|
149.5|377.5|2|149.5|377.5|0|0|
174.5|157.5|3|174.5|157.5|0|0|
174.5|157.5|3|146.5|153.5|-28|-4|
174.5|157.5|3|158.5|169.5|-16|12|
146.5|153.5|3|174.5|157.5|28|4|
146.5|153.5|3|146.5|153.5|0|0|
146.5|153.5|3|158.5|169.5|12|16|
158.5|169.5|3|174.5|157.5|16|-12|
158.5|169.5|3|146.5|153.5|-12|-16|
158.5|169.5|3|158.5|169.5|0|0|
",Repeating and replicating data frame,947cvt,new
"I would greatly appreciate if someone could point to a package that can be used to  statistically (as in meta--analysis) compare bayesian factors and/or  cohen's D's in R.

Thank you!",meta-analysis of bayesian factors,944k8d,new
"Can not handle categorical predictors with more than 53 categories.

The structure of the data frame looks as posted in the image.

// rfm <- randomForest(UserType\~.,dt4.train)

Looking for some suggestions on how to proceed . My target variable is UserType

https://i.redd.it/5vt0u7yvfqd11.png",Error: Random Forest modeling . Can not handle categorical predictors with more than 53 categories.,942g90,new
"Apologies if my question is hard to understand and the data isn't presented in the best manner but I'm a complete novice and only started learning R a few days ago.

I have a dataframe that consists of all tennis match records since the year 2000, with variables for ""Tournament""; ""Date""; ""Winner""; ""Loser""; ""WRank"" (winner's ranking); ""LRank"" (loser's ranking). Using tidyverse, I created a new dataframe that consists only of matches played by the top 5 tennis players of the generation (Federer, Nadal, Djockovic, Murray, Wawrinka)

    top5.data <- filter (full.data, Winner %in% c(""Federer"", ""Nadal"", ""Djockovic"", ""Murray"", ""Wawrinka"") | Loser %in% c(""Federer"", ""Nadal"", ""Djockovic"", ""Murray"", ""Wawrinka""))

The first goal is to use ggplot and make a barplot using this data. 5 bars, one for each player, each of which on the x-axis has the name of the respective player, and on the y-axis, the height of the bar is represented by the the total number of matches that the respective player has played. However, I'm not sure how to proceed. Here is one potential method, though I'm not sure it's best way or feasible:

Use a conditional statement which replaces the observations in top5.data$Winner and top5.data$Loser with NA unless the observations are any of the top 5 players (""Federer"", ""Nadal"", ""Djockovic"", ""Murray"", ""Wawrinka""). Then use the combined data of both variables with NA removed to plot the graph. Is there a way to do this?        

    ggplot(data = top5.data) + geom_bar(mapping = aes(x = Winner, x = Loser))

Obviously, the above code isn't correct, but I'm just trying to figure how to use the combined data of two categorical variables on the same axis as well as remove NA values.

Further the only conditional statement I'm familiar with is ifelse, however I don't how to how to keep the value the same if it meets the conditions.

Any help would be greatly appreciated. Thanks",Best way to use data from two separate categorical variables for a bar plot,94239z,new
"I need to use R for writing a query coming from a database my R environment is connected to. The structure of the query looks like this:

    ALTER TABLE cph.table_id ADD PARTITION (event_date = 'YYYY-MM-DD')
    LOCATION 's3://external-dwh-company-com/id-to-idl/YYYYMMDD'

So for example, today's addition would like as such:

    ALTER TABLE cph.table_id ADD PARTITION (event_date = '2018-08-02')
    LOCATION 's3://external-dwh-company-com/id-to-idl/20180802'

The issue is, I need to be doing this for every data going back to 03/01/2018. 

So the steps would look like:

    initial_query <- paste(#however the above query would be formatted with the dates)
    
    results_query <- dbGetQuery(conn,  initial_query)

But yeah, the biggest hurdle for me is:

1.) Figuring out the `paste` formatting for that first part AND

2.) Creating a loop that will allow me to run the above steps until the current date.",Writing a loop that brings in two different date formats,941h7u,new
"So, the general outline is I have a data set (can't share it, srry).

I used a 60 40 split for training and testing respectively. I imputed both seperately (that is what I found adequate sources for).

So, when I imputed with m = 100 iter = 20, I am left with 100 data frames which I must pool in order to train a model. Now, I know that I could just use stepAIC and glm on one of those frames to get a logistic regression, but in order to determine which variables are most adequate across all the data frames I would have to use stepAIC and glm across every single data frame and then average out the coeffs, looking for the overall strongest variables. How would I accomplish this? (I cannot just use stepAIC on the imputed data of class mira, because it is not a df but rather a collection of 100 dfs). Alternatively, I could use LASSO to select a variable, but if I was to do that, I would still need to apply it to each one of the dfs generated by imputation, then take all the results together. I'm not too keen to do that manually, and I am quite sure that I can't really just average out the variables.

There are probably other methods that I am ignoring at the moment so if there are others, I would love to be enlightened. The output of using mice on my training set is an object of class mira, which means that it is more or less a collection of 100 imputed dataframes due to my imputation criteria. If you need any clarification or for me to answer any questions, please let me know! Any help or guidance offered would be appreciated greatly!

Edit: Alright, well here is a solution which I am working on, please let me know if it is a dead end. I first make a glm with all the variables, then apply it to every df using with fullmodel <- with(imputedtraining, glmmodel) . Then I pool it, and doing summary(pool(fullmodel)). Now I want to do something like this, where I perhaps do stepmodel <- with(imputedtraining, stepAIC(modelpooled)). However, the modelpooled must be an actual model. Can I convert the estimate I get when I do summary(pool(fullmodel)) somehow?",I would like a bit of help for variable identification in R in MICE imputed datasets,940plb,new
"Well  some user told  me  it  was  easier  to use  than R  in ubuntu ( R commander)...   well I  can't  understand  how to use it. No simple interface, only  terminal / command line

Don't   know where to plot  the data,  where  to make  linear regressions, nothing.  I am lost.. could  you help me please?

[https://image.ibb.co/kF4MJz/Schermata\_da\_2018\_08\_02\_11\_58\_52.png](https://image.ibb.co/kF4MJz/Schermata_da_2018_08_02_11_58_52.png)",I have downloaded R from R studio,93xz83,new
"I can't  find...   on Google it  seems like there is  only  for  Windows... I can't  code in R,  could  R  VISUAL  STUDIO  be used  by  who doesn't  know  how to  code in R?

Can you give me  a link to download  R visual  studio in Linux?",A link to download R visual studio for Ubuntu 18?,93t553,new
"Hi y'all,

[Here's what my data looks like](https://imgur.com/a/t9MOyS9)

I transposed the data, then attempted to run a linear regression with the employee names on cost. Each employee has multiple observations, which is different from my image.

However, Janet does NOT show up in the list of coefficients. It will show every other employee and their estimates, but Janet's just isn't there.

[Here is what I am dealing with](https://imgur.com/a/6dTrB8W)

It says 2 observations deleted due to missingness(Which is REALLY weird because I have 3 observations for Janet), and so I tried missing.cases() on the employee column and I got a FALSE. I've looked at the CSV, and the values for Janet look fine... I can't tell what's wrong with them, or how to fix this at all. 

So... wondering how to proceed from here? I was able to ""force"" a regression by adding a new row with Bob as everyone else's name and Janet's for hers and just regressing that...

However, I want it to show up nicely with everyone else's name in the regression results...",lm() keeps dropping group of observations for no reason?,93q09b,new
"Spent the last 6 months in R doing basic EDA(tidyR, dplyR), building some classification models, visualisations(ggplot2), web scraping, basic sentiment analysis. I never wrote complicated functions or anything. It was mostly stuff I learnt while doing uni coursework. This will be my first time working on a real life project with R. I am kind of lost on where I should begin with. I would like to prepare myself by getting acquainted with the packages. I have a week before my project starts. Below is the description of the project. Thanks.

**Predicting the suitability of student applicants from their “Statement of Purpose”.**

This project will take place at the Centre for Data Analytics and Cognition. There are three phases to this project. In Phase 1, the successful candidate will need to manually build a small learning data set to bootstrap the process. The candidate is expected to start with using LDA or other feature construction techniques to create the training data set.

In Phase 2, the candidate will need to develop a R code to read a text input and predict the suitability of the applicant against the course he or she has applied for. There are two possible ways to approach this: from comparing the LDA outputs, or through traditional classification modelling, or a combination of both.

Once the model is built, the applicant is expected to build in Phase 3, a Web-based interface to accept “statement of purpose” inputs from the user and feeds this to the predictive model created in Phase 2. The result of each prediction is to be sent to a designated email address.",Working on my first industry project using R. Need guidance how what packages to proceed with.,93mix2,new
"Hi everyone! I'm new to R and Arch Linux.

I recently started using Rmarkdown for notes. I have noticed that when I type any Korean .Rmd -> (any other formate) It will just use (???) instead of Korean. I've tried including different latex packages but still get the same result. I am using vim for editing the .Rmd files. I'm not sure if that might be the root cause. I am using this script to run it in vim

autocmd FileType rmd map <f5> :!echo<space>""require(rmarkdown);<space>render('<c-v%')""<space>\\|<sapce>R<space>--save<enter>

Due to my lack of knowledge in Linux and R, I was hoping someone could point me in the right direction",[Noob] Adding Korean in rmarkdown results in (???),93ixev,new
"So I code in a wide variety of languages in addition to R, and it irks me to switch between IDEs every time I need to make edits in one file versus another.  So my strong preference is to keep everything in Atom.  
  
I use Hydrogen for line by line interactive editing and it's great, and I have the Script package if I need to easily run an entire script for producing plots or whatever, but I haven't quite figured out an easy way to render my r markdown files.  
  
I have a feeling that I could probably configure Script somehow to simply run the render function through a command call, but I haven't been able to figure out how to make it work.  
  
As of now, I've been manually running the terminal command 'R -e ""rmarkdown::render('filename.rmd')"", which gets the job done, but nearly as convenient as a simple keyboard shortcut that automatically runs whichever rmd file I'm editing through this.  
  
Any packages or tricks I could use to easily run my rmd files through knitr while keeping everything in atom?",Using atom with .rmd files?,934trb,new
"So I'm currently trying to analyse some data in R, looking at bats preferences for different types of roosting boxes at 4 different sites. I'm specifically looking at differences in use by males and females, the differences between species in their box choices, and finally looking to see if there are any differences in site use and if competitive exclusion is present in the 3 species – (ideally a negative correlation)

So far I have carried out proportion tests for the male and female choices, as well as for the species choices. I also did a proportion test looking at the overall site use by the 3 species, however I'm not sure if this is the best test to show that? I've hit a brick wall in trying to find a test that will work to show this! Any ideas?
 ",Do not understand what I'm doing!,926ljo,new
"basically I have a large dataset of this form: 



        users <- c(""John"",""Paul"", ""Luke"", ""Mary"", ""John"", ""Mary"", 
                    ""Luke"", ""Paul"")
        start_times <- c(""2018-07-14 04:55:57"", ""2018-07-14 
                             04:47:31"",
                             ""2018-07-15 03:02:22"", ""2018-07-15 
                              03:58:21"",
                             ""2018-07-16 04:56:41"", ""2018-07-16 
                              03:59:28"",
                              ""2018-07-16 03:13:21"", ""2018-07-16 
                              04:58:14"")

         end_times <- c(""2018-07-14 14:02:31"", ""2018-07-14 
                           15:03:17"",
                           ""2018-07-15 12:01:14"", ""2018-07-15 
                            12:59:45"",
                            ""2018-07-16 14:02:14"", ""2018-07-16 
                             13:01:14"",
                             ""2018-07-16 11:25:41"", ""2018-07-16 
                             13:22:17"")

    df <- data.frame(users,start_times,end_times)


and I need to figure out how much time was spent in each 30 minute interval by day. I'm not sure how to do it without looping over everything which isn't really feasible with the actual data set. any clever tricks you guys know that could help me out? 
                ","given start and stop times, figure out time spent in each 30 minute interval",925pjn,new
"I pulled [County Adjacency](https://www.census.gov/geo/reference/county-adjacency.html) data from the Census Bureau, however, there is a problem with the format of the data they provided. For ever county, they list the adjacent counties below it, but leaves the source county name and FIPS code as *NULL*

My data looks like this: https://imgur.com/2KNcwXz

That's what they give you (a load of crap if you ask me)

What I need to do is create a function that takes a vector of FIPS code(s), and returns a vector of the the Neighboring county FIPS codes. The problem I have is all of these *NULL* values. on the *CourceCountyFips* column. I need to get the correct value into that column for each row. I know how to tackle this kind of problem in SQL, but I'd like to keep this entirely within my R script.

Any help on approaching this problem would be greatly appreciated. Thanks!",Help cleaning up bad data source,924qyg,new
"I'm coding a simple card game just as an exercise to learn programming with S3 classes. I've got a class ""Card""  which is a list of the card name, its text, and other relevant data.  Then I create the class ""Deck,"" essentially a list of cards.

So I can store an actual list of Cards, or just a store a list of card names as character strings (and use something like a dataframe as a lookup table to match the name to the associated Card object). Is one of these approaches considered better style than the other, or is it a case-by-case decision? Seems like the former might lead to clearer code, but the latter might be less memory-intensive?",OO style question,921x50,new
"I have some data that fits very well to an exponential function of the form

y = (Peak - Plateau) \* exp(-K\*X) + Plateau

Where Peak is the maximum value, Plateau is the asymptotic value and K is the decay constant.

I have recorded this data in two different conditions, and I want to know whether the condition effects the best fit value for plateau.

Specifically, my null hypothesis is that the data is fit well by a curve with a single coefficient for plateau, and my alternative hypothesis is that Plateau must have a different value depending on the condition.

The data is organized in a data frame with three columns ""Y"" ""X"" and ""condition"", where Y is what was measured, X is a varied input to the system, and Condition is either 1 or 0, representing the two conditions.

I can then fit the curve with the following:

model\_simp = nls(Y \~ (A - B )\*exp(-K\*X) + B, data=onset, start=list(A=100, B=30, K=0.1))

This fits the data so that the plateau coefficient (i.e. B) is the same for both conditions.

I can then fit the alternative hypothesis

model\_full = nls(Y \~ (A - B + C\*condition)\*exp(-K\*X) + B + C\*condition, data=onset, start=list(A=100, B=30, C=1, K=0.1))

This means that the coefficient C is added on to plateau when condition=1

If I then perform the following

\> anova(model\_full, model\_simp)

Is the output of this ANOVA answering the question I want it to? Specifically, is it testing the null hypothesis laid out above?

Thanks for any input.",Hypothesis testing subsequent to non-linear regression,91ybo7,new
I have 14 days and I need to learn R for medical research. I do not know the exact type of research that I will do but I need to be an average user of R in 14 days. I know how to program in general and have basic knowledge of medical statistics. Which book do you recommend?,Recommend the book to learn R in 14 days for medical research to a person that already knows programming and basic statistics.,91v33z,new
"As pictured, ID 01012 has two FORM 2s with a year that matches that of FORM 7 and a year that matches that of FORMs 8 and 18.

What I am trying to do is return the most recent FORMs so that I have the latest ID's information to go with the other FORMs.  I have tried filter, unique, and distinct without much luck. Any help would be awesome!

I tried: df <- df\[!duplicated(df\[c(1,3)\]),\]

but it doesn't return  the max value of the DTYvisit col. (ie returns forms 7,8,18, and the most recent form 2)

P.S.  I tried this coding and it worked --> but it dropped my form 7, which I need to keep;

df <- df %>%

group\_by(CASEID) %>%

top\_n(1, abs(DTYvisit))

https://i.redd.it/ic2bdmx9z3c11.png",Subsetting a dataframe with most recent date based on values in other columns,91slha,new
"Still pretty new to R, wondering if someone could help me solve this problem.  I have a data frame with NFL stats, where each season's individual stat has it's own column.

|Full Name|Position|Passing Attempts (2016)|Passing Attempts (2017)|Passing Touchdowns (2016)|Passing Touchdowns (2017)|Carries (2016)|Carries (2017)|Rushing Touchdowns (2016)|Rushing Touchdowns (2017)|
|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|
|A.J. McCarron|QB||14||0||0||0|
|Aaron Rodgers|QB|610|238|40|16|67|24|4|0|

I'd like the resulting data frame to look like this:

|Full Name|Position|SEASON|Passing Attempts|Passing Touchdowns|Carries|Rushing Touchdowns|
|:-|:-|:-|:-|:-|:-|:-|
|A.J. McCarron|QB|2016|||||
|A.J. McCarron|QB|2017|14|0|0|0|
|Aaron Rodgers|QB|2016|610|40|0||
|Aaron Rodgers|QB|2017|238|16|24|4|

Thanks in advance for your help!!",Change Data Frame with Columns for Each Year to Data Frame grouped by Year,91m5gj,new
"I always have weird requests from people, so my methods end up being weird as well.  I've come to a point where some digging (admittedly not too deep) has come up with nothing. So I come to you for help.  

I have a List of Vectors of Integers (so like:

    [[1]]
    [1]  1 2 3 
    [[2]]
    [1] 4
    [[3]]
    [1] 5 6 7

and I'd like all permutations of that list.

output should be something like: (whether it's a list or a matrix or whatever I don't care)

    1 4 5
    1 4 6
    1 4 7
    2 4 5
    2 4 6
    2 4 7
    3 4 5
    3 4 6
    3 4 7
 
permn from the combinat package didn't work on my list, it returned:

    Error in vector(""list"", gamma(n + 1)) : 
      vector size specified is too large",Permutations of a list of vectors,91k1zb,new
"Machine learning is one of the most searched keyword on any search engine at this point of time. The reason is quite clear; the benefits of utilising it in any industry is beyond imagination. Machine learning is making computers learn from data to find patterns & generate business insights. In e-commerce, machine learning is even far more relevant because of digitally generated user-specific data points. Daily, we read so much about big companies using machine learning in their business decisions. With the technological advancement, machine learning is very much accessible for any small to medium enterprise. However, still thousands of companies are not capitalising the value generated from machine learning. We will briefly discuss most useful cases of machine learning in e-commerce.

>*With the technological advancement, machine learning is very much accessible for any small to medium enterprise*

* User churn prediction: By using customer transactional historic data and other behavioural traits, user churn probability can be predicted. Engaging a customer at right time can help reduce the churn if we know specific customers are about to churn, machine learning plays a pivotal role.
* [Recommendation engine](https://www.datatobiz.com/2017/09/15/product-recommenders/): Up-selling & cross-selling based on machine learning basket analytics can boost revenue. Everyone know about amazon product recommendations. It has been surfaced in one of the report that 27% of Amazon revenue comes from recommendations only. The power of recommender engine can be estimated from these numbers itself.
* [Customer Life Time value v/s Customer acquisition cost](https://www.datatobiz.com/2017/10/29/machine-learning-trasactional-analytics/) : Understanding customer LTV can be very crucial for any business. Using RFM (recency, frequency & monetary), machine learning can figure out the customer LTV to make strategic decisions on acquisition channels & cost of acquisitions.
* Customer segmentation: With statistical segmentations, users can be defined in the specific type of users to better understand of your customer base. Which type of users are more profitable, who buys more stuff. These types of answers will create a solid foundation for strategic business decisions.
* Marketing Campaign optimisation: Every marketing campaign has its cost. To better manage marketing budget, one need to analyse which campaign doing well and why. Machine learning can work quite well in figuring this out.
* Spatial analytics: Matching demand supply spatially & timely can be very productive in any business. Using machine learning, demand & supply can be predicted to take business actions to reduce this gap.
* Product inventory optimisation: Another use case of machine learning is inventory management, with the demand prediction, a business can be lean enough to reduce storage & waiting for costs for various products.

The above mentioned key areas where any e-commerce firm can make better business decisions using machine learning. In addition, fraud detection, customer service, voice analytics, web page & content selection analytics, image recognition and lot more can make managers better at business decisions.

This blog has been published originally at [DataToBiz](https://datatobiz.com/blog) official blog page.",7 Ways to use machine learning in E-commerce​,91h0qf,new
"Any help in clustering categorical data into clusters in r  . Can svm be used . If so how .. 

Any help would be appreciated ",Categorical values clustering,91ed3c,new
"I'm a complete R novice so forgive me for stupid questions!

I have a list of dataframes, each containing one column of integers. I want to filter this list, and print the name of every dataframe where the sum of the column is 0. I'm sure I've learnt how to do similar things before but I'm struggling to do it with a list of dataframes like this. Any help is very much appreciated!

Additionally, I think my next stage will be easier I instead have a list of vectors rather than dataframes. Any advice on how to convert them or edit my code to generate vectors in the first place. The code I have used so far is below.

`filenames <- list.files(""data/var_counts/"", full.names = TRUE)`

`vcffiles <- lapply(filenames, read.table)`

`names(vcffiles) <- gsub("".txt"","""",list.files(""data/var_counts/"",full.names = FALSE),fixed = TRUE)`

Edit:

I feel like there must be a simple solution to this that I am missing. I can do

`lapply(vcffiles, sum)`

and get an output like below. All I'm missing is a way to only print the answers which are zero (like GENE\_2 here).

`$GENE_0`

`[1] 84477`

`$CGENE_1`

`[1] 43389`

`$GENE_2`

`[1] 0`

`$GENE_3`

`[1] 57703`",Finding dataframes in list where sum of column matches condition,919sy4,new
"Hello all. I am someone who is extremely new to R. I've figured out how to use the e1071 package to create a SVM in R that is to my satisfaction. I was just wondering what the syntax was for changing the legend names of the SVM plots generated (currently they shows up as ""1"", ""2"", ""3"", ""4""). If I wanted the legend names to show up as ""a"", ""b"", ""c"", and ""d"", how would I go about doing this?

Thank you!",How to change legend names of plot.svm (e1071),912qcg,new
"I need to automate a process in R. Basically I have a an R script (I will call it R1) that needs three separate files to run. These three files are the results output of one trial in my study.

For each run of R1 on the three files, I obtain the summary results for one trial, in a csv file, plus 32 graphs for each decision point in the trial. 

One subject goes through nine trials. I was thinking about putting all the files originally generated by one subject in one big folder, so I will have 27 files (three files times nine trials). This way I won't have to change working directory multiple times (I wonder if there is a way to have R open a folder with a certain name as directory, run a scripts, move the directory to the next folder, run the script again...)

The nine trials are specified by the labels: AA AB AM BA BB BM MA MB MM. So for subject 1, trial 1, I will have three files with the ending
…mov1_AA

After a run of the three files corresponding to one trial, R should save the csv summary output in a separate folder called “summary_mov1” and name the file summary_mov1_AA, and so on. R should save the 32 graphs in a different folder, named mov1_graphs, graph1_mov1_AA, graph1_mov1_AB and so on. 

Ideally, after the script has gone through the nine trials, another R script called R2 should take the nine csv files and build some graphs out of them.

Once R has run the R1 script nine times, I would proceed to a new subject.

So basically: 

- use R1 with three mov1 files, get a summary csv file in a summary folder (plus 32 graphs in a different folder).

- do this nine times. Once one gets the nine csv summary files in the same folder, use R2 to average them and build a graph.

- Then do this for each subject (right now I have 7).

I have never done this type of automation so I am a bit lost. Any suggestions? Any examples you can point me to? Which would be the best workflow? At which level should I automate and which things should I rather do by hand?",Automation in R?,910p3w,new
"I have a runjags script that generates predicted burrow density for every cell on an island. I’m looking to obtain multiple draws (around 100) from an mcmc object for every cell. My dissertation supervisor thinks I should be able to do this using the coda package but I’ve only been able to extract the mean value for each cell rather than multiple realisations.

Code used to run the model and extract the summary stats:

S2VS1\_best\_fit\_result <- run.jags(model=S2VS1\_best\_fit\_model, burnin=100000, sample=1000, n.chains=3, modules=""glm"", thin = 100)

S2\_result <- as.mcmc(S2VS1\_best\_fit\_result, vars = ""S2"")

S2\_result\_list <- as.mcmc.list(S2VS1\_best\_fit\_result, vars = ""S2"")

S1\_summary <- summary(S2\_result\_list)

S1\_stats <- S2\_summary$statistics

I've posted the full model on [Stackoverflow if that's any use](https://stackoverflow.com/questions/51459110/run-jags-extract-multiple-realisations-from-mcmc-object). 

Can anyone tell me how to get multiple independent values for each cell?  


Thanks in advance for any response.",Runjags - extract multiple realisations from mcmc object,90s05i,new
"I am not even a bit good in using R and i have to use it for my Bachelor-Degree. 

I just need to build a simple Graph or better 32 but i cant even get the first one to work. 

The following is what i got so far and im allways getting a ""Error: Discrete value supplied to continuous scale""

I even tried to set every collum as a foctor and even that did nothing. 

I spend 12 hours on this so far and i am stuck.

What am i missing?  


library(dplyr)

library(ggplot2)

library(gridExtra)

data1.1 <- read.table(""Fishing1\_1.txt"")

data1.2 <- read.table(""Fishing1\_2.txt"")

data1.3 <- read.table(""Fishing1\_3.txt"")

data1.4 <- read.table(""Fishing1\_4.txt"")

data2.1 <- read.table(""Fishing2\_1.txt"")

data2.2 <- read.table(""Fishing2\_2.txt"")

data2.3 <- read.table(""Fishing2\_3.txt"")

data2.4 <- read.table(""Fishing2\_4.txt"")

data3.1 <- read.table(""Fishing3\_1.txt"")

data3.2 <- read.table(""Fishing3\_2.txt"")

data3.3 <- read.table(""Fishing3\_3.txt"")

data3.4 <- read.table(""Fishing3\_4.txt"")

data4.1 <- read.table(""Fishing4\_1.txt"")

data4.2 <- read.table(""Fishing4\_2.txt"")

data4.3 <- read.table(""Fishing4\_3.txt"")

data4.4 <- read.table(""Fishing4\_4.txt"")

c <- c(""VP"", ""Trial"", ""Target Position"" , ""Guess Position"" , ""Difference"", ""Score"")

colnames(data1.1) <- c

colnames(data1.2) <- c

colnames(data1.3) <- c

colnames(data1.4) <- c

colnames(data2.1) <- c

colnames(data2.2) <- c

colnames(data2.3) <- c

colnames(data2.4) <- c

colnames(data3.1) <- c

colnames(data3.2) <- c

colnames(data3.3) <- c

colnames(data3.4) <- c

colnames(data4.1) <- c

colnames(data4.2) <- c

colnames(data4.3) <- c

colnames(data4.4) <- c

DataVP1<- rbind (data1.1, data1.2, data1.3, data1.4)

DataVP2<- rbind (data2.1, data2.2, data2.3, data2.4)

DataVP3<- rbind (data3.1, data3.2, data3.3, data3.4)

DataVP4<- rbind (data4.1, data4.2, data4.3, data4.4)

\#Transfer Pixel to a -0.5 to 0.5 scale

DataVP1$""Target Position"" <- DataVP1$""Target Position""/2560-.5

DataVP2$""Target Position"" <- DataVP2$""Target Position""/2560-.5

DataVP3$""Target Position"" <- DataVP3$""Target Position""/2560-.5

DataVP4$""Target Position"" <- DataVP4$""Target Position""/2560-.5

DataVP1$""Guess Position"" <- DataVP1$""Guess Position""/2560-.5

DataVP2$""Guess Position"" <- DataVP2$""Guess Position""/2560-.5

DataVP3$""Guess Position"" <- DataVP3$""Guess Position""/2560-.5

DataVP4$""Guess Position"" <- DataVP4$""Guess Position""/2560-.5

DataVP1$""Difference"" <- DataVP1$""Guess Position"" - DataVP1$""Target Position""

DataVP2$""Difference"" <- DataVP2$""Guess Position"" - DataVP2$""Target Position""

DataVP3$""Difference"" <- DataVP3$""Guess Position"" - DataVP3$""Target Position""

DataVP4$""Difference"" <- DataVP4$""Guess Position"" - DataVP4$""Target Position""

idx1 <- which (DataVP1$Trial<200)

idx2 <- which (DataVP2$Trial<200)

idx3 <- which (DataVP3$Trial<200)

idx4 <- which (DataVP4$Trial<200)

DataVP1 <- DataVP1\[-idx1,\]

DataVP2 <- DataVP2\[-idx2,\]

DataVP3 <- DataVP3\[-idx3,\]

DataVP4 <- DataVP4\[-idx4,\]

DataVP1$VP <- factor(DataVP1$VP)

DataVP1$Trial <- factor(DataVP1$Trial)

DataVP1$Score <- factor(DataVP1$Score)

gg <- ggplot(data=DataVP1\[1:400,\] , aes (x=""Target Position"",y= ""Guess Position"")) +

  geom\_point(colour = ""gray91"", shape=1, size=1, alpha=.4, stroke=.2) +

  geom\_smooth(method = lm, se= FALSE, colour = ""firebrick"" )+

  scale\_x\_continuous(""Target"", breaks=c(-0.5, 0, 0.5), expand = c(-.5,.5)) + 

  scale\_y\_continuous(""Guess"", breaks=c(-0.5, 0, 0.5), expand = c(-.5,.5))+

  coord\_fixed(ratio=1, xlim=c(-0.5,0.5), ylim=c(-0.5,0.5)) + 

  ggtitle(""A"") +

  theme\_bw() +

  theme(plot.title = element\_text(size = 25, face = ""bold""), axis.title = element\_text(size=20), axis.text = element\_text(size=15))

print(gg)

The Dataframe(DataVP1) looks basically like this : 

215

1

215

\-0.18023203125

\-0.158203125

0.02202890625

0

216

1

216

\-0.02453125

\-0.031250000

\-0.00671875

0

217

1

217

0.0277109375

0.039062500

0.0113515625

0

218

1

218

0.22152734375

0.239453125

0.0179257812500001

0

219

1

219

\-0.0158828125

\-0.020312500

\-0.0044296875

0

220

1

220

0.21695703125

0.197656250

\-0.01930078125

0",New to R and R-Studio and i am absolutly frustrated,90por2,new
"I'm using this example for my own project:

[http://www.sthda.com/english/wiki/text-mining-and-word-cloud-fundamentals-in-r-5-simple-steps-you-should-know](http://www.sthda.com/english/wiki/text-mining-and-word-cloud-fundamentals-in-r-5-simple-steps-you-should-know)

Everything is going well except that the cloud is not shaped like a cloud. It's rectangular, and it cuts words off mid-word.

I've looked online and so far haven't found anything that quite addresses this problem.

My txt file is definitely not too big, just 30 different words and 236 words altogether.  

Thanks in advance for any help you can provide :)","word cloud is not cloud-shaped, it's rectangular",90j1w0,new
"I've had trouble with over fitting while doing MLR so I coded my own function. I thought I'd share it: https://textsave.de/text/VU1rHhkcGPNfjSR8

Input: ""x"" is a matrix containing the predictors, ""y"" is a vector containing the observed values, and ""scales"" is a Boolean variable. If ""scales"" is set as ""TRUE"", 4 different models will be evaluated: the original one, a logged model where values are between 0 and ln(2), an exponential model where values are between 1 and exp{10}, a normal model where the variables have been normalised via a Yeo-Johnson transformation, and a combination of all 4 previous models.

Output:

vector: the vector ""v"" such that x %*% v ~ y

matrix.short: the reduced matrix ""x"" such that predictors that weren't considered are cleaned off

vector.short: analogous the matrix.short, but with ""v""

The rest is self-explanatory, i.e.: ssr, x.fitted, ect.

Methodology:

Recursively chooses the best vector so that adding a predictor minimizes the SSR. The Pseudo-Inverse is calculated via block matrix inversion / Sherman-Morrison formula in order to speed up the process. The process stops when the Adjusted R2 no longer increases.",Multiple Linear Regression R code with optimal Adjusted R^2,90ikh5,new
"Is there a way to quickly get the dimensions of .tif images without loading them into memory? The images in question are gigantic and numerous. Doing this is possible in command-line ImageMagick through *identify*, which only examines the header. However, the magick package implements *identify* in a weird way and the corresponding *image\_info* function requires the image to be loaded into memory.

Is there an R package or base function that retrieves tif image dimensions without fully loading the image?",Way to get tiff dimensions without loading?,90i3wc,new
"I  am  trying to run a  linear  regression model on the GUI of R -  commander   but I get  this error: ''ERROR\_ OBJECT REGEL MODEL1  (NOT  FOND)''

ERROR:  REGEL.MODEL.1 IS NITCHT MORE (NO MORE)  DISPOSABLE

ERROR :  ''I CANNOT  FIND  LM  FUNCTION''

Why   these  errors?",R problems help,90hv8w,new
"I read this answer : [How to control number of minor grid lines in ggplot2?](https://stackoverflow.com/questions/12793577/how-to-control-number-of-minor-grid-lines-in-ggplot2) which is almost exactly what I need.

Although I couldn't figure out a way to reconcile it with my requirements.

I want there to be a way to input the number of minor gridlines between two major ticks. (or the ratio of the minor to major grid size) Say I want to divide it into 5 parts (4 minor gridlines). How do I do that?

Since there will be many graphs, of which I wouldn't know the axis limits, I can't explicitly define the size of one minor gridline step. I want to use whatever algo ggplot2 uses to pick the number of major gridlines, and just have 4 times as many minor ones.

[I'd like the r graph on the right to look like the excel graph on the left.](https://i.stack.imgur.com/53E3y.png)


CODE (in case that helps solve the issue)

    ggtheme <- theme(axis.line = element_line(size = 0.5, colour = ""black""), 
    panel.background = element_rect(fill = ""white""),
    panel.grid.major = element_line(colour=""grey90"",size = rel(0.5)),         
    panel.grid.minor = element_line(colour=""grey95"",size = rel(0.25)));

    ggp_sctr2 = ggplot( sub2_ac_data, aes(x=(sub2_ac_data[,i]), 
    y=sub2_ac_data[, rescol], colour =     factor(sub2_ac_data[,topfac[1]]), 
    shape = factor(sub2_ac_data[,topfac[1]])  )) + geom_point(size = 2.5) +
    scale_shape_manual(values=symlist[Nmsn_sub1+1:20])  + 
    scale_colour_manual(values = unname(cols[Nmsn_sub1+1:16])) + 
    geom_smooth(method=""lm"", formula = y ~ splines::bs(x, 3),  
    linetype = ""solid"", size = 0.25,fill = NA ) 

    print(ggp_sctr2 + ggtitle( paste(scxnam[1],nomvar,
    ""vs"",colnames(sub2_ac_data[i]),i, sep = "" "")) + 
    theme(axis.text.x=element_text(angle = 90, hjust = 1,vjust = 0.5,size=8)) + 
    labs(x = colnames(sub2_ac_data[i]), y=colnames(sub2_ac_data[rescol]), 
    colour=colnames(sub2_ac_data[topfac[1]]), 
    shape=colnames(sub2_ac_data[topfac[1]])) + ggtheme + 
    theme(plot.title = element_text(face = ""bold"", size = 16,hjust = 0.5))) ;",Change number of minor gridlines in ggplot2 (per major ones)?,90g1zz,new
I’m making a notebook using the IRkernel on jupyter and wanted to know if there is anything like ipywidgets for R. I want to have widgets like text boxes or dropdown menus that give the user the flexibility to interact with the notebook.,How to use widgets in R kernel on jupyter notebook?,90fcek,new
"Hi! I'm a beginner R user and working on an interesting exercise: I have to predict which service will be degraded by an incident based on some categorical data (IDs of machines where the incident happened). I have like thousands of these ids and in an incident one or more of them is affected. I'm not sure that using dummy variables is the best method... I can convert the IDs to unique numbers, but won't that affect the precision of the model? (Like one service is degraded when ID 12 and 5 are down, and another service is degraded when ID 10 and 7 is down...) I plan to use knn or random forest for the solution. Many thanks in advance for your ideas!",Best way to handle categorical variables for classification?,90dexy,new
"Hey all,

so I recently used HTMl tab to write a script to scrape data off of some tables on various sites and it worked really well.  Today, I tried to write a similar script for a different website but kept getting no data in the table I was trying to create.  To troubleshoot, I went to my old script which to my surprise was generating similar problems and sometimes just couldn't even find the table on the URL at all.  Has anyone been having similar problems?  Could it be the package updated?  I did update Rstudio but also tried the old version which didn't work as well",Problems with HTMLtab?,90bmg1,new
"gsub is giving me a problems. What I want to do is somewhat meta. I want to escape regex string patterns so special regex characters are interpreted as literals. i.e. `t(es)t` -> `t\(es\)t`. So for every regex special character, I try to do the replace.

    gsub(""\\("", ""\\\\\\("", ""test("")

But no matter what I do, I get even number of backslashes in result.",String replace and backslashes,9040fm,new
"Lets say I have a value composed of a,b, and c, which can only be the values 0 and 1. This number is made up in the following scheme: abc, so that for instance one combination could be 100, or 101, or 011 etc. 

How can I sum up all the possible combinations of these values in R? 

 I have been tinkering around in R, but with no such luck. I have tried a complex series of for loops. This was an exercise in futility. I then summed all numbers from the lower bound of 000 to the upper bound of 111 and then I have tried to remove all values that contain any digits other than 0 or 1. This proved challenging. Any answers would be appreciated. ",Complicated Summation,902mou,new
"I applied to the company where they sent me the coding challenge in R, python and Django. I'm very good at python, not so good at Django, but I haven't used R for four years and I completely forgot everything. I need to do as best as possible, to get an interview. I'm not asking to do the challenges for me, I just need a little guidance. due date is by tomorrow. This is a very first time a company actually some company got back to me after applying to about 500+ companies in the last 3 months. Please someone save me. I'll be up all night probably trying to do this stuff. There are 12 pretty questions, but It's taking me pretty long to read R docs, and they are barely descriptive. 

If anyone can point me to the right tutorials, or websites for the following topics for the beginner I'd also appreciate, if you are not able to help:

simple functions in plyr and dplyr packages to pull out certain rows and do computations with them.

calculating number of unique values in certain columns using purr package,

making functions that return other functions,

drawing plots, saving it to a variable.

and others
",Can someone help with R coding challenge?,8zzhk6,new
"I have two dataframes each organized by date and time (using lubridate, they are ""as_datetime"" objects). However the df lengths are different and none of the times match. 

The first data frame has page views associated with the dates (length=39)

The second data frame has clicks associated with the dates (length=15). 

But I want these data in the same df so that I can analyze the time between clicks. It would be fine if NAs appear in subsequent columns where no data is available. 

Thank you in advanced for your help.  ",Combining two dataframes by date and time where the date/time column is ordered and missing values are NA?,8zxqpb,new
"Hi all,


I have a data frame of NBA basketball data in data frame nba


I'm experimenting with beginner things such as




    nba[team==""Brooklyn Nets"",] #return all row of data for brooklyn nets players
    nba[team==""Brooklyn Nets"",c(""name"",""salary"")] #return all brookyln nets players for column ""name"" and ""salary""



I was also experimenting with the ORDER function and it works great on its own



    nba[order(salary,decreasing=TRUE),c(""name"",""salary"")] #return the ""name"" and ""salary"" for the ENTIRE LEAGUE with highest salary on top



This is fine, but I would like to:


1 - Order the ""Brooklyn Nets"" (1 team) by highest salary (""Who has the top salary in the Brooklyn Nets?"")


2 - Find the top salary for each team 




Appreciate any help, Thanks",Beginner Question: Filtering and Ordering in a Data Frame,8zx2w0,new
"Yes, I posted earlier, but I deleted it because I'm much closer now and just need some help on the homestretch! Anyone who solves it will get gold.

So I have a script that I run, with the final data frame called `sandwich`. It creates a CSV file in the end, as such:

    currentDate <- Sys.Date()
    
    csvTest <- paste(""/Users/joesmith/test_file_"", currentDate,"".csv"",sep="""")
    
    write.csv(sandwich, file = csvTest, row.names = FALSE)

This creates a file called `test_file_2018-07-17.csv` in the local folder `/Users/joesmith`

But for the next step, I need to use the `RCurl` package to send it to an FTP server. 

To do that, I have the following script written out:

    library(RCurl)
    
        ftpUpload(what = ""test_file_2018-07-17.csv"",
                  to = ""ftp://ftp.infores.com/jsmith/Up/test_file_2018-07-17.csv"",
                  verbose = TRUE,
                  userpwd = ""jsmithftp:abc123xyz"")


(**Note: All these usernames, passwords, etc... are all fake, so I'm not posting anything confidential or breaching anything security related**)

But when I run it I get this error:

    TCP_NODELAY set
    * Connected to ftp.infores.com (170.111.111.11) port 21 (#0)
    < 220 Microsoft FTP Service
    > USER jsmithftp
    < 331 Password required for jsmithftp.
    > PASS abc123xyz
    < 230-Welcome to ftp.infores.com
    < 230 User jsmithftp logged in.
    > PWD
    < 257 ""/jsmithftp"" is current directory.
    * Entry path is '/jsmithftp'
    > CWD jsmithftp
    * ftp_perform ends with SECONDARY: 0
    < 550 jsmith: The system cannot find the file specified. 
    * Server denied you to change to the given directory
    * Connection #0 to host ftp.infores.com left intact
    Error in function (type, msg, asError = TRUE)  : 
      Server denied you to change to the given directory

Does anyone know how I can fix this or troubleshoot this?
",Keep getting server denied error when pushing file to FTP with RCurl (whoever can solve it gets gold!),8zntq5,new
"Ive used rstudio in windows and tried to put it on Mint. I have R-base installed and can use it from the command line, and I also have rstudio installed. It will not open though. If I try to open it either from the gui or command line nothing happens, no message is returned to me. Not sure what is going on. ",Rstudio wont open in Mint,8zht12,new
"Hi all, 

Can anyone recommend any packages or tools that would count and tag the number of words in a paragraph? So for instance: 

Pre-processing a paragraph might look like this. 

And another like this. 

*But post-processing*

Pre-processing a paragraph might look like this (7). 

And another like this (4).

Or similar. 
",Any packages for counting and tagging paragraph lengths?,8zh57h,new
"As far as I understood CRAN doesn't allow them, but what about Bioconductor?

Thanks",Are C shared libraries (.so) allowed on Bioconductor ?,8zbvu2,new
"I'm an undergrad in a human genetics lab which likes to use computational biology as well as wetlab for research. During the upcoming year I will be analyzing a lot of bacterial DNA sequences that have been previously extracted from mouse stool. I want to figure out how to construct a bacterial profiles and know what other cool things I could do with R using this data (and maybe other languages/software, if you know any). 

I have previously taken an introductory statistics course which used R, and that is basically my only experience using it.  I have no previous serious coding experience. Of course I would like to have a thorough understanding of the R language, although I am in need of guidance to what (possibly shorter) path to take in this as I would like to be ready in about 2 months when the academic year starts.

Currently I am following through a Udemy course called ""Master Data Science in R"" but it just seems that it is too broad for my needs (and it bored me pretty easily, maybe books/YT videos are better?). Right now I'm pushing through the initial sections, and thinking ""When am I gonna get to the stuff?"". I was recommended to follow ""Advanced R"" by Hadley Wickham. I'm going to give it a shot, but the word  \~advanced\~ sorta feels scary for a newbie like me. 

What do you think? I have never taught myself a programming language, so all help/advice is appreciated!!! :)",New to R. Advice on Analyzing Microbiome Data?,8z3z6h,new
"Hi everyone,

I've been trying to process microarray data in R using the following guide: [https://wiki.bits.vib.be/index.php/Analyze\_your\_own\_microarray\_data\_in\_R/Bioconductor#Loading\_packages\_in\_R](https://wiki.bits.vib.be/index.php/Analyze_your_own_microarray_data_in_R/Bioconductor#Loading_packages_in_R)

Are there any other resources that could help me accomplish this on my own? I've been struggling to find a quality resource on the internet.

Thanks!",Processing Microarray Data,8yuzm8,new
"Title pretty much says it all. Difficult to spot a dark cursor on a dark background (which I prefer). I assume there's  a way to change the color of the cursor, but I can't find anything in the usual menu settings in RStudio. Any insights?   


Thanks.",Changing color of cursor in RStudio?,8ysfu7,new
"I am trying to plot ~10000 points with labels and not have the labels overlap. I tried everything in Python and there does not seem to be a solid solution. 

I've been using pyplot to make the plots and it can do 10000 points with labels no problem, the issue is that many of the labels to the points overlap.

There is package called adjustText to change the positions of the labels so that they don't overlap, but seems to handle at most 3500 points, anything beyond that and Google Colab is not able to process the graph before the time limit for a session is up (12 hours), even on GPU mode.

I am looking to see if there is anything R can do for this situation. ",How possible is it to plot 10000 points with non-overlapping labels in R within a reasonable time?,8yqqt3,new
"Hi everybody, I'm trying to run a log-log model linking the price of the houses with the age:

logprice <- log(hp$price)

logage <- log(hp$age)

hp\_loglog <- lm(logprice \~ logage, data=hp)

but I encounter an error due to the fact that the result of some log transformations is -Inf. Is there a way to exclude those values or anything else to make the model run smoothly?",Log Transformation problem (log-log model),8ylplc,new
"I run into the issue where when plotting data data points on a DV versus time graph, the data points at time 0 get layered under the y-axis. Is there a way to ensure that the data points appear on top?

As for why I want it this way, I'm trying to automate certain graphing parts of my job, and my PI prefers a particular graphing/statistical software (GUI-based, which does not lend itself well to automation). However, this is also how most other graphing software I've seen do it anyways (GraphPad, SigmaPlot, and even Excel). I've replicated the aesthetics of the plots from his software fairly well, with the exception of this last issue. 

thanks!",GGplot2: layering data points on top of y-axis rather than underneath,8ycnav,new
"I'm trying to PDF some figures that have a primary and secondary axis. I set the margins so that the secondary axis label shows up correctly in the plots window (I'm using R studio) but when I actually start the graphics driver and save to a pdf the secondary axis label gets cut off. I've tried adjusting the height and width of the pdf output but this hasn't changed anything and there doesn't seem to be a margin option.

Here's some skeleton code:

par(mar = c(5, 4, 4, 4) + 0.3)

pdf(filename,width=12,height=8,paper='special')

plot(df1)

par(new=T)

plot(df2, axes = FALSE, bty = ""n"", xlab = """", ylab = """")

axis(side=4, at = pretty(range(df2\[,2\])))

mtext(""Label"", side=4, line=3)

dev.off()",Secondary axis cut off from figure when PDFing,8ycc6z,new
"Hi all, I'm in a situation where I have some free time at work and would like to allocate it to learning R.


Only problem is, I won't be able to install RStudio because of installation restrictions. Reading R books and PDF are fine, and I've been learning a lot form doing so already but I've like to get some practice typing/writing out codes and testing examples from the books in R/Rstudio.


Is there a version of R, say in the browser, where I don't have to install anything? I heard about R server but that requires set-up/installation and unfortunately won't be doable for my situation.


Any thoughts/input on getting access to R/Rstudio to practice some codes without set-up/installation would be appreciated. Thanks",Learning R at Work?,8y9qd6,new
"I have to make a subset that includes only the top 20 item that have count >5 sorted by lift. I was only able to get the top 20 sorted by count >5. How do i get also sorted by lift as well.
This is what I put: 
subrules <- subset(myrules, subset=count>5 )
a<-head(sort(subrules,by=""lift"",),20)
inspect(a)
What else do I add?
Here Is my current output:https://imgur.com/a/GaDRE9P",I need some help for sorting within a subplot?,8y7zgn,new
"Im trying to plot the results after running the boruta package to my data but I cant seem to add x and y axis labels.

im following this code [here] (https://imgur.com/a/LyS3dve)


and [here](https://imgur.com/a/saeD5VL) is my code 

and [here](https://imgur.com/a/mLNGDtw) is the result that Im getting


could anybody point out what seems to be wrong?",plotting boruta results,8y3c20,new
"I'm building a package that relies on the execution of other binaries (I build them too). According to the 'Writing R Extensions' manual, packages that include binaries are not accepted on CRAN. What is the best practice for such cases ? My current plan is to host the binary on GitHub and fetch it through the 'download.file' function, would that be OK ?

Thanks",including external binaries in package,8y37ao,new
Talking Android here. I have my R textbook on the go and I would love to mess with things as I read about them. ,Are any of the R language phone apps good?,8y2csy,new
"Hello all!

I am working on creating some assessments for Blackboard, a learning management system (LMS) my school uses. I am following the [tutorial](http://www.r-exams.org/tutorials/exams2blackboard/), but am running into difficulty getting things to work. As I work through the example code, I run into a problem when I run exams2blackboard. I get the following error:

`> set.seed(1234)`

`> exams2blackboard(myexam)`

`Error in xexams(file, n = n, nsamp = nsamp, driver = list(sweave = list(quiet = quiet, :`

`Cannot create temporary work directory 'C:\Users\ark56\AppData\Local\Temp\Rtmp4K8Qw6\file5bf055852f0a'.`

`In addition: Warning message:`

`In dir.create(dir_temp) :`

`cannot create dir 'C:\Users\ark56\AppData\Local\Temp\Rtmp4K8Qw6\file5bf055852f0a', reason 'No such file or directory'`

I'm not the best at digging into issues like this, so any help would be appreciated!",Having Trouble with the exams package (X-Post on r/rprogramming),8y1lte,new
I have some trouble installing packages from git hub (gganimate) and I think it's because R tools is not compatible with the newest version of R. Does anyone know how long time it usually takes for a new version of Rtools to get out?,R tools for version 3.5.1,8xp70n,new
I’m pretty new to scraping but I have successfully used rvest before although it’s not working for this.  So I was wondering if there is some trick or another package to use for scraping dynamic websites? ,How to scrape dynamic website?,8xh7x1,new
"I am just getting into R and bought R for Everyone. The book suggests using RStudio, but I am used to Atom. Thoughts are appreciated! ",What IDE do you use for R?,8xeufu,new
"Hello all,

I’ve been using mlr a little to learn about machine learning, but recently found out about caret.

The way I understand it is that both are wrappers to various ML packages, but have slightly different approaches. Although mlr appears to also wrap some things from caret - so maybe we can sort of consider mlr a superset of caret.

I’m of a mind to stick with mlr for that reason, to save having to switch or learn both. But I’ve also heard the author of caret has joined the tidyverse guys - so maybe this will become the de facto standard now. 

Any views on the pros/cons of the two packages, which covers more stuff, which has a more streamlined approach, which is more flexible/easier etc etc?",mlr or caret,8x0e1i,new
"I am trying to conduct a meta analysis of a group of studies. I am trying to figure out the code to properly output what I would like. Essentially  I am trying to run a fixed effects meta-analysis test using the \`metafor\` package and collect the  coefficient estimates to store them inside a matrix. 

I have several problems. For example, I want to run these tests only for research that have multiple results. So studies whose study numbers turn up more than once (see code for example). When I try this using my existing code, it does not work, it spits out a number, but it isn't the right one. Also, some study-numbers are larger than the actual amount of studies I have. In my personal dataset there is a study numbered 3500 for example. When I run my loop, R spits out the results for that particular fixed effects model on the 3500th row, instead  of just placing it in the next empty row.

I have a basic example below that anyone can run in R.

library(metafor)

origdata <- data.frame(matrix(data=NA, nrow=15, ncol=3))

colnames(origdata) <- c(""studynum"", ""Mail\_b"", ""Mail\_SE"")

origdata$studynum <- c(1, 1, 1, 1, 1, 2, 3, 3, 3, 4, 7, 7, 7, 7, 7)

origdata$Mail\_b <- c(1.8, 0.8, 1.2, 1, 1, 5, 3, 3, 6, 4, 5, 8, 5, 9, 2)

origdata$Mail\_SE <- c(1.6, 0.8, 1.3, 1, 1, 1, 3, 2.9, 6, 4, 5, 8, 5, 8, 1)  

collapsedtest <- data.frame(matrix(data=NA, nrow=5, ncol=3))

colnames(collapsedtest) <- c(""studynum"", ""Meta\_b"", ""Meta\_SE"")

collapsedtest$studynum <- unique(origdata$studynum)

for(i in unique(origdata$studynum)) {

if((table(origdata$studynum) == 1) == FALSE){

collapsedtest\[i, 2\] <- (coef(summary(rma(yi=Mail\_b\[origdata$studynum == i\], 

sei=Mail\_SE\[origdata$studynum == i\], 

method=""FE"", 

data=origdata)))$estimate)

collapsedtest\[i, 3\] <- (coef(summary(rma(yi=Mail\_b\[origdata$studynum == i \], 

sei=Mail\_SE\[origdata$studynum == i\], 

method=""FE"", data=origdata)))$ci.ub 

\-

(coef(summary(rma(yi=Mail\_b\[origdata$studynum == i\], 

sei=Mail\_SE\[origdata$studynum == i\], 

method=""FE"", 

data=origdata)))$estimate)) / 1.96

} else {

collapsed\[i, 2\] <- origdata$Mail\_b\[origdata$studynum == i\]

collapsed\[i, 3\] <- origdata$Mail\_SE\[origdata$studynum == i\]

}

}",conditional for loop for meta analysis,8wswwr,new
I’ve been thinking about Dvorak lately and was wondering if there’s one that’s especially good for R coding. Thanks!,Anyone use non-QWERTY keyboard layouts?,8wobim,new
"Are there any tools that automate identifying lines of code that will be getting slower and slower with larger and larger input data, instead of just outputting the time of each line directly?

I know I could manually input sys.time to measure each line to track which ones are getting slower and slower, to make sure I catch any line that may be contributing to non-linear time complexity.  

There may be some places in my code where vectors are being reallocated instead of appended to, etc.,  so I just want a tool to measure and confirm this.

I was hoping some profiling tool existed that would have this functionality built in, but based on my research so far haven’t found anything. I have never used a profiler in R though so I could be missing something. ",How to analyze time complexity with profilers,8wl3h6,new
"Hey everyone, got a pretty nice website going on, but I was wondering if anyone had ideas on how to implement a ""random post"" \[\[menu.main\]\] function. If this is more of an html question I understand, but nothing I've looked at really helps because other sites already have shortcuts/plugins to do it. Any ideas to do this with my blogdown files?",Quick Blogdown Question,8wgmdi,new
"How do I go about building recommendation engines. I have a fair amount of experience with data analysis and some data mining in R and am looking to build a recommendation engine that feeds into a REST api. Are there any good books or tutorials on doing this?

",Recommendation Engines in R,8wbkcc,new
"Working in the poliscidata that comes with r studio and for my final I have to make my own hypothesis, which is, left leaning females are more likely to be accepting of gays. The data sets are nes$gender nes$gay_marry and nes$pid3 (which I used a true false formula to detect if dem and renamed that to nes$dem) 
I can see the how many females are demicrats by doing a function with nes$gender and nes$dem 
I can also see how many females or democrats are accepting of gays by using the corresponding formulas.
But for my graph I need to find female democrats in one formula.
I’ve tried stuff such as 
freqC(~nes$dem + nes$gender, ~nes$gay_marry)
But get an error message shot back at me.
How do I make it search graph female democrats with gay marriage approval.
As I said I can create a graph 
of how many males/females are ok with gay marriage
Dems that are ok with gay marriage
And how many males/females are democrats 
But I can’t find out how to do female democrats for gay marriage 
Thanks for the help",Please help need to combine two data sets,8wbhz2,new
"Is there a tool similar to mypy, but for R? I would like to gradually annotate existing code (e.g. with comments or in some other way that doesn't change its runtime behaviour) and then check the code for type errors without running it. The only package I've found that is kind of similar to what I need is rtype, but it solves a rather different problem (and requires that I actually run the code). I also know that RStudio performs some kind of static analysis and can detect things like missing arguments, but I don't know how to accomplish what I need with RStudio either. I understand that writing a checker like that is hard. To be useful, it would need to know the types not only for R base but also for third party packages, which weren't written with static typing in mind. But maybe something like that exists. I would appreciate any hints.",A static type checker for R?,8w80ke,new
"I am often using knitr to create PDF files (R-markdown) and will use print() statements throughout my chunks. Problem is, these statements will sometimes run-off the page in the final PDF.

How can I control this? 

Thank you!",Knitr/PDF: Keeping printed text on page,8w2846,new
"Hi,

How can I approximate the Y axis line from the first value on X axis? 
[Here's a example of how the chart is now[1]](https://imgur.com/HPHJJwO) and[ how I would like it to be.[2]](https://imgur.com/dDXqMoj) 





Script for reproduce the chart: 
    
    library (ggplot2)
    
    QTD <- c(""11"",""10"",""9"",""13"",""15"",""12"",""10"")
    DATE <- c(""2018-01-01"",""2018-01-02"",""2018-01-03"",""2018-01-04"",""2018-01-05"",""2018-01-06"",""2018-01-07"")
    
    dataset <- data.frame(DATE,QTD)
    
    p<- ggplot(dataset, aes(x = DATE, y = QTD, group = 1)) + geom_line()
    
    p
 
Thanks!",Approximate Y and X axis on ggplot2,8vxfg5,new
"I'm extremely unfamiliar with RCurl and I've tried putting something together that pushes a script to an SFTP but have failed many times now. Here are the specs:

(None of this is actually my real info, obviously)

File name (locally): /Users/jsmith/test\_0704.csv

Password: fogj4of0w

Uploading to: ftp://jsmithftp@ftp.com

So what exactly would this look like using the RCurl package?",Pushing something to the sftp via RCurl (help!),8vsunj,new
"I'm having trouble in converting a cURL request into an httr post request, when communicating with the Zendesk API. I've successfully pulled data from the API, but posting is so far proving problematic.

The cURL example from the documentation is as follows (all sensitive information replaced):

curl https://{subdomain}.zendesk.com/api/v2/nps/surveys/{survey_id}/invitations.json  -d '{""invitation"": {""recipients"": [{""name"": ""Ed C"", ""email"": ""example@subdomain.com"", ""language"": ""en-US""}]}}' 
    -H ""Content-Type: application/json"" 
    -v -u {your_email}/token:{your_api_token} -X POST

My cURL knowledge is very limited, but I believe I am contacting the API correctly with the below script (again, all sensitive information replaced):

r2 <- POST('https://{subdomain}.zendesk.com/api/v2/nps/surveys/{survery_id}/invitations.json'
          ,add_headers(Authorization=""Basic {api_key}"")
          ,body  ='{""invitation"": {""recipients"": [{""name"": ""Ed C"", ""email"": ""example@subdomain.com"", ""language"": ""en-US""}]}}'
          ,encode='json'
)

I've scoured Stack Overflow repeatedly, as well as other sources, but haven't found a situation applicable to my issue so far.

I’ve tested the cURL request in the command line and it works perfectly, so I know now the issue is with my R script. ",Converting cURL to to httr,8vs6ni,new
"I have a .csv with 45 rows and about 13 million columns, all numeric. I can't seem to read it into R. I'm passing the argument

> set <- (""original.csv"", colClasses = ""numeric"", nrows = 45)

The result is a stall. I'm not getting an error, it just seems to try and read the data for an indeterminate amount of time. 

Any tips? 

Thanks. ","Trouble reading ""big"" data",8vibt5,new
"Hi,

I was wondering if anyone knew if Rstudio was capable of viewing data from websites? Specifically I am interesting and view my fantasy football teams website and view peoples rosters and salary cap.

[http://home.myfantasyleague.com/](http://home.myfantasyleague.com/)

This is the website I want to use to view things like teams rosters and team salaries.

Thanks!

Note: [myfantasyleague.co](https://myfantasyleague.co) has this example code, but I am not sure really how to convert it well. I have only just started by R learning so I am just looking for any help I can get. Below is the example code they have provided, but not sure where to start. 

\#!/bin/perl  

\# Set these variables somehow: 

my $league\_id = ""LEAGUE\_ID""; 

my $username = ""USERNAME""; 

my $password = ""PASSWORD""; 

my $year = ""2017"";  

\# Defaults my $proto = ""https""; 

my $host = ""api.myfantasyleague.com""; 

my $json = 0; 

my $req\_type = 'league';  

use HTTP::Request::Common qw(GET);   

use LWP::UserAgent;   

$ua = LWP::UserAgent->new();    

my $login\_url = ""[https://api.myfantasyleague.com/$year/login](https://api.myfantasyleague.com/$year/login)?

USERNAME=$username&PASSWORD=$password&XML=1""; 

my $login\_req = HTTP::Request->new(""GET"", $login\_url); print ""Making request to get cookie: $login\_url\\n""; my $login\_resp = $ua->request($login\_req); 

my $cookie; if($login\_resp->as\_string() =\~ /MFL\_USER\_ID=""(\[\^""\]\*)"">OK/) {     $cookie = $1; } else {     die ""Can not get login cookie.  Response: "" .         $login\_resp->as\_string() . ""\\n""; } print ""Got cookie $cookie\\n"";  

my $url = ""${proto}://${host}/$year/export""; 

my $headers = HTTP::Headers->new(""Cookie"" => ""MFL\_USER\_ID=$cookie""); 

my $ml\_args = qq(TYPE=myleagues&JSON=$json); 

my $ml\_req = HTTP::Request->new(""GET"", ""$url?$ml\_args"", $headers); 

print ""Making request to get league host: $url?$ml\_args\\n""; my $ml\_resp = $ua->request($ml\_req);  

\# find host in the return string - note that this is for illustrating the # API. 

A more robust solution would be to use a proper XML parser. if($ml\_resp->as\_string() =\~ m!url=""(https?)://(\[a-z0-9\]+.myfantasyleague.com)/$year/home/$league\_id""!s) {     $proto = $1;     $host = $2;     $url = ""${proto}://${host}/$year/export""; } else {     die ""Can't find info for league id $league\_id.  Response: "" .          $ml\_resp->as\_string() . ""\\n""; } print ""Got host $host\\n"";  my $args = qq(TYPE=$req\_type&L=$league\_id&JSON=$json); my $req = HTTP::Request->new(""GET"", ""$url?$args"", $headers); print ""Making request to get league info $url?$args\\n""; my $resp = $ua->request($req); print ""\\nLeague Info:\\n""; print $resp->as\_string();  print ""\\n"";",Fantasy Football Data,8vbe23,new
" Hi everybody, I'm a newbie with R. I would like to know how to increase the digits displayed with the summary function after creating a multiple linear regression with lm function. Is there a way to show more digits for all the coefficient or, otherwise, single out specific coefficients to see more digits  for each of them? Thanks ",Increasing the number of digits displayed,8vac9u,new
"Hi,

I am having trouble finding this on google. I wast to point to the location of my R interpreter on windows for pycharm.

It looks like there is a folder:

C:/Users/myusername/Documents/R/win-library/3.4

but its a busy folder and I am not sure if the interpreter is in there or not. Please help if you can, I tried googling first but am a bit stuck. 

",How to find the location of my interpreter on windows,8v5t6v,new
"I am running a model (lmer) model in lme4 

Then getting standardized coefficients with 
lm.beta.lmer <- function(mod) {
  b <- fixef(mod)[-1]
  sd.x <- apply(getME(mod,""X"")[,-1],2,sd)
  sd.y <- sd(getME(mod,""y""))
  b*sd.x/sd.y
}


But how do I get 95% CI for those standardized coefficients? 

Maybe I should be getting my standardized coefficients directly through the model...",95% confidence intervals for standardized coefficients for lmer model in lme4,8uxfav,new
"I have a bunch of geom_smooth() plots that are overlaid but am struggling to create a legend which labels each plot. Any ideas?


Code looks something like this:
ggplot(data=x) + geom_smooth(...) + geom_smooth(...) + ...",Showing legend with overlaid plots?,8uwmys,new
"I have all the makings of a website. It builds fine in RStudio, but when i use Netlify it simply doesn't recognize .Rmd files. It'll do .md files fine (but not what I use). I have tried so hard to find any answer, but no one else has this issue where I've committed everything to github, the files are in the public folder, etc. It just doesn't want to read them and I don't know why. Any help would be greatly appreciated",I can't find this blogdown answer anywhere,8uqanh,new
"I've got an R script that I wrote locally that looks like below. When I run it locally, it works totally fine.     

    library(rJava)
    library(RJDBC)
    library (RPostgreSQL)
    
    URL <- 'https://s3.amazonaws.com/athena-downloads/drivers/AthenaJDBC41-1.1.0.jar'
    fil <- basename(URL)
    if (!file.exists(fil)) download.file(URL, fil)
    drv <- JDBC(driverClass=""com.amazonaws.athena.jdbc.AthenaDriver"", fil, identifier.quote=""'"")
    con <- jdbcConnection <- dbConnect(drv, 'jdbc:awsathena://athena.us-east-1.amazonaws.com:443/',                                  
                                       s3_staging_dir=""s3://aws-athena-query-results-XXXXX-us-east-1"",
                                       user= ""XXXXXX"",
                                       password= ""XXXXXX"")

The problem arises when I copy it over to `nano` on the server setup through my work. 

[So it looks like this.](https://i.stack.imgur.com/JLA12.png)

The reason I only posted those lines is that the last line is where the problem comes up.

When I run it, this error comes up:

`Error in .jfindClass(as.character(driverClass)[1]) : class not found
Calls: JDBC -> is.jnull -> .jfindClass`

Does anyone have a solution to this?",Works locally for me on R but not on my server,8ujern,new
"Hi Guys! I'm working on a data analysis project but my knowledge on R is quite limited. I wanna see if this would work by using R.   


I have a name to google search, let's say ""Donald Trump"". I want to find the top 10 keywords associated with ""Donald Trump“. Is that possible? If yes, any open source i can refer to? Thanks!",Google search_R Language,8ug1le,new
"So I'm using these three packages in R in order to connect to some databases and query them:

    library(rJava)
    library(RJDBC)
    library (RPostgreSQL)

    id_query <- dbGetQuery(conn2, ""SELECT b.id id FROM table1 a LEFT JOIN table2 b ON a.id = b.id WHERE a.id = 1684 AND b.id <> 40378;"")

This produces an output as such:

    id
    25559
    30352
    15352
    17587
    16480
    16296
    40449
    34962
    25827
    37282

But then I want to take those results and paste them into a `WHERE` clause that uses `IN`

    results_query <- dbGetQuery(con, ""SELECT
    i.event_date,
                                  i.id,
                                  i.id2,
                                  i.id3,
                                  i.id4,
                                  i.id5,
                                  COUNT(i.sales) sales,
                                  COUNT(c.volume) volume
                                  FROM table1 i
                                  LEFT JOIN
                                  table2 c
                                  ON i.id = c.id
                                  AND i.id2 = c.id2
                                  AND i.id3 = c.id3
                                  WHERE i.event_date = DATE('2018-06-18')
                                  AND i.id IN (**RESULTS FROM id_query**)
                                  GROUP BY 1,2,3,4,5,6
                                  LIMIT 10
                                  ;"")

So basically, I want it to read like this:

`AND i.id IN (25559,
    30352,
    15352,
    17587,
    16480,
    16296,
    40449,
    34962,
    25827,
    37282)`

I've tried doing this:

    results_query <- dbGetQuery(con,  paste(""SELECT 
                                      i.event_date,
                                      i.id,
                                      i.id2,
                                      i.id3,
                                      i.id4,
                                      i.id5,
                                      COUNT(i.sales) sales,
                                      COUNT(c.volume) volume
                                      FROM table1 i
                                      LEFT JOIN
                                      table2 c
                                      ON i.id = c.id
                                      AND i.id2 = c.id2
                                      AND i.id3 = c.id3
                                      WHERE i.event_date = DATE('2018-06-18')
                                      AND i.id IN ("", paste(id_query$id, collapse = "", ""), "")
                                      GROUP BY 1,2,3,4,5,6
                                      LIMIT 10
                                      ;"", sep = '')

Which yields this error:

    Error in .verify.JDBC.result(s, ""Unable to execute JDBC prepared statement "",  : 
      Unable to execute JDBC prepared statement SELECT
            i.event_date,
                                          i.id,
                                          i.id2,
                                          i.id3,
                                          i.id4,
                                          i.id5,
                                          COUNT(i.sales) sales,
                                          COUNT(c.volume) volume
                                          FROM table1 i
                                          LEFT JOIN
                                          table2 c
                                          ON i.id = c.id
                                          AND i.id2 = c.id2
                                          AND i.id3 = c.id3
                                          WHERE i.event_date = DATE('2018-06-18')
                                          AND i.id IN  ( (Method Connection.prepareStatement is not yet implemented)

Anyone have either:

A.) A solution to fixing my current query OR

B.) An alternative?",Pasting another variables results into my SQL query in R,8ucscs,new
"I have a data set with 2 categorical columns.  I am looking to count how many times there are matching rows.  For example, if 1 column has variables A,B,C and the other one has 1,2,3; I am looking to count A1, A2, A3, B1,...; i.e. how many of each combination there is throughout the data set.
All the best.

Quick edit: the reason I don't do it manually is because one column has 50 different variables and the other has 12.",Need help Counting Data,8uab4e,new
"So I have been  trying to map GTFS info in the leaflet package for R studio for a project. I have been trying many days to come up with a solution but am at a brick wall. I have code to make a map of each individual route ID but because there are almost 200 individual route ids, this is not that useful. I also have code to map things by route\_type which is what I want but that map routes are not correct and many of them are straight lines :/ I have attached my code in a word doc and some pictures. The GTFS data download link is also attached, I am using the Januard 2015 version. I have a feeling it is something with the way I am merging them or ordering them but I am really at a loss.   


    #BY ROUTE
    
    library(tidyverse)
    library(leaflet)
    
    shapes <- read.csv('kansas/shapes.txt')
    
    shapes_simplified <- shapes %>%
    
      mutate(shape_pt_lat = round(shape_pt_lat, 3),
    
             shape_pt_lon = round(shape_pt_lon, 3)) %>%
             distinct(shape_id, shape_pt_lat, shape_pt_lon)
    
    my_map <- leaflet(data = shapes_simplified) %>%
    
      addProviderTiles(""Esri.WorldTopoMap"")
    
    groups <- levels(shapes_simplified$shape_id)
    
    groupcolors <- colorFactor(palette = 'viridis', domain = groups)
    
    for(grp in groups) {
      my_map <- my_map %>%
      addPolylines(data = filter(shapes_simplified, shape_id == grp),
                   lng = ~shape_pt_lon,
                   lat = ~shape_pt_lat,
                   group = grp,
                   color = groupcolors(grp),
                   weight = 2)
    }
    

https://i.redd.it/vbn2g66cif611.png

    my_map
    
    #BY ROUTE TYPE BUT ROUTES ARE STRAIGHT LINES IN SOME CASES
shapes_simple <- shapes %>%
    
      mutate(shape_pt_lat = round(shape_pt_lat, 3),
    
             shape_pt_lon = round(shape_pt_lon, 3)) %>%
              distinct(shape_id, shape_pt_lat, shape_pt_lon, shape_pt_sequence)
    
    routes_simple <- routes %>%
      mutate(route_id, route_type, route_short_name) %>%
      distinct(route_id, route_type, route_short_name)
    
    trips_simple <- trips %>%
      mutate(trip_id, shape_id, route_id) %>%
      distinct(route_id, trip_id, shape_id, route_type, shape_pt_lat, shape_pt_lon, shape_pt_sequence)
    
    t_s_simple<- full_join(trips_simple, routes_simple, by = NULL) %>%
      mutate(trip_id, shape_id, route_id, route_type, route_short_name) %>%
      distinct(route_id, shape_id, route_type, shape_pt_lat, shape_pt_lon, shape_pt_sequence)
    
    M_MAP <- full_join(t_s_simple, shapes_simple, by = NULL) %>%
    
      distinct(route_id, shape_id, route_type, shape_pt_lat, shape_pt_lon)
    
    M_MAP[,3] <- lapply(M_MAP[,3,drop=FALSE], factor)
    
    M_MAP <- filter(M_MAP, shape_pt_lat != ""NA"")
    
    my_map <- leaflet(M_MAP) %>%
      addProviderTiles(""Esri.WorldTopoMap"")
    groups <- levels(M_MAP$route_type)
    groupcolors <- colorFactor(palette = 'viridis', domain = groups)
    
    for(grp in groups) {
      my_map <- my_map %>%
      addPolylines(data = filter(M_MAP, route_type == grp),
                   lng = ~shape_pt_lon,
                   lat = ~shape_pt_lat,
                   group = grp,
                   color = groupcolors(grp),
                   weight = 2)
    }  
    my_map %>% addLegend(""bottomright"", pal = groupcolors, values = ~groups, title = ""Legend"", opacity = 1) -> my_map
    

https://i.redd.it/b82gv9d7if611.jpg

    my_map
    
    ",Need Help with this code-GTFS Leaflet Visualization,8u4q9a,new
"Hi everyone, I am in need of some help with data tidying. I downloaded my conversation with someone on Facebook messenger, but it's output is something as followed:

V1.  
Person A  
Coolcool  
2018-06-25 19:34  
Person B  
See you later  
:D  
2018-06-25 19:34  
Person A  
You called Person B  
Duration: 30 seconds  
2018-06-25 19:19  
Person B  
What's up?  
2018-06-25 19:09  
Person A  
Hey!  
2018-06-25 19:09  
    
They're all in one column, but I'm trying to make a data frame where the speaker is in one column, the message is in another, and the date would be in another. 
The problem that I'm facing is that, sometimes, the message is in two rows, so I can't just split the whole column into three columns. What would be the best solution to this?
Appreciate any help with this :)",Data tidying help: splitting one column with all the data,8u1gh1,new
"Hi, 

We've just about to have our company website operational which is going to speed things up a LOT. One of them, is the way we display our performance data - will soon automatically get pulled from the backend and hence we will not have to create the charts each time, manually. 

As of now, we've been creating reports with charts etc manually. Now, most of the people we have in the analysis team are comfortable with R and hence the charts we're currently using (apart from basic Excel ones) have been coded on R. However, for the website my Dev has said JS is the best. 

Is there a way I could convert this code into JS? Additionally, does anyone know where I could source the JS code for:

- Heatmaps

- Shot Distribution

- Spider/Radar charts

- Donut charts

- Gauge (speedometer) charts

- Radial bar charts.

TIA.",Need to convert R code of a chart to JS,8tz3pl,new
"When using the plot function, I want to choose the axis sizes myself. How do I do that?","plotting, choosing the x and y axis",8tv63p,new
"I have a vector of varying numbers of A, B, C, D, which I need to rearrange randomly. Is there a way to fix the values of D in place? Eg if I have ABCD I could have ABCD, ACBD, CBAD, CABD, BCAD, BACD?

The actual vectors have a length of around 100 so it isn't feasible to list all combinations like I did above or use sample and remove when they aren't in the right place.",Rearranging a vector but keeping certain values in place,8tq7j9,new
"I have a dataset that looks like this, where the variable 'NewEvent' counts the number of days between events occurring for each person in the dataset (if NewEvent=0, then event has occurred). 

Day = c(1:8,1:8)

Person = c(1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2)

NewEvent = c(NA,NA,0,1,2,3,0,1,NA,0,1,2,3,0,1,0)

dat <- data.frame(Person,Day,NewEvent);dat

https://i.redd.it/4rsoqo174z511.png

I am trying to restructure the dataset so that it takes the maximum value BETWEEN events occurring for each person, and copies or fills that value. I want it to look like this:

https://i.redd.it/q6el2fcc4z511.png

Any help would be greatly appreciated!",Data restructuring help: How to identify maximum number of days between 'events' and copy that value,8tito9,new
"Not sure what else to say really. Using ggsave gives me the same result. PNGs are fine but some reason PDFs don't work whatsoever. Any help would be appreciated.

EDIT: **Issue solved** (somewhat, described below).

The root of the problem was me trying to use an imported font and have it exported in a pdf.

A work-around that I discovered (through Googling and the help of other users, not by my own ingenuity) to get R to produce PDFs with or without the desired font type was to use

`ggsave(""Graphs.pdf"", g, device = cairo_pdf)`

where  g is the desired plot to export. For some reason using ""device = cairo_pdf"" brute forces R/ggplot to provide a plot in the pdf.

When I did this it didn't have the font I tried to import, however. It had the regular font. I decided to give up on that and just go with the closest Windows default font I could find and that's good enough for me. Hopefully this helps someone else in the future.","Using RStudio, whenever try to export my graph I get a blank PDF file.",8talhn,new
"Hi all,

Just wanted to pose a general question to other r users outside of my field. I’m an RA doing a masters in ecology. Like many of you, I’ve been using R daily for a couple of years now, and I consider myself pretty darn good at it. Like many r users, I work on really specific things (spatial habitat analyses, wildlife mark recapture analyses etc) that I need to know for the work I’m currently doing. That said, like many other r users, I’ve gotten really good at learning how to do new things in r efficiently which I think is a skill in itself. The job market in the wildlife field is limited.

My question is this: Are there many job opportunities out there for folks doing general data analysis, manipulation, etc in R? Trying to be realistic about my future in this field, and would like to try and expand my horizons if necessary. I’m not a programmer, and any coding I’ve done has been in a statistical setting. Any thoughts?

Also, sorry for the grammar/spelling. I’m currently a little drunk. ",Job opps for folks with solid R coding skills?,8t8hx1,new
"I'm doing the following to pull the top and bottom values from my date/time column https://pastebin.com/raw/DdY9BSB9 but instead of keeping the entire cell value of ""2014-02-17 00:00:00 UTC"" it drops the time value. How do I force it to keep the time and timezone when I'm pulling it? (Also I'm guessing this problem is unique to 00:00:00 times?)  

EDIT: for clarity  

EDIT: As per [this](https://stackoverflow.com/questions/51003927/how-do-i-force-r-to-keep-time-value-when-selecting-date-time-cell) it worked using: format(Angels.rolling$date.hour[1], '%Y-%m-%d %T %Z')",Time lost when selecting date/time cell from data frame?,8t7nkl,new
"We have data coming off our instrument where a few different pieces of information gets smushed together on a single identifier line, and needs to be separated out - but only in certain sample types. Essentially, this:

    type|identifier
    :--:|:--:|
    unkn|Thing 1
    unkn|Thing 2
    unkn|OtherThing 1
    unkn|OtherThing 2
    stnd|High
    neg|Negative Control (Type A)
    neg|Negative Control (Type B)

needs to turn into this:

    type|name|replicate
    :--:|:--:|:--:
    unkn|Thing|1
    unkn|Thing|2
    unkn|OtherThing|1
    unkn|OtherThing|2
    stnd|High| *NA*
    neg|Negative Control (Type A)| *NA*
    neg|Negative Control (Type B)| *NA*

If I use `df %>% separate(identifier, list = c(""name"", ""replicate""), sep ="" "")`, then that splits out the identifier on the controls and makes a mess. I know I could split the data frames by type, manipulate the columns separately, and then reunite them - but that's clunky and weird, and I'm hoping there is a simpler or more elegant solution that I'm missing. 

For various reasons which are probably not good ones but are out of my control, changing the identifier coming off the instrument isn't a viable option. Unfortunately.  ",Applying an action to specific rows only,8t75zu,new
"I have pretty big dataset of 7027 observables and 65 variables with many NAs, and i want to scale the columns.

First i took minimal values and maximal values:

maxs <- apply(year, 2, max,na.rm=TRUE)

mins  <- apply(year, 2, min,na.rm=TRUE)

then i tried to scale them:

scaled <- as.data.frame(scale(year, center = mins, scale = maxs - mins))

and i got following error:  Error in scale.default(year, center = mins, scale = maxs - mins) :

length of 'center' must equal the number of columns of 'x'

but when i check : length(mins)==ncol(year)

\[1\] TRUE

Feel free to ask questions. I tried everything that came to my mind ;\_;

UPDATE ; i cleaned dataset from NAs and the problem still persist",problem with scaling values,8t0a5t,new
"I'm importing a csv that has column named ID that contains an ID number with leading zeros, which I need to preserve.  So I just want to import that as a string.  So here's my code which I swear to god should work

    calpads.csv <- read.csv(""Filepath/filename"", header = T, colClasses = c(""ID""=""Character""))

But I'm getting this error: 

    Error in methods::as(data[[i]], colClasses[i]) : 
    no method or default for coercing “character” to “Character”

I've also done the thing where I do the vector so that I specify an class for every column and I'm getting the same error.  I feel like this should work!  Am I going Crazy?
",Forcing a column to string in read.csv,8swzs4,new
"Hey all!

I'm learning R for work, just for some basic data wrangling and manipulation. I'm having a trouble combining columns for manipulation, would love to do this in R and not pull it out to excel as this will be a repeated task. Any guidance is appreciated but if there's a dplyr answer that would be best!

I need to combine multiple columns into 1 column with all values stacked. So if I have 2 columns with 2 rows -> 1 column 4 rows. 

Example 
a     b
1      3
3     5

Becomes 
a
1
3
3
5

Thanks in advance for the help!
",How to combine columns (dplyr preferred),8so1d9,new
"Hi everyone, I am trying to create an LDA that looks like this: 

https://i.redd.it/2asdp06nk7511.png

I have followed this: 

    install.packages(""devtools"") 
    library(devtools) 
    install_github(""fawda123/ggord"") 
    library(ggord) 
    ord <- lda(Species ~ ., iris, prior = rep(1, 3)/3) 
    ggord(ord, iris$Species)

I am getting an error with prior and since I don't really know what I'm doing I can't figure out what prior is. 

I have 8 variables and 14 classes

    library(MASS)
    library(RColorBrewer)
    library(ggplot2)
    
    dat.sub <- dat[dat$Year!=""R"",c(1:5,7:10)] 
    
    mod <- lda(Year~., dat.sub) 
    mod
    plot(mod, dimen=3, col=classes,pch=classes)
    ####################################################################################### 
    
    install_github(""fawda123/ggord"")
    library(ggord)
    ord<-lda(Year~.,dat.sub,prior=rep(3,15)/15)
    ggord(ord,dat$Year)
    
    Error in lda.default(x, grouping, ...) : 'prior' is of incorrect length",Linear discriminant analysis biplot with ggord,8slase,new
"At my internship this summer, I did some great data work using R that my boss has found very useful. Is there a way for me to turn it into an easy to use command line tool so all my boss has to do is put the current CSV files in the right folder then run the tool?",Creating easy to use tool,8sixno,new
"Hi everyone,

Using an API i downloaded stock data for approx 350 stocks, which was in the form of 350 xts files.  Rather than converting each other to a data frame and then one data frame for all 350 stocks, what is the best, most accurate way to go about this.

Would something like this work:

for(class(xts() in ls(envir = globalenv())), lapply(class(xts), function(as.data.frame(class(xts))))

For each xts format in the global environment, convert each xts format to a data frame?

Appreciate any assistance.

Regards,


",Convert all xts in global environment to data frame,8shxtx,new
"I am a long distance PhD Student and I am learning R by myself.

 I have done a biodiversity survey collecting insects in trial plots with different treatments (x4), each treatment was replicated 4 times (total:16 plots). 

I have collected my samples on the same plots,  5 times in one year. I have called this variable ""Event""

I have identified and counted all the different insects and put the data in the excel sheet. Each column represents a taxonomic group of insects. for example ""Araneae""

  
In the excel sheet, there is:

\- 1 column for Event ('I','II','III','IV','V')

\- 1 column for Treatment('Bd','Org','Con','Bt')

\- 1 column for replicates ('r1','r2','r3','r4')

\-The other columns are the counted taxonomic group of insects.

\-""TP17Grouped"" is the name of my file

I have done one way anova for one group ""Araneae"" 

\> View(TP17Grouped)

\> aov.17tp.Araneae=aov(Araneae\~Treatment,data = TP17Grouped)

\> summary(aov.17tp.Araneae)I have then done a tukey test   

\> comparison.tp17.5.Araneae<-TukeyHSD(aov.17tp.Araneae) 

\> plot(comparison.tp17.5.Araneae,las=1) 

  
 I would like in my formula to : 

1. Include ""replicates"" as random factors
2. Include ""Event"" in the model as the repeated measure factor

Can any one help me please?

Thank you",Using R in Natural science,8shx3t,new
"Hi I’m looking to plot multiple lines onto a single plot and can’t figure out how to. I have a working code to do it by hand but considering there are like 40 specimens I’d rather not have to type out each specimen name by hand. I am looking to plot all of these specimens with the y being variable 3 and the x being variable 1, on one graph. They all have varying lengths of x.Is there a way to do this using a for loop or any other type of looping thing? I also know that some of the later specimens in this data set have a longer x value than the first one, and I’m not sure how that will change it.

The data that I want to use is formatted into a list similar to this: 
List Name

-Specimen 1

--Variable 1

--Variable 2

--Variable 3

-Specimen 2

--Variable 1

--Variable 2

--Variable 3

-Specimen 3 etc…

The working by hand code is this:
-plot(ListName$`Specimen1`$Variable1, ListName$`Specimen1`$Variable3, type = ""l"", main = ""ListName  Variable 3"", xlab= ""Year"", ylab= ""Variable 3"", col=""light green"")

-lines(ListName$`Specimen2`$Variable1, ListName$`Specimen2`$Variable3, type = ""l"", col=""light green"")

-lines(ListName $` Specimen3`$ Variable1, ListName $` Specimen3`$ Variable3, type = ""l"", col=""light green"")

Thank you in advance to anyone who looks at this!
",Plotting Multiple Lines on a Single Plot,8sea0u,new
"I'm not a GIS person, but I do have census tract data I'm really hoping visualize across the US and was hoping someone had a package recommendation for me to use. So far I've been using acscenus for my data (it's great), but its tigris recommendation for shapefile mapping results in an R Studio crash due to the size (hardly surprising).

I looked into TileMill, but I've heard it had a lot of issues with but datsets (it also instantly rejected my csv and suggested I use SQLite instead; already clunky).

Also, if it matters, I'll be doing a bivariate choropleth so that capability is ideal.",How best to map data on Census Tracts?,8sckcf,new
"Hello, 

I'm facing issues with the sample function for my classification data modeling. I used a data set (shown below)

[Sample of Data set](https://i.redd.it/5d6d3tg5yp411.png)

and this is my code. 

    set.seed(1234)
    ind = sample(1, nrow(seedData), replace = TRUE, prob = c(0.7,0.3))
    trainData = seedData[ind==1]
    testData = seedData[ind==2]
    
    library(party)
    Formula = class ~ area + perimeter + compactness + kernelLength + kernelWidth + asymmetry + kernelGroove
    
    seedData_ctree = ctree(Formula,data = trainData)

However, I get the following error:

    > set.seed(1234)
    > ind = sample(1, nrow(seedData), replace = TRUE, prob = c(0.8,0.2))
    Error in sample.int(x, size, replace, prob) : 
      incorrect number of probabilities
    > trainData = seedData[ind==1]
    Error in `[.data.frame`(seedData, ind == 1) : undefined columns selected
    > testData = seedData[ind==2]
    Error in `[.data.frame`(seedData, ind == 2) : undefined columns selected
    > 
    > library(party)
    > Formula = class ~ area + perimeter + compactness + kernelLength + kernelWidth + asymmetry + kernelGroove
    > 
    > seedData_ctree = ctree(Formula,data = trainData)
    Error in model.frame.default(formula = ~class, data = list(sepal.length = c(5.1,  : 
      object is not a matrix

I tried to change the code a few times, but nothing seems to work. Anyone can help? ",Sample() function error,8rxwio,new
"Hello /r/Rlanguage,

I'm new to R and I'm trying to replace all the values = 0 with a small number (e.g. .000001) to perform a log function. However, I'm struggling to find the correct code I need to do so.

I was hoping someone might see this and know the answer. I feel like it is a simple answer, but I can't seem to figure it out. 

Thank you in advance!",How can I replace all zeros with a small number?,8rvawz,new
"Hello. I have a question. I have trained a text classifier (using Naive Bayes Classification) in R. It classifies sentences based on the words in each of the sentences into positive or negative or neutral. I used about 50,000 sentences to train it. I’ve also tested it on another 10,000 sentences and the accuracy is about 90%. 

I now want to save that trained classifier and use it for other R sessions to categorise other sentences. 

How do I save the trained classifier? Do I save it as an .rdata file? 

Thanks in advance for any help. ",Finished training a text classifier; how do I save the trained classifier and apply it to other corpora?,8rv9gt,new
"I have a dataframe/datatable that is like this:

     A     B
     a1   b1
     a2   b1

and a vector: `v1, v2, v3`

I am trying to get a result like this:

     A     B     C
     a1   b1    v1
     a1   b1    v2
     a1   b1    v3
     a2   b1    v1
     a2   b1    v2
     a2   b1    v3

Having trouble googling this, if anyone could point me in the right direction I would be very grateful. ",In R how to expand a dataframe with a vector?,8rt3s7,new
"Hi all,


Beginner to R here. 


I have a column of data called ""Position"" where is listed the basketball positions, and when I input it into the editor, it confirms this:


    > levels(Position)
        [1] ""C""  ""PF"" ""PG"" ""SF"" ""SG""


Everything is fine when I do a:


    plot(Position,Weight)


It returns this: https://imgur.com/1gHqdZy



The labels are fine, on the X axis, it is ""C""  ""PF"" ""PG"" ""SF"" ""SG""


But, the problem is when I use pairs(). When I input:


    pairs(~Position +Salary+ Weight)


The labels on the Position becomes 1,2,3,4,5, instead of ""C""  ""PF"" ""PG"" ""SF"" ""SG""


Pic: https://imgur.com/tUxOYxc




Much appreciate if anyone can advise, how I can show on the graph the respective levels, instead of 1,2,3,4,5.


Thanks","Label Question: Showing the ""Levels"" instead of the Numbers (1,2,3,4,5)",8rrz7y,new
"Hi everyone! This is my first time posting here. I've recently started an R course and I feel like my life has been changed forever!

I will never look at data the same way ever again. It's awesome.

I was wondering if anyone has ever successfully opened [this](https://www.reddit.com/r/datasets/comments/63spoc/19gb_of_urban_dictionary_definitions_1999_may_2016/) dataset from /r/datasets. I was looking for something interesting to slice and dice but so far have had no luck importing it. Here's the code I've got so far:

`remove.packages(""rjson"") #previously used rjson first`

`install.packages(""jsonlite"")`

`library(jsonlite)`

`data <- fromJSON(file.choose())`

This is the error I'm currently getting:

`Error in parse_con(txt, bigint_as_char) : parse error: trailing garbage`

`ercase_word"" : ""yayeeyay"" }  { ""_id"" : { ""$oid"" : ""571e394cb`

`(right here) ------^`

I've opened the +/- 2GB file in Hex Editor Neo to try and identify any issues with the JSON structure but haven't found any (from what I can see). I even copied several objects into Notepad++ to try and structure the data...seems to be fine though?!

Thanks in advance for any assistance (and apologies for the dataset, it can be quite NSFW -- it's a dump of Urban Dictionary terms!)",Newbie struggling to open large JSON file,8rrscm,new
"I'm new to working with networks in R. I have a .csv file that's an edgelist and another .csv file that has the node names in column1 and their attribute value (SH, SL, and SN) in column2. How can I add the attributes to the network? Also how can I calculate which nodes are islands (e.g. SH nodes that don't directly connect to any other SH nodes but only connect to SL or SN nodes)?",Adding node attributes to network made from edgelist?,8rhunn,new
"I've just started learning R and am playing around with a dataset of chess games, which has about 3.5 million rows and 17 columns (from [http://chess-research-project.readthedocs.io/en/latest/](http://chess-research-project.readthedocs.io/en/latest/)). Trying to clean this data to remove rows where  game moves are missing often takes several minutes per command. I'm using the sqldf package to write SQL commands to clean it as that's what I'm familiar with so I don't know if this is slower than other methods, but I'm finding it frustrating that the vast majority of my time spent working on this is just waiting for commands to complete. As an example, the following command to get rid of all rows in my data frame that don't contain a certain string:

    df2 <- df[-grep(""W1."", df, invert = TRUE),]

Took a good 10 minutes. My computer is a 2.70GHz i5-6400 CPU with 16GB ram. What kind of performance should I be expecting with this machine and dataset?",New to R - very slow performance running commands,8r9x63,new
"The [Hack for the Sea](https://hackforthesea.tech) Crew is proud to present this year's challenge statements and data sets.

They are, as follows:

* [How does a changing coastal watershed impact coastal waters?](https://hackforthesea.tech/GLO/challenge/1)
* [Can you predict where and when cod spawning will occur?](https://hackforthesea.tech/GLO/challenge/2)
* [Can you design a mooring that's both eelgrass and user-friendly?](https://hackforthesea.tech/GLO/challenge/3)
* [Can an individual whale be identified based on its blowhole?](https://hackforthesea.tech/GLO/challenge/4)

The event is all ages and open to anybody who is ready and willing to provide their skills to help the oceans. Also, while the summit will be held in person, the community is open and involved year round. Join us!",Data Sets and Challenge Statements Released for Hack for the Sea,8qyv96,new
"I'm about 12 courses into Datacamp, finishing three skill tracks (R Programming, Importing & Cleaning Data, Data Manipulation).  I've yet to take on a project, and I'm feeling the need for some practical application and exercises to keep me hungry.   I'm planning to jump into the Stats or DataVis track next, so that's exciting, but I still desire something tangible.  

I'm hoping y'all can give me some encouragement to stick with this and it'll benefit me eventually.  I need this!

Right now it's hard to see the positives over Excel, but I'm very comfortable with Excel and have written dozens of VBA macros that my team utilizes daily.  Thanks.","Somebody validate my efforts, give me hope please!",8qt5ms,new
"
I am trying to create a generalised linear model with random effect. I have a small dataset, with longitudinal data of 4 subjects during different years. The data I obtain from them is a frequency data, and for one of the subjects all of the data points are 0. So when checking the normality and the residual plots the distribution is not normal. [Residuals plot](https://i.stack.imgur.com/BifAH.png)

I tried transforming the data in different ways but the plot remains to look the same.

Is there any model or transformation I can use for this type of data, where one of the subjects shows no variability?

m=lme(Freq ~ Time, random=~ 1|Subject,  data=my_data, method='ML')

Thank you",Zero-inflated generalised linear model?,8qqgxs,new
"I am starting a new job as a Data Scientist soon. I come from a CS background and so have extensive experience with many programming languages. To date, I have done all of my statistical and ML work through Python, but have rarely used any R. I have been asked to become more familiar with it before I start the job - what are some recommended online resources to gain a reasonable knowledge in R?",Best free online course for learning R?,8qiny8,new
"Say I have data that looks a bit like this 

    Name     Type   seconds

    Dave     Good   3
    Steve    Bad    4
    Steve    Good   6
    Dave     Bad    9
    Tom      Bad    10
    Marianne Good   12
    Tom      Bad    13
    Steve    Bad    14
    Marianne Bad    15

And I want to find the difference in time (seconds) between every current row and a condition, lets say type==""Good"". In practice this would look like this, with each diff being the current row's seconds value minus the seconds value of the most recent ""Good"":

    Name     Type   seconds  diff

    Dave     Good   3         0        
    Steve    Bad    4         1
    Steve    Good   6         0
    Dave     Bad    9         3
    Tom      Bad    10        4
    Marianne Good   12        0
    Tom      Bad    13        1  
    Steve    Bad    14        2
    Marianne Bad    15        3

Alternatively, how could I do this for specific rows? I.e, only perform the operation on rows that also meet a certain condition. Say, only for rows where name==""Marianne"".

Thanks for any help",How to find a time difference between current row and most recent (previous) row that meets a condition?,8qi7ib,new
"#My goal is to find the extreme points of a function and determine whether they are max/min/inflection points. Right now I have:

e <- polynomial(c(-1, 1))^3

eCritVal <- Re(polyroot(coef(deriv(e))))

e2nd <- as.function(deriv(deriv(e)))

for (i in eCritVal) {

  if (e2nd(i) == 0) {

  print(paste(""Critical value"", i,""is an inflection point.""))

} else if (e2nd(i) < 0) {

  print(paste(""Critical value"", i,""is a minimum point.""))

} else {

  print(paste(""Critical value"", i,""is a maximum point.""))

}

}

#This works for all polynomials except those with inflection points as shown above. Any help in directing me towards a method that will return 1 root instead of two at an inflection point would be greatly appreciated.",polyroot() gives two roots very close to the one actual root?,8qg7hd,new
"I'll preface this by saying that I am only recently dabbling in command window prompts (and, correspondingly, issuing them in R), and am generally unfamiliar with this subject, so I may not be able to answer certain questions about context or background.

I work in a company with a computer network (all using Windows 10) which can access certain shared drives, and I am developing some code that can create and update a selection of files on a daily basis.  I'd like this to be fully automatic, and R cannot write to files that are open in write-access in other programs or on other machines.  Instead of try-catching write attempts, I'd rather just set all access to read-only for every other person who can access the files, except for me (or whatever ""user"" owns the R program writing everything).

I've been experimenting with permissions on some burner .csv files with Sys.chmod(), like below:

> Sys.chmod(""file_path.csv"", mode = ""0777"", use_umask = FALSE)

My understanding from [the file system permissions](https://en.wikipedia.org/wiki/File_system_permissions#Numeric_notation) Wikipedia page is that this means everyone should have read, write, and execute permission.  If I want to make everyone have read-only, including myself (as the owner of the file), then I can write:

> Sys.chmod(""file_path.csv"", mode = ""0555"", use_umask = FALSE)

Then when I try to open  the .csv file in Excel, it opens a read-only version by default.  My coworker, on a different computer than mine but on the same network, also opens a read-only when he tries to open it.

I can confirm that I am the ""owner"" of the file by using the **dir** command with shell():

> shell('dir /q ""directory location""', intern=TRUE)

where the output for each item in that directory location is a string with a ""column"" with something like **NA\\\\richard_sympson**.  The NA, I suppose, refers to ""North America"", our region.

However, when I specify Sys.chmod() to allow read, write, and execute for only the owner, but read-only for everyone else:

> Sys.chmod(""file_path.csv"", mode = ""0755"", use_umask = FALSE)

my coworker, when he opens the file, opens a write-access version.  When he views the file properties, the ""Read Only"" box is not ticked.

I am not sure what's going on here.  For my specific purposes, I can get around this problem *in effect* by setting the permissions twice: once before writing, to allow write access, or 0777 / 0755; and once again immediately after writing, to set everything to read-only, or 0555.  However, I'd still like to try to avoid that gap, and have only myself able to write.

I've asked our IT guy if he's familiar with command window file permission changes, and he says he is not.  So, I'm wondering if anyone else has some familiarity.",Sys.chmod() does not seem to make a distinction between owner and others in Windows 10. Thoughts?,8qbbwp,new
"Hi everyone! I am currently learning R in one of my classes and need to display two histograms in the same window and overlay lines of fit over the both of them. I managed to get the graphs in the same window, but can not figure out how to get the lines to overlay correctly. If anyone has an idea how to help it would be greatly appreciated! Thanks!

Edit: Adding my code so other can see

par(mfrow=c(2,1))

hist(NewMaleHeight, xlab = ""Height"", ylab = ""Frequency"", density = 25,

main = ""Histogram of Male Height with Normal Distribution"", freq = FALSE)

rug(NewMaleHeight, col = ""red"")

curve(dnorm(x, mean = 70.51, sd = 3.080943), col = ""red"", lwd = 2, add = ""TRUE"")

hist(NewFemaleHeight, xlab = ""Height"", ylab = ""Frequency"", density = 25,

main = ""Histogram of Female Height with Normal Distribution"", freq = FALSE)

rug(NewFemaleHeight, col = ""red"")

curve(dnorm(x, mean = 64.76, sd = 3.363986), col = ""red"", lwd = 2, add = ""TRUE"")

Edit 2: Solved!",How to add lines of fit to multiple histograms in the same window?,8q2vpj,new
"The idea is simple but I can't figure out how to implement it. I have a datatable with measurement values and I need to calculate a rolling average on the measurement values but since some measurement values are NA I need to keep track of how many actual measurements were used to calculate each rolling average, I want to store this information in another column inside the original datatable but I can't figure out how to do this.

>library(tidyverse)
>library(zoo)

>df <- tibble(
>  run_number = 1:100,
>  MEASUREMENT = c(runif(24, min = -1, max = 1), NA, runif(24, min = -1, max = 1),
>                  NA, runif(24, min = -1, max = 1), NA, runif(25, min = -1, max = 1))
>)

>df <- mutate(df, RUNAVG = rollapply(df$MEASUREMENT, width=8, FUN=mean, fill = >NA, align = ""right"" ))
> df$AVGSAMPLECOUNT=NA

>df <- mutate(df, AVGSAMPLECOUNT = rollapply(df$MEASUREMENT, width=8, FUN=length(!is.na()), fill = NA, align=""right""))
        

here is what I wrote so far but I am unable to pass FUN=length(!is.na()) to rollapply() is there anyway to pass composite functions to rollapply?",need to apply a rolling average to a table and track the number of NA's in the rolling avergae,8pr5gi,new
"Hey all! I'm creating a decision tree using ctree() in the party package. I am struggling to get a simple behavior to occur in my code: The lower predicted value should always be on the same side of each branch. This seems to work fine when the independent variable is a FACTOR, but not when it's a numeric.

For example let's say I'm measuring X on my tree against dependent variable Y. Y can be any positive integer, so I want to keep Y as an integer instead of a factor so my tree can figure out to split at Y=236. At that point I want the bucket with the LOWER response value X (e.g. &#37; likelihood of getting a sale) to be on the right and the higher value to be on the left. ctree does this just fine when class(Y)==""factor"" but for integers/numerics the default behavior is to sort ascendingly based on Y: the branch for Y\<236 is on the left and Y\>236 is on the right.

Any thoughts on how to adjust this? I cannot find a parameter in ctree or ctree.plot to modify. If it makes a difference I intend to print the plot as a pdf.

Thanks!",Question about Decision Tree Visualization in Party package,8pm8pw,new
"X-post from /r/Database: As per the title: How do I setup a Windows IIS 7.0 webserver to host R Visualizations? I'm both a web app developer and DBA, and have setup many IIS webservers over the years, but I'm brand new to R Visualizations. A co-worker needs to host some R Visualizations, and I need to help him get it onto our internal web server. Any links to tutorials or walk-throughs would be appreciated.",How do I setup a Windows IIS 7.0 webserver to host R Visualizations?,8pm25r,new
"Hi all! I was browsing the candidates in the primaries for my local House elections (MA-3rd district) and noticed that there's a *ton* of overlap between their campaign platforms. It made me wonder, what's the real difference between these candidates? 

As a new R user (started learning through DataCamp last October), I thought this might make a fun project to try out web scraping, comparing strings, interactive report generation, and whatever other concepts I might be able to squeeze in! So far, I've used rvest (in combination with SelectorGadget) to grab as much of the platform text as I could for each candidate, then various commands from stringr (combined with rebus) and base R to clean/organize the data into lists.

Anyway, all that was very satisfying to do (I almost feel like I have some idea what I'm doing!), but now that I've gathered the data, I'm feeling a little stumped on how to go about the real analysis. I think my fundamental questions would be: 

* What are the most repeated words/phrases among platforms (and how often do they occur)?
* What unique words/phrases are used by each candidate (and which candidate uses the most unique words/phrases)?
* How *specific* does each candidate get on the issues (recognizing that this may be the hardest question to answer programmatically, although I think a good starting point would be which platforms mention things like ""House Bill"" or ""H.B."")?

Does anyone have any experience working with data in this way? What packages would be helpful? What would be the optimal way of organizing the data? All input is more than welcome; I'm just excited to be building something!

I'm more than happy to share code/data/whatever, which would also be a learning experience since I've never done that before! Thanks for reading. :)",My first R project: Platform differences,8pkh7a,new
"I see this assignment in a script I am looking at:


counts.df <- NULL

This basically just means the variable count.df is assigned the value NULL right?

You can't have variable names with periods in python that is why I am thrown off by this and asking. Thanks","Coming from python, I just want to check something about periods being in variable names",8pd9sa,new
"I imported an excel file using read.xlsx(). Instead of the time showing as 6:00 AM, it is displayed as 0.25. How do I convert it back to 6:00 AM? In addition, the Date/Time column is also changed, and is displayed as ""43241.25"".",Converting Time from 0.25 to 6:00AM,8p4j9c,new
"Hi everyone, I am plotting an lda with 15 different variables. I want to use a combination of 2 different r.brewer palettes (https://www.r-bloggers.com/ggtutorial-day-5-gradient-colors-and-brewer-palettes/) for 2 specific chunks of variables. 

Right now I only have it as 
plot(lda, dimen = 2, col = classes, pch = classes)

Can someone help me get the r.brewer palette to work? 
",Combining color palettes,8p1ysz,new
"So im trying to use a function called ""principle"" in the psych package ive installed it with ""install.packages(""psych"")"" it still doesn't find it how do i get it to load the package so it works im new to r and dont understand my teacher is useless at explaining. He says just get pacman but i cant figure out how.",Load a package,8op8o8,new
"I'm trying to merge two dataframes by ID but keep getting 0 observations. I created test dataframes and used merge(d1, d2), and the only observations in the output were ones that had the same ""ID"" variable in both frames (See below). The other rows were not included. How do I merge two files by one variable so that it includes all rows, including those that are not present in both datasets?

Ex: 
D1
ID: 1 2 3 4
Var: a b c d

D2
ID: 3 4 5 6
Bar: e r t y

Merge (D1, D2, by=""ID"")

Merged output was
ID: 3 4
Var: c d
Bar: e r",Trouble merging dataframes,8om7xr,new
"So I want to try how well glmnet classification works on data with varying number of features and varying number of classes. How can I create a dataset where I can vary these parameters easily?

The classes should preferably be equally sized so I will use accuracy to measure how well glmnet performs. I am using the parameter family = ""multinomial"" in glmnet other that that just the default settings.",Create dataset with certain amount of features and classes,8okq9o,new
"Hello all,

I’m pretty new to R and programming so please forgive me if my questions/knowledge are lacking.

I’m trying to convert text within PDFs of quarterly financial statements into data-frames for manipulation and analysis. 

I’ve tried read_pdf() but it dumps the results as one single string which makes the data cleaning up process a nightmare and very unstructured. 

I’m exploring tabulizer’s extract_tables() function. It’s slightly better as a rough data frame format is provided in the output but a lot of the data values are still recognised as row names. 

I’m hoping someone here would’ve attempted something similar and can give me some pointers.

Any help / input would be greatly appreciated!

Thanks all! ",Reading financial statements (PDF) for data analysis,8ogebe,new
"I am using this example from the book ""Linear Algebra and Its Applications"" to produce the sample covariance matrix.

https://imgur.com/a/oceFrtw

This is my R-code

    M = cbind(c(1,2,1), c(4,2,13), c(7,8,1), c(8,4,5))
    m = apply(M, 1, mean)
    X = M-m
    X%*%t(X)/3

    >     [,1] [,2] [,3]
    >[1,]   10    6    0
    >[2,]    6    8   -8
    >[3,]    0   -8   32

This produces the same output as the book. But when I use the built in Cov to calculate the sample covariance I get something else.

    cov(M)

    >           [,1]       [,2]       [,3]       [,4]
    >[1,]  0.3333333  -2.166667   1.333333 -0.8333333
    >[2,] -2.1666667  34.333333 -22.166667 -1.3333333
    >[3,]  1.3333333 -22.166667  14.333333  1.1666667
    >[4,] -0.8333333  -1.333333   1.166667  4.3333333

How come?",Covariance of this data,8o2jl4,new
"
For example, if I wanted to make a scatter plot that looked like this : https://i.imgur.com/XISLc5H.png

There are two groups there.

Mainly I want to be able to create a scatter group for which I can manipulate the

* standard deviation (in relation to x and y)
* the average (the average being the (x,y) point which is where the average of x meets the average of y)
* Pearson correlation ( being able to control this )

I was thinking about something like this :

    x = rnorm(100, 0, 10)
    y = rnorm(100, 0, 1)
    plot(y ~ x)

But this doesn't seem to work... 

I'm sure this is pretty easy, but I'm not sure how to go about it. 

Thanks!


not sure if this is of any use for reference : https://i.imgur.com/5Jg9jrU.png
",[beginner] How should I go about simulating scatter plots?,8o0aam,new
"I am using this http://r4ds.had.co.nz/data-visualisation.html#facets, trying to learn basic stuff. I am on the exercises where I have to make the plot on the right: https://imgur.com/a/XQqj0eJ

My attempt is on the left. 

I tried changing the size of the points but that doesn't seem to be right, how do I make them overlap like the example?

edit: My code: 
ggplot() + 
	geom_point(data = mpg, mapping = aes(x = displ, y = hwy), show.legend = FALSE) + 
	geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy, group = drv), se = FALSE)",Beginner R problem with point overlapping,8nsznr,new
"function: https://textsave.de/text/vZNABUXjQ4F7owDv

examples of curve-fitting on weekly stock prices fluctuation in % (152 data-points): https://i.imgur.com/ECkXEId.png

examples of curve-fitting on randomly generated functions simulated from the NLM's curve-fitting function (300 data-points): https://i.imgur.com/HspfyXE.png

**Motivation**:

I was very, very, VERY annoyed by the need for starting parameters in regards to NLM procedure, especially with anything related to trigonometric interpolation. I'm not too-shabby with numerical analysis, so I thought I'd have a shot at programming my own curve-fitting function.

**Arguments**: 

x,y : self-explanatory

tol: should exist in (0,1]. The lower it is, the more cosine frequencies are included

plot: TRUE if you want to include plots

print: TRUE if you want to print the name of the list's components (i.e.: ReturnedObject$_____)

spaced: TRUE if the x-points are evenly spaced. If they aren't, the FFT will use cubic-spline interpolation.

**Packages dependency**: 

GGplot2, minpack.lm

**General procedure**:

1. Fit ""a + bx"", then fit ""ce^dx "" (lm on log(y)) through the data-points. Add both models with weights based on the respective SSR. Use a custom function that chooses between gradient descent using the Hessian on 3 terms (the Hessian is singular if ""c"" and ""d"" are included in the model at the same time), or simple gradient descent on all terms with optimal step size (step size is found with uniroot). The coefficients are then fed to nlsLM, which can handle singular Hessians. 

2. Perform a FFT (fast Fourier transform) on the residuals. Identify the outliers of Mod(FFT) based on the tolerance (tol argument). Perform an inverse-Fourier transform to get the strength, amplitude and delays of the outliers.

3. Perform step 1 on the de-trended data for a better fit.

4. Perform gradient descent on the model (all terms, including strengths, amplitudes and delays). The step size is found using a simple line search rather than using R's uniroot.

**Output**:

trend_coefs: coefficients of the Trend component

season_coefs: string enumerating the cosine components

fourier: strengths, amplitudes and delays of the cosine components

residuals: residuals

estimators: fitted data points

residuals_summary: P_value of Shapiro normality test on the residuals, SD of residuals and mean of abs(residuals)

estimate: calls the curve-fitting function (vectorized)

estimate_season: calls the periodic part of the curve-fitting function (vectorized)

estimate_trend: calls the trend part of the curve-fitting function (vectorized)

MeanSd: Mean and SD of the estimator and the actual-data (mean and SD of the estimator are calculated using integrals rather than point-values, i.e.: moments)

final_plot: plot of fitted vs actual data

trend_plot: plot of trend vs de-seasonalized data

residuals_plot: plot of the residuals

season_plot: plot of the cosines components vs de-trended data

frequency_plot: plot of the frequencies of the cosine components

interpolation_plot: plot of the interpolated values of the estimator (only makes sense if spaced = FALSE)




",NLM function that doesn't require starting coefficients (linear + exponential + cosine components),8np7rk,new
"I asked the same question in /r/rprogramming without any answers yet. I am pretty sure the solution is simple though I have no idea how to solve it. Is there a way to remove the black diagonal line from my [plots](https://imgur.com/a/GVGplIS)? I am doing the other four lines but the diagonal line pops out by itself.

I am generating these plots using this code:

    xrange <- range(0,0.40) 
    yrange <- range(0,100) 
    
     plot(xrange, yrange, type=""o"", xlab=""Velocity, m/s"", ylab=""Depth, %"")
     lines(measured, depthMea, type=""b"", lwd=2, lty=1, col='dark blue')
     lines(predicted1, depthPre1, type=""b"", lwd=2, lty=1, col='dark green')
     lines(predicted2, depthPre2, type=""b"", lwd=2, lty=1, col='dark red')
     lines(rangeHeight, plantHeight, type=""b"", lwd=2, lty=2, col='dark grey')
     stationName <- paste(""Station"", data.df$cSite[i], sep="" "")
     title(stationName) ",[XPOST] Help remove the diagonal line from my plots,8njm4h,new
"I have a roster with start dates and end dates for team assignments.These are used to track team changes over time. I'm trying to take that and turn it into a file which will gives a list of everyone's team on a specific day. For instance if I have: 

                team.assignment <- as.data.frame(matrix(nrow = 5, ncol = 4))
                names(team.assignment) <- c(""name"", ""supervisor"", ""start.date"",""end.date"")
                team.assignment$name <- c(""John"", ""Mark"", ""John"", ""Mark"", ""Luke""                               
                team.assignment$supervisor <- c(""Matt"", ""Matt"", ""Steve"", ""Kyle"", ""Sarah"")              
                team.assignment$start.date <- c(""2016-05-02"", ""2018-02-02"", ""2017-02-12"", ""2018-04-05"", ""2018-03-14"")
                team.assignment$end.date <- c(""2017-02-01"", ""2018-04-04"", ""2018-05-30"",""2018-05-30"",""2018-05-30"" )

I want to return a dataframe with every date for every person and who they were assigned to on that day. Obviously the actual list of people is way larger so I think looping through everyone would be too slow. 

I tried this: 

                all.dates <- function(x,y){
                    z <- seq.Date(x,y,1)
                    return(z)}
                team.assignment$dates <- mapply(all.dates, as.Date(team.assignment$start.date),as.Date(team.assignement$end.date))


             
and was thinking some kind of melt but it did't work correctly with the list. Any ideas?  ",creating list of assignments for all dates between two dates,8nbpf3,new
"Probably a dumb question but here goes:

Trying to do mixed model analysis on phylogenies, one of my variables predicts the measured variable negatively, and one positively (and both significantly).

How can I make a mixed model equation to include this?

Edit: for clarity",Using mixed models with positive and negative correlations,8na0l7,new
"I am trying to split the column x$location by parenthesis and a few things I have tried have not produced the results I am looking for.  Here is the dput from my dataset:

 dput(head(x))
structure(list(ROWNUM = c(1, 2, 3, 4, 5, 6), CASEID = c(1099487L, 
1117507L, 985415L, 986019L, 996883L, 967855L), CRIMEID = c(1321797L, 
1344185L, 1181882L, 1182632L, 1195867L, 1160270L), CRNO = c(""0910020373.1"", 
""0911060289.1"", ""0902190512.1"", ""0902200294.1"", ""0903170149.1"", 
""0901080218.1""), CATEGORY = c(""MISCELLANEOUS"", ""MISCELLANEOUS"", 
""MISCELLANEOUS"", ""MISCELLANEOUS"", ""LARCENY"", ""LARCENY""), OFFENSEDESCRIPTION = c(""MISCELLANEOUS - GENERAL NON-CRIMINAL"", 
""MISCELLANEOUS - GENERAL NON-CRIMINAL"", ""MISCELLANEOUS - ABANDONED VEHICLE"", 
""MISCELLANEOUS - GENERAL NON-CRIMINAL"", ""LARCENY - FROM BUILDING (INCLUDES LIBRARY, OFFICE USED BY PUBLIC, ETC)"", 
""LARCENY - FROM BUILDING (INCLUDES LIBRARY, OFFICE USED BY PUBLIC, ETC)""
), STATEOFFENSEFILECLASS = c(99009L, 99009L, 99009L, 99009L, 
23003L, 23003L), INCIDENTDATE = c(""01/01/2009 12:00:00 AM"", ""01/01/2009 12:00:00 AM"", 
""01/01/2009 12:00:00 AM"", ""01/01/2009 12:00:00 AM"", ""01/01/2009 12:00:00 AM"", 
""01/01/2009 12:00:00 AM""), HOUR = c(0L, 0L, 0L, 0L, 0L, 0L), 
    SCA = c(1107, NA, 1005, 414, 908, 312), PRECINCT = c(11L, 
    NA, 10L, 4L, 9L, 3L), COUNCIL = c(""City Council District 3"", 
    NA, ""City Council District 5"", ""City Council District 6"", 
    ""City Council District 3"", ""City Council District 6""), NEIGHBORHOOD = c(""CONANT GARDENS"", 
    NA, ""PECK"", ""HUBBARD-RICHARD"", ""BURBANK"", ""NECKLACE DISTRICT""
    ), CENSUSTRACT = c(5070L, 9999999L, 5313L, 5211L, 5052L, 
    5172L), LOCATION = c(""18000 WEXFORD\n(42.4261, -83.0649)"", 
    ""00 UNKNOWN\n(999999, 999999.0001)"", ""02000 CALVERT\n(42.3821, -83.1058)"", 
    ""00 W GRAND BLVD AND W FORT\n(42.3145, -83.083)"", ""12500 CONNER\n(42.4134, -83.008)"", 
    ""01500 WOODWARD\n(42.3358, -83.0494)"")), .Names = c(""ROWNUM"", 
""CASEID"", ""CRIMEID"", ""CRNO"", ""CATEGORY"", ""OFFENSEDESCRIPTION"", 
""STATEOFFENSEFILECLASS"", ""INCIDENTDATE"", ""HOUR"", ""SCA"", ""PRECINCT"", 
""COUNCIL"", ""NEIGHBORHOOD"", ""CENSUSTRACT"", ""LOCATION""), row.names = c(NA, 
-6L), class = c(""tbl_df"", ""tbl"", ""data.frame""))


I've tried the following snippets and received an error that I couldn't find enough documentation on to resolve.

library(tidyr)

extract(x,x$LOCATION, into = c('block','latlong'),""([^(]+)\\s+\\(([0-9]+)."")

separate(x,x$LOCATION, into= c('block','latlong'), sep = ""[^[:alnum:]]+"",convert = TRUE)


I also tried
library(stringr)
y<-strsplit(x$LOCATION, split=""[\n]"")
but this brings back 2 rows instead of a new column.

Any help would be greatly appreciated!",Trouble splitting a column into a new column,8n461a,new
"So when I try to run this to install the GPU version:

install_keras(method = c(""auto"", ""virtualenv"", ""conda""), conda = ""auto"",
  tensorflow = ""gpu"", extra_packages = NULL)

I get this error: 
Usage: conda [options] [INPUTFILE]
       (STDIN is assumed if no INPUTFILE is given)

conda: error: no such option: --yes
Error: Error 2 occurred creating conda environment r-tensorflow

Any advice is much appreciated!",Trying to install keras and tesnorflow backend,8n3off,new
"Dear R users and enthusiasts,

After several months in the public domain, the first major version of the ‘crypto’ package was just released on CRAN with some new features and bug fixes.


The R package that provides historic OHLC crypto currency market data for ALL coins and exchanges.

The ‘crypto' package is the R resource to go to for anything crypto currency related and includes a variety of different functions to extract data about the crypto currency markets. 


Featured on Kaggle as the 35th most popular dataset, it is quickly becoming the go-to resource for crypto currency market information in the data science community.
				
- `crypto_history()`		Retrieves OHLC historical crypto currency data  
- `crypto_prices()`		Retrieves current crypto currency prices  
- `crypto_list()`			Retrieves list of all crypto currencies  
- `crypto_exchanges()`	Retrieves all crypto exchanges and their listings  
- `crypto_xts()`			Converts/summarises historical data into xts objects  
- `daily_market()`		Time series market data perfect for charts and visualisation  
- `global_market()`		Global market time series for all coins or alt-coins

> Now featuring enhanced localisation support for different encoding standards.


CRAN:	[https://CRAN.R-project.org/package=crypto](https://CRAN.R-project.org/package=crypto) 

Github: 	[https://github.com/JesseVent/crypto](https://github.com/JesseVent/crypto) 

Kaggle: 	[https://www.kaggle.com/jessevent/all-crypto-currencies](https://www.kaggle.com/jessevent/all-crypto-currencies) 


All suggestions, comments and feedback are welcome,

Thanks",crypto R package: Historical cryptocurrency market data for all digital currencies,8mzq9v,new
"Hello. How would i transpose this SQL query to R ?

SELECT books.publisher, SUM(sales.sales), COUNT(books) AS ""Nr. 2015 published books""

FROM books

INNER JOIN sales ON books.ISBN=sales.ISBN

WHERE books.year = 2015

GROUP BY books.publisher

ORDER BY COUNT(books) ASC, SUM(sales.sales) DESC

LIMIT 10;

This is what I got so far,

books %>%

inner_join(sales) %>%

sum(sales) %>%

filter(year == '2015') %>%

group_by(publisher) %>%

count() %>%

top_n(10, publisher) %>%

arrange(desc(sum(sales)))

but I get the following error
Joining, by = ""isbn""
Error in FUN(X[[i]], ...) :
only defined on a data frame with all numeric variables

Stackoverflow doesn't really help me, as everything there looks like spaghetti to me.
",Problem with transposing SQL to R,8mpxoh,new
"Hi, I'm trying to get the whole data from an infinite scroll table and then scrap it as stated in the title. My progress so far goes like this;

    library(rvest)
    library(RSelenium) 
    #https://github.com/ropensci/RSelenium/issues/172
    
    Url <- ""http://www.tjk.org/TR/YarisSever/Query/Page/Atlar? 
    QueryParameter_OLDUFLG=on""
     
    driver<- rsDriver()
    remDr <- driver[[""client""]]
    remDr$navigate(url = Url)
    #remDr$close()
    
    webElem <- remDr$findElement(""css"", ""body"")
    while(TRUE) {
      webElem$sendKeysToElement(list(key = ""end""))
      #Error in resContent[[""status""]] : subscript out of bounds
      #https://github.com/ropensci/RSelenium/issues/169
    }

It is a large table with around 70000 entries and only shows 50 of them per scroll. This code scrolls down something like 40 times, and gives that error that I've copied as a comment:

    #Error in resContent[[""status""]] : subscript out of bounds

Is there a way to solve this problem in RSelenium? Another thing I might be able to use is that as I scroll down in the browser and inspect, the newly loaded tables go like this;

    <tbody id=""tbody0"" class=""ajaxtbody"">...</tbody>
    <tbody id=""tbody1"" class=""ajaxtbody"">...</tbody>
    <tbody id=""tbody2"" class=""ajaxtbody"">...</tbody>

and adds a new one as I scroll. Could those id's be useful to get the information? Thanks in advance.",Loading an infinite scroll table,8mpejy,new
" Is there a good function, package, or tried and true method that will allow me to discretize a good chunk of columns into fixed categories? I've got around 1000 columns to discretize, and I'd like to place them into a set number of categories \(say, 3, labeling them as 1, 2, 3 or Low, Med, High\). I'd rather not make a For loop \(ew!\) but will do so if I gotta. I'm not as comfortable with the apply\(\) family of functions as I should be, but if there's a way to use it for this particular problem, I'd appreciate a nudge in the right direction. Any guidance is appreciated.",Discretize 1000+ columns without using For loop?,8mmpzj,new
How do I go about making it use the 64bit version when I call it? Thank you!,Trying to use python and keras in R but it says I have 32bit version installed and not the 64 bit version.,8maj79,new
"Hey all, I think I've run into a bug that is preventing me from running my scripts on my work server. I was running v3.3.2 for a long time and recently upgraded to v3.5.0. I had no issues with v3.3.2.

The issue is that when I use Rscript.exe to run an R script, it doesn't handle space characters correctly. It instead just cuts off the name of the file when it encounters a space in the path name. Here's a command line example:

Input:
> Rscript ""\\\\Companyname\Location\Department\Resources\Data Validation\Scripts\myScript.r""

Output:
>Fatal error: cannot open file '\\\\Companyname\Location\Department\Resources\Data': No such file or directory

This stackoverflow [post](https://stackoverflow.com/questions/48544345/rscript-file-path-with-space) seems to confirm it's a bug (see the additional comments), but maybe there's workaround, idk. Stuck!",Bug in v3.5.0 (can you confirm?),8m36mf,new
"I want to loop through data frames. Let's do something simple with dataframes A, B, and C

> df_list <- c(""A"", ""B"", ""C"")

> for(i in df_list){

> df_i <- mutate(i, FUN)

>}

I don't think R is putting in ""i"" correctly. It's passing in ""A"" into mutate rather than A, so mutate thinks its a character. How do I make it pass through as a dataframe?",How do you loop through characters in R?,8lv8cd,new
"I have a matrix of integers which can be positive and negative, and each row of the matrix is treated as a dataset. I am trying to analyze streaks of positive and negative numbers in each row of the matrix, for example to get the probability of a streak of length n appearing. I was able to do this using ""rle"" and some manipulation, however I also want to analyze the size of streaks in addition to their length, and I am unsure how to approach this.

For example, let's say I have the following matrix:

         [,1] [,2] [,3] [,4] [,5] [,6]  [,7]  [,8] [,9] [,10] [,11] [,12] [,13]
    [1,]  252  455 1364   68 2125 2400 -1514   252 2775  2064   575   242  2376
    [2,] -390 2847  976 -726 2099  233   270 -1346 1584 -1961   496  1516  2233

In row 1, the streak lengths are +6, -1, +6. In row 2, they are -1, +2, -1, +3, -1, +1, +3. I'm able to collect this data easily with rle, but I am also interested in the sums of each streak. So for row 1, I want (252+455+1364+68+2125+2400), -1514, and (252+2775+2064+575+242+2376).

It would also be nice to have all of this information in one big object I can query. Any help is appreciated.","Trying to do analysis on streaks, not sure how to approach it",8ljdqp,new
"I was reading an article found [here](https://www.linkedin.com/pulse/why-you-keep-missing-your-service-level-targets-stefan-de-kok) and figured it would be cool if I could recreate this for shits and giggles. The issue I am having is getting the service level numbers that the author is reporting, I am off by a little, not by much but the answers should be closer due to the simplicity of the example. See my code below:

    library(fitdistrplus)

    #real demand from article, I seem to be missing a number :P
    realdemand <- c(5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,10,10,10,10,10,10,
                10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,
                10,10,10,10,10,10,10,10,10,15,15,15,15,15,15,15,15,15,
                15,15,15,15,15,15,15,15,15,15,15,15,15,15,5,15,15,15,15,
                20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,
                20,20,20,20,20,20,25,25,25,25,25,25,25,25,25,25,25,25,25,
                25,30,30,30,30,30,30,30,30,30,30,30,30,30,35,35,35,35,35,
                35,35,35,40,40,45,45,45,45,45,45,50,50,55,70,75,80,90,90,
                105,110,115)

    #Normal Distribution =================================================
    #finding safety stock
    stock <- round(x = qnorm(p = .99, mean = 20, sd = 20), digits = 0); stock

    #simulating service level
    sampledemand <- sample(x = realdemand, size = 10000, replace = TRUE)

    #calculating service level, if ending stock is greater than or equal to 0, SL is 100%
    #If ending stock is less than 0, SL is <100%
    simservicelevelnorm <- ifelse(test = stock >= sampledemand, 
                              yes = 100, 
                              no = (((stock)/sampledemand)*100))

    # Finding average service levels, article had it at 96.95%
    avgservicelevelnorm <- mean(simservicelevelnorm); avgservicelevelnorm


    # Lognormal Distribution ===============================================

    logdist <- fitdist(data = realdemand, distr = ""lnorm""); logdist

    # Finding safetystock, for either paramters from article or actual parameters I found
    # Going to use parameters from article
    # stocklnorm <- round(qlnorm(p = .99, meanlog = logdist$estimate[1], sdlog = logdist$estimate[2]), digits = 0); stocklnorm
    stocklnorm <- round(qlnorm(p = .99, meanlog = 2.645, sdlog = .83255), digits = 0); stocklnorm

    #calculating service level, if ending stock is greater than or equal to 0, SL is 100%
    #If ending stock is less than 0, SL is <100%
    lnormsimservicelevel <- ifelse(test = stocklnorm >= sampledemand, 
                               yes = 100, 
                               no = ((stocklnorm)/sampledemand)*100)

    # Finding average service levels, article had it at 99.01%
    lnormsl <- mean(lnormsimservicelevel); lnormsl


    # SUMMARY ================================================
    # Assuming demand follows normal distribution, article had it at 96.95%
    avgservicelevelnorm

    # Assuming demand follows lognormal distribution, article had it at 99.01%
    lnormsl

The service levels I am getting are not really close to his, what do you all think? Could my service level formula be wrong?
[article again](https://www.linkedin.com/pulse/why-you-keep-missing-your-service-level-targets-stefan-de-kok)",Trying to find out how LinkedIn Author got his results using resampling,8lenzz,new
"So, I'm very new to R & Rstudio, and I'm taking a class online to try to learn. I've encountered a question in this course where you need to enter how many ordered factors are in the dataset. I thought the number of ordered factors are the number of different ordinal datapoints there could be in a dataset, (in this dataset there are 3 columns with non-numerical data, with 4, 8, and 8 different possibilites) but I am clearly mistaken, and am missing something..",Trying to figure out how many ordered factors are in a dataset,8ldd1c,new
"R has a few ways of making presentation slides - slidy, ioslides, slidify etc.

I have made a presentation using slidify that contains image carousels. Works great on my laptop. But I can't publish it on RPubs, nor can I publish even the simplest slidify example to RPubs. 

So I need an alternative; I went for ioslides. Also, having found the 'slickR' package, I can use that to generate a working carousel in RStudio. However, when I generate the ioslides presentation slides with a slickR carousel, the carousel in the slides is unresponsive/unclickable, as if it was just an ordinary image.

Does anyone know either

- How to make that carousel work in ioslides?
- What else I could use to generate a presentation with an image carousel?",Which of the options for an R presentation will allow me to include an image carousel?,8l47gd,new
"I work with large data sets and I have to run thousands of economics scenarios through a model to get a full distribution of the results. Currently the that process takes days since the data sets are so large. What is the best way downsample data and still maintain its characteristics and riskiness? The data set contain both categorical and numerical values and by downsampling I mean removing rows, not columns. ",Best way to downsample a data set while maintain its characteristics?,8l2b2y,new
"**Error Message:** Error in `[<-.data.frame`(`*tmp*`, tdoc$PROBATION == FALSE, , value = list( :   
missing values are not allowed in subscripted assignments of data frames  
  
New to R and looking to improve on the code before me. How can I get past this? 
   
     tdoc[tdoc$PROBATION == FALSE,]$PROBATION <- (tdoc[tdoc$PROBATION == 
     FALSE,]$SENTENCE_FACILITY == 'CC'
             & tdoc[tdoc$PROBATION == FALSE,]$SENTENCE_LENGTH > 0
             & tdoc[tdoc$PROBATION == FALSE,]$PROBATION_LENGTH == 0
             & tdoc[tdoc$PROBATION == FALSE,]$SPLIT_1_LENGTH == 0
             & tdoc[tdoc$PROBATION == FALSE,]$SPLIT_2_LENGTH == 0)

  
  
",Missing value not allowed in subscripted assignment of data frames,8l12b5,new
"I want to add two convergent lines, one upper and one lower, for the existing plot in R.
Is there a way to do so in R?
I fail in googling the answer.

Thank you!

Image here : https://imgur.com/a/Si6clb4

Code :


    set.seed(123)
    plot( x = 1:100,
          y = rnorm(100)/1:100,
          type = ""l""
    )",Adding a upper and lower boundary curve to enclose existing plot,8kzfzr,new
I was thinking data mining my email for common requests via a word cloud given an email mailbox surrounding s specific business activity.,What is a simple practical beginner use for R in the business office?,8ko9tq,new
"I've got a function which I'd like to keep track of how many times it is called.  So I embed a counter function in it and assign the count to an environment which is ideally not the global environment.
    
    counter <- function(fun) {
    if (!exists(""counter.env"")) {
    counter.env <- new.env(parent = emptyenv())
    counter.env$i <- 0
    }
    function(...) {
    counter.env$i <- counter.env$i + 1
    fun(...)
    }
    }

then I would like to have another function which, when called, returns the ""i"" value stored in the environment.

    get_calls <- function() {
    return(counter.env$i)
    }

Basically I had something like the above (I've already tried it so many times I've lost track of what worked) However when I exported it all to a package, suddenly it stopped working.  I know it's an issue with environments but I can't figure it out. ",Storing a counter in an environment,8kmnhl,new
So I was told that I need to get R and RStudio and I did. I don't have much experience with them. Isn't it the same thing just that RStudio has more features?,Having both R and RStudio,8ki5qn,new
"Hey guys, I've been struggling with getting this done and I'm honestly frustrated. I have an SQL statement that I would like to translate to R. 

**Data**

Table 1:  Customers


CustomerId | DateCreated |
---|---|----
1 | 2018-01-01 | 
2 | 1999-03-05 | 
3 | 1956-12-12 | 
4 | 2012-12-03 | 
6 | 2018-03-02 |

Table 2: Purchases



CustomerId | DateCreated | PaymentAmount
---|---|----
3 | 1999-06-03 | 10
3 | 2018-06-04 | 20
6 | 2018-03-03 | 30
4 | 2014-12-03 | 45
1 | 2018-02-02 | 6
 

**The SQL**

The goal of this is to find how many new customers signed up *and* purchased in a given year(2018)
    
                        
     select
    	count(c.CustomerId),
    	sum(p.PaymentAmount)
    from
    	Purchases p
    inner join Customers c on c.CustomerId = p.CustomerId
    group by
    	c.CustomerId,
    	DATEPART(year, c.DateCreated)
    having
    	DATEPART(year, c.DateCreated) = 2018 and
    	sum(p.PaymentAmount) > 1


plz halp me",Translating SQL to R,8keckq,new
"Hello all!

I'm a relative newcomer to R, and I suppose in general to programming overall (< 1 year). I've got a project I'm working on to learn the language, and as part of my everyday routine, I find that there are about 5 different ""starting up"" functions that I run when beginning work. Is there any way to create a simple, custom function, say ""startup()"", that will execute a number of other functions sequentially? 

Thanks in advance for shaving off a few seconds of my daily routine :)",Startup Function,8k9v7y,new
"Hi guys, I'm a highschool senior looking to major in nuclear engineering next year in college. Would you recommend learning R over the summer or is there a better program I night want to check out?",New comer to R,8k15to,new
"Hey guys, im trying to find a function in r that can a rotated Pareto chart plotting like the example in the picture and im trying to add the p\-value of my linear model in the plot, but until now I found only the possibility to plot a Pareto chart vertically using Pareto.chart function that can be in qcc package found. If anyone can help me that will be much appreciated, thank you guys.

EDIT: [https://imgur.com/a/qHBJyXI](https://imgur.com/a/qHBJyXI)",Rotated Pareto chart in r,8jvx4i,new
"I have a file that looks like this:


Name 23 32


Height 22 21


...

I want to build a scatter plot in unix, using column 2 and 3 on the x and y axis. There are 1000+ lines similar in the .rpt file. How do I read the .rpt file and plot the data? Also is it possible to view what column1 data a particular point points to in the scatter plot by selecting it. I want to be able to view the outliers.",How do I do this in linux,8jravy,new
"Hi everyone, is there a way to use corrplot with a dataframe containing NAs, without using n.omit or complete.obs (these reduce my sample size by too much). I have 180 obs. 16 variables and 508 NAs scattered throughout.",Corrplot with NAs in dataframe,8jpcs4,new
"I'm running through R For Data Science and can't seem to get through the chapter ""Pipes with magrittr""

The book assumes that little\_bunny\(\) is built into the library, but it doesn't seem to be the case for me.

When I type in:

foo\_foo \<\- little\_bunny\(\)

I get an error message:

Error in little\_bunny\(\) : could not find function ""little\_bunny""

I've insured the magrittr library is installed correctly as well as trying to install tidyverse then running the code. Anyone know the issue? Or what the output of little\_bunny\(\) looks like so I can just write it myself?

Thank you in advance.",Little_bunny(),8jlwyr,new
"Hey guys

I used the interplot package to plot interactions effects of a model.
It looks like this: (image uploaded to imgur).
https://imgur.com/a/3QkU2Hu

But the problem is, i plotted the interaction effects of a dummy variable, but in the graph the points are quite far apart, so it looks wierd. Anyone know how to move them closer to the center?

I used the following code:

    mod5<-lm(alle ~ x*pop +z +as.factor(pdat$year) + as.factor(pdat$ID))
    
    iplot_pop<-interplot(m = mod5, var1 = ""x"", var2 = ""pop"") +
    xlab(""1 = populært udgiftsområde"") +
    ylab(""Benchmarkingkoefficient"") +
    theme_bw() +
    ggtitle(""Interaktionseffekt af udgiftsområdets popularitet på benchmarkingeffekten"") +
    theme(plot.title = element_text(face=""bold"")) +
    geom_hline(yintercept = 0, linetype = ""dashed"")
",Change position of plotted effects on the x-axis for. interplot package.,8jlkdh,new
"Looking to control a browser with R, is there a way to set this up with R 3.5.0 or a better package I should be using?",RSelenium removed from Cran?,8jktpe,new
"I have some JSON data which formats the date like this: 2018-01-17T10:17:34Z


Whats an easy way to format that so I keep the granularity down to the second and I'm able to perform calculations on it, like subtracting a start and end time to get the difference? ",help with JSON time formatting in R: convert to time,8jdt6c,new
"Hello all,

I am a beginner/novice with R attempting to perform data analysis of some experiments.  The idea is that I have data in the following format as a series of .txt files:

||Parameter 1|...|Parameter n|
|:-|:-|:-|:-|
|Group 1|number|number|number|
|Group ...|number|number|number|
|Group n|number|number|number|

Where each group is a separate .txt file with one row of labeled data.

Currently, the code I am running scans the directory for any .txt file, adds them as a variable, and then a for loop extracts data from each file and saves it as a data frame.  After, the code separates each group into subsets based on experimental protocol \(indicated by the .txt file name\), after which it's written to a .txt file which I open in excel and then analyze.

Since R is capable of many statistical tests and analyses, I would like to generate an entire code \(in markdown if possible\) as a template to facilitate analysis.  Ideally, it would recognize each file, separate and organize the data based on experimental protocol, and then perform full analyses on the data to determine significance \(ANOVA, ttests, bar/scatter plots\).  My knowledge of R is limited to one semester of data science, so any assistance would be appreciated.  My code is posted below.

\-\-\-\-

library\(norm\)

setwd\(""C:/Users/Username/Documents""\) #Sets working directory for R Script

filetype = list.files\(path = ""C:/Users/Username/Documents"", pattern = "".TXT""\) #Lists files in directory

fileselect = file.path\(""C:/Users/Username/Documents"", filetype\) #Maintains full file path

all\_cells = data.frame\(\) #Generates an empty data.frame prior to the for loop

for \(i in fileselect\) {                                                                                     #For loop that iterates

indiv.cells = read.delim\(i, sep = ""\\t"", [as.is](https://as.is) = TRUE, header = TRUE\)    #through each file in

indiv.cells\[1\] = i                                                                                            #directory and stores data

all\_cells = rbind\(all\_cells, indiv.cells\)}                                                    #in a data.frame

all\_cells$X.1 = NULL  #Removes unnecessary X.1 column

ExpProtocol\_1 = subset\(all\_cells, grepl\(""Exp1\_"", all\_cells$X\)\)

ExpProtocol\_2 = subset\(all\_cells, grepl\(""Exp2\_"", all\_cells$X\)\)

Exp1\_E = subset\(ExpProtocol\_1, grepl\(""\_ECS.TXT"", ExpProtocol\_1$X\)\)

Exp1\_I = subset\(ExpProtocol\_1, grepl\(""\_ISO.TXT"", ExpProtocol\_1$X\)\)

Exp1\_IC = subset\(ExpProtocol\_1, grepl\(""\_ISOCCH.TXT"", ExpProtocol\_1$X\)\)

Exp1\_IA = subset\(ExpProtocol\_1, grepl\(""\_ISOATR.TXT"", ExpProtocol\_1$X\)\)

Exp1\_C = subset\(ExpProtocol\_1, grepl\(""\_CCH.TXT"", ExpProtocol\_1$X\)\)

Exp1\_A = subset\(ExpProtocol\_1, grepl\(""\_ATR.TXT"", ExpProtocol\_1$X\)\)

Exp2\_E = subset\(ExpProtocol\_2, grepl\(""\_ECS.TXT"", ExpProtocol\_2$X\)\)

Exp2\_I = subset\(ExpProtocol\_2, grepl\(""\_ISO.TXT"", ExpProtocol\_2$X\)\)

Exp2\_IC = subset\(ExpProtocol\_2, grepl\(""\_ISOCCH.TXT"", ExpProtocol\_2$X\)\)

Exp2\_IA = subset\(ExpProtocol\_2, grepl\(""\_ISOATR.TXT"", ExpProtocol\_2$X\)\)

Exp2\_C = subset\(ExpProtocol\_2, grepl\(""\_CCH.TXT"", ExpProtocol\_2$X\)\)

Exp2\_A = subset\(ExpProtocol\_2, grepl\(""\_ATR.TXT"", ExpProtocol\_2$X\)\)

write.table\(all\_cells, file = ""OUTPUT.TXT"", sep = ""\\t"", row.names = FALSE, col.names = TRUE\)

# Later include code to organize and output subsets",Assistance with template for data analysis,8jcphb,new
"Hi everyone,

I'm trying to do a sentiment analysis on text messages in R, but I can't seem to properly get them from XML to a dataframe object. Googling is not going so hot for me, I think it's because the data are not formatted as is typical for an XML file (data are coded as XML attributes). (Files are from my android phone, I used the app [SMS Backup & Restore](https://play.google.com/store/apps/details?id=com.riteshsahu.SMSBackupRestore&hl=en))  
Here's an example of how the data are formatted:

    <?xml version='1.0' encoding='UTF-8' standalone='yes' ?>
      <sms protocol=""0"" address=""1234567890"" date=""1521766063682"" type=""1"" subject=""null"" body=""Lorem Ipsum"" toa=""null"" sc_toa=""null"" service_center=""null"" read=""1"" status=""-1"" locked=""0"" date_sent=""1521766056000"" readable_date=""Mar 22, 2018 8:47:43 PM"" contact_name=""Jane Doe"" />
      <sms protocol=""0"" address=""1234567890"" date=""1521771828209"" type=""2"" subject=""null"" body=""Ipsum Lorem"" toa=""null"" sc_toa=""null"" service_center=""null"" read=""1"" status=""-1"" locked=""0"" date_sent=""0"" readable_date=""Mar 22, 2018 10:23:48 PM"" contact_name=""Jane Doe"" />

Since it's unclear, `type` seems to signify if a text is sent by her `type=""1""` or me `type=""2""`  
I'm trying to get a dataframe with 3 values: the timestamp `date`, the sender `type`, and the body of text itself `body` so that I can do sentiment analysis. I imagine someone has done this before, does anyone have any tips to get texts into a workable format?

# Problem Solved!!

Adjusting a bit from [this stackoverflow thread](https://stackoverflow.com/questions/32896861/from-xml-attributes-to-data-frame-in-r) I managed to figure it out.

    library(dplyr)
    library(rvest)
    rows <- read_xml('text_messages.xml') %>% xml_nodes('sms')
    df <- data.frame(
      ID = rows %>% xml_attr(""type""),
      date = rows %>% xml_attr(""date""),
      body = rows %>% xml_attr(""body"")
    )",Extracting Oddly Formatted XML into a DataFrame in R?,8iy2ea,new
"Looking into the job advertisements I see a lot of companies requiring R as one of their skills. But all of the benchmarks I have seen so far show that R is way slower in comparison to other options \(e.g. Python, Julia\). For example [this](https://www.ibm.com/developerworks/community/blogs/jfp/entry/A_Comparison_Of_C_Julia_Python_Numba_Cython_Scipy_and_BLAS_on_LU_Factorization?lang=en), [this](https://modelingguru.nasa.gov/docs/DOC-2625) and [this](http://www.laketide.com/julia-vs-r-vs-python/). So I'm wondering why R is so popular and if there are any benchmarks proving that R is fast enough or even faster?",Any benchmarks showing the benefits of R over other languages?,8ison9,new
"I have a set of data about stays, and if those encounters meet these conditions: (same person_id) && (same location_id) && (that person's enc_start_date is within 30 days of their previous enc_end_date) I want to show that as one row with person_id, location_id, first_start_date, last_end_date, sum_of_days_for_each_enc.

 Many times a person has only one encounter (so no summing of days would be necessary), sometimes a person could have multiple stays that should all be added together as one.

I tried doing this as a for loop, but the it doesn't seem to be summing correctly (or at all).



Here's basically the code I have that doesn't seem to work:
    
    VISIT.test <- data.frame(""PERSON_ID"" = character(),
                            ""LOCATION_ID"" = character(),
                            ""ENC_FROM_DT"" = character(),
                            ""ENC_THRU_DT"" = character(),
                            ""ENC_PMT_AMT"" = numeric(),
                            ""ENC_LOS"" = integer(),
                            ""ENC_FROM_YEAR_MONTH"" = character(),
                            stringsAsFactors = FALSE)
        encIndx = 1
        VISIT.test[nrow(VISIT.test)+1, ] <- c(test$PERSON_ID[1], test$LOCATION_ID[1], test$ENC_FROM_DT[1], test$ENC_THRU_DT[1], test$ENC_PMT_AMT[1], test$ENC_LOS[1], test$ENC_FROM_YEAR_MONTH[1])
        for (ii in 2:nrow(test)) {
          # if same person as previous, same location as previous, and encounter starts within 30 days of previous, add this LOS to previous LOS
          if ( (test$PERSON_ID[ii]==test$PERSON_ID[ii-1]) 
                  && (test$LOCATION_ID[ii]==test$LOCATION_ID[ii-1]) 
                  && (as.Date(test$ENC_FROM_DT[ii]) - as.Date(test$ENC_THRU_DT[ii-1]) <= 30 )) 
              {
                # update encounter through date
                VISIT.test$ENC_THRU_DT[encIndx] = test$ENC_THRU_DT[ii];
                # recalculate length of stay
                VISIT.test$ENC_LOS[encIndx]     = as.numeric(VISIT.test$ENC_LOS[encIndx]) + as.numeric(VISIT.test$ENC_LOS[ii])
                # add this payment amount to previous payment amount
                VISIT.test$ENC_PMT_AMT[encIndx] = as.numeric(test$ENC_PMT_AMT[encIndx]) + as.numeric(test$ENC_PMT_AMT[ii])
              }
          else {
            encIndx = encIndx + 1;
            VISIT.test[nrow(VISIT.test)+1, ] <- c(test$PERSON_ID[ii],test$LOCATION_ID[ii],test$ENC_FROM_DT[ii],test$ENC_THRU_DT[ii],test$ENC_PMT_AMT[ii],test$ENC_LOS[ii],test$ENC_FROM_YEAR_MONTH[ii])
          }
        }
    

Any help would be greatly appreciated.",Conditionally summing rows,8ir08j,new
"    >z <- list(a=1,b=2,c=3)
    >names(z)[1] <- ""foo""

How exactly does that work?? Because storing n <- names(z)  and then setting n[1]=""foo"" does nothing.

Even more puzzling, the documentations says that this works because it's evaluated as z<-""names<-""(z,""[<-""(names(z), 3, ""c2""))

Huh... like... how does that make ANY sense??? ""names<-"" is a string!? but yes, the whole expression ""names<-""(z,""[<-""(names(z), 3, ""c2"")) actually returns a list.. !?

Wait... if I do >""print""(""foo"") it actually prints foo!? What? Why?",How does names assignment work??,8iqjt8,new
"I'm trying to upload my slides (made using slidify) to RPubs, but it keeps generating a completely blank webpage. The slides look fine when they're knitted into a html file that I view in RStudio and when I tell it to open in my browser too, but everything disappears upon publishing it.

After some googling, all I can find is the instruction to set

mode : standalone

at the start of my .Rmd file, and to add

options(rpubs.upload.method = ""internal"")

to my .Rprofile file. None of this has made a difference. I notice also that my local html file is blank when opened if I move it out of the directory it was originally created in and open it up. Anyone know what I have to do? ",Slidify presentation is blank/empty when published to RPubs?,8ip89o,new
https://devopedia.org/r-plotting-systems,Get an overview and compare the different plotting systems in R,8ikdwz,new
"[This code](https://pastebin.com/raw/HaUfV4bW) captures the lower limits for each confidence interval, but it drops the upper limit when making the data.frame. Would changing the arguments to something like 'd_avg_cil, d_avg_ciu = blah$d.avg.ci' make R keep both values in separate columns when creating the data.frame?",Capture upper/lower limits into data.frame?,8ihjx2,new
"I'm familiar with R and the tidyverse suite of packages but my experience up to now have been exclusively with files such as CSV,
Txt, etc. 

I need to analyse netCDF files obtained the European Centre for Medium-Range Weather Forecasts

What are the best packages for dealing with netCDF files? ",Beginner working with netCDF files in R,8ifpgc,new
"Hi all,

Really basic question here that I'm struggling to find a straight answer to. Code is being run on R v3.4.1 through the RStudio IDE in Sierra 10.12.6.

A while back I explored parallel computing options in R and after some fiddling decided to settle on the doParallel/foreach package (instead of e.g. multicore). Basically needed to run multiple independent scripts (with e.g. input differing in each, but everything else being the same) and for small jobs got tired of generating new scripts for ppss. I figured out how it worked and have been copy+pasting something like the following ever since:


    cl <- makeCluster(8, outfile="""")
    registerDoParallel(cl)
    getDoParWorkers() #all there?
            
    foreach(m=1:100, .packages = c(""package1"", ""package2"", ""package3"")) %dopar% {
       #code
       #code
       #code
    }


Sometimes, though, I want to prematurely stop execution when I realize I made an error (logic) in the code, i.e. everything's doodling along just fine but is actually doing something wrong. If I click the stop sign in RStudio, it only halts a single one of the workers (i.e. the one accessible from the console), and not any of the processes/workers distributed to other cores. I need to go into activity monitor and manually kill all the (7, in the above case) other processes if I want to actually stop all execution.

Calling stopCluster(cl) from the console doesn't seem to do the trick. Is there anything that would? 

(is this because what's currently being executed is running on whatever C++ or Fortran backend instead of R directly?)

(sorry if my description doesn't quite use the correct lingo -- I'm not formally a computer scientist :S)

",noob foreach() question,8i9ylp,new
"Hi everyone, I'm just starting to learn R and I'm having a lot of trouble with the order()  function. I keep getting the same error message (object length issue) even though the objects in question are the exact same length (10)? Can anyone help me out here? i've pasted the code that includes the error message.


        # Creating factors for boxes and weights. Replace values in weights with any weights of boxes.
         boxes <- c(""1"", ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"")
         weights <- c(12, 32,17, 54, 15, 18, 65, 32, 22, 29)
         # The heaviest two boxes are box 4 and box 7 in this example
         box_weight_dataframe <- data.frame(boxes, weights, stringsAsFactors = FALSE)
         str(box_weight_dataframe)
        'data.frame':	10 obs. of  2 variables:
         $ boxes  : chr  ""1"" ""2"" ""3"" ""4"" ...
         $ weights: num  12 32 17 54 15 18 65 32 22 29
         Colnames <- c(""box_number"", ""box_weight"")
         colnames(box_weight_dataframe) <- Colnames
         box_weight_dataframe
           box_number box_weight
        1           1         12
        2           2         32
        3           3         17
        4           4         54
        5           5         15
        6           6         18
        7           7         65
        8           8         32
        9           9         22
        10         10         29
         positions < - order(box_weight_dataframe$box_weight)
        Warning message: longer object length is not a multiple of shorter object length
         [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
         positions
        [1] 1 4 2 3 8 7 6 5
 ",Having some trouble with the order() function,8i68vp,new
"I have the following code:

    dfWine<-data.frame(wine,pred=fit$fitted.values,resid=fit$residuals)

    par(mfcol=c(2,2))

    # Histogram of Residual Values

    myhist <- hist(dfWine$resid, xlab = ""Residual Values"", main = ""Fig 22. Hist. of Residual Values"")

And the [output](https://imgur.com/a/8V9f6Cu)

I want to change the values of the X-axis, as well as add a normal distribution curve on top. 

Any help is appreciated!","How to change x axis values, and add normal distribution curve on histogram?",8i5y1j,new
"Say I have a string stored in a variable, like

    fileToOpen <- ""file_to_open.txt""

And I want to execute a unix command to open a file with that name, like

    ""unzip -p zipped_dir.zip path_to_zipped_file/file_to_open.txt > file_to_open.txt""

How do I do this to system()?  i.e. how do I pass my 'fileToOpen' variable to system()?",The system() function for executing system commands - how do I pass variables to it?,8hpkrc,new
"For rolling calculations (e.g. rolling mean), is there a traditional/standard way to refer to and/or label the values? For example, do I refer to a mean by both bounds (e.g. 2009-01-12 to 2009-02-12) or only the starting or ending boundary? I've been labeling my values with the starting limit thus far, and the plot subtitle says the range used in the rolling calculation.  

EDIT: No responses so I'm guessing there isn't a tradition yet.",Traditional/standard way to label rolling calculation,8hgioq,new
"Hi,

I am trying to add a vertical average line for each conditioned ""Species"" group from data ""iris"".

I only manage to add same vertical mean line for all conditioned groups.

But I want each group to have its own mean line.

How should I configure it?


    library(lattice)
    D = get(data(iris))
    histogram(  ~ Petal.Length | factor(Species),
                data = D,
                type = c(""count""),
                
                breaks = 5,
                lwd = 2,
                col = ""papayawhip"",
                border =""seashell3"",
                
                panel = function(x, ...) {
                  panel.histogram(x, ...)
                  panel.abline(v= mean(D$Petal.Length))
                },
                
                main = ""Histogram"",
                xlab = ""Petal Length (cm)"",
                ylab = ""Frequency"",
                
                layout = c(1, 3),
                scales = list(alternating = F)
    )

Thanks!
",[lattice] add vertical lines of means for conditional histogram,8hcwa3,new
"Hi all,

I have a problem on how to implement a graph with edges and vertices based on my available data. The dataset is very simple although very large, around 200 000~1 000 000 rows. The data sets looks like the following:

source|target|value                        
:--|:--|:--                                  
50|100|20     

source -> target may appear several times. I would want to create a graph where the edges are thicker if it appears several times in the data.

Any idea how to start? As I'm struggling with the sheer amount of data it is quite hard to visualize, therefore, I would like edges to be thicker if source->target appears multiple times.

Sincerely,
Nowarez",[HELP] Using igraph with very large data set,8h8vb9,new
"I am learning how to run regression modeling in R, and I am confused as to whats happening in this piece of code:

model <- lm(IV ~ dv1 + dv2)
colors <- ifelse(dv1==1, ""black"", ""gray"")
plot(dv2, IV, xlab=""dv1"", ylab=""IV"", col=colors, pch=20)
curve(cbind(1,1,x) %*% coef(model), add=TRUE, col=""black"")
curve(cbind(1,0,x) %*% coef(model), add=TRUE, col=""gray"")


What im particular confused about is the curve(cbind()) part, as I am completely clueless as to what is happening here.

Thanks!",Can someone help me understand what is happening with this code?,8h11ja,new
"When publishing my updated shiny apps I now recieve the following error, (i transferred to a new machine and updated R version).

Error building crayon (1.3.4). R version 3.5.0 currently unavailable

Is there a package I need to update or something to change?

Thanks again..",Publishing to Shiny no longer working on update to 3.5.0. Error building crayon.,8h035h,new
"How does it work? and why can't I use it? 

When I enter the command I get the following message

Error in summaryStats(The relevant stuff): could not find function ""summaryStats""",The summaryStats function,8gx924,new
"Hey everyone

I am trying to make a shiny app for use at work. Basically other users would upload data, pick some variables from the data, and run PCA on that and the app would display the plot. 

I have this working pretty well so I wanted to add in a tSNE option using the Rtsne package. When you run Rtsne locally, you can make verbose=TRUE, where it will print status updates to the console. I want to show these in my shiny app since the function can take anywhere from 10-90+ minutes to run. 

I have tried capture.output() but the R thread is locked until tSNE finishes so it doesn't work. I tried using the future package to put the tsne run on a new process, but still I don't get any output to a renderPrint call.

Any advice? Thanks!


edit: I figured it out!

I had to use the future and promises packages to get it working.

So here is the observeEvent for my button to run the calculation

v is a reactiveValues() that I use to store data to for various steps. 

v$data is my original dataset
```
 observeEvent(input$runtsne, { 
    v$plotstyle <- ""tSNE""
    v$ncells <- isolate(input$numcells)
    v$data2 <- v$data[sample(nrow(v$data), v$ncells),]
    
    v$markers <- colnames(v$data)
    chosen_markers <- input$choices
    f <- future({
    tmp <- v$data2[1:v$ncells, chosen_markers]
    #tsne <- Rtsne(tmp, verbose=TRUE, perplexity=20)
    sink(tmpfile, type=c(""output"", ""message""), append=FALSE)
    tsne <- Rtsne(tmp, verbose=TRUE, perplexity=20)
    sink()
    
    return(tsne)
    })
    then(f, function(value) {
      v$X <- value$Y[,1]
      v$Y <- value$Y[,2]
    })
  })
```

then to print the items I created a verbatimTextOutput object in my UI and have this to populate it:

```  
log <- reactiveFileReader(50, session=NULL, tmpfile, read.delim, sep=""\n"")
  output$text <- renderPrint({
    validate(
      need(try(
        suppressWarnings(print(log())), silent=TRUE), 
        """")
    )
    })
```

The validate(need(try etc is because I get errors since it tries to print before the tempfile is populated, resulting in an error that immediately resolves once it gets going.",[Question][Shiny],8gv66x,new
"Hi everybody, we are happy and proud to announce the **3rd Annual Hack for the Sea** being held Sept 22-23 at the American Legion in Gloucester, MA

If you don't know, a ""hackathon"" is an attempt to ideate and make progress toward solutions to shared challenges. Hack for the Sea is slightly different than many other hackathons in that:

* It focuses on marine science exclusively
* All submissions must be released as open source
* It is meant to be a healthy, inclusive, and outcome-driven event.

This year's challenges come from our beneficiary organizations: the Consortium of Universities for the Advancement of Hydrologic Science, Inc. (CUAHSI), the Gloucester Marine Genomics Institute (GMGI), The Massachusetts Division of Fisheries and Wildlife, Ocean Alliance, and the MassBays National Estuary Program.

1. How does a changing coastal watershed impact coastal waters?
2. Where and when will Cod spawning occur?
3. Can a whale be identified based on their blowholes?
4. Can a mooring be designed that is not only eelgrass-friendly, but also user-friendly?

Ask me anything!

Early-bird Tickets are available here: https://www.eventbrite.com/e/hack-for-the-sea-2018-tickets-45603855359",Announcing Hack for the Sea 2018: Sept 22-23 in Gloucester MA,8gn2ud,new
"I have this function, and a need to make parallel because its take much time for my windows PC running this number of repetition.
#Autor JoAO LUCIO MATOS RESENDE
#Projeto: Algoritimo de play-offs

########
# FUNÇÕES QUE VAMOS UTILIZAR:
#

# confronto: obtém o resultado de uma de disputas de times.

confronto <- function(equipe_1, equipe_2){
  result <- sample(c(equipe_1[1], equipe_2[1]), size = 1,prob = c(equipe_1[2], equipe_2[2]))
  return(get(result[[1]]))}

# sorteia_times: cria um vetor com os times de ordem aleatoria.

sorteia_times <- function(times){
	sorteio_times <- sample(times)
	#criação dos dois lados de cada chave
	chave1 <- sorteio_times[c(1,2,3,4)]
	chave2 <- sorteio_times[c(5,6,7,8)]
	list(chave_1 = chave1, chave_2 = chave2)
		} # Fim da função sorteia_times!

# playoffs: coloca os times em uma determinada ordem nas chaves e simula o campeão.

playoffs <- function(chave1, chave2){
    
  # criação das partidas de quartas-de-final

  semi_finalista_1 <- confronto(equipe_1 = chave1[[1]], equipe_2 = chave1[[2]])
  semi_finalista_2 <- confronto(equipe_1 = chave1[[3]], equipe_2 = chave1[[4]])
  semi_finalista_3 <- confronto(equipe_1 = chave2[[1]], equipe_2 = chave2[[2]])
  semi_finalista_4 <- confronto(equipe_1 = chave2[[3]], equipe_2 = chave2[[4]])
  
  # criação das partidas de semi-final
  
  finalista_1 <- confronto(equipe_1 = semi_finalista_1 , equipe_2 = semi_finalista_2)
  finalista_2 <- confronto(equipe_1 = semi_finalista_3 , equipe_2 = semi_finalista_4)
  
  # criação da final
  
  final <- confronto(equipe_1 = finalista_1 , equipe_2 = finalista_2)
  
  # imprime somente o nome do time campeão sem o seu peso
  
  campeao <- final[1]

	} # Final da função playoffs

########################

#Começando com a criação das equipes para a montagem dos playoffs

times <- list(
  time_A <- list(""time_A"",9),
  time_B <- list(""time_B"",9),
  time_C <- list(""time_C"",9),
  time_D <- list(""time_D"",9),
  time_E <- list(""time_E"",1),
  time_F <- list(""time_F"",1),
  time_G <- list(""time_G"",1),
  time_H <- list(""time_H"",1)
)

ordem <- list()
campeao <- NULL

for(i in 1:8064000){
i <- i + 1
sorteio <- sorteia_times(times)
aux <- c(sorteio$chave_1[[1]][1], sorteio$chave_1[[2]][1], sorteio$chave_1[[3]][1], sorteio$chave_1[[4]][1],
sorteio$chave_2[[1]][1], sorteio$chave_2[[2]][1], sorteio$chave_2[[3]][1], sorteio$chave_2[[4]][1])

# Parte para obter os strings apenas:

aux <- unlist(aux)
aux <- sub(pattern = ""time_"", replacement = """", x = aux)
string <- paste(aux, collapse ="""")
ordem[[i]] <- string

campeao <- c(campeao, playoffs(chave1 = sorteio$chave_1, chave2 = sorteio$chave_2)[[1]])
}
",Do parallel,8giwcw,new
"I am having troubles plotting histograms in R. I have a dataset that I want to mirror about the y\-axis to get a normal distribution, however, R doesn't want to plot it symmetrically. It instead plots some bins as larger than others, even though they are identical.

Example:

`myData = c(mpg$cty, mpg$cty *-1)`

`hist(myData)`

I haven't been able to find why this problem is. It seems to happen with most datasets but not with every one.

https://i.redd.it/12gjm7ooygv01.png",Histogram problems,8giqt1,new
"Are there any users that have done loops and package loading on HPC that I could correspond with about some trouble I'm having? I'm new to HPC and parallels package, and I'm having trouble getting the job to take advantage of all the cores correctly.",Help with using a package/loop on HPC R/,8gghgp,new
"There is one example in ?rlang::UQ

```
args <- list(1:10, na.rm = TRUE); quo(mean( UQS(args) ))
```

&nbsp;

Why ```mean( UQS(args) )``` doesn't work? How can I execute this without ```eval_tidy(quo(mean(UQS(args))))```?",Non-standard evaluations example,8gaw6t,new
"I'm making a bar graph that includes data about vehicle makes. I want to show the country of origin for each company (USA for Ford, Japan for Honda, etc) by having the country's flag as the image for each bar. Is there any way to do this?",Ggplot2 Images in Bar Graph,8ga6bx,new
"My code looks like this:

    tables <- c(""x"", ""y"", ""z"", ""a"", ""b"")
    tables2 <- c(""x2"", ""y2"", ""z2"", ""a2"", ""b2"")

    for (i in 1:nrow(x)){x2[i] <- length(which(!is.na(x[i,])))}
    for (i in 1:nrow(y)){y2[i] <- length(which(!is.na(y[i,])))}
    for (i in 1:nrow(z)){z2[i] <- length(which(!is.na(z[i,])))}
    for (i in 1:nrow(a)){a2[i] <- length(which(!is.na(a[i,])))}
    for (i in 1:nrow(b)){b2[i] <- length(which(!is.na(b[i,])))}

How do I do the second part using a loop? All the element x, x2 etc. are data frames. I tried using get() and assign() but I couldn't get it to work.
",How do I assign things with a loop?,8g9w53,new
"This is a problem that's highly specific to the company I work for. I'm not a data scientist, but I'm the best we've got, so I'm trying to tackle this problem. I've tried to make the problem as general and reproducible as possible.

I'm trying to summarize user behavior by getting the amount of time a user spends on each step of a process. I've got a dataframe (df.log) with columns user.id (integer), item.id (integer), log.event (factor), and timestamp (POSIX time). Cells in log.event can have the following values, with their respective meanings:

1 - user takes item  
2 - user releases item without submitting work  
3 - item expires before user submits work on item, say after 24 hours  
4 - user submits work on item  

For some reason, our database associates user IDs with log events 1 and 4, but not 2 and 3. However, only one user can ""hold"" an item at a time (i.e., after user takes action 1 on item X, another user cannot take that action until action 2 or 3 is taken on that item). After an item has undergone action 4, it is no longer visible to users.

I also have a list of all unique users whose user IDs are present in df.log$user.id. I would like to construct a dataframe (user.summary) with the following columns:

user.id (unique - each user should only have one row in user.summary
take.count (number of times the user has done log code 1)
release.count (number of times the user has done log code 2)
expire.count (number of times user has allowed an item to expire before submitting, i.e. log code 3)
submit.count (number of times user has done log code 4)
avg.working.time (average difference between when a user takes an item (log code 1) and when they submit it (4)
avg.preview.time (average difference between when a user takes an item (1) and releases it (2)

This has proven tricky because rows with log codes 2 and 3 do not contain a user ID. BUT: because no two users can be ""holding"" an item at the same time, it is safe to infer the user ID from that log event by taking the user ID from a row with the following conditions:

log.code == 1  
item.id == item.id of the current row with log event 2 or 3  
timestamp == max(timestamp) less than the timestamp of current row with log event 2 or 3 (I have no idea how to do this)  

So I have conceptually identified what I need to do, but I have failed to figure out how to write the code to do it. The best solution I can think of is creating a data frame containing all log events for each user, sorting by timestamp, and inferring the user.id for each row missing one using the above logic. This is where I get stuck:



foreach(i=which(df.log$user.id==NA)) %dopar% {  
  current.item <- df.log$item.id[i]  
  df.log$user.id[i] <- df.log$user.id[df.log$item.id == current.item &  df.log$timestamp ==  max(df.log$timestamp[df.log$item.id == current.item]) & df.log$timestamp < df.log$timestamp[i]  
}  

Obviously this code does not return the row for which timestamp is the greatest value less than the timestamp of the current row. I'm not sure how to do that, and I would appreciate any tips you can offer.

Additionally, I'd appreciate any tips on getting the average difference in time between rows with the same item.id and user.id but two different log.codes.

I'm happy to clarify if any of this doesn't make sense. Thanks for your time!",Organizing log timestamps in a data frame where certain events lack a user ID,8g64kv,new
"I am working with log files where the most meaningful columns are encoded.  The logs are CSV files with 168 columns.  I would like to expand my working versions with text meanings so that as I develop analysis the meanings are not hidden.

I created a CSV file with the 10 fields and their encoded meanings.  For example,

    head(BsFieldTable)
           FIELD  FRIENDLY VALUE            MEANING
    1  TRIP_TYPE  TripType     0               None
    2  TRIP_TYPE  TripType     1              Dummy
    3  TRIP_TYPE  TripType     2    Route:Var Trip 
    4  TRIP_TYPE  TripType     3 Non-Route:Var Trip
    5 EVENT_TYPE EventType     1             BUS ID
    6 EVENT_TYPE EventType     2           DISTANCE

The first column is the field name, the second is a friendly version, the third is the encoded value, and the fourth is the meaning in text.  This format continues for 173 rows.

If this were SQL, I could create a table for each field, and do a join to update the meaning fields.  I am essentially doing that in R using a series of ""selects"" followed by ""merges"".  For example,

    trip_type  <- select(.data=subset(BsFieldTable,
            FIELD == ""TRIP_TYPE"") [,2:4],
            TRIP_TYPE=VALUE,
            TripType=MEANING)

    r <- merge(x=bstable,y=trip_type, by = ""TRIP_TYPE"", all.x = TRUE)

BsFieldTable is the CSV file with decoding information
bstable is the log file I want to decode

This gets the job done, but the more I learn about R, the more I am convinced there is a better way than almost anything I can come up with.  Surely this common issue must have been solved, and I simply don't know the correct terms to search for the solution.

Guidance is very appreciated!",Best practice for decoding table columns?,8g2hk1,new
"Moving to a new machine, worried something will not work, is there a way to copy my full r setup?",Moving to a new machine. Can I just copy my library files?,8g1rrk,new
" Hi,

I have a recurrent problem and I saw that I was not the only one in various forum. However, I do not find the solution to this problem... 

I installed Rcmdr but, when I load it this is the error message that I have: 

Loading required package: RcmdrMisc

Loading required package: car

Error: package or namespace load failed for ‘car’ in loadNamespace\(j \<\- i\[\[1L\]\], c\(lib.loc, .libPaths\(\)\), versionCheck = vI\[\[j\]\]\):

there is no package called ‘data.table’

Error: package ‘car’ could not be loaded

Obviously I downloaded RcmdrMisc and car but still the same error message... 

Does anyone has a possible solution for this problem ? 

Thank you very much 

JB ",Rcmdr - impossible to load,8fsk79,new
"EDIT :  
thanks guys! I totally appreciate your help. Unfortunately , it still didn't work. 
I tried all your options but somehow I still either get error messages or the function will only pick the comments from the first list element instead of all the 398 list elements. 

per request hereby the link to my list / dataframes: https://imgur.com/a/ptruY0y
(do you guys mean this when you mean a reproducible dataframe, I wasn't hundred percent sure, also next time will definitely include something visual!) 

Hi for my thesis i am planning to create an analysis on Facebook posts by big Facebook pages and their interaction

I am a novice user  and learning on the go however I can’t seem so find the solution to my problem. Hopefully you guys can point me in the right direction. 

So in short using rfacebook I collected all comments of their Facebook post. However the end result is a list  of 398 objects. And each one of them is a list that contains to data frames. I want to acces the second data frame every time and merge all those data frames in to one big data frame or list. 
And then afterwards I can do data cleaning etc because I want to analyse all the sentiments between posts and comments and likes etc etc 

Anyway every time I try to do a for loop or while loop to go through every initial list to get to the comment framework, in the end I do get the comment however only from the first list. 
 
I am not sure right now what I am doing wrong 

Code rn is : 

For (i in 1:length(list) {
If (I < length (list) { 
Bind_rows(list[[i]][[“comments”]], list[[i+1]][[“comments”]])-> newcommentlist
}
}


",How to bind multiple dataframes that are nested within a list in a list ?,8focj2,new
"Hello everyone,

I've been doing some analysis the past few days and am wanting to display it in various charts and plots now.  I performed a Welch Two Sample T-Test and got the data that I wanted.  However, I was thinking about the best way to plot it.  Would it be best to use a Box plot?  Or is there another chart that is more often used to show data from a T-Test like this?

Thanks you all.",Best way to display data from a Welch Two Sample T-Test?,8fl8za,new
"Hi,
In the following code:

    ident <- function(x) x

    f0 <- function(n) {
      value <- 0
      for (i in seq_len(n)) value <- value + i
      value
    }

    f1 <- function(n) ident({
      value <- 0
      for (i in seq_len(n)) value <- value + i
      value
    })

The results of

    microbenchmark::microbenchmark(
      f0(1e5),
      f1(1e5)
    )

are 

    Unit: milliseconds
         expr       min        lq      mean    median       uq       max neval
    f0(1e+05)  2.732656  2.756592  2.804606  2.779885  2.82474  3.432165   100
    f1(1e+05) 14.912117 15.549524 16.634027 15.876213 18.18758 20.830598   100

Looks like the R compiler is unable to optimize the block { ... } wrapped within ident(). How can this be explained, and is there any way to make this compilation happen ?

    sessionInfo()

is

    R version 3.4.4 (2018-03-15)
    Platform: x86_64-pc-linux-gnu (64-bit)
    Running under: Ubuntu 14.04.5 LTS

Thanks in advance for any suggestions.

Konrad",Is there a way to make R compiler do the optimization,8fkrx2,new
"Hello,
I'm doing a ML course where I'm using R to plot graphs. The plots used to come out fine. But suddenly R studio started to go crazy on me, the top part of the plots are cut. For example, if the title of the graph is Age vs Salary, I'm only seeing half of it! Not vertically cut, but horizontally! Some weird lines show up for no reason, axis labels are not where they should be anymore, the axes themselves decide to move to the left or more to the bottom, making the plot look like it's been put in a blender and thrown back. What's going on, I didn't change the code one bit and I am checking with the code the lecturer is using and there's nothing wrong. Please help. What should I do. I restarted R studio, my laptop and also told my Mom I love her very much. 

https://imgur.com/a/n1V97fi",Problem with Plots. Plots in R are derping.,8fikw4,new
"Hi there, new to reddit and to R. I'm trying to learn the tidyverse and want to use my own book reading data. I'm usually reading 2-3 books at a time. How should I log this? I'd like to use Excel if possible, but I don't know the best way to do the columns (if that makes sense). Sorry, still a newb.

Thanks for your help!",Want to collect my book reading data to learn the tidyverse. How do I organize the data?,8fgm8d,new
"Hey everyone,

I have a large dataset with 1,400 rows and 92 columns. Of those 92 columns, I'm only really interested in 4 - 5 of them.  Is there a way that I can define something like ""MyVars = (LargeDataSet, ""What I Care About"") to filter it down?

I was thinking this would allow me to more easily find correlation/significance without wading through a bunch of unnecessary stuff.

Please let me know if you need more information.  I'm rather new to R if you can't tell",Pulling out just the variables I want from a larger dataset?,8fcnom,new
"Hello, 

I've learned some of the basics of python through the sololearn Python 3 course (I also started the first week of the MIT Intro to computer science and programming on edx.org, but I found it beyond beginner level and decided to go through the sololearn Python 3 first). 

My company (environmental consulting/environmental engineering) is interested in how R can be used for some of the basic statistics we perform (groundwater/soil analytical data). Since a co-worker already knew some R (used it in graduate research), I prioritized R since at this time it was more directly applicable to my job. I've gone through the data camp Intro and intermediate R tutorials. 

I know it's not generally recommended to start learning both at the same time, but I'm already familiar with the syntax of both and I intend to learn both regardless (python mainly for open source GIS, e.g. GRASS & QGIS, and ArcGIS). Would it be counter productive to practice and continue building on both at the same time (~15 hours/week). 
",Practicing R and python at the same time,8fcm10,new
"I posted this on StackOverflow, but I'm desperate for a solution so here it goes:

I am trying to download an excel file, which I have the link to, but I am required to log in to the page before I can download the file. I have successfully passed the login page with rvest, rcurl and httr, but I am having an extremely difficult time downloading the file after I have logged in.  (Unfortunately the website I am trying to download from is a proprietary site related to work, so I cannot provide a working example):  

    library(rvest)

    url <- ""https://website.com/console/login.do""
    download_url <- ""https://website.com/file.xls""
    session <- html_session(url)
    form <- html_form(session)[[1]]

    filled_form <- set_values(form,
                                          userid = user,
                                          password = pass)

    ## Save main page url
    main_page <- submit_form(session, filled_form)

    download.file(download_url, ""./file.xls"", method = ""curl"")

When I run the download.file command, the file pops up in my working directory, but it is not the file I am trying to download, and is actually just a corrupted .XLS file with no data.  

  

For reference, if I log in to the website via chrome, and paste the download link into the browser window after I have logged in, the file automatically starts downloading. If I do the same in IE, the file download dialog box pops up and asks me if I want to save the file.

Possibly relevant info:

* This is for my computer at work, where cookies are disabled, so I cannot use a cookie from my browser  

* I have tried using different methods with httr and rcurl based on numerous posts on SO to no avail.  

Thanks in advance for your time!",Downloading an excel file from an https URL after login,8f7u6f,new
"Currently have this solution in R, that i am hoping to translate to SQL:

a <- aggregate(Product ~ consumer + attribute_A, data = b, FUN=paste, collapse=""_"")

the goal of this is to collapse the products purchased by a consumer, in some order with a ""_"" between them. 

Sample data would look like this 
product: c(toy, toy, car)
consumer: c(12, 3, 12)
attribute_A: c(smart, dumb, smart)

final output intended would be:
toy_car
toy ",Quick Logic question - converting small snippet of R to SQL,8f3ioc,new
"I am starting to go through my first book on the R language, Learning Base R by Lawrence M. Leemis. In the Preface he states, ""The greater-than symbol (>) at the beginning of the line is a prompt that awaits an R command from the user."" However, in R Studio there is no greater-than symbol, instead there are only numbers indicating the line of code. Is this some sort of recent change in R where the greater-than symbol is no longer at the beginning? ",What happened to greater-than (>) symbol?,8ez6um,new
"I'm trying to deploy a Shiny app I've made, and the total size of the files (0.35 GB) is far below the upload limit (1 GB), but the total number of files (>50,000) is far more than the upload limit (10,000). 

What are my options for getting around this, other than excluding many of these files?",Shiny app can't deploy as I have too many files - what's a way around this?,8exwn9,new
"Hi!

I am using my original data called ""FakeDataR"" and I am trying to make a boxplot out of group means, but every tutorial I have looked up has not been working for me. Can someone help me?

Thank you in advance!",Creating a Barplot from Group means?,8exr80,new
"Right now I have a data frame that I subset using about 6 conditions and its slowing down my whole model since I have to continuously do it based on new information so I was wondering if there is a better way to do it.  This is a shortened fake version but right now I have something like

data[which(data$first==aaa & data$second==bbb),]

I was wondering if I can do anything to improve this by changing class or really anything.  The most common thing I see is to change to a data table which I have tried but I havent found anything that is faster than what Im using.  ",What is the fastest way to subset,8ex6y7,new
"I have a column in a dataframe I need to extract a name from. Its surrounded by a bunch of text I don't need. 
{""@odata.type"":""#Microsoft.Azure.Connectors.SharePoint.SPListExpandedUser"",""Claims"":""i:0#.f|membership|agent@email.com"",""DisplayName"":""**First Last**"",""Email"":""agent1@email.com"",....

basically I need a way to tell it to pull the substring after ""DisplayName"":""  and before "",""Email"":""agent1@email.com

I think I can use some form of grep to get it, but I'm not exactly sure how. The name will always follow after the DisplayName and before Email",extracting a name in the middle of text,8evtq5,new
"This is a continuation of my last post - So I thought I had the solution when applying my function to a list and its components...

test_data

    structure(list(mengzi = structure(list(chapter = c(""liang-hui-
    wang-i"", 
    ""liang-hui-wang-ii"", ""gong-sun-chou-i"")), .Names = ""chapter"", 
    row.names = c(NA, 
    -3L), class = c(""tbl_df"", ""tbl"", ""data.frame"")), liji = structure(list(
    chapter = c(""qu-li-i"", ""qu-li-ii"", ""tan-gong-i"")), .Names = 
    ""chapter"", row.names = c(NA, 
    -3L), class = c(""tbl_df"", ""tbl"", ""data.frame""))), .Names = 
    c(""mengzi"", 
    ""liji""))

a simple function pasting the list name and the embedded values.

    my_function <- function(book, chapter) {
    paste(""www.fakewebsite.com/"", book, ""/"", chapter, sep = """")
    }

Now look what happens when I map my paste function to the list.

    map2(book_list, names(book_list), ~  my_function(..2, ..1))

result - the base url was pasted once, ie, not vectorized, whereas all list values were pasted onto it!  
   
    structure(list(mengzi = ""www.fakewebsite.com/mengzi/c(\""liang-
    hui-wang-i\"", \""liang-hui-wang-ii\"", \""gong-sun-chou-i\"", 
    \""gong-sun-chou-ii\"", \""teng-wen-gong-i\"", \""teng-wen-gong-
    ii\"", \""li-lou-i\"", \""li-lou-ii\"", \""wan-zhang-i\"", \""wan-zhang-ii\"", 
    \""gaozi-i\"", \""gaozi-ii\"", \""jin-xin-i\"", \""jin-xin-ii\"")"", 
    liji = ""www.fakewebsite.com/liji/c(\""qu-li-i\"", \""qu-li-ii\"", \""tan-
    gong-i\"", \""tan-gong-ii\"", \""wang-zhi\"", \""yue-ling\"", \""zengzi-
    wen\"", \""wen-wang-shi-zi\"", \""li-yun\"", \""li-qi\"", \""jiao-te-
    sheng\"", \""nei-ze\"", \""yu-zao\"", \""ming-tang-wei\"", \""sang-fu-
    xiao-ji\"", \""da-zhuan\"", \""shao-yi\"", \""xue-ji\"", \""yue-ji\"", \""za-ji-
    i\"", \""za-ji-ii\"", \""sang-da-ji\"", \""ji-fa\"", \""ji-yi\"", \""ji-tong\"", 
    \""jing-jie\"", \""ai-gong-wen\"", \""zhongni-yan-ju\"", \""kongzi-xian-
    ju\"", \""fang-ji\"", \""zhong-yong\"", \""biao-ji\"", \""zi-yi\"", \""ben-
    sang\"", \""wen-sang\"", \""fu-wen\"", \""jian-zhuan\"", \""san-nian-
    wen\"", \""shen-yi\"", \""tou-hu\"", \n\""ru-xing\"", \""da-xue\"", 
    \""guan-yi\"", \""hun-yi\"", \""xiang-yin-jiu-yi\"", \""she-yi\"", \""yan-
    yi\"", \""pin-yi\"", \""sang-fu-si-zhi\"")""), .Names = c(""mengzi"", 
    ""liji""))

For the record, I can always rely on transforming my data to a data frame format that plays nicely - and the simple function works cleanly.  IE,

    df_format <- map2_df(test_data, names(test_data), 
    ~mutate(.x, book = .y))

    map2(df_format$chapter, df_format$book, ~my_function(..2, 
    ..1))

results 

    list(""www.fakewebsite.com/mengzi/liang-hui-wang-i"", ""www.fakewebsite.com/mengzi/liang-hui-wang-ii"", 
    ""www.fakewebsite.com/mengzi/gong-sun-chou-i"", ""www.fakewebsite.com/liji/qu-li-i"", 
    ""www.fakewebsite.com/liji/qu-li-ii"", ""www.fakewebsite.com/liji/tan-gong-i"")


So, while I can accomplish what I need right now,  I'm wondering WHY I can't get it to work with purrr... Why can't I vectorize the paste function with the book arg, for each chapter embedded under it?


##Begging for an answer, lol!
",Purrr - paste function not vectorizing when using Map(),8ej4qh,new
"Are there suggested libraries for running an http server in R?  I want to wrap some R models so that they can be used as an API.  If I have an R process sitting and waiting for requests, I wont have to deserialize the R object every time I need a prediction.  Thanks!",How to get R to wait for http requests?,8ei41t,new
"Hi all! I'm very new to R programming and programming in general, first language I'm learning. But I'm trying to make a program which does three things: 

1. calls Bitcoin price data from an API every few seconds

2. requires user input asking them to guess if the price will go: up, down, or not move in X amount of seconds. 

3. then it checks it after the set amount of time, chosen by the user, to decide if their prediction was right. 

But I'm having issues with the API call. Any help would be great! 

Here's my code so far:
            
library(httr)
            
library(jsonlite)
    
    # pull from website
    url.coin <- 'https://min-api.cryptocompare.com/'
    ticker <- 'BTC'
    convert <- 'data/price?fsym='
    base.currency <- 'USD'
    middle <- '&tsyms='
    #API request 
    request <- GET(url = paste0(url.coin,convert,base.currency,middle,base.currency))        

I got how to do some of this from https://www.cryptocompare.com/api/#-api-data-coinlist- and https://tclavelle.github.io/blog/r_and_apis/

Thanks!                        ",Help using an API,8eh0n3,new
" I've written a length script with lots of plots. I want to save them as images without: jpeg(....) dev.off(). As I need to modify most of the code for that.

Is there a way to automatically save everything that the plot window sees ?

",How to save all plots from a scripts as different files,8eelvn,new
"Hello all,

I am currently trying to import OTU tables so I can create a phyloseq object. I have done the following \(apologizes for the rather roundabout and probably redundant codes, I'm not very good at R yet...\):

sample\_data\<\-read.csv\(""OTU\_data\_here""\)

sampdat\<\-as.data.frame\(sample\_data\)

tax\_table\(otu\_matrix\)

class\(otu\_table\)

otumat\<\-as.matrix\(otu\_table\)

class\(otumat\)

class\(otu\_matrix\)

taxmat\<\-as.matrix\(otu\_matrix\)

class\(taxmat\)

class\(otumat\)\<\- ""numeric""

Once I figured out how to make the OTU work as a matrix, I tried to use phyloseq to turn it into an object \(as per this page's instructions: [http://joey711.github.io/phyloseq/import\-data.html](http://joey711.github.io/phyloseq/import-data.html)\).

OTU = otu\_table\(otumat, taxa\_are\_rows = TRUE\)

TAX = tax\_table\(taxmat\)

OTU

It looks like the objects are created no problem, but when I look at the OTU object generated it looks like this:

https://i.redd.it/m3jtfvjvrpt01.png

So the row names are sp1, sp2, etc. and OTU is a column full of NAs instead of the actual OTU names. What could be going wrong here? How do I make the OTU identifiers the row names?

Any help is much appreciated! Thank you!",Help-OTU names appear as NA column instead of row names in Phyloseq object,8eefqz,new
"So I have a data file that I am looking to fit to two exponential decay equations, a first order and second order decay model. I am able to create a first order decay no problem, but how do I generate a second order decay model? Any help is appreciated, thanks! ",Help with exponential decay modeling,8ee2ga,new
"I'm a linux newb, so unpacking tarballs is a PITA, and I don't want to bother if it won't help.","Unable to install glmnet on my laptop using Linux? I was using the R-base in the repository, will updating the R version manually fix the issue?",8e8bh8,new
I developed an app using shinyapps.io that runs the resolution mechanic for the roleplaying game I am developing.,What have you programmed in R solely for your own amusement?,8e85g2,new
Hello Guys! I need to create a for loop that reads some csv's and add them to an existing data frame. Does anybody know how to do that?,Help appending data frames,8e10i0,new
"Hey guys, I'm trying to figure out how to pass a function to a list but using different arguments for each component-  Purrr seems to be the right tool. 

I've got 5 data frames in a list. Each data frame is a book,  and the values are its chapters.  The function has 2 arguments, one being the book name, the other argument being the chapters.  The function feeds this information to an API address to download the specified chapters from the specified book.  It calls something like ""website.com/book/chapter"".  Now you can see what I mean - if I call the same book over and over, then the API call will be all wrong.

 I can do it for one chapter since the arg names are the same.  I can do it for one book (since I can still specify the same ""book"" arg) Problem is, I want to do it for multiple books, but can't figure out how to pass different book name arguments to the list of books. The book names are the names of each list component. And the API call goes all wrong as a result.

    library(tidyverse)
    library(httr)
    library(jsonlite)

##My basic API call function - (Not very robust... lol)
    ctext_api <- function(path) {
    url <- modify_url(""https://api.ctext.org/"", path = path)
    resp <- GET(url)
    if (http_type(resp) != ""application/json"") {
    stop(""API did not return json"", call. = FALSE)
    }
    parsed <- jsonlite::fromJSON(content(resp, ""text""), simplifyVector = FALSE, flatten = TRUE)
    parsed
    }

API call for grabbing a chapter in a text:

    get_text <- function(book, chapter) {

    path <-  paste(""/gettext?urn="", ""ctp:"", book, ""/"", chapter, sep = """")
 
    raw_data <- ctext_api(path)

     ##R-bind the ugly raw data for parsing
    bound_data <- do.call(rbind, raw_data)

    ##Make it into a pretty data frame
    setNames(data.frame(matrix(unlist(bound_data), ncol = 2, byrow = TRUE)), c(""Word"", ""Chapter""))
    }


Here is a short list of books and chapters for example, I need to call the function on this list,  ideally by designating each individual name for the ""book"" argument, but for the proper element. 


    book_list <- structure(list(analects = c(""xue-er"", ""wei-zheng"", ""ba-yi"", ""li-ren"", 
    ""gong-ye-chang"", ""yong-ye""), mengzi = c(""liang-hui-wang-i"", ""liang-hui-wang-ii"", 
    ""gong-sun-chou-i"", ""gong-sun-chou-ii"", ""teng-wen-gong-i"", ""teng-wen-gong-ii""
    ), liji = c(""qu-li-i"", ""qu-li-ii"", ""tan-gong-i"", ""tan-gong-ii"", 
    ""wang-zhi"", ""yue-ling""), mozi = c(""befriending-the -learned"", 
    ""self-cultivation"", ""on-dyeing"", ""on-the-necessity-of-standards"", 
    ""seven-causes-of-anxiety"", ""indulgence-in-excess""), hanfeizi = c(""chu-jian-qin"", 
    ""cun-han"", ""nan-yan"", ""ai-chen"", ""zhu-dao"", ""you-du"")), .Names = c(""analects"", 
    ""mengzi"", ""liji"", ""mozi"", ""hanfeizi""))
  
Simple test - test it on one single chapter, in a single book. Chapter 1 of Analects, ""xue-er"". This is the most basic call, the arguments simply get pasted into the API function, so no need to apply it to the list. 

    Analects_Chapter_1 <- get_text(""analects"", ""xue-er"") 

And it works well, output is:

    structure(list(Word = structure(c(5L, 15L, 6L, 12L, 9L, 7L, 1L, 
    3L, 13L, 10L, 8L, 16L, 14L, 4L, 11L, 2L), .Label = c(""子夏曰：「賢賢易色，事父母能竭其力，事君能致其身，與朋友交言而           
    有信。雖曰未學，吾必謂之學矣。」"", 
    ""子曰：「不患人之不己知，患不知人也。」"", 
    ""子曰：「君子不重則不威，學則不固。主忠信，無友不如己者，過則勿憚改。」"", 
    ""子曰：「君子食無求飽，居無求安，敏於事而慎於言，就有道而正焉，可謂好學也已。」"", 
    ""子曰：「學而時習之，不亦說乎？有朋自遠方來，不亦樂乎？人不知而不慍，不亦君子乎？」"", 
    ""子曰：「巧言令色，鮮矣仁！」"", ""子曰：「弟子入則孝，出則弟，謹而信，汎愛眾，而親仁。行有餘力，則以學文。」"", 
    ""子曰：「父在，觀其志；父沒，觀其行；三年無改於父之道，可謂孝矣。」"", 
    ""子曰：「道千乘之國：敬事而信，節用而愛人，使民以時。」"", 
    ""子禽問於子貢曰：「夫子至於是邦也，必聞其政，求之與？抑與之與？」子貢曰：「夫子溫、良、恭、儉、讓以得之。夫子之求之   
    也，其諸異乎人之求之與？」"", 
    ""子貢曰：「貧而無諂，富而無驕，何如？」子曰：「可也。未若貧而樂，富而好禮者也。」子貢曰：「《詩》云：『如切如磋，如  
    琢如磨。』其斯之謂與？」子曰：「賜也，始可與言詩已矣！告諸往而知來者。」"", 
    ""曾子曰：「吾日三省吾身：為人謀而不忠乎？與朋友交而不信乎？傳不習乎？」"", 
    ""曾子曰：「慎終追遠，民德歸厚矣。」"", ""有子曰：「信近於義，言可復也；恭近於禮，遠恥辱也；因不失其親，亦可宗也。」"", 
    ""有子曰：「其為人也孝弟，而好犯上者，鮮矣；不好犯上，而好作亂者，未之有也。君子務本，本立而道生。孝弟也者，其為仁之   
    本與！」"", 
    ""有子曰：「禮之用，和為貴。先王之道斯為美，小大由之。有所不行，知和而和，不以禮節之，亦不可行也。」""
    ), class = ""factor""), Chapter = structure(c(1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = ""學而"", class = ""factor"")), .Names = c(""Word"", 
    ""Chapter""), row.names = c(NA, -16L), class = ""data.frame"")

Test 2 - Try it on an entire work.  The book of ""mozi"". Since I need this vectorized over many chapters (which I don't have memorized) I use map from Purr to apply it to my list.  The results come out in a list due to the map function, so the results itself need to be parsed. But otherwise this works well too. I can't show output due to API running out of credits for today :( 

    mozi <- map(book_list$mozi, function(chapter) get_text(book=""mozi"", chapter = chapter))

     do.call(rbind, mozi)



So yeah, now I am trying to pass this get_text(book, chapter) to my entire list, but I have no clue how to pass a different (""book"") arg to each different data component of my list.
    
IE, I need to pass ""analects"", ""chapter"" to the analects, ""mengzi"", ""chapter"" to book_list$mengzi, ""liji"", ""chapter"" to book_list$liji     etc. 

I try:

       Books <- map(book_list, function(chapter) get_text(chapter = chapter, book = names(book_list)))

 (above doesn't work) I thought I could simply use the ""names"" function to access the book names and they'd be passed to the function as it is called on different list elements, but nope.  

Help? 
  


 
[Current Status: Not Purring](https://image.ibb.co/cEbCnS/1180183937.jpg)",Help - Applying Function to list with Purrr,8duqpv,new
"I'm stuck here, I cant seem to get my styling to work. I specifically would like to add conditional formatting to the first four columns of each chart.

Here is what I've got working without the formatting

    library(shiny)
    library(DT)


    ui <- fluidPage(
      sidebarPanel(
        sliderInput(""n"", ""Number of DTs"", value=1, min=1, max=maxTables)
      ),
      mainPanel(
        uiOutput(""dt"")
      )
    )
    
    server <- function(input, output, session) {
      
      output$dt <- renderUI({
        lapply(as.list(seq_len(input$n)), function(i) {
          id <- paste0(""dt"", i)
          DT::dataTableOutput(id)
        })
      })
      
        observe({
          species <- sort(unique(iris$Species))
        lapply(as.list(seq_len(input$n)), function(i) {
          id <- paste0(""dt"", i)
          output[[id]] <- DT::renderDataTable(iris[iris$Species == species[i],],
                                              extensions = 'Buttons',
                                              options = list(paging = FALSE, searching = FALSE,
                                                         columnDefs = list(list(width = '210px', targets = ""_all"")),
                                                             info = FALSE, dom = 'Bfrtip',
                                                             buttons = c('copy', 'csv', 'excel', 'pdf', 'print')),
                                              rownames = FALSE)
        })
    })
    }
   shinyApp(ui, server)",Adding styling to a dynamic number of datatables in a shiny app.,8dnj3t,new
"I am new to R and trying to run a [detrended fluctuation analysis](https://www.rdocumentation.org/packages/nonlinearTseries/versions/0.2.3/topics/dfa) using the [nonlinear time series package](https://www.rdocumentation.org/packages/nonlinearTseries/versions/0.2.3). 

I am able to execute the dfa() function as outlined in the [first line of the usage example](https://www.rdocumentation.org/packages/nonlinearTseries/versions/0.2.3/topics/dfa). This produces a plot of fluctuation function (Y) vs window size (X) - however, it does not give a trendline.

To get a meaningful result, I need to plot a trendline and get it's slope. Does anyone know the easiest way to accomplish this? Should I be trying to plot the output of the dfa() function and then running my own linear regression? Or is there an easier way to do it using the ""estimate""() parameter?",Help with running a detrended fluctuation analysis,8dl0te,new
"https://stackoverflow.com/questions/49889316/how-to-change-all-values-within-group-following-lagvalue-1

I have a simple problem (I think) but every logical attempt I make fails. I am not trying to write a FOR loop but I suck at those. Basically I want to split all cases for a person based on the first time there is a 45 day gap. The default is episode 1, and if there is a 45 day gap I want the rest to be episode 2. Every thing I have tried ends up with 2 cases at most labeled as case 2. I suspect it's because dplyr runs in parallel or something but I need it to run in order checking each row one at a time, that way if I tell it to change a value based on the previous row, it makes the change before evaluating the next row.",How to change all values after to another one,8dg87k,new
"I am trying to get a handle on what most R programmers believe to be best practice in regards to style. Also, I'm not a big fan of some of the rules Google and Hadley have, so I want to know how much of a faux pas it is to use my own style rules. 

Packages that can reformat your code to match style guides (*formatR*, *styler*) exist, so you could theoretically keep copies of your scripts that use a custom style and then use those packages to reformat them when you need to share outside your team. Keeping up with all the copies does seem difficult, but I could see some advantage if you find your custom style easier to read for some reason.

I don't like some of the rules Google and tidyverse have for object naming. For instance, I don't understand why objects have to be lowercase. I am learning SQL now and really like how readable it is. Because functions are capitalized (at least if you follow style conventions), it's easier to see what the tables and variables are at a glance. Highlighting from the text editor (I have maxed out RStudio's highlighting capabilities) helps, but so does the capitalization. I detest SQL code that does not use caps.  ",Do You Follow a Style Guide? Why or Why Not?,8df1n7,new
"Can someone please explain how I can add units in y Axis ticks.

For example how can I show Y axis Ticks as 1%, 2%, 3%? I haven't found a single solution on Google. Reddit you are my only hope. Thank you in advance.",Adding units in Y axis Ticks,8d9diu,new
I'm pretty familiar with R and want to learn python by myself. It just seems super confusing to get started and wondering if anyone knows a crossover tutorial for R users.,Python for R users? Tutorials?,8d6xsy,new
"Hi there! I am currently using Cox Mixed Effects model under the 'coxme 'package in R, and there are two things which I have been trying to find out but to no avail. 


1. What are the assumptions of the Cox Mixed Effects model? Are they the same as the Cox PH model? 

2. How do I test for multicollinearity of my variables? The vif function does not appear to work here.


Any help would be greatly appreciated!! ",Need help with Cox Mixed Effects model,8d6v8x,new
"So before today I hadn't even heard of R, but after a little research it turns out this language is rather good when it comes to data.

So the idea in a little more detail that I am trying to achieve; There is a 1000 x 1000 csv grid. Each cell in the grid has a value from 0 to 100. The objective is to find the most 'prosperous' 10 x 10 pieces on the grid, and preferably find them as quick and as optimal as possible.

Is this possible in R and how hard would it be to achieve? ","Read in a 1000 x 1000 csv grid, of values 0 to 100, and determine the best value 10x10 grids.",8d6paf,new
"I work for a small non-profit and have picked up R to solve many of our data and reporting requirements. We have a database managed by our parent organization which we use to collect our service data. I've been download excel reports from the database and doing relatively simple data manipulation and cleaning before exporting .csv files for use in reports created in Tableau. 

Everything is running great and going smoothly, however, I'll be leaving the organization in August and no one else on staff is prepared to learn R to manage the scripts and run the workflows. I'm trying to create a solution that will allow our less computer savvy staff to generate the required .csv files so they can use them with Tableau.

In my head, I'm imagining a simple website that will allow users to upload the required .xlsx files, run the R program, and then allow users to download the .csv files generated. 

I have a few questions though. 

First, does that seems like a possible solution that is somewhat stable? 

Second, I currently know a bit of Python and am in the process of learning Django, so I'm hoping that the web server portion of this can be somewhat easily done with that language/framework. If so, are there any recommendations on how to get started with that? Specifically using R scripts in conjunction with Python/Django.

Third, are there any obvious things I'm missing that will cause this solution to be more difficult for myself or my team once I leave? I'm hoping to train an intern or my hopeful replacement on how to manage the code once it is hosted somewhere, but I'm not sure how difficult it will be to access and manipulate the files once they are hosted. 

Any ideas are greatly appreciated! ",Running R Script from a Webpage,8cyje5,new
"Hi All,

I'm trying to take audio files and perform audio to text.  I've got my API all set-up and have gotten the test files to work and transcribe from audio to text correctly.  However, when trying to use it on my own .wav file, I run into issues.  Any idea what I may be doing incorrectly?  Below is my code:
gl_speech(""C:/Users/smars/Documents/BG.wav"")$transcript

All I get is a NULL
> gl_speech(""C:/Users/smarshall/Documents/BG.wav"")$transcript
NULL
> 

When I try other methods I get a:
 Error: Path '' does not exist

test_audio <- system.file(""C:/Users/smars/Documents/eric.wav"",lib.loc =""C:/Users/smars/Documents/"")

> gl_speech(test_audio)$transcript
Error: Path '' does not exist


Any ideas as to what I'm doing incorrectly?  ",googleLanguageR,8cxy7y,new
"Hello so, I have to create a project surrounding opinion polling on a political issue- in my case gun control and party ID. I need like two more datasets for this class and seriously cannot find one more. Is there some place I’m not looking or what. Do you know of any place that has publicly available polls or CSVs. Sorry about this tall order but I’m lost. Thanks for any direction!",Help finding polling,8cq6fy,new
"I'm making some slides using Slidify and I have a limited number of slides to play with, but a lot of content to include, so I have to get creative. My plan is to have a slide display some text, then have it fade away and be replaced by different text when the mouse is clicked. Can I do this, and if so, how?","Slidify - how to make text appear then disappear, and be replaced by different text, rather than putting the second lot of text on a different slide?",8copy1,new
"I'm trying to make some presentation slides using ioslides and I need a way to change the font. I've already managed to change the font colour, and there are loads of webpages discussing how to change the font size, but almost nothing regarding the font itself. I suspect it needs to be done in a css file, which I'm a complete beginner with. Any ideas?",ioslides presentation trouble - how do I alter the text font?,8cm1g0,new
"It's a question from assignment. I'm not sure what's wrong with my code. Just can't get the right answer. Thanks a lot!

# Use grep\(\) to find which words in test set match the following requirements. \(return locations of the matched words in test set\)

# A string that would be our netID \(lower case letters \+ number\) \(1 pt\)

test\_2 = c\(""mxian111"", ""ANSA111"", ""Jeffery"", ""199"", ""Jeff333"", ""linz22"", ""wod123""\)

My answer:

**grep\(pattern = ""\[\^\[a\-z\]\\\\d$\]"", x = test\_2, perl = TRUE, value = TRUE\)**

# **character\(0\)**",A question of grep function and regular expression,8ci9qp,new
"Putting this out there first, by no means am I competent or even vaguely adequate at R. However, I have been studying it progressively for the past 2 months and would like to know if there are any kind of competency tests I can try out to see if I am getting better with R or not. I study social sciences but I've pretty much exhausted re-analysing my data using R and I'm sure theres a ton out there to learn in order to advance my data analysis skills.


Does anyone know of any way to test my progress in R? Or, even better, does anyone know of any certifications to prove competency in R that I can study for? By no means am I good enough now, but it would give me something to work towards as well making my portfolio to get into uni look better. Thanks so much for reading!",Are there any R language competency tests?,8ce7vk,new
"I’m looking to learn how to create a Conditional Logistics Regression model in R. However, I can’t find any resources that talk about the basis of this type of regression.   

Does anyone know of a good source for informational on this model, how to formulate your data, how to build the model, etc?",Need to learn Conditional Logistic Reggression,8c596i,new
"For some reason it runs but returns a blank plot, I am not sure what I am doing wrong: 

grouped_data =  
source target value
1       8     10     2
2       9     10     4
3       9     11     2
4       9     12     1
5       8     13     1
6      10     14     6
7      11     15     2
8      12     15     1
9      13     16     1
10     14     17     6
11     15     18     3
12     16     19     1
13      0      2     5
14      1      2     1
15     17     20     2
16     19     20     1
17     17     21     4
18     18     21     3
19     20     22     2
20     21     22     1
21     20     23     1
22     21     23     5
23     21     24     1
24     22     25     2
25     23     25     3
26     23     26     2
27     24     26     1
28     22     27     1
29     23     28     1
30      0      3     2
31      0      4     2
32      2      5     2
33      4      5     1
34      2      6     4
35      3      6     2
36      4      7     1
37      5      8     2
38      7      8     1
39      5      9     1
40      6      9     6


nodes =
   V2
2   0
3   1
4   2
5   3
6   4
7   5
8   6
9   7
10  8
11  9
12 10
13 11
14 12
15 13
16 14
17 15
18 16
19 17
20 18
21 19
22 20
23 21
24 22
25 23
26 24
27 25
28 26
29 27
30 28

code: 

names(grouped_data) = c(""source"", ""target"", ""value"")
sankeyNetwork(Links = grouped_data, Nodes = nodes,
              Source = ""source"", Target = ""target"",
              Value = ""value"", NodeID = ""V2"",
              fontSize= 5, nodeWidth = 5)


","Cant get Sankey Diagram to Work, can some one help me out?",8c3t0a,new
"Hi all,

I'm hoping to learn how best to do some operations on vectors. For the sake of using a default dataset, I will use ***iris*** dataset as an example. 

Imagine for some reason you wanted a new column that was the sum of ***Sepal.Width*** and ***Petal.Width***, you could easily enough do:

    iris$new_column = iris$Sepal.Width + iris$Petal.Width

However, let's say I wanted this sum of ***Sepal.Width*** and ***Petal.Width*** EXCEPT if the ***species*** column was *setosa*. If it were *setosa* then (for whatever reason) I would want it to be *-1*. How would I best accomplish this without using a for loop and iterating through?  Any thoughts?
",Vector operations with conditions-- looking for best practice,8c2otk,new
"the way i know it <- was inherited from the s language, whereas = is just the way you know it as a programmist. now, when you define a map (or a named vector; call it what you will), the <- operator doesn't bind a value to an object:

>vectorMap <- c(purple=""Tinky Winky"",red<-""Po"", yellow=""laa laa"")

>vectorMap

returns

>purple (,) (,) yellow

>""Tinky Winky"" (,) ""Po"" (,) ""laa laa""

It is basically the same as if you used ""Po"" for red<-""Po"". Does anyone know of the rationale behind this?",in which cases is <- not the same as an =?,8bxi7r,new
"So today I tested caret using as training and testing data an image and I was wondering if there is a way to take my data again and use a deep learning classification process to...classify my data based on their features or train my data using multiple images of the same thing. Now I haven't find what I am looking for so I decided to search here.

TL;DR Is there a deep learning example in R, or a book, that you would recommend to a newbie like me for image classification?",Looking for deep learning for image classification,8bq288,new
" Hi there,

I am trying to iterate through a fairly large dataset of English words. First things first, I want to eliminate all derivative words (e.g. keep ""pet"" but removed ""pets"". In the code you will see some examples of the conditions I am going to use, but there are many more I need to add. (the 'to_delete' array to which I am appending values that match my conditions—I am going to use it to eliminate derivatives from the 'words' dataset afterwards, but I want to be able to just look at an array of potential derivatives first and evaluate from there.)

Buuuuuut, my problem: is iterating with a for loop the best strategy? I did a test run and the code will literally take days to run as is. Hahaha. 

I thought of using something similar to:
df[!(df$... ==...)] but I could not figure out a way to make this work for checking to see if word *n* in my dataset was duplicated as a derivate (adj, adverb, etc) somewhere else in the dataset. 

Any tips would be greatly appreciated. Thank you. 

    for (i in 1:NROW(words)) {
            print(i)  ## to see how code is progressing
            for (j in 1:NROW(words)) {
                if (words[j] == paste(words[i], ""s"", sep="""") ||
                    words[j] == paste(words[i], ""ed"", sep="""") ||
                    words[j] == paste(words[i], ""d"", sep="""") ||
                    words[j] == paste(words[i], ""ly"", sep="""") ||
                    words[j] == paste(words[i], ""ing"", sep="""")) {
                    to_delete = append(to_delete, words[j])
                }
            }
        }    

------
EDIT: Thanks to everyone who contributed their thoughts and suggestions. Ultimately, /u/guepier and /u/antiheaderalist provided the crucial tip and I found the tidytext package to be extremely useful.  ","Iterating through large dataset for linguistics project, using nested for loops—am I a fool?",8bpa5l,new
"I can't seem to get a hang of what I can or can't use the round fuction for. The round function if I'm not wrong is


round(command, digits=x)


However I've only been able to round items like stat.desc and data frames and not other items such as summaries 


round(summary(dataframe), digits=3)


Am I using the command wrongly or is there a rule of thumb for knowing what can be rounded or not? If not, is there any better command that is more general? Would appreciate any help, and thanks for reading!",round() Function?,8boq9p,new
how to get the most occurrence number in a set? thanks,how to get the most occurrence number in a set,8bh0it,new
"Hi /r/Rlanguage,

I have an assignment that I cannot figure out for the life of me, and it's using R and the read.transactions method. I have a CSV file that is full of transactions with multiple transactions per row. I am just trying to figure out how to separate each transaction into its own row so that I can start the market basket analysis.

Thank you in advance for your help!",Help with reading csv file and doing a read.transactions for market basket analysis,8be2rr,new
"I've been struggling for over a day with R, I still haven't gotten a grasp on how to accomplish my goal. ggplot bar graphs and data frames keep throwing me off.

Here is the example which I'm trying to emulate, but using my data.:

https://www.r-graph-gallery.com/288-animated-barplot-transition/

Hopefully one of you will be willing to help.

My dataset is a CSV file that looks something like this:
    
    Year,LabelOne,LabelTwo,LabelThree
    
    87-88,15160,3190,1590
    
    88-89,16530,3260,1650
    
    89-90,17050,3340,1650

I'm using 

    df <- read.table(""~/Downloads/data.csv"", header = T, sep = "","") 

But that's where I get stuck, I'm trying to make an animated bar graph, but I can't even make a static one. The idea is that each row in the dataset is one frame in the final GIF. (Lables as labels, and the values are the heights of each corresponding bar and column 1 being used as the title for each bar graph.)

For ex. Frame one should have 3 bar graphs side by side, with ""LabelOne"" having a height of 15160, ""LabelTwo"" having a height of 3190, etc. And a title of ""87-88"".",Need help extrapolating a R-Gallery example onto a simple dataset.,8bchkg,new
"How does one go about getting certification in R?
I'm asking to be able to put it on my resume for future career endeavors. If anyone has any verifiable sources that will give certification for R after taking some courses I would greatly appreciate it. I'm going to be researching it myself but wanted some perspective on anyone who has received certification either online or through another class setting.

Thanks.",Certification in R,8b9w8l,new
"I'm sure this is easy but I'm an R beginner.

I have a data set that has two variables one is continuous (# of species) and the other is categorical (pH level in low, med, and high).

I want to run shapiro wilks test on the species data for each category (i.e. shapiro wilks on species in low, med and high categories). How do I do that?",Quick easy question on performing tests on categories of data,8b2nnk,new
"Hello everyone,

I am still relatively new to R and would your support.


I want to analyze the following:


Y - Cortisol


X - Time (Within: 8 measurement points)

   - Light condition (Mixed: 2 within for some subjects, and 3 within for other subjects)

  
I realize that calculating a standard between ANOVA does not take into account the repeated measure nature of the light conditions.


I came up with this:

model1 <- lme(cortisol ~ light * time, random = ~ light | subject, data=df)

When I anova() it, I get plausible results, however they are ""worse"" than the between ANOVA I ran originally. Is this possible? I thought accounting for the within-variance could only improve the results. What am I missing?

Thank you for any help =)",Mixed Model Question,8ayvh8,new
"I want to plot a point graph from the iris dataset for the setosa species only, using Sepal.width for the x-axis and Sepal.Length for the y-axis. This is my script so far:

    ggplot (subset(iris, Species ==""setosa""), aes(x= iris$Sepal.Width, y = iris$Sepal.Length)) + geom_point()

But that gives me the following message: 

Error: Aesthetics must be either length 1 or the same as the data (50): x, y

Any advice?",[ggplot2] How to plot a subset of the iris data?,8ax6t4,new
"Hi all,

I've found a few R style guides which suggest using `<-` not `=` for assignment, but none of them tell me *why*.

I've searched this sub for insights, and https://www.reddit.com/r/Rlanguage/comments/2fv52q/r_style_do_you_use_or_for_assignment/ suggests a range of opinions - including the interesting ""`<-` for assignment; `=` for definitions"".

I'd like to understand when I can/should break the rules! What's the thinking behind this commonly-stated preference?","What's the *rationale* behind the preference for ""<-"" over ""=""?",8at85x,new
"https://imgur.com/a/pWxIH

So this is what i got first line is the intercept and having 5 independent variables. What are exactly Pr () and the asterisks? I searched online but it was quite confusing to understand. Are variables okay to use?

Thank you for your help in advance",How to interpret summary()?,8ap8fu,new
"Hi, I had a super simple issue that made me want to get advice on how to handle something similar in the future. I had just imported a large new data set and wasn't sure what all the factors inside a column were called, but when I tried to look it up, I had no idea what I was looking for.  In that situation, it was as easy as getting more familiar with the names of objects. Once I knew I was looking for the unique factors inside a column it was easy to find, but in the future, things will be much more complex I'm sure.

My question is, how do I ask a proper question when I don't know what I'm actually looking for?",Question about how to ask questions,8aiswp,new
"Hi all, not an entire novice in R, but no expert either. I'm blanking a bit... so I'm bringing in excel sheets, and after some tidying I can get it to something like this: 

https://i.imgur.com/hUoB2qD.png


I want to split up the ""personnel"" so that the names are separated... easy enough with stringr:

https://i.imgur.com/uwawcHF.png


But now I'd like to break out the split-up names based on what is in the ""role"" column, sort of like a key-value pair I guess. and thus the wall I'm running into. I'd like to make it look like:

https://imgur.com/GHmwl01 

This feels like something I know I've done before but since I don't really use R daily so it's escaping me. A bit out of practice. Thoughts?",Data tidying basic problem,8a4950,new
"I am currently writing an R script that takes in two sets of data and uses CCF() on them. Once given the output with the x-axis Lags and the y-axis ACF, I need to be able to figure out which lag contains the max ACF and set that lag and ACF values in two variables. For example, if I had identical data sets, I would have the max ACF of 1 at lag 0. So I need to know how to actually calculate this for non-trivial examples. Thanks in advance!

EDIT: Just figured it out.

Given x = ccf(dataSet1, dataSet2)

Lag that has max ACF is: which.max(x$acf)

Then the ACF is x$acf[which.max($acf)]",Determining What Lag has Max ACF using CCF,8a2dcv,new
Is it possible to put something in the labs= section on ggplot2 so that it will always have the limits in parentheses despite me adding new data later?,Obtain x-axis limits and put in labs= ?,8a2933,new
"       







I can get the app to either show both graphs or no graph at the same time. I want it so when the check box is clicked, the bar graph shows up, and when its not, the line graph shows up. 

        x1<- as.Date(c(""2017-01-01"", ""2017-02-01"", ""2017-03-01"", ""2017-04-01"", ""2017-05-01"", ""2017-06-01""))
        y1 <- c(1,2,3,4,5,6)
        
        graph1 <-function(){ 
             plot_ly(x = x1,y = y1,
                type = 'bar')
        
        }
        
        graph2 <- function(){
             plot_ly(x=x1, y=y1,
                    type = 'scatter',
                    mode = 'lines')
        }
        
        
        
        ui <- fluidPage(
            titlePanel(""Title""),
            sidebarPanel(""side panel"",
                         checkboxInput(""barGraph"", ""Bar Graph""),
                         verbatimTextOutput(""conditionalInput""),
                         uiOutput('conditionlInput')
            ),
            mainPanel(""main panel"",
                      plotlyOutput(""AhtPlot"")
                      # ,
                      # conditionalPanel(condition = ""input$barGraph == FALSE"",
                      #                  plotlyOutput(""AhtLineGraph""))
                      
            )
        )
        
        
        
        
        
        
        
        
        ################################################################################
        
        server <- function(input, output){
            
            
            reactive({if(input$barGraph == TRUE){
                output$AhtPlot <- renderPlotly(graph1())
            }})
            reactive({if(input$barGraph == FALSE){
                output$AhtPlot <- renderPlotly(graph2())
            }})
            output$conditionalInput <- renderText({input$barGraph})
            
            
        }
        
        
        shinyApp(ui, server)
",Need help with Shiny using checkbox input to control graph output.,8a1ksl,new
"I am trying to make choroplethr plots on Florida Counties (relative noob), and I want to compare the raw data with the log data. (I am using Census data to make this.) However, when I create the second data table, and change the ""value"" column to log, it also updates my original data table to overwrite the ""value"" column to be the log

I have:

    flCensus <- fread(""FloridaCensus.csv"")
    flCensus <- flCensus[YEAR == 9 & AGEGRP == 0, c(""FIPS"", ""TOT_POP"")]
    names(flCensus) <- c(""region"", ""value"")
    
    flCensusLog <- flCensus
    flCensusLog[, value := log(flCensusLog$value)]

So, I start out with *flCensus* having raw population data, but at the end of this script, the *flCensus$value* becomes the log value, instead of the raw value, in addition to the *flCensusLog* also being updated. This makes no sense to me. Any insight here would be appreciated!!",Data Table help (probably a noob question),89sdjw,new
"Hi,

I'd like to connect with folks who are bilingual in R and Java or folks who have used both extensively at different points in their career.

I wanted to exchange ideas on why they think Java is not suitable for statical machine learning.

Cheers!
",Java and R -- any bilingual folks?,89reyo,new
"I have been following this guide to scrape data from a website:
https://sportsdatachallenge.wordpress.com/2016/10/04/loop-through-the-player-links-and-collect-the-name-and-tm-value-of-the-players/

On the final step (scroll to very bottom of URL) we end up with a string with the following information ""40,00 Mill (Euro sign) Last Change: Any Date""

As the next part hasn't been published yet, I was curious if anyone else could provide some insight into cleaning the string up and converting it to a number. ",Converting string with numbers and characters to just numbers,89qd6a,new
"Hi R world,

I’m fairly new to the software so I wanted to ask what’s best way to overcome the 12-month constrain when using the #ggridges package to present a graph? (Example of Lincoln). More specifically, I have more than 12 months in my .csv but the software presents only the first 12 months. Thanks in advance 😉 ",ggridges question,89o6jh,new
"Is it possible to remove the white space between my grobs which [generate this](https://puu.sh/zVaUc/46561c68af.png)? Since the x-axes are the same, I'd like them to look more unified that separated. My grob code is:  

grobz <- lapply(list(EVE_Total.rolling.ACME_Est.plot, EVE_Total.rolling.ADE_Est.plot, EVE_Total.rolling.TE_Est.plot, EVE_Total.rolling.PM_Est.plot), ggplotGrob)  

grobz.plot <- arrangeGrob( grobs = list(rbind(grobz[[1]], grobz[[2]], grobz[[3]], grobz[[4]], size = ""last"")), ncol = 1)  

grid.draw(grobz.plot)
",Remove grob gap?,899nbk,new
"Does anyone know how low a p-value has to be in R that it rounds it to zero? The summary() shows p-values of zero, which is nice, but knowing what the rounding/cut-off is by default (and/or how to find/change that rounding) would be very useful.",R cut-off value for rounding p-value?,894t51,new
"I'd like to have something notify me when a script ends, rather than having to bring up my RStudio window to check. Does anything for this exist?",Is there any way to have R / RStudio give me a visual or audio alert when a script has finished running?,894hzn,new
"Testing it on my university HPC, it doesn't seem like the 'mediation' package works with parallels, but I was wondering if there's a list on CRAN somewhere of packages known/confirmed to work with it?",Ways to find out if a package works with parallels?,88v0j2,new
"Sorry if i am posting in the wrong place. I also posted this issue on stackoverflow here:

https://stackoverflow.com/questions/49590192/change-color-of-existing-polygons-onrender-function-htmlwidgets-leaflet

     library(shiny)
     library(leaflet)
     library(dplyr)
     ui <- fluidPage(""Mapping Characteristics of the USA"",
           fluidRow(
                    column(10, leafletOutput(""map"")),
                    column(2, radioButtons(inputId = ""radio"", selected=character(0), label=""Characteristics"",
                                           choiceNames = c(""Unemployment Rate"", ""% w/out high school education"", ""% w/out insurance""),
                                           choiceValues = c(""uer"", ""no_hs_per"", ""no_insur"")))))

     server <- function(input, output, session)
     {
       #Render the map
       output$map = renderLeaflet({leaflet(counties)})

       observeEvent(input$radio,
       { 
         #Create color function
         pal = colorBin(palette = topo.colors(10), domain = counties[[input$radio]], pretty=TRUE)

         #Redraw Map
         m = leafletProxy(""map"", session=session, data=counties) %>% clearShapes() %>%
           addPolygons(stroke=TRUE, weight=1, fillOpacity = 0.5, color = pal(counties[[input$radio]]))
       }) #End of observeEvent(input$radio, ...)
     }

     # Run the application 
     shinyApp(ui = ui, server = server)

Above is my code. The problem is every time a user clicks on a new radio button the leaflet map redraws the entire polygon layer. This can take a while, and it doesn't create a seamless user experience. What I would like to be able to do is simply edit the color of the already existing polygon layer.

Using pseudo code, it might look like some thing like this:

    #Create the map where every county is initially blue
    output$map = renderLeaflet({
             leaflet(counties) %>% addPolygons(stroke=TRUE, weight=1, fillOpacity = 0.5, color = ""blue"", group=""Counties"")
     })

    observeEvent(input$radio,
    {
         #Create color function
         pal = colorBin(palette = topo.colors(10), domain = counties[[input$radio]], pretty=TRUE)

         #Edit the already existing counties group
         m = leafletProxy(""map"", session=session, data=counties) %>% setStyle(group = ""Counties"", newColor = 
         pal(counties[[input$radio]]))
     })

I believe something like this could be done by adding in some Javascript. On the Leaflet for R tutorial page, they mention the onRender() function from htmlwidgets as a way to introduce Javascript (https://rstudio.github.io/leaflet/morefeatures.html).

On the documentation page for the Leaflet Javascript package, there is also a setStyle() function which would do what I want, I think (an example of it in use can be found here http://leafletjs.com/examples/choropleth/).

The only problem is I am hopelessly lost when it comes to Javascript. If somebody could point me in the right direction on how to add Javascript to my above script to get it to work that way I want, that would be great.

Also if anyone knows of any other packages, mapping tools, etc. to create the map I want which might be easier than what I am currently doing, I am eager to hear about them.

Two examples of kind of what I want to do: http://www.nytimes.com/projects/census/2010/explorer.html https://www.socialexplorer.com/a9676d974c/explore",Question About Using Leaflet With R,88tmy6,new
"Could someone please suggest simple way to convert data matrix into beautiful table in MS Word.
I'm kinda beginner but this is like biggest problem I have encountered 😔
Especially, I cannot get point of 'print'. Using xtable package doesn't let You save to docx but, f, I can't even save it to HTML the way it should look like 😕

(Sorry for such a idiot q, I'm just desperate)",Data Matrix to scientific table in MS Word,88sjgh,new
"What I want to do is, say I have a data frame with some character strings in one column and a number in another column. Some of the rows have the same value in the character string column. I want to select those rows first of all, then for each unique term, get the sum of the numbers for that particular term. However, my attempt isn't producing the expected results:

Here's my code:

    vec_1 <- c(""aaa"", ""aaa"", ""bbb"", ""ccc"", ""ddd"", ""bbb"", ""aaa"", ""aaa"", ""aaa"", ""bbb"")
    vec_2 <- c(10, 1, 1, 1, 1, 1, 1, 1, 1, 1)
    df_3 <-  cbind(vec_1, vec_2)

    colnames(df_3) <- c(""term"", ""count"")
    df_3 <- as.data.frame(df_3)
    cat(""\ndf_3:\n"")
    print(df_3)

    df_times_unique_terms_occurred <- as.data.frame(table(df_3$term))
    colnames(df_times_unique_terms_occurred) <- c(""term"", ""num_rows_seen_on"")
    cat(""\ndf_times_unique_terms_occurred:\n"")
    print(df_times_unique_terms_occurred)

    df_repeating_terms <- df_times_unique_terms_occurred[
      df_times_unique_terms_occurred$num_rows_seen_on > 1, ]
    cat(""\ndf_repeating_terms:\n"")
    print(df_repeating_terms)

    df_3__repeating_terms_only <- df_3[df_3$term %in% df_repeating_terms$term, ]
    df_3__repeating_terms_only$term <- as.character(df_3__repeating_terms_only$term)
    df_3__repeating_terms_only$count <- as.numeric(df_3__repeating_terms_only$count)
    cat(""\ndf_3__repeating_terms_only:\n"")
    print(df_3__repeating_terms_only)

    df_aggregated <- aggregate(x = df_3__repeating_terms_only$count, 
                           by = list(df_3__repeating_terms_only$term),
                           FUN = sum)
    colnames(df_aggregated) <- c(""term"", ""sum_counts"")
    cat(""\ndf_aggregated:\n"")
    print(df_aggregated)

Here's the output:

    df_3:
       term count
    1   aaa    10
    2   aaa     1
    3   bbb     1
    4   ccc     1
    5   ddd     1
    6   bbb     1
    7   aaa     1
    8   aaa     1
    9   aaa     1
    10  bbb     1

    df_times_unique_terms_occurred:
      term num_rows_seen_on
    1  aaa                5
    2  bbb                3
    3  ccc                1
    4  ddd                1

    df_repeating_terms:
      term num_rows_seen_on
    1  aaa                5
    2  bbb                3

    df_3__repeating_terms_only:
       term count
    1   aaa     2
    2   aaa     1
    3   bbb     1
    6   bbb     1
    7   aaa     1
    8   aaa     1
    9   aaa     1
    10  bbb     1

    df_aggregated:
      term sum_counts
    1  aaa          6
    2  bbb          3

So, as you can see, there are 5 rows in the initial dataframe df_3 that contain ""aaa"" and 3 that contain ""bbb"". So these are the rows I'm interested in. However, the ""count"" column in df_3 shows that one of the ""aaa"" rows has count = 10, and the rest of the ""aaa"" rows have count = 1, for a total of 14 rather than 6. And all of the ""bbb"" rows have count = 1. So my final dataframe, df_aggregated, should instead show:

      term sum_counts
    1  aaa          14
    2  bbb          3

What am I doing wrong? The problem seems to appear when I'm creating df_3__repeating_terms_only, because the first ""aaa"" count has dropped from 10 to 2.",Why isn't my attempt at aggregating working as expected?,88l23s,new
"Hi.
I'm writing some functions in R and so far I'm using the following code to power a matrix in R. 
This method is using the `expm` package and its `%^%` operator.

    Qmp <- expm::`%^%`( as.matrix(Qm), (as.numeric(L)-1) )

While with small matrices the code responses quite good, when I'm trying to execute it for a kinda big matrix which dimensions are

    > dim(Qm)
    [1] 17328 17328

I realized that is taking too long time to complete. To be honest, I let that code for two hours and then stopped it.

Also after the powering of the `Qm` I'm also performing and a multiplication of two matrices like

    Pm <- Qmp %*% as.matrix(Rm)

where

    dim(Rm)
    >17328    58

For more info, `Qm` and `Rm` are specific sub-matrices of a bigger transition matrix that describes a weighted graph.

So I was wondering if there is any other way to approach such task and be quicker by using the Rcpp.

",Rcpp approach to power large matrices,88k94n,new
"I am trying to find all the stock records where the yield is greater than the median for all stock using sqlds but I am getting this message. I have tried using the actual number 2.39 and it works but I have not been successful substituting a variable to make it dynamic. Maybe a subselect would be better?

mYd <- median(df3$Yield, na.rm = TRUE) 

df4 <- sqldf(""SELECT a.* FROM df3 a WHERE (a.Yield > mYd) ;"")

Error in rsqlite_send_query(conn@ptr, statement) : no such column: mYd",Using sqldf to find records greater than median of all values,88byfh,new
"I’m performing a project in R where I want to try and avoid pulling email signatures.  So, generally speaking, I’m looking for “@”, “.com”, “mailto”, etc; and then pulling once those expressions are identified, pulling everything to the left of them

So for example, in excel, I might right something like: =IFERROR(FIND(""net"",N2),IFERROR(FIND("".com"",N2),IFERROR(FIND("".edu"",N2),

And then use min and left to pull the text to the left of everything.  So, looking at the fake email below:
Hello,

Please review this document.

Best Regards,

Sam Smith@xyzcompany.com
We are doing the best we can to make you happy

I want to pull just; 

Hello,

Please review this document.

Best Regards,

Sam Smith


Basically, the function should go, find when “@” or “.com” appears, and pull the smallest minimum count, then pull everything to the left.  So in this case, @ would be seen before “.com”  and would pull prior. 

So, I started playing around with functions and loops and found some helpful stuff online.  

trial <- matrix(c(""I don't understand @ this"",""Why won't this work .com this"",""How can't we .com figure this out"",""Please @ help me""), ncol=1)

colnames(trial) <- c('text')

trial.table <- as.table(trial)

trial

This fix.contractions function works: 

fix.contractions <- function(doc) {

  # ""won't"" is a special case as it does not expand to ""wo not""

  doc <- gsub(""won't"", ""will not"", doc)

  doc <- gsub(""can't"", ""can not"", doc)

  doc <- gsub(""n't"", "" not"", doc)

  doc <- gsub(""'ll"", "" will"", doc)

  doc <- gsub(""'re"", "" are"", doc)

  doc <- gsub(""'ve"", "" have"", doc)

  doc <- gsub(""'m"", "" am"", doc)

  doc <- gsub(""'d"", "" would"", doc)
  # 's could be 'is' or could be possessive: it has no expansion

  doc <- gsub(""'s"", """", doc)


  return(doc)

}  

trial2 <- trial

trial2 <- as.data.frame(trial2)

trial2$text <- sapply(trial2$text, fix.contractions)
trial2

                                     text

1   I do not understand @ this .com stuff

2 Why will not this work .com this @ what

3     How can not we .com figure this out

4                        Please @ help me




Then I tried to pull everything to the left, of either the “.com”, “@”, etc.

#Take everything to the left
left = function(text, num_char) {
  substr(text, 1, num_char)
}

fix.stuff <- function(doc2) {
  #take everything to the left of particular values
  pos <- regexpr(""@"",doc2)
  pos2 <- regexpr("".com"",doc2)
  minimum <- min(pos,pos2)
  doc2 <- left(doc2,(minimum)-1)
  return(doc2)
}

trial2$text <- sapply(trial2$text, fix.stuff)


But when I run the function, all I get is blank.  Ideally, I want the data to look as follows

Text

I do not understand

Why will not this work

How can not we

Please


Any ideas???  Thank you!
",Pull everything to the left based on various “expressions”,88aw6j,new
"I created a 15 minute interval for time binning using seq. I also have data points with exact times and a count next to it. How can I take those counts, sum them and put them in the appropriate bins?",How to add counts to intervals,883344,new
"Good morning I am looking for a way to create a new column to an existing dataframe that has the value of the rolling mean of all rows that contain a specific label. 

For instance let's say I have a dataframe where each row contains shape and I want to get a rolling mean of all the rows where ""shape"" == ""spherical"" of the columns ""volume"" and put the values into a new column called ""rollmean"" note,  leave the column ""rollmean"" set as  NA if ""shape"" != ""spherical"".",Create a rolling mean to specific rows of a dataframe,88233d,new
"I tried this and it's working:

df <- within(df, Name[Name == 'John Smith' & State == 'WI'] <- 'John Smith1')

However, is there a way to do it for multiple columns like I have ID numbers. and I want to add job title sales for example based on these id numbers, like whole column, how can I do it in r? Is there a way to update the column job based on id numbers? if I have 50 id numbers and I want to insert sales into job for all 50 rows. Moreover, is there a way to query columns, so let's say if column job contains sales, update industry to marketing for example. Any ideas or suggestions? is there a library that can do this? like pandas in python?","How to insert values into a column based on another columns value, conditional insert/ update.",87ur1l,new
"I'm looking for some feedback on the way I have always structured my R visualization projects. At a high level, I have emphasized ease of debugging and execution. So I source several R files, use small single-purpose functions and most importantly, embed all dependencies within a given function.

What does this mean in practice? As an example, if I load my plot.R file, it will load all required libraries and source any required custom files such as load_data.R.

Then when I run plot_function1(), it will just run and I will see the output. It calls the load_plot_data(params) function to retrieve its data. Since there is no setup required, it makes iterative development quite fast and debugging even easier. 

(I've also held to the convention that all function parameters have defaults so I can always make a simple call to the function to test it out.)

Alternatively, if I want to dig into the load_plot_data() function, I can just load the load_data.R file and execute load_plot_data() and I will be presented with its output.

Every function in my application works this way. All of the dependencies are inherently wired into the sourcing of the files.

This is completely counter to the principles of Inversion of Control where I should actually be passing all of my dependencies into the function in question. So to call plot_function1, I would first need to call DATA <- load_plot_data() and then call plot_function1(DATA).

I understand the rationale for IoC in OOP programming, especially when it comes to doing unit/integration tests. But I constantly question whether that is appropriate for an R/Shiny data analysis project, especially with function-centric R is. I can find scant little information on the matter. This is the only hit I come up with:

http://r.789695.n4.nabble.com/Dependency-Injection-amp-Inversion-of-Control-for-Data-td4694710.html

I know my methodology works very well for me and I have developed some decently sized applications using this approach. But in fairness, I haven't attempted to implement any kind of unit testing in my applications and it's probably time to correct that. On the other hand, I have found that the demands of an R application are less about ensuring that the code doesn't break and more about identifying that the underlying data is correct. Exposing the intermediate data flow for scrutiny has driven my programmatic approach.

Is IoC be a prerequisite for unit testing? Is there a third way that I may not be thinking of? (I suppose I could theoretically enable both...)

Does anyone know of any recommended resources that delve into architecting larger scale R data projects?",Inversion of Control and R,87snel,new
"Hi all,

I've been trying to figure this out for a while - I have a dataframe that has GPS location data stored for about a hundred different animals(with over 400,000 entries), it looks something like this:
   

    > head(the.animals[,1:11])
    name bear_ID location_n        x       y   loc_date loc_time loc_year loc_month loc_day fix_type
    1: G001   21202        161 494000 5820000 2000-05-24 11:01:00     2000         5      24        2
    2: G001   21202        590 512000 5830000 2000-09-01 19:01:00     2000         9       1        3
    3: G001   21202        621 498000 5830000 2000-09-13 07:01:00     2000         9      13        2
    4: G001   21202         66 493000 5830000 1999-05-11 13:02:00     1999         5      11        3
    5: G001   21202         31 489000 5800000 2000-04-26 11:01:00     2000         4      26        3
    6: G001   21202         63 49000 5830000 1999-05-10 21:01:00     1999         5      10        3

... I want to subset those data with another dataframe that looks like this: 

    > head(target.animals)
    name sex                  years
    1 G008   2                   2006
    2 G040   1                   2006
    3 G074   3             2009, 2010
    4 G110   2                   2008
    5 G111   1 2008, 2012, 2013, 2014
    6 G115   2                   2011

So at the end of my operation, I will have a new dataframe that includes all rows from the first dataframe (the.animals) that belong to the appropriate animal across the years specified in the second dataframe.

I welcome any thoughts

Thanks!",Selecting rows of a dataframe efficiently,87ny5u,new
"Hi all,

I am working on a project that uses the tuneR package to parse and analyze midi files of videogame music. I've been impressed with some aspects of the tuneR package. I've been underwhelmed by other aspects.

One thing that bugs me about tuneR is that I can't use it to write midi files. It looks like the function lilyinput was going to do that, but the developers never got around to finishing it. 

So I'm taking the lilyinput function and sprucing it up so that I can write lilypond files. Then I use lilypond to generate a score and a midi file. 

Here's the github project: [lilyinput](https://github.com/areeves87/lilyinput). Pretty bare bones right now. Would love to collaborate and maybe get some feedback. ",Writing midi files with R: lilyinput2,87nout,new
"I'm fairly new to using Rstudio. I used to use Stata for regression analysis but I didn't want to pay for it anymore so that's how I found Rstudio. I came across the OLSRR package but whenever I install it, it installs the 0.4.0 version even though the newer version is 0.5.0. I try to update it from Rstudio but it's not actually doing anything. I seem to not be able to use any functions within the package and I think it's cause it's not the newest version. Any help is greatly appreciated.",Trouble Updating OLSRR Package,87eipm,new
"Hello,

Fairly new to R and I'm currently trying to loop through all the columns in a data table and apply rollapply a I wrote. I will then take the bottom value of each column and divide it by the same position in the Acc column. 

ret = data.frame(
  Acc = c(89518 ,62382 ,54202 ,72308 ,51548 ,69929 ,84618),
  d1 = c(14200,	10681,	9455,	9559,	8777,	12353,	12850),
  d2 = c(7685,	6160,	4678,	5539,	4987,	5678,0),
  d3 = c(5937,	3785,	3694,	4173,	3310, 0, 0),
  d4 = c(4264,	3494,	3113,	3104, 0, 0, 0),
  d5 = c(4831	,3141	,2389, 0, 0, 0, 0),
  d6 = c(4929,	2450, 0, 0, 0, 0, 0),
  d7 = c(3835, 0, 0, 0, 0, 0, 0) )

rp <- rollapply(df[length(ret):7], 2, sum, partial = TRUE, align='right')

colret <- function(x,y){print(x[which(x > y)])}

zk <- for(i in 1:ncol(ret)){
  colret(ret[,i],7)

I'm not sure how to loop through the columns from L -> R while looping through the columns vertically at the same time.

Does anyone know of a reference I could use to understand this?

Thank you!",Rolling Sums Using Rollapply,87eeno,new
"Hello all! I'm using ggplot2 an all works great, I'm trying to produce this a figure ... the code is as follows (see below). But the chunk that produces side by side visualizations ""facet_wrap"" tells me Error: 'predicate' must be closure or function pointer.

ggplot(orlando_combined, aes(x = (dist/1000), y = lq)) + geom_smooth(span = 0.3, method = ""loess"", color = ""blue"") +
geom_hline(yintercept = 1, color = ""black"", linetype = ""dashed"")+
theme_minimal() + facet_wrap( ~year)+ labs(x = ""Distance from Downtown (km)"", y = ""Concentration relative to metropolitan area"", caption = ""Data source: 1990 Census and 2012-2016 ACS"", title = ""Home Owners in Greater Orlando Area"") +
theme(plot.caption = element_text(size = 6))

The rest works! It is just that!

Any recommendations?

",help with a ggplot!,87cz26,new
"Hi all,

Is anyone aware of a package that removes email signatures?  I tried  the package ""‘tm.plugin.mail"" but I can't get any of the functions to actually work, I believe it has to do with how my data is set up.

Basically, I'm pulling information from the Salesforce ""Case"" Object.  The way emails are read into those tables really makes it difficult to pull out signatures.  For example, my data may look like:

Hello XYZ,
Your product is awful.  
Sincerely, 
James

*James Ford*
CEO/Co-Founder

*Services, Inc., *
Office: 111-111-1111
*We are committed to the pursuit of excellence*

OR, we might get data as follows:

Would it be possible to get a copy of the front/back of this document?
Randy
Accounting Manager 
(222) 222-2222 - Direct 
bxyz@randyrocks.com<mailto: bxyz@randyrocks.com >
Management COMPANY 


Basically, I want to find a way to pull all the information before a footer or signature appears...but I don't know of an easy way to do this?  Thoughts?  As mentioned, everyone's email signatures being so different makes life very difficult.",Removing email signatures,87bcb6,new
"Hello, 

I have just stated using R, I have been trying a couple things. 

I would like to make a plot like said in the title, with the contour XYZ and vector XYAM like this [one](https://imgur.com/a/4aYes) from Origin. I don't find Origin practical for this type of graph even though the result is pretty nice. I find it a pain to deal with, so this is the main reason I am heading toward using R.

I have my data and all done on R, I plotted [this](https://imgur.com/a/SQJ1H) using quiver. I don't get why some vectors are completely off. 

I can't use the filled.contour and contour because of the error with ""x and y should be increasing..."". I looked at heatmaps as an alternative at the moment. 

If you have any idea, tips, insights on this issue it would be fantastic.

Cheers,
",Plotting a contour XYZ and vector XYAM,8733km,new
"I'm exploring the topic of boxplots, the notch option in particular.
I'm wondering what notch width to notch height tells us (in other words, how skewed the line is.
My intuition is:
- the bigger ration (notch height / notch width) is, the bigger is the distance between a median value and the rest of inlines.
Am I right? BTW, can you describe some examples where boxplot analysis served you well?",Boxplot - notch width to notch height ration.,86ruwz,new
"I have a data set containing people's identifiers and the medication they have received. I need to compare their medication schedule to a given schedule applicable at the time. Are  there any packages/pre-existing code that I could use with modifications? This is a complex problem, so anything out there would help.

an example of one row of data: name, DOB, date of administering A(1), age at administering A(1), date of administering B(1), age at administering B(1), date of administering C(1), age at administering C(1), date of administering A(2), age of administering A(2), date of administering C(2), age at administering C(2), date of administering D(1), age at administering D(1), etc

Notice that there isn't a date and age for administering B(2) because perhaps it wasn't scheduled till after D, or not scheduled at all.

I need to: 

1. Make clear the difference between ""missed set of medications on day x"" and ""selectively missed medication on day x"" (eg. if A, B and C were supposed to be given on day x but only A and C were given, the program should return B under ""selectively missed on day x"")

2. Be able to change the administration schedule applicable to each person based on their date of birth (schedules have changed and different ones apply to different people as a result) OR have a file with all the schedules and link up a person with a given schedule up to a certain age and then change the schedule they are linked to.

3. Certain medications are given together on a certain day, but separately afterwards: 

     eg. on day x1, A, B and C are supposed to be given;
     on day x2, A and C are scheduled to be given;
     on day x3, C and D;
     on day x4, B. 

     I wouldn't want what I produce to tell me that D is selectively missing at x1, x2 and x4, or that A and C should 
     always come together and therefore A is missing at x3.

I am a complete noob at R, so any helpful packages that you could think of would be great. Thanks!",Helpful packages for comparing dates and values to a changing schedule,86oekm,new
"Hell RLanguage.  Awesome R shiny is a curated list of r shiny resources in the following areas:

- [Resources](https://github.com/grabear/awesome-rshiny/blob/master/README.md#resources)

- [General](https://github.com/grabear/awesome-rshiny/blob/master/README.md#general)

- [Community](https://github.com/grabear/awesome-rshiny/blob/master/README.md#community)

- [Deployment](https://github.com/grabear/awesome-rshiny/blob/master/README.md#deployment)

    
- [Tutorials](https://github.com/grabear/awesome-rshiny/blob/master/README.md#tutorials)

- [Tools](https://github.com/grabear/awesome-rshiny/blob/master/README.md#tools)
    
- [Packages](https://github.com/grabear/awesome-rshiny/blob/master/README.md#packages)
    
- [Integrations](https://github.com/grabear/awesome-rshiny/blob/master/README.md#integrations)

- [People](https://github.com/grabear/awesome-rshiny/blob/master/README.md#people)

- [Books](https://github.com/grabear/awesome-rshiny/blob/master/README.md#books)

- [Galleries](https://github.com/grabear/awesome-rshiny/blob/master/README.md#galleries)

- [App Examples](https://github.com/grabear/awesome-rshiny/blob/master/README.md#app-examples)

- [Contributors](https://github.com/grabear/awesome-rshiny/blob/master/README.md#contributors)

I'm currently working on updating the list for 2018 with a few others.  If anyone here knows of something that we're missing, we'd really appreciate a [PR](https://github.com/grabear/awesome-rshiny/pulls) or a comment on the [2018 update issue](https://github.com/grabear/awesome-rshiny/issues/61).",[Help Wanted] Awesome RShiny list - 2018 update.,86nd3w,new
"Let's say I have a 4x4 matrix. Is there a way I can view it in the viewer in a grid like format, with four squares, and in them the values in the corresponding index in the matrix?

I'm not sure this is feasible, but since I'm new at R, I thought I'd ask!

Thank you!",[Question] Is there a way to display matrix in the viewer in R studio,86meli,new
"I'm attempting to do some webscraping. Some of the text I want to scrape is within an ""accordion"" type of layout. I'm currently attempting to use the rvest package to do this, but I've been unsuccessful.

My code:

    webpage2 <- read_html(""https://...)

    data <- html_nodes(website2, ""#panel-0-0"") %>% html_text()

[This is the website in question.](https://education.iupui.edu/academics/degrees-programs/masters/urban-principalship/program.html)

Any advice would be appreciated. Thanks!",Webscraping text in an accordion layout,86eytc,new
"Hi to everyone and first of all sorry for my poor eng. My professor ask me to compute an orthogonal garch with the language R, using 3 assets price, and i know that there are package for doing that. But the core is to compute the orthogonal garch following the decomposition of the portfolio with eigenvectors and than compute the variances of each uncorrelated portfolios with univariate garch. I dont really understand how to do it, if someone can explain how to decompose the protfolio apllying univariate garch and then put toghether the variances estimatet into a cov matrix. I dont know if you can understand what i am writing due to the bad comprehension that i have on this task. Thanks :) ",OrtGARCH,86b4z3,new
"**Edit:** Thanks for the input guys. I wrote a heatmap function after all: [example output](https://github.com/SchmidtPaul/useful/blob/master/img4.png?raw=true)

Hey there! Mediocre R stats guy here.

So I don't often work with matrices, but when I do, they are too large to be displayed in the console or viewer and I often want to quickly check things like 

* What are its dimensions?
* Is it diagonal?
* How many differnt values are on the diagonal?
* Are there mostly zeros or small values on the off diagonal?
* Are there exceptions to an overall pattern?

So what do you guys do to quickly investigate/check your matrices. I thought that looking at the matrix as a heatmap would be quite nice. Yet, before I throw myself into writing a function I wanted to make sure that I am not missing an important point here.

Bonus: table(df$col1, df$col2) output also creates such ""matrices"" that I would like view as heatmaps for a quick overview.

Cheers! 

","Guys, how do you quickly examine your large matrices?",862q94,new
"I was only good with excel on a very basic level and vlookup/pivot tables. Was very impressed with a temporary colleague (sent from HQ) who saw how I was struggling with some simple work and made a file which im not sure from macro or Visual Basics.

I did not have chance to ask him more about those skills but I would really like to improve on my skillset with data manipulating and things along that line. 

Should I bother with learning Visual Basics/VBA, or should I go straight into R or Python and then apply them in Excel?",What's next for me?,85tmfm,new
"I am a Data Analyst at a national financial software company.  Right now I use VBA and SQL exclusively for my job.  


A typical request would be something like:
 ""Hey, CYANBD, can you give me all the transaction numbers that match that this certain specific criteria?""  This requires me to manipulate HUGE spreadsheets, think a handful of spreadsheets all 200k-300k rows long.  


vLookups and formulas won't work unless I cut down the spreadsheets quite a bit, so I end up writing VBA loops to get the data how I need it.  I've found this way has its own limitations.


I also spend a large portion of my time creating macros that utilize custom user interfaces to manipulate data and create reports for people throughout the company.


I'd like to expand my programming knowledge (being an expert in VBA doesn't go very far) and I'd like to be better at my job at the same time.  That said, if I don't need to do any statistical or predictive analysis, and I just primarily work with very large data sets and creating custom interfaces, would there be any benefit to learning R?",Should I learn R?,85ojr0,new
"I already posted here, but I figured out my last problem and fell into another. 
I was given a dataset here-> https://www.cdc.gov/nchs/data-visualization/drug-poisoning-mortality/ and was asked to create a county level map of ODs in the year 2004 and 2014. I created a map, but am struggling to convert the ""Estimated Age"" section into actual numerical values for R to read and plot on the map. I used this as the code, and was given the also listed responses-> 
data(""county.fips"")
> my.data <- merge(Drug_Poisoning_Mortality_by_County_United_States, county.fips, by.x = ""County"", by.y = ""FIPS"")
Error in fix.by(by.y, y) : 'by' must specify a uniquely valid column
> my.data <- merge(Drug_Poisoning_Mortality_by_County_United_States, county.fips, by.x = ""County"")
Error in merge.data.frame(Drug_Poisoning_Mortality_by_County_United_States,  : 
  'by.x' and 'by.y' specify different numbers of columns
> my.data <- merge(Drug_Poisoning_Mortality_by_County_United_States, county.fips, by.x = ""FIPS"", by.y = ""fips"")
> my.colors <-colorRampPalette(c(""red"",""purple"",""blue""))(10)
> my.data$County <- as numeric(cut(my.data$`Estimated Age-adjusted Death Rate, 16 Categories (in ranges)`, seq(0,100, length.out = 16)))
Error: unexpected symbol in ""my.data$County <- as numeric""
> my.data$County <- as.numeric(cut(my.data$`Estimated Age-adjusted Death Rate, 16 Categories (in ranges)`, seq(0,100, length.out = 16)))
Error in cut.default(my.data$`Estimated Age-adjusted Death Rate, 16 Categories (in ranges)`,  : 
  'x' must be numeric
> my.data$County <- as.numeric(cut(my.data$`Estimated Age-adjusted Death Rate, 16 Categories (in ranges)`, seq(0,100, length.out = 16)))
Error in cut.default(my.data$`Estimated Age-adjusted Death Rate, 16 Categories (in ranges)`,  : 
  'x' must be numeric
> DrugData <- read.csv(""Drug_Poisoning_Mortality_by_County_in_United_States"")
Error in file(file, ""rt"") : cannot open the connection
In addition: Warning messages:
1: In doTryCatch(return(expr), name, parentenv, handler) :
  display list redraw incomplete
2: In doTryCatch(return(expr), name, parentenv, handler) :
  invalid graphics state
3: In doTryCatch(return(expr), name, parentenv, handler) :
  invalid graphics state
4: In file(file, ""rt"") :
  cannot open file 'Drug_Poisoning_Mortality_by_County_in_United_States': No such file or directory
> DrugData <- read.csv(""Drug_Poisoning_Mortality_by_County_United_States"", stringsAsFactors = FALSE)
Error in file(file, ""rt"") : cannot open the connection
In addition: Warning message:
In file(file, ""rt"") :
  cannot open file 'Drug_Poisoning_Mortality_by_County_United_States': No such file or directory
> DrugData <- read.csv(""Drug_Poisoning_Mortality_by_County__United_States"", stringsAsFactors = FALSE)
Error in file(file, ""rt"") : cannot open the connection
In addition: Warning message:
In file(file, ""rt"") :
  cannot open file 'Drug_Poisoning_Mortality_by_County__United_States': No such file or directory 
I needed help making R read the values as different concentration, and projecting them onto the map as seen in this video >https://www.youtube.com/watch?v=M prUQT8N9M&index=44&list=PLE3uzGh7FZRl4UEkm9LQpy7lOv9H6ibjY",How to make estimated values numeric? in R,85ohy2,new
"So Im trying to create a county map of the US that shows drug overdoses in 2004 and 2014. I have the map, but I am unsure how to use make R use my data. i got my data here https://www.cdc.gov/nchs/data-visualization/drug-poisoning-mortality/ and according to the question have to, ""Read the data in to R. Matching on the fips variable, merge it with the county name data from the maps() library in R. Then create two county- level maps of drug poisoning mortality in the United States, one for 2004 and the other for 2014.
Be sure to add a legend to each map explaining what the colors mean."" I did import the data from a csv, but cannot get it to plot the data on the map. Thanks for any help!",How to create a map.,85o2t1,new
"Hi,

I was assigned to write a program that simulates the game connect 4, where the user plays against my program.

I'm an intermediate programmer, so writing the code itself wasn't hard. So for a bit more of a challenge, I thought, maybe I could write a code, that learns to play connect 4, as you play more and more games. Basically using machine learning. But I dont know how hard that would be using R, if possible at all.

I was just wondering if you guys think that would be possible, and if possible, how should I get started with it?

I know there are probably better languages to do that, but I'm restrained to R here.

Thanks!

EDIT: I've never used machine learning before, so I don't know how feasible this all would be, or if it would be beyond my coding skills to begin with. Any advice is welcome",[Question] Machine learning connect 4 game,85n4ur,new
"I want to Expose hong kong stock data to public user, which way is the best? thanks",Expose data to public user,85k7nr,new
"https://www.reddit.com/r/dataisbeautiful/comments/7ol3gy/gaussian_distribution_oc/

I know R isn't the ideal software to do so, but I was wondering if it'd be possible to achieve that result using R",[Question] Is there anyway to do this in R,85gy40,new
"How do you get r to graph a scatter plot? I every time I enter the code, it automatically plots a boxplot. I am using plot() command with my data and it plots it all as a multiple box plots. I was using a box plot() command prior, but I researched and it said R should go back to the scatter plot. Not sure of any other ways to trouble shoot. I can provide code if needed.",Help.,85ghxq,new
"So, I've been looking at this R language thing, did some tutorials, and am really enjoying it. However, I do not work in a field (at all actually, about to start college this summer) that requires the use of this software. How could I use this to my own advantage, or better said, what are the uses that statistical software offers to the average joe?",What uses does R have for the average joe?,85e3rz,new
"Sorry the title is vague, I'll explain more here to prevent titlegore.

I have a data frame with multiple columns. One column is dates with some dates being repeated and others just a single occurrence. 

I'd like to get rid of only the rows that are multiples of the same dates and only keep the first occurrence of that date. I can't use the unique() function because the other columns differ here and will just return the full dataset. 

Normally, I have some things to try and post here, but I honestly have no idea where to even start. I've tried googling, but I don't even know how to word the problem I'm having. 

Any help would be appreciate and I can offer more information if it's needed!

Thank you in advance!

Edit: I think I've figured it out!

    newdf <- df[match(unique(df$date), df$date), ] ",Removing specific rows in a dataframe,85cbxc,new
"Im new to R.  Approximately a year of self teaching.  I can do most code/functions etc in R.  But, when it comes to designing large processes/scripts in R , im sure im not doing it the best way.

Basically,  my R-Scripts are set up like this.

**Creating Master Tables for Process**

1)  Load Data: bring in tables from a few different data sources

2)  Merge data:  I merge the needed variables and rows from the loaded data into a few work tables or sometimes just one master table.

3) Create new variables, clean data, etc:  I create alot of new metrics using the work tables, clean the data, and more or less create my final work tables for the actual process

**The Process**

This is where I will do things like customer segmentation, regressions, or other analytic processes.  

1)  Metric Creation(Optional):  An example of this is average price paid per product.  It is in my master table, but occassionally i get request to over write those prices and use different time frames or customer segments.  For example in my base data i use average price per product for last 12 months.  Here I am loading the product data and calculating the average price for the last 3 months.

2)  Run Segmentation,Regression, etc: Just run the analytical process here and create new variables that are then reassigned to my work tables

3) Create Output table: More or less drop variables from my work table and create a cleaner output table that is pushed into AWS to be used by others.


**Questions**

1. This is one large script.  Would it be better to seperate Part 1 into its own script and save the rdata.  Then just load the rdata for part 2?  And i can just update the rdata whenever needed.

2.  In Part 2.  I have very time consuming steps where i load some of the original data sources and recalculate one value based on end user request.  This is an issue for two reasons.  One it is the most time consuming part of the part 2. Two, it is alot of code that only needs to run sometimes that i just note out otherwise.

What do you do with code that you only need to run sometimes?  Right now im just putting # in front of large sections of code. And manually going in and deleting the # when needed.  There has to be a better way here.
",Creating large processes/scripts. A few design questions,85c0fm,new
"I'm attempting to create a heatmap of a dataframe using [ComplexHeatmap](http://bioconductor.org/packages/release/bioc/vignettes/ComplexHeatmap/inst/doc/s1.introduction.html). However, I've run into a problem where the values of the heatmap run from -1 to 1, and many are extremely close to each other, such as 0.98 and 0.99. As a result, the colors of the heatmap are useless when attempting to differentiate smaller values. 

[The heatmap can be seen here](https://i.imgur.com/dxaAMqv.png).

In the above heatmap -1 is red, 0 is white and 1 is blue.

Is it possible to better differentiate these close values in ComplexHeatmap?",Is there a way to better differentiate close values (i.e. 0.98 and 0.99) in a visualized heatmap?,855icw,new
"The original R Markdown displays input and output result line-by-line:

e.g.

    ```{r ECHO= TRUE, EVAL = TRUE, results='hold'}
    print(1)
    print(2)
    ```
---
Input Chunk display :

print(1)

print(2)

---

Output Chunk display:

1

2

---

Is is possible to make a table with 2 columns, left column holding input result, right column holding output result?

e.g.

Result Display:

==========|

R Code  |Result|

==========|

print(1) |1

==========|

print(2) |2

==========|

---
Thanks.","R Markdown, HTML : display R code in left, output result in right, like a table with 2 columns",851ic1,new
I am writing a vignette for a package that I am making but for some reason knittr outputs my html file in a random temp directory which I need to search for after knitting then I have to manually move the file hoping that I didn't accidentally grab an older iteration of the file.  Instead I would like my output to be placed in either vignette directory (under the package root) or the package root directory itself overwriting any previous version that might be there. Saving the file in a random temp directory makes no sense to me. ,how to set the directory of knittr output,84znyy,new
"I have the pdf f(x) = 2*(x-1) for 1<=x<= 2 and 0 everywhere else.
The median should be at 1+sqrt(2)/2.
How do I find it in R?
Thanks in advance :) ",Help on median function.,84xepw,new
"New to R Markdown.

Wanna know can I adjust the chunk such that all results are displayed as ONE chunk, instead of line-by-line code?

e.g.

    ---
    title: ""Basic R Operators""
    output:
      html_document
    ---

    ```{r echo = FALSE, eval= TRUE}
    5 + 5 # return 10
    5 - 5 # return 0
    5 * 5 # return 25
    5 %/% 5 # return 1
    5 %% 5    # return 1 
    5 ^ 3    # return 125
    5 ** 3     # return 125
    ```



---

Desired output ( All lines in 1 chunk ) :

## [1] 10

## [1] 0

## [1] 25

## [1] 1

## [1] 0

## [1] 125

## [1] 125






However, the above code returns the following  (7 lines as 7 chunks):


## [1] 10


## [1] 0


## [1] 25


## [1] 1


## [1] 0


## [1] 125


## [1] 125



Hope you understand my presentation. Thanks.
","R Markdown, HTML : how to output the result of a code chunk as a result chunk, instead of a line-by-line result?",84u8a5,new
"If you have a data set with 52 rows and 6 columns, and you wanted to output a new list with every other row from that data set, what would the code for that be? ",How can you subset every other row in a table?,84s99x,new
I have a ggplot in polar coordinates and i want to 3D print it or bring it into a CAD program. Any ideas on how to do this?,Export to 3D model or STL,84rvzc,new
"current code is


 ggplot(female_data, aes(x = Age, y = EPG)) + 
  geom_boxplot(fill = ""cornflowerblue"", colour = ""black"") +
  facet_wrap(~Year, nrow=1) +
  theme_bw() +  
  ggtitle(""Female comparison between age and EPG"") +
  ylab('Eggs per gram')

but no legend is coming",How do i add a legend to a boxplot in ggplot2,84omt4,new
"Hey, I have data table consisting 3 columns. I wrote a function which shows the volume of a cylinder and I want to put a certain column of the data to the function. does someone know how to do it despite scan() function?
",Linear regression in r,84gle0,new
"I have a time series graph using plotly. How can I specify what I want the starting axis label to start on without shifting the axis itself? 

For example I have daily data for a month, but I only want the first monday of every week to show up as a label on the graph. I know how to set the shift between labels, but can't figure out how to set the initial label date. ",plotly selecting which axis labels to appear,84g7ji,new
"I'm attempting to replicate the work in a paper on how opinions change in a population (https://www.frontiersin.org/articles/10.3389/fphy.2015.00017/full).  I've managed to build simulations that generate data that seems appropriate but I'm struggling getting a chart that looks like the one in the paper.  This link shows the chart I'm trying to replicate (on left) and what I can currently get (on right):
[Imgur](https://i.imgur.com/DEIStqM.png)

I'm particularly interested in the ""calmer"" coloring of the original chart.

A coarse version of chart can be generated with the below:

	library(plot3D)


	z <- structure(c(0.023, 0.02, 0.025, 0.03, 0.038, 0.046, 0.058, 0.069, 
					 0.087, 0.105, 0.104, 0.087, 0.07, 0.056, 0.046, 0.038, 0.03, 
					 0.025, 0.022, 0.022, 0.023, 0.021, 0.025, 0.032, 0.022, 0.006, 
					 0.006, 0.024, 0.106, 0.259, 0.23, 0.086, 0.022, 0.006, 0.006, 
					 0.023, 0.034, 0.025, 0.022, 0.022, 0.023, 0.02, 0.029, 0.038, 
					 0.01, 0.005, 0.028, 0.133, 0.142, 0.083, 0.091, 0.142, 0.103, 
					 0.023, 0.005, 0.011, 0.041, 0.03, 0.021, 0.022, 0.023, 0.02, 
					 0.037, 0.028, 0.009, 0.086, 0.191, 0.085, 0.022, 0.005, 0.01, 
					 0.016, 0.083, 0.167, 0.098, 0.009, 0.031, 0.039, 0.019, 0.022, 
					 0.023, 0.019, 0.041, 0.017, 0.063, 0.272, 0.064, 0.001, 0, 0, 
					 0, 0.006, 0.008, 0.028, 0.268, 0.086, 0.02, 0.042, 0.019, 0.022, 
					 0.023, 0.02, 0.041, 0.024, 0.252, 0.14, 0, 0, 0, 0, 0, 0, 0, 
					 0.004, 0.066, 0.309, 0.037, 0.042, 0.019, 0.023, 0.024, 0.022, 
					 0.04, 0.079, 0.277, 0.058, 0, 0, 0, 0, 0, 0, 0, 0, 0.02, 0.291, 
					 0.104, 0.044, 0.019, 0.023, 0.024, 0.024, 0.039, 0.18, 0.213, 
					 0.02, 0, 0, 0, 0, 0, 0, 0, 0, 0.01, 0.209, 0.188, 0.05, 0.021, 
					 0.023, 0.024, 0.028, 0.045, 0.236, 0.154, 0.014, 0, 0, 0, 0, 
					 0, 0, 0, 0, 0, 0.119, 0.27, 0.066, 0.022, 0.023, 0.024, 0.031, 
					 0.116, 0.232, 0.098, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.065, 0.283, 
					 0.104, 0.025, 0.023, 0.024, 0.034, 0.183, 0.169, 0.089, 0, 0, 
					 0, 0, 0, 0, 0, 0, 0, 0, 0.064, 0.26, 0.124, 0.028, 0.024, 0.024, 
					 0.036, 0.241, 0.134, 0.064, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.053, 
					 0.242, 0.149, 0.032, 0.024, 0.024, 0.04, 0.242, 0.135, 0.059, 
					 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.037, 0.203, 0.2, 0.037, 0.024, 
					 0.024, 0.05, 0.262, 0.13, 0.033, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
					 0.033, 0.146, 0.253, 0.043, 0.024, 0.024, 0.063, 0.264, 0.115, 
					 0.033, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.033, 0.123, 0.262, 0.058, 
					 0.024, 0.024, 0.089, 0.243, 0.11, 0.033, 0, 0, 0, 0, 0, 0, 0, 
					 0, 0, 0, 0.033, 0.096, 0.263, 0.084, 0.024, 0.024, 0.128, 0.216, 
					 0.099, 0.033, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.033, 0.049, 0.292, 
					 0.102, 0.024, 0.024, 0.153, 0.191, 0.099, 0.033, 0, 0, 0, 0, 
					 0, 0, 0, 0, 0, 0, 0.033, 0.033, 0.279, 0.131, 0.024, 0.024, 0.176, 
					 0.17, 0.098, 0.033, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.033, 0.033, 
					 0.258, 0.153, 0.023, 0.024, 0.203, 0.158, 0.082, 0.033, 0, 0, 
					 0, 0, 0, 0, 0, 0, 0, 0, 0.033, 0.028, 0.244, 0.172, 0.023, 0.024, 
					 0.205, 0.156, 0.082, 0.033, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.033, 
					 0.017, 0.248, 0.179, 0.023, 0.025, 0.21, 0.15, 0.082, 0.033, 
					 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.033, 0.017, 0.231, 0.196, 0.023, 
					 0.026, 0.246, 0.125, 0.07, 0.033, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
					 0, 0.033, 0.017, 0.215, 0.212, 0.023, 0.026, 0.268, 0.107, 0.066, 
					 0.033, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.033, 0.017, 0.188, 0.239, 
					 0.023, 0.026, 0.283, 0.092, 0.066, 0.033, 0, 0, 0, 0, 0, 0, 0, 
					 0, 0, 0, 0.033, 0.017, 0.18, 0.247, 0.024, 0.027, 0.284, 0.089, 
					 0.066, 0.033, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.033, 0.017, 0.169, 
					 0.256, 0.024), .Dim = c(20L, 26L))



	persp3D(x=1:nrow(z),y=1:ncol(z), z, theta=-20, phi=30, axes=TRUE,scale=3, expand=0.25, 
			box=TRUE, xlab=""opinion (-1.0 to 1.0)"", ylab=""ticks * 10"", zlab=""Distribution"", 
			r=2, shade=0.4, nticks=4, ticktype=""detailed"")
",[Question] Help using Persp3D (or other 3d charting) to match a published chart,84fwu6,new
"Hi all! I've just gotten started learning R with Swirl, and I love the interactive courses so far, they've been incredibly helpful. I'm trying to intertwine more statistics into my major (HCI), and thought R would be a great addition when doing research, analysis, and data visualization.

I've been looking for reference books that are good for beginners, but everything I've found thus far has mixed reviews, and I'm honestly not sure what exactly to look for in a R reference book. It seems like the best I've found is [this](https://www.amazon.com/gp/product/1593273843/ref=ox_sc_act_title_5?smid=ATVPDKIKX0DER&psc=1), but I'd like to know if there's any better resources that I could utilize before making a purchase. 

Thank you!",R books for beginners?,848n9k,new
"Just started on statistics major and that was the homework for the first class, I have no idea how to do it, please help me.",I need to calculate variance on R only with the function sum(),83vucs,new
"Instead of always highlighting the code to be executed and then press Ctrl + Enter, is it possible for RStudio to predefine a certain region of code, and then the user the user can always execute by Ctrl + Enter, without the need to highlight?

( or any other similar process? I am still googling the answer. )
Thanks.",execute only a predefined region of code in RStudio,83txbf,new
"Say I have a vector that looks like

    my_vec <- c(""AAA"", ""BBB"", ""CCC"")

and a constant, say 
    
    my_const <- ""xxx""

And I want to end up with

    ""xxx AAA""  ""xxx BBB""  ""xxx CCC""

How do I do this? I've been trying with apply() functions that I'm not too familiar with, trying things like:
 
    pasteFun <- function(x1, x2){
        x <- paste(x1, x2, sep = "" "")
        return(x)
    }

    new_vec <- lapply(x = my_vec, FUN = pasteFun(x1 = my_const, x2 = my_vec))

but I've had no success so far. What should I do?
",How to paste a constant string onto each element of a vector of strings?,83slu6,new
"Hey, does someone know how to do it this :
The sum of n independent exponentially distributed random variables with parameter λ = 1 has a
gamma distribution with parameters λ = 1 and α = n. As the exponential distribution is rather skewed,
it is to be expected that the central limit theorem gives a bad approximation for small values of n.
Show that the approximation improves as n grows larger. To do this, write a function stand.gamma()
that generates 1000 standardized realizations from a gamma distribution with λ = 1 and α = n. So this
function has only one parameter: n",Gamma distribution from the sum of exponential,83ohoh,new
"I wrote a function which can output all relevant names, and corresponding indexes for an , as follows:

Everything works fine, except it prints out "" NULL"" at final line. How can I get rid of that ""NULL""?

    ==================== [ Code ] ====================
    
    PRINT_NAMES = function(obj){
      msg = """"
      L = length(names(obj))
      for (i in 1:L){
        part = paste0(""[["", i, ""]]"", "" \"""", names(obj)[[i]], ""\"""", ""\n"")
        msg = cat(msg, part)
      }
      print(msg)
    }
    
    df = read.table( header = TRUE, text = '
                     Name Age Height Sex
                     A 4 123 M
                     B 3 142 F
                     C 6 131 F
                     D 3 124 F
                     E 7 153 M
                     F 2 132 M
                     G 4 135 M
                     H 4 122 M
                     ')
    m = lm( Age ~ Height , data = df )
    
    PRINT_NAMES(m)
    
    ==================== [ Result ] ====================
    
    [[1]] ""coefficients""
    [[2]] ""residuals""
    [[3]] ""effects""
    [[4]] ""rank""
    [[5]] ""fitted.values""
    [[6]] ""assign""
    [[7]] ""qr""
    [[8]] ""df.residual""
    [[9]] ""xlevels""
    [[10]] ""call""
    [[11]] ""terms""
    [[12]] ""model""
    NULL","UDF : avoid ""NULL"" to be printed",83me1c,new
"So I've tried create a shiny app from scratch using geographic data, but my attempt had no success. What I tried to create was a simple app that will just take two inputs (a shapefile and a raster) and then plot them. But by using this [code](https://pastebin.com/sQPgfFBH) i ran into this error 
>Error in .getReactiveEnvironment()$currentContext() : 
  >Operation not allowed without an active reactive context. (You >tried to do something that can only be done from inside a >reactive expression or observer.)

Can anyone give me any advice on whether it is a logical or a syntax error because I am fairly new to Shiny
",Creating a map with R Shiny,83fi5v,new
"Below is a function to return a numerical max of a given formula from a certain x range

Everything works fine as follows.

--------------------------------------------

MAX_FN_XY = function(Fn, x1 = 0, x2 = 100)

{

  x = seq(x1, x2, by = 0.001)

  i = which.max(Fn(x))

  x_max = x[i]

  y_max = Fn(x[i])

  return (c(""X"" = x_max,""Y"" = y_max))

}

MAX_FN_XY(function(q){q-2*q^2})

--------------------------------------------

Output :

   X    Y

0.250 0.125 

--------------------------------------------
To make the function calling more concise, is it possible to rewrite the script to achieve the following ?

MAX_FN_XY(q-2*q^2)

Thanks!",pass formula as function parameter,83d53i,new
"I am working on a project for a non-programmer. It's based off of a smallish data set but I don't want to do it in excel(ugly graphics, not customize-able, etc). What is the best way for me to share my R code, graphics, and some analysis with them? R markdown requires having R installed, correct? Is there something else similar, or is it best to pop this all in an intermediate document format like word/ markdownfile saved as a pdf? ","Best way to communicate R code,analysis, and data with someone who doesn't have R",832drb,new
"Hi 

New R disciple here. I'm trying to learn how to use R for Value at Risk and Expected shortfall (Conditional VaR) estimations through GJR-GARCH modelling.

Which libraries can help me out plus I'd appreciate some pointers with GARCH type modelling with R.

Thanks in advance.",Which R libraries best handle GJR-GARCH volatility modelling?,8326dd,new
"Hi everyone, after avoiding R so far I have decided to add it to my toolbox. As a Python intermediate user, what are some recommended resources?

I don't mind paid options too.

Thanks in advance",R resources for a Python user.,83215l,new
"Say I had a column like:

    the
    the
    of
    the
    and
    the
    the
    and
    of
    and

What's the best way to end up with:

    and  3  
    of  2
    the  5
","If I have a column with repeating values, how best to count the number of rows each unique value appears on?",830rzf,new
"Hi, 
I am using RStudio. But I find it hard to come up with a full list of acceptable values for those ggplot2 parameters.

e.g. 
How do I know that ""linestyle"" allows values such as ""dashed"", ""solid"" ?

Is there a convenient way to check it besides googling websites by websites?

I visited the official website but seems no full list can be found.

Thanks.","ggplot2 : how to check the built-in values to input for ggplot2 parameters like linestyle, position, etc?",82x2ru,new
"Are there anyone experienced with scraping SEC 10-K and specifically downloading the exhibit 21 in R?

What I basically want to do is the following:

**1)** Download all 10-K available on SEC between for a specific list of company names (or tickers or sic number etc.)

**2)** Search every 10-K filing for Exhibit 21

**3)** Search every Exhibit 21 for a list of country names and create a merged dataset like the following where all the subsidiaries of a company are listed with the country location of each subsidiary per firm:

[Dataset example][1]


  [1]: https://i.stack.imgur.com/9BuLr.png



Here is one example of the 10-K exhibit 21 filing that I need to parse:

https://www.sec.gov/Archives/edgar/data/320193/000032019317000070/a10-kexhibit2112017.htm


So I basically need to parse/scrape this for a list of companies.


 
","How to scrape web, SEC Edgar 10-K , exhibit 21?",82rwsq,new
"Hi I am making a business proposal for R this week and I was wondering if you can give me unique or power uses for R and examples.

I'm going to be using R to text mine and analyze data from databases for work. Is there other things R can do that would help me for creating a case for it?",Benefits of R?,82pj75,new
"In R I'm attempting to construct a heatmap using the ComplexHeatmap package from bioconductor. My data goes from -1 to 1, with -1 being red, 0 being white, and 1 being blue. I'd like to break the legend up into two of equal size, one going from 0 to -1 and the other going from 0 to 1. I think that organizing the legends in this way will better represent my data. However, it hasn't been as easy as I thought it would be to add a second legend. My attempt is seen below:

    Heatmap(gsea.heatmap.df,
            cluster_rows = FALSE,
            cluster_columns = FALSE,
            show_row_dend = FALSE,
            show_column_dend = FALSE,
            col = colorRamp2(c(-1, 0, 1), c(""red"", ""white"", ""blue"")),
            heatmap_legend_param = list(color_bar = ""continuous"",
                                        at = c(0, -0.1, -0.2, -0.3, -0.4, -0.5, -0.6, -0.7, -0.8, -0.9, -1), 
                                        labels = c(""1"", ""0.9"", ""0.8"", ""0.7"", ""0.6"", ""0.5"", ""0.4"", ""0.3"", ""0.2"", ""0.1"", ""0"")),
             heatmap_legend_param = list(color_bar = ""continuous"",
                                         at = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1), 
                                         labels = c(""1"", ""0.9"", ""0.8"", ""0.7"", ""0.6"", ""0.5"", ""0.4"", ""0.3"", ""0.2"", ""0.1"", ""0"")),
            row_dend_width = unit(15, ""mm""))

However, this gives me the following error:

    Error in Heatmap(gsea.heatmap.df, cluster_rows = FALSE, cluster_columns = FALSE,  : 
      formal argument ""heatmap_legend_param"" matched by multiple actual arguments

Is there a way to add a second legend to the data? If not, is there a different R heatmap package that would work better?",How to add two legends to the same heatmap in R?,82hcst,new
"Hello all, 

I have 3 datasets structured like so:
> subject measure1 measure2 measure3

The steps for my analysis are:

* Import datasets and covariates

* multivariate multiple regression and keeping the residuals

* normalize

* perform MANOVA and other tests if significant (alpha = 0.05/3 = 0.017).


I can copy paste the commands while changing the name of the datasets in order to run the analysis on all 3 of them but would rather use apply or a loop. Advice/suggestions?

    # Load packages

    library(mvnormtest)

    # Import datasets (shortdata, mediumdata, long data)

    setwd(""C:/Users/jaewook/Documents/anal/"")
    path = ""C:/Users/jaewook/Documents/anal/""
    dataset <- list()
    file.names <- dir(path, pattern = "".csv"")
    names <- c(""longdata"", ""mediumdata"", ""shortdata"")
    for (i in 1:length(names)){
        assign(names[i], read.table(file.names[i], header = TRUE,             sep = "",""))
    }

    # Import demeaned covariates (age, framewise_displacement, scanner)

    regressors <- read.table(""demeaned_regressors.txt"")

    # Multivariate multiple linear regression with covariates, keep residuals for MANOVAs

    model <- lm(cbind(longdata$longcon, longdata$longeglob,         longdata$longeloc) ~ as.matrix(regressors), data = longdata)
    regressedlongdata <- residuals(model)

    # Standardize

    zreslongdata <- scale(regressedlongdata, center = TRUE, scale = FALSE)
    zreslongdata <- longdata
    zreslongdata[3:5] <- zreslongcon

    # MANOVAs

    longdata.man <- manova(cbind(longcon, longeglob, longeloc) ~     group, data = zreslongdata)


In the code above, I imported the 3 datasets but just ran the analysis through ""longdata"". In the end I would like to have longdata.man, mediumdata.man, and shortdata.man. Or man.long, man.med, man.short. 

Thank you in advance. Even links or videos explaining the right approach would be greatly appreciated.",Running the same analysis on 3 datasets,82h73l,new
"Let's say I have a data set with columns Year and Temperature. I want to only keep data from 2015. So I use

> df <- df[Year=2017,]

What R does is replace all rows not in 2017 with NA. Why doesn't it just remove those rows?",Why isn't my subset code removing irrelevant rows?,82bs40,new
"If I read in data for say computers, with each row listing out amount of ram, type of cpu, and amount of storage (say: 16, intel, 1) how could I find rows that contain both ""intel"" and 16 gb of ram? I know that table(pc$cpu) will give me the number of intel cpus but how do I apply both conditions?",how to find data that fills two conditions,82a6um,new
"I have a column of Product Types, about 30.  its mostly in 3 major types. I want to write a function that will check each row of that column and replace one of the 30 with the appropriate of the 3 major product types.

I've got a for loop with a series of if conditions with a lot of OR operators, doing the work but its taking a long time to get through all 130k observations. so i'm just wondering if you guys know any tricks that could help speed this up. 

A lot of the 30 look something like this ""Networking: Subtype X""",how to check a condition and replace a string without for loops and if conditions?,829xmh,new
"Introducing a BETA release of dashboardthemes - an experimental R package designed to provide custom theme options for Shinydashboard applications.


More details are given in the below links:


Blog post: https://nik01010.wordpress.com/2018/03/05/introducing-dashboardthemes/


Github repo and detailed instructions: https://github.com/nik01010/dashboardthemes


Please read the disclaimer before using this package.

Feel free to provide any comments or feedback.

N",Introducing dashboardthemes - experimental themes for Shinydashboard,829t92,new
"I'm doing a homework now, a bit confused about the saying below. 
""Use the sample function to generate a vector named ""group"" of 1s and 2s that has the same length as the diamonds dataset.""

The data is diamonds from ggplot2, and I don't understand the meaning of 1s and 2s. Should I create a vector with ""1"" and ""2""? ","I want to generate a vector using sample function, but a bit confuse about the requirement.",824mq0,new
"I already know many languages, and have a practical knowledge of machine learning and data science with Python. I’m looking to expand my skills in statistics and pick up R at the same time.

Are there any resources out there that target my demographic?",Learning R as an experienced programmer,823ybl,new
"Hey everyone,

I just recently installed RStudio and took a few courses on it and now I'm getting into more nitty-gritty datasets and manipulation but RStudio on my PC crashes literally every three minutes.

Maybe I'm doing something ill-advised within the software? I'm just typing my code and comments into the script and printing it to the console and such; nothing ridiculously heavy. I Google'd ""RStudio crashing on Windows 10"" to basically no avail.

Thanks for your time in advance from a beginner!",New to R and having a hard time w/ the software,823n30,new
"Hi Team!!

I am trying to merge 2 data frames together (actually 4, but 2 for the sake of this example :P ). Rbind does not let me do this because the column names are different, but I am working with Forecast data and receive it in quarterly chunks (Jan-Mar, Apr-Jun, etc.) So I want to merge the quarterly chunks together.
See below:

    Q1 <- data.frame(Customer = c(""Ford"", ""Chevy"", ""Dodge"",     ""Subaru""), 
                     Project = c(""F150"", ""1500"", ""Ram"", ""Impreza""), 
                     January = c(10, 15, 10, 20), 
                     February = c(20, 30, 20, 40),
                     March = c(15, 20, 15, 30), 
                     OtherInfo = 1:4); Q1

    Q2 <- data.frame(Customer = c(""Ford"", ""Chevy"", ""Dodge"",     ""Subaru""), 
                     Project = c(""F150"", ""1500"", ""Ram"", ""Impreza""), 
                     April = c(10, 15, 10, 20), 
                     May = c(20, 30, 20, 40),
                     June = c(15, 20, 15, 30), 
                     OtherInfo = 5:8); Q2

 And combine Q1 and Q2 such that:

    Q1Q2 <- data.frame(Customer = c(""Ford"", ""Chevy"", ""Dodge"",     ""Subaru"", ""Ford"", ""Chevy"", ""Dodge"", ""Subaru""), 
                       Project = c(""F150"", ""1500"", ""Ram"", ""Impreza"",     ""F150"", ""1500"", ""Ram"", ""Impreza""),
                       January = c(10, 15, 10, 20, 0, 0, 0, 0), 
                       February = c(20, 30, 20, 40, 0, 0, 0, 0),
                       March = c(15, 20, 15, 30, 0, 0, 0, 0),
                       April = c(0, 0, 0, 0, 10, 15, 10, 20),
                       May = c(0, 0, 0, 0, 20, 30, 20, 40),
                       June = c(0, 0, 0, 0, 15, 20, 15, 30),
                       OtherInfo1 = 1:8); Q1Q2 

Any idea how I could accomplish this? There is also more columns than what is stated here, I just need to find some way to merge the rows together and keep all other data intact.

Thanks in advance.

Edit: changing grammar to hopefully make it easier to understand. Please ask any clarifying questions. ",Trying to merge 2 data frames together but column names do not quite match up,821oun,new
"I realized i've only made models based on 1 independent and dependent variable, and both were continuous. 

I have absolutely no idea how to do this. 

I'm doing an experiment on cells where i treat them with something (using 10 different treatments), and measure the viability of the cells over time (3 time points where measurements were made). 

So i need to make a model that predicts cell viability based on the treatment and the time point. 

uhhh... how???? any help would be greatly appreciated. ",Building a model based on 2 independent categorical variables and 1 independent continuous variable.,821877,new
"hi, i'm looking for some help using lines() within a loop.  i've created a list of xts (extensible time series) objects, and when i iterate through the list to plot and add a moving average line to each one with a for loop, lines() makes the line black, where i've specified red.  

this seems to be related to the lines() call within the loop or the list itself, because if i create each xts object individually and use plot() and lines() outside of any loop the lines() color output is correct.

is this a common issue, where plotting/printing from within a loop is different from doing it outside?

this is what the loop code looks like, the lines() output is black:

    zone_vec <- /* [ a list of text ids ] */
    zone_list <- list()
    for (node in zone_vec) {
        # process data
        # append xts objects to a zone_list
        print( plot( zone_list[[ node ]], main = paste(node, "" Hourly TotalLMP"")) )
        print( lines(WMA(zone_list[[ node ]][ , ""Price""], n = 168, col=""red"", lwd=2)) )
    }

the time series plots correctly and so does the WMA line, it's just the wrong color.  any suggestions?  thanks.",lines() gives wrong color in a loop,81zocj,new
"So I have a script which basically needs two inputs; a raster and a shapefile. Is there a scenario where I can make a shiny app by just creating two inputs and executing that script without learning Shiny from the beginning? If so, how do I do that? Where do I look for it?",Looking for a quick way to integrate R script to Shiny,81z25w,new
"i've followed the tutorials on using foreach and it seems to work fine. however when i try to use it inside a function block, it seems like it can't find my iteration range. here's my simple function

    doClara <- function(data, k) {
        cm <- clara(data, k, samples=100, pamLike=TRUE)
        sil <- silhouette(cm, full=FALSE)
    }

here's my usage of `foreach` inside a function

    doClaraParallel <- function(data, start, end) {
        foreach(k=start:end) %dopar% {
            doClara(data, k)
       }
    }

it complains that `k` is not defined.

",[Question] Using foreach inside a function block,81kyw0,new
"I have an R Shiny app hosted on an aws server, and yesterday I realized that the app wasn't getting up to date data due to the data querying happening in global.R, which is only run when the app starts.

However, today it looks as though the app has rerun global.R and the data is now up to date, however, the AWS server was apparently not restarted.

What could have caused this? Can the Shiny app restart itself independently of the server? How can I check this?

Also, if I cloned the directory holding the original shiny app and ran the clone, would running global.R for the clone update global.R for the original?

The one thing I'm not able to do is update the data in the original data source to see whether the app updates to reflect the changes.",How would an R Shiny app hosted on a AWS server rerun global.R without a server restart? Is it possible?,81ens4,new
" hey, does someone know how to make that n people have a birthday within k days of each other.?
",Birthday paradox problem,81dioy,new
"EDITED POST WITH SOLUTION

So for my thesis I'm working with different accents. Each participant saw one of the 3x2x2 conditions, such as Hispanic Accent * Positive condition * Male (if they were male). The only data I have to use in R from that is an attention check at the end so if they were in the HS_POS_M there will be an integer in the hs_pos_m_accent variable, otherwise it's NA.

I'm trying to find a way to code this as a single variable, called Condition, so that I can treat the conditions as a factor. So far everything I try manages to create a variable where only about 22 of the observations have a value, AKA one of the 3x2x2 groups. It should basically just say HSPOSM

I know that I am doing this wrong, and it might be a simple fix, but I'm drawing a blank. I initially tried mutating all those into the same variable but that didn't work so I'm trying to created individual variables and merge/gather them.

    df_accent <- df_orig %>%
      select(`hs_pos_m_time_First Click`:rp_neg_f_att_accent)%>%
      mutate(HSPOSM_accent = ifelse(hs_pos_m_att_gender > 0, TRUE, FALSE)) %>%
      mutate(HSNEGM_accent = ifelse(hs_neg_m_att_gender > 0, TRUE, FALSE)) %>%
      mutate(MWPOSM_accent = ifelse(mw_pos_m_att_gender > 0, TRUE, FALSE)) %>%
      mutate(MWNEGM_accent = ifelse(mw_neg_m_att_gender > 0, TRUE, FALSE)) %>%
      mutate(RPPOSM_accent = ifelse(rp_pos_m_att_gender > 0, TRUE, FALSE)) %>%
      mutate(RPNEGM_accent = ifelse(rp_neg_m_att_gender > 0, TRUE, FALSE)) %>%
      mutate(HSPOSF_accent = ifelse(hs_pos_f_att_gender > 0, TRUE, FALSE)) %>%
      mutate(HSNEGF_accent = ifelse(hs_neg_f_att_gender > 0, TRUE, FALSE)) %>%
      mutate(MWPOSF_accent = ifelse(mw_pos_f_att_gender > 0, TRUE, FALSE)) %>%
      mutate(MWNEGF_accent = ifelse(mw_neg_f_att_gender > 0, TRUE, FALSE)) %>%
      mutate(RPPOSF_accent = ifelse(rp_pos_f_att_gender > 0, TRUE, FALSE)) %>%
      mutate(RPNEGF_accent = ifelse(rp_neg_f_att_gender > 0, TRUE, FALSE))

    df_test <- 
      df_accent %>%
      select(HSPOSM_accent:RPNEGF_accent) %>%
      gather(key = ""accent"", value = ""Accent Type"")


[Imgur](https://i.imgur.com/AzXirr9.png)
[Imgur](https://i.imgur.com/LJUo2gP.png)

What it looks like now

    		hs_pos_m_att_acce…	hs_neg_m_att_acce…	mw_pos_m_att_acce…	mw_neg_m_att_acce…	rp_pos_m_att_acce…	rp_neg_m_att_acce…	hs_pos_f_att_acc…	hs_neg_f_att_acc…	mw_pos_f_att_acc…
    	1	NA	NA	NA	NA	NA	2	NA	NA	NA
    	2	NA	NA	NA	NA	NA	NA	NA	NA	NA
    	3	NA	NA	NA	NA	NA	NA	NA	NA	NA
    	4	NA	1	NA	NA	NA	NA	NA	NA	NA
    	5	NA	NA	NA	2	NA	NA	NA	NA	NA
    	6	NA	1	NA	NA	NA	NA	NA	NA	NA
    	7	NA	NA	NA	NA	NA	NA	1	NA	NA
    	8	NA	NA	NA	2	NA	NA	NA	NA	NA
    	9	NA	NA	NA	NA	NA	NA	NA	NA	2
    	10	NA	NA	2	NA	NA	NA	NA	NA	NA

What I want is a factor that looks something like this, except in the full sample there would be no NAs. I basically need to collapse the variable so I can use it as a factor in my analysis of its effects on the various other variables.

    		Condition
    	1	rp_neg_m_att_acce…
    	2	NA
    	3	NA
    	4	hs_neg_m_att_acce…
    	5	mw_neg_m_att_acce…
    	6	hs_neg_m_att_acce…
    	7	hs_pos_f_att_acc…
    	8	mw_neg_m_att_acce…
    	9	mw_pos_f_att_acc…
    	10	mw_pos_m_att_acce…

SOLUTION FOUND


    df_accent <- df_orig %>%
      select(`hs_pos_m_time_First Click`:rp_neg_f_att_accent)%>%
      mutate(Condition = case_when(
        hs_pos_m_att_gender > 0 ~  ""hs_pos_m"",
        hs_neg_m_att_gender > 0 ~ ""hs_neg_m"",
        mw_pos_m_att_gender > 0 ~ ""mw_pos_m"",
        mw_neg_m_att_gender > 0 ~ ""mw_neg_m"",
        rp_pos_m_att_gender > 0 ~ ""rp_pos_m"",
        rp_neg_m_att_gender > 0 ~ ""rp_neg_m"",
        hs_pos_f_att_gender > 0 ~ ""hs_pos_f"",
        hs_neg_f_att_gender > 0 ~ ""hs_neg_f"",
        mw_pos_f_att_gender > 0 ~ ""mw_pos_f"",
        mw_neg_f_att_gender > 0 ~ ""mw_neg_f"",
        rp_pos_f_att_gender > 0 ~ ""rp_pos_f"",
        rp_neg_f_att_gender > 0 ~ ""rp_neg_f""))

That code results in a single variable called Condition with the appropriate string denoting which accent the participant/observation heard. ",Help creating factor,81b4ob,new
"I am new to R and I am stuck.  I know how to do this in Excel but want to learn to do it in R.  

I have some data that looks like this. Actually city names separated by “-“s.  I want to extract the first city and the last city using the “-“ (marker) and I would appreciate some ideas on how to best do that.

Original data looks like this
====================
abc-efghijk-lmnop-qrstuv-wxyz

ab-cefgh-ijklmnop-qrstuvwxy-z

abcefgh-ijklmnop-qrstu-vwxyz

abc-efghijklm-nopq-rstuvwx-yz

I want to extract the first and last entry so the results looks like this
============================
abc, wxyz

ab, z

abcefgh, vwxyz

abc, yz",Help extracting data from a string,81ayou,new
"I am learning how to use roxygen2 so I created a simple test file to see how it works but I am getting this error. What am I doing wrong?

    library(roxygen2)
    library(rstudioapi)
    setwd(<path to *.R file>)
    
    library(devtools)
    
    roxygen2::roxygenise()
    
    #' Add together two numbers
    #'
    #' @param x A number
    #' @param y A number
    #' @return returns \code{x} to the \code{y} th power
    #' @examples
    #' 8 <- newfucnt(2,3)
    #' 10 <- netfunct(10, 1)
    newfunct <- function(x, y) {
      x^y
    }
    
    
    print(newfunct(2,3))



Error: File file doesn't exist


Edit: OK, after googling for hours and playing with the code a lot I discovered that the online documentation for learning roxygen2 is bad. First you need to have DESCRIPTION and NAMESPACE files there needs to be a /R directory where your code resides and you should run devtools::document() from an interactive environment and not embed this in your code. I wish there was well written documentation on how to properly use roxygen2 seeing how it's supposed to be used for literate programming.",Error: File file doesn't exist (roxygen2),819ph0,new
"My script takes around 20-30 mins to run right now on my mid'15 mbp. I have a windows desktop with a 1080ti on the same network. I would like to set that desktop up to be able to process the script being sent from my laptop and sending the results back, both text output and a couple plots. Is there anyway to do this? 

I have done some googling and have fun r-packages to utilize a GPU but I don't want to develop off my windows machine as I prefer the unix environment on macOS as well as the probability of a laptop. I have also seen Hadoop which I think would work for what I'm trying to do but am curious if there is a simpler solution. 

Any help would be greatly appreciated. Thanks 

-----
Edit #1: Since it's relevant, I do have some networking and systems admin experience",Speeding up run time,8176p4,new
"In a perfect world I would write a function that creates an empty vector and populates it with values along the lines of something like this

    myFunction<-function(emptyVector){
      emptyVector = c()
      for(i in 1:10){
           emptyVector[i] = i
      }
    }

such that the name of emptyVector would be whatever I put in the parenthetical once I execute myFucntion, e.g myfunction(x) would create vector x and store the numbers 1 to 10 in them. 

When I try this, it fails with no x value being stored in R's memory.

Likewise, when I create an empty vector outside of the function and try to update the vector within the function, R does not store the values, as if once the loop is terminated it forgets it ever operated on it at all. So, 

    x<- c()

    myFunction<-function(emptyVector){
      for(i in 1:10){
        emptyVector[i] = i
      }
    }
 

Still comes up with a null value for x after the function is executed. 

What am I doing wrong here, and what do I need to learn so I don't do this anymore? ",Update an empty vector with a function,813b7g,new
"I am trying to glean some info from the weather.gov forecasts, which consistently use the same language, but never the same string length.  For example: In the following data, I am trying to retrieve the snow projections which are typically something like ""2-4 inches possible"" and then place the ""2"" and ""4"" in a csv as high and low projection to do analysis.

1 Snow.  Temperature rising to around 20 by 11pm. Wind chill values as low as -7. Windy, with a southwest wind 23 to 32 mph, with gusts as high as 41 mph.  Chance of precipitation is 100%. Total nighttime snow accumulation of 5 to 9 inches possible. 
2 Snow showers.  Temperature falling to around 8 by 8am. Wind chill values as low as -10. Breezy, with a south southwest wind 17 to 23 mph, with gusts as high as 33 mph.  Chance of precipitation is 80%. New snow accumulation of 1 to 3 inches possible. 
3 Snow showers.  Low around 4. Wind chill values as low as -11. Breezy, with a south wind 18 to 22 mph, with gusts as high as 31 mph.  Chance of precipitation is 90%. New snow accumulation of 2 to 4 inches possible. 
4 Snow showers likely.  Mostly cloudy, with a high near 14. Wind chill values as low as -12. Southwest wind 16 to 18 mph, with gusts as high as 31 mph.  Chance of precipitation is 70%. New snow accumulation of 0.5 to 1 inch possible. 
5 A 50 percent chance of snow showers.  Mostly cloudy, with a low around 5. South wind around 7 mph.  New snow accumulation of 0.5 to 1 inch possible. 
6 A 50 percent chance of snow showers.  Partly sunny, with a high near 14. New snow accumulation of 0 to 0.5 inch possible. 
7 A 30 percent chance of snow showers.  Mostly cloudy, with a low around 5. New snow accumulation of 0 to 0.5 inch possible. 
8   A chance of snow showers.  Mostly cloudy, with a high near 14.
9  A chance of snow showers.  Mostly cloudy, with a low around 6.
10 A chance of snow showers.  Partly sunny, with a high near 18.
11 A chance of snow showers.  Mostly cloudy, with a low around 11.
12 Mostly sunny, with a high near 25.
13 A slight chance of snow.  Mostly cloudy, with a low around 15.",How would you scrape text for numerical ranges?,812w55,new
"Hi All,

I'm trying to create a large dataframe from some 10.000+ .txt files containing JSON strings.

Each .txt file is sequentially named as YYYY-M-DD HH-M.txt (or YYYY-M-DD HH-MM.txt in case the minutes are double digits) and has some 500+ JSON strings formatted uniformly like so:
    
    [
    {""variable1"":0,""variable2"":""text"",""variable3"":0,""variable4"":0,""variable5"":0,""variable6"":null,""variable7"":""text"",""variable8"":null,""variable9"":0,""variable10"":0.00,""variable11"":0.00,""variable12"":""text""},
    {""variable1"":0,""variable2"":""text"",""variable3"":0,""variable4"":0,""variable5"":0,""variable6"":null,""variable7"":""text"",""variable8"":null,""variable9"":0,""variable10"":0.00,""variable11"":0.00,""variable12"":""text""}, 
    {etc},
    {etc},
    {etc},
    ]

So 12 columns of variables with 500+ objects each.

Now I've done a bit of googling of course but I can't seem so figure out how to read the JSON strings from multiple .txt files.

I can read the data from one txt file using:

    setwd(""/directory/path/"")
    dataframe <- fromJSON(""<file_name>.txt"")

Using code I stole from [here](https://stackoverflow.com/questions/39937310/creating-a-data-frame-with-the-contents-of-multiple-txt-files), I can create a list variable of all the text files with:

    # Put in your actual path where the text files are saved
    mypath = ""/directory/path/""
    setwd(mypath)
    # Create list of text files
    txt_files_ls = list.files(path=mypath, pattern=""*.txt"") 

but the rest doesn't seem to work because (I guess) it doesn't take into account the JSON formatting within the files...(?)

    # Read the files in, assuming comma separator
    txt_files_df <- lapply(txt_files_ls, function(x) {read.table(file = x, header = TRUE)})
    # Combine them
    combined_df <- do.call(""rbind"", lapply(warnntxt_files_df, as.data.frame)) 

How do I combine fromJSON() with the formula above?
Or is this approach all wrong for my stated goals?

Any help would be much appreciated!
",Creating a single dataframe from multiple .txt files containing JSON strings,810q2e,new
"I'm trying to import data from the ImmuneSpace database using ImmuneSpaceR, and keep getting the following error after the very first line of code (study<-CreateConnection(""SDY180"")). I've googled for hours but no luck - anyone have any ideas as to how to fix this? Thanks in advance!

Error in labkey.setCurlOptions(ssl.verifyhost = 2, sslversion = 1, useragent = ""ImmuneSpaceR connection"") : 
  The legacy config : ssl.verifyhost is no longer supported please update to use : ssl_verifyhost",Error message help - ssl.verifyhost vs ssl_verifyhost,810m61,new
"In a shiny app I'm attempting to trigger a code block in server.R from the UI input from a module. Here is the server.R block I'm attempting to trigger:

    user_auth_return <- observeEvent(user_auth_return, {

      js$getcookie()
      
      return(
        callModule(
          user_auth_module,
          ""user_auth"",
          cookie = input$jscookie
        )
      )

    })

Here is the server function in the module:

    user_auth_module <- function(input, output, session, cookie) {
    
      observeEvent(input$login, {
        return(input$login)
      })
  
    }

Ideally I want the code block in server.R to be triggered in two ways. First, I'd like it to run once without input being given to the module's UI. Secondly, whenever the user presses the action button in the UI, ""login"", I'd like the code block in server.R to run.",What is the correct way to trigger a code block from an R Shiny module?,80qz5h,new
"Say I have a function that depends on two parameters and returns a list. A shiny app could start off by having the user enter one of these parameters, and the other one could be null by default. But when the user enters another input, this time the non-user-chosen parameter would be taken from the list that the function returned the last time the app called it.

Does anyone have any examples of this being done if it's possible?",Shiny App - How do I automatically use my most recent output as part of the input when the user next triggers the app to refresh?,80qhah,new
"Hey guys, I've been working with R for about six months. I took an MBA-level analytics class built around the language, so understand the basics.

I'd like to get better with the software and am not sure what tools are best to use for continuing education. (Small bite-size pieces will probably be best.)

My experience is that most resources for programming are very applied. (i.e. On Stack Overflow, the format for most things is ""I need to solve this problem, how do I do it?"") I'm interested in continuing to learn the language from a more broad standpoint.

Any recommendations?

Thanks!
INP

PS I posted something similar on r/Stata, as my company uses both.",Best resources for broad ongoing R learning?,80ofku,new
"So i started the book ""Building recommendation engines"" from packt and in the 2nd chapter, they build a movie recommendation thing.

  This is the CSV they provide: https://pastebin.com/FXv8gjvQ and this code: https://pastebin.com/errexiyj. 

This all works fine https://imgur.com/Pc2Aowc , but i thought it would be fun to add a friend to the data, so i did that so the CSV file looks like this: https://pastebin.com/TYa7T2N2.   
I changed this line:  
> sim_users = cor(movie_ratings[,1:6], use=""complete.obs"") 

to  
> sim_users = cor(movie_ratings[,1:7], use=""complete.obs"")

Now i keep getting the error ""In cor(movie_ratings[, 1:7], use = ""complete.obs"") :  the standard deviation is zero"".

I really can't figure out why this happens and i hope one of you can show me how to solve this.","New to R, can't understand standard deviation is zero error.",80m5o7,new
"In my server() function I have a function (doesn't matter what it is as far as this question goes) that creates a list:

    my_list <- reactive({
        predict_ending_wrapper(input$my_string, input$num_suggestions, input$largestNgramOnly)
      })

Then I get the length of my list:

    list_length <- reactive({ length(my_list()) })

Then I call renderUI():

      output$suggestions_fileName2 <- renderUI({   
          str_vec <- reactive({ vector() })
          for(i in 1:list_length()){
            current_str <- reactive({
              paste(my_list()[[i]][[4]], ""-gram file used is "", my_list()[[i]][[3]], "".txt"", sep = """")
            })

         str_vec <- c(str_vec(), current_str()) 
         } # end of for(i in 1:list_length())

      HTML(paste(str_vec[1:list_length()], sep = '<br/>')) 
      })

So inside renderUI() I create a vector, str_vec. Then I run through a for-loop the same number of times as the length of my list. 

Each iteration of the loop builds a character string out of elements of the list, then adds them onto the end of str_vec.  

Then finally, I include a call to HTML() that is supposed to display the contents of str_vec over multiple lines. This produces the expected output when str_vec is only one element long. However, if this vector is longer:

    Error: could not find function ""str_vec""

How do I solve this? I've tested pasting ""Hello"" and ""world"" over two lines and I can get that to work fine. Also I get the same error if I include () after str_vec, like:

    HTML(paste(str_vec()[1:list_length()], sep = '<br/>'))",Shiny app - Why can't I get renderUI() to display elements of a vector spread over multiple lines?,8088a0,new
"hey, does someone know how to import data frame from r to desktop, then from desktop to some library and then again to r?
",import/export data frame,804tly,new
"My app has the user choose the input values for ""my_string"",  ""num_suggestions"", and ""largestNgramOnly"", and my function, ""predict_ending_wrapper()"", takes these values and generates a short list of lists that each contain 4 objects. To display one of them, which is a table, the following code works as expected:

    server <- function(input, output){
  
      output$prediction_df <- renderTable({
        predict_ending_wrapper(input$my_string, input$num_suggestions, $largestNgramOnly)[[1]][[1]]
      })
  
    } 

For now I would like to make the app display a few elements of the first list without having to call the function once for each element. Which would mean having:

      output$prediction_df <- renderTable({
        predict_ending_wrapper(input$my_string, input$num_suggestions, $largestNgramOnly)[[1]][[1]]
      })
      output$prediction_df <- renderTable({
        predict_ending_wrapper(input$my_string, input$num_suggestions, $largestNgramOnly)[[1]][[2]]
      })

and so on.

So, I want to call the function/make the list once then have the render*() functions select which elements they need. However, I get an error when my code looks like this:

    server <- function(input, output){
  
      prediction_list <- predict_ending_wrapper(input$my_string, input$num_suggestions, $largestNgramOnly)
  
      output$prediction_df <- renderTable({ prediction_list[[1]][[1]]  })
  
    } 

      Error in .getReactiveEnvironment()$currentContext() : 
      Operation not allowed without an active reactive context. 
      (You tried to do something that can only be done from inside a 
      reactive expression or observer.)

What am I supposed to be doing here?",Shiny app - returning separate elements of a list created by interactive user input?,804jt8,new
"I have 90 GBs of camera trap footage from a recent field trip.

I'm looking to write a script that can be used to extract information, such as date and time the video was recorded, from the videos.

The videos are MP4s.

Can anyone provide any pointers on how to proceed? I've had a look on Google but haven't been able to find anything appropriate.

Thanks for any responses.",Extracting information from MP4 video files,7zxokw,new
"Hey all,

I'm attempting to add a module to a preexisting R Shiny app to verify users through a cookie based system. To work with cookies in R Shiny, I've followed [this tutorial](https://calligross.de/post/using-cookie-based-authentication-with-shiny/) and I've extended shinyjs with the following javascript code:

    shinyjs.getcookie = function(params) {
        var cookie = Cookies.get(""id"");
        if (typeof cookie !== ""undefined"") {
            Shiny.onInputChange(""jscookie"", cookie);
        } else {
            var cookie = """";
            Shiny.onInputChange(""jscookie"", cookie);
        }
    }
    shinyjs.setcookie = function(params) {
        Cookies.set(""id"", escape(params), {
            expires: 0.5
        });
        Shiny.onInputChange(""jscookie"", params);
    }
    shinyjs.rmcookie = function(params) {
        Cookies.remove(""id"");
        Shiny.onInputChange(""jscookie"", """");
    }

I made a test example with a small R Shiny app that worked correctly without modules, however, when I tried to implement a module to perform the same function, I ran into an issue retrieving the cookies.

From within server.R, I can retrieve the cookies without issue using the following code:

    observe({
      js$getcookie()
      print(input$jscookie)
    })

However, when I put that same code into the module's server function, it prints out NULL every time. I believe that the problem has to do with namespaces, and that maybe `input$jscookie` in server.R refers to a different thing than `input$jscookie` in the module. However, I'm very new (just a few days) to Shiny modules, so I'm still unsure of some aspects of how they work.

Is there a way to retrieve the cookie from within the module?",Trouble accessing input variables in R Shiny module.,7zx9hq,new
"Is it possible not to re-create the whole plot, while also possible to remove these newly added ingredients?
Thanks.","How to remove just newly added ""text"",""legend"" on an existing plot?",7zwc9e,new
"I am trying to create my own implementation of K-means. The theory isn't confusing. It's just my lack of knowledge with R.

I have a matrix of data and I am confused about instantiating new variables. I have a matrix of my initial random centroids.

Now I am not quite sure how to create an empty cluster to start filling based on the distances. Do I create an empty matrix for each cluster and put them in a list of size k? Then add a point to that matrix using rbind? Just not sure of what to store things in. Any insight will really help! Sorry if this is the wrong subreddit for this.",Problems with R. Trying to implement K-means.,7zt533,new
"I have raw data of a sine wave generator. I would like to make a plot where each period is plotted and aligned to the other periods so I can see where there are issues in the sine wave. The plot would look like a thick fuzzy period of a sine wave with maybe one area that's fuzzier than the rest.

I've use nls to fit the data and I have the period. I can then use the fit to break the data into periods and can graph them. However, they don't plot exactly over top of each other. They seem to slowly shift one way or the other, so the frequency isn't perfectly stable, but its very close. I've tried to align them using the max lag from ccf, but the max lag from ccf seems to do a terrible job with sine waves. It can be off by a quarter wave sometimes. What other methods could I use to compare periods of a periodic signal?",Comparing periods of sine wave data,7zt1db,new
"Let's say I have a vector (1,2,3). The possible combinations of elements are:


    1 2 3
    1 3 2
    2 1 3
    2 3 1
    3 1 2
    3 2 1

How can I get R to tell me that?
",How to get all possible combinations of elements in a vector?,7zo06t,new
"Hey, I need help, about making an exercise : 
Take a piece of paper and lie it flat on a table. Hold the left half flat and fold the right half on top of
the left half (so you fold in a counter-clockwise direction). Now you have a new (double folded) piece of
paper. Now fold this piece of paper counter-clockwise again, and continue folding the resulting piece of paper
counter-clockwise for a total of n folds (including the first two folds). If you now unfold the piece of paper,
pull a little on both sides to flatten it and look at it from the side, you will see a sequence of mountains and
valleys.
c) Use recursion to generate a sequence of -1’s and 1’s that represent the mountains and valleys,
respectively. HINT: You may want to use the number of folds and the direction of the folding as input
parameters.",Recursion functions,7znf3r,new
"Hey everyone, I've got a CSV with a million rows (more data than I normally work with in R).

Essentially I have a user id (they all exist, no NA's).  I can sort data frame from user 1 -> N (it tops out at like 80K unique users).

Each user has a medical bill.  I want to aggregate a new dataframe with the sum of each user's total medical bills, the number of medical transations they have, and the mean spend per bill (this is just the first number divided by second of course).

I couldn't get the aggregate/group_by function to do quite what I need.  Not that i'm looking for somebody to solve my problem, but somebody point me in the right direction towards packages to use?  Simply sorting the dataframe by user id and aggregating the results until the id changes takes wayyyy too long.",R question on aggregating data (not sure if I want simply the aggregate function),7zm7l9,new
"I want to change the values in one column based on the values in another column for a given row.  The goal is to create a dataframe suitable for a Sankey diagram using networkD3.

My dataframe is like this:

origin                destination            passengers            country_code

Antigua             Barbados               739                      na

Jamaica             Trinidad                497                      na



and so on.  I want to update the country_code column based on the value in the origin column.  In SQL this would be a simple UPDATE WHERE statement but I can't figure out the equivalent in R.  I've looked at sqldf but I can't make sense of it, nor anything else on the subject.

I have 12 countries for both origin and destinations, 56 different combinations of them, so nested statements could get messy.

If you know the answer, please share!  Thanks!

",change values for a variable similar to UPDATE WHERE in SQL?,7ziftr,new
"I'am trying to access following [API](https://dev.procountor.com/general-information/oauth/). Documentation seems pretty straight forward and I could achieve this using Postman or C# but having troubles implementing it in R.

I have tried both POST and httr (create custom endpoint and app) approach but don't seem to get forward. Can someone give me an example code?",R and oAuth,7zdm2f,new
"I am trying to write a function that checks to see if (i+1) is less than i. Here's what I have

    testFunction<-function(vectorpls){

      for(i in seq_along(vectorpls)){
        if(vectorpls[i+1]<vectorpls[i]){
         print(vectorpls[i]) 
        }
      }
    } 

I am getting an message saying: Error in if (vectorpls[i + 1] < vectorpls[i]) { : 
  missing value where TRUE/FALSE needed

What am I doing wrong here? This same thing basically works in python",Basic function question,7zdchg,new
"I am trying to create a custom HTML output format using the following [guide](https://rmarkdown.rstudio.com/developer_custom_formats.html), wherein I am defining the function as follows,

    custom_html_format <- function() {
    
    #File locations
    css <- system.file(""/resources/css/styles.css"")
    header <- system.file(""/resources/header.html"")
    
    rmarkdown::html_document(toc = TRUE,
                                              theme = ""lumen"",
                                              css = css,
                                              includes = includes(in_header = header))
    }


I will be using the function in an RMarkdown document as follows -

    ---
    title: ""Your Document Title""
    author: ""Document Author""
    date: ""`r Sys.Date()`""
    output: custom_html_format
    ---
    
    ## Header
    This is an example of a text

But, for the life of me, I am unable to figure out where should I place this custom function at, so that I can mention just 'output: custom_html_format' to call the rest.

Any help is appreciated!",RMarkdown: Creating Custom HTML Output Format?,7z9jeb,new
"I'm learning ggplot2, using resources like this:

http://zevross.com/blog/2014/08/04/beautiful-plotting-in-r-a-ggplot2-cheatsheet-3/

and a few others.

The trouble I'm having is putting it all together - all my preferences for the tick marks, legend, colours, etc.  The examples usually show one change at a time, not several.

I can't seem to make more than one work at a time.

For example, this works:

>create line graph of TotalTrav data

Totalplot <- ggplot(TotalTrav, aes(x=Year, y=Travelers, group=1)) +geom_line() + scale_y_continuous(labels = comma ) 

>print graph with preferred gridlines

Totalplot + theme(panel.grid.major = element_line(color = ""black"", size = 0.25), panel.grid.minor = element_line(color = ""gray"", size = 0.05))


But not this:

Totalplot <- ggplot(TotalTrav, aes(x=Year, y=Travelers, group=1)) +geom_line() + scale_y_continuous(labels = comma ) + theme(panel.grid.major = element_line(color = ""black"", size = 0.25), panel.grid.minor = element_line(color = ""gray"", size = 0.05))

I get this message:

Error in inherits(x, ""theme"") : argument ""e2"" is missing, with no default

I can't figure out what I'm doing wrong.

All help appreciated :)",ggplot2 and syntax issues (very nooby),7z9h42,new
"Hi I'm trying to keep in my dataframe only client codes that are repeated at least two times. I've been searching on stack overflow and Google  without luck
Thanks ",Need help with duplicates values,7yznc4,new
"I have a large workflow in R that combines large datasets from various sources based on cusotmer ID keys.

Then I create alot of basically binary flags more or less using if statements to create one master customer file.  For example, a section of code will be ""

Target Customer: if in the southeast, active product users, with median household income then 1, else 0.

However, the if statements are much more complex then that.

Goal:

1. Have a quality control process to ensure no data is being lost/duped/nulled out/etc from the source files to the end file.

2.  Anyway to build into the code a check to see if my if-statements are calculating correctly? like a double check?

this is run on a weekly basis and the issue is the source files change alot. some months i never have to update anything, some months, im updating my code every week.

additionally the if statements are gettign more and more complex.

I want to build some safety checks into my code to help with this and wanted to hear if any body had good ideas",Recommendations on how to Quality Control for large workflow in R?,7yyba3,new
"I have to import and merge several excel files into a database. I have to do some data cleaning, fix some column names, etc, but my greatest problem at the moment is that I have six columns, being three dates, and three timestamps. When I import the data, readxl imports the first column of dates and the first column of time stamps as POSIXct elements, but the rest as characters. Is some sheets this can be fixed easily, but there's one where the dates are in a format I don't know (ex.: ""40573"" ""40574"" ""40575"" ""40575""). I thought that since the first column was recognized as POSIX maybe these two were in a different format. Checked the Excel sheet and they are all the same. Any idea on how can I fix this? Is there any alternative to readxl that might help me here? Already tries xlsx with no sucess",read_excel is not recognizing dates and times from Excel sheet,7yxm9q,new
"So I have a table that shows inventory values by Item ID. I need to find the number of days, and which days, each item was out of stock. My table only adds a new row each time there is a change in the inventory value, so I only have the day that any given item went out of stock, but not any accompanying days it continued to be out of stock. Here's an example of what it looks like//

ItemID | QTY | ADate 
---|---|----
10007 | 2 | 2011-07-22
10007 | 1 | 2011-07-27
10007 | 2 | 2011-09-01
10007 | 1 | 2011-09-23 
10007 | 2 | 2011-09-29 
10007 | 0 | 2011-10-29
10007 | 2 | 2011-11-03
10007 | 1 | 2011-11-21
23028 | 2 | 2011-07-23 
23028 | 0 | 2011-08-03 
23028 | 2 | 2011-08-10 

What I'd like to have is:

ItemID | QTY | ADate 
---|---|----
10007 | 2 | 2011-07-22 
10007 | 2 | 2011-07-23
10007 | 2 | 2011-07-24
10007 | 2 | 2011-07-25
10007 | 2 | 2011-07-26
10007 | 1 | 2011-07-27
10007 | 1 | 2011-07-28
10007 | 1 | 2011-07-29
10007 | 1 | 2011-07-30
etc...

I'm pretty new with R (3 months now) and don't even know where to begin with this one. I don't need anyone to write code for me, but pointing me in the right direction would be extremely helpful. Thanks so much!

TLDR: I have a list of when inventory changes, I need a list of inventory every day, even if it's redundant, in order to calculate number of days out of stock.",Populating missing date values,7yx7kz,new
"I'm doing something where I loop over letters of the alphabet to construct a three-letter file name, eg.

    for(i in 1:26){
       for(j in 1:26){
          for(k in 1:26){
              first_letter <- letters[i]
              second_letter <- letters[j]
              third_letter <- letters[k]

              output_dir <- paste(""./whatever/"", first_letter, second_letter, ""/"", sep = """")

              fileName <- paste(output_dir, first_letter, second_letter, third_letter, "".txt"" sep = """")
        
             # Here I create some data frame df

             write.table(df, fileName)
          }
       }
    }

Everything is going great until I get to attempting to writing out ""./whatever/au/aux.txt"".

At this point I get: 

    Error in file(output_fileName, open = ""w"") : cannot open the connection

All the previous files "".../au/au<?>.txt"" have been created successfully, including ones that feature an 'x' at some point. What's going on here?",Why would R have a problem with this simple file name?,7yu9tx,new
"I have to plot 6 different plots on multiple files and I'm not quite sure on how to get it done. I'm able to plot one and get it into a file, but outside of that I'm not sure how I get the rest into one as well. ",plot multiple plots in seperate jpeg or png files,7ytikx,new
"I've been working with some large files, and at the end of my script, I pass the objects they're stored as to rm(), in the hope that R will release that memory once my script has finished running. 

However, this doesn't happen - afterwards I still have >3 GB of my computer's memory taken up by my R session, and when I go into task manager and tell it to 'end task', I find that when I open RStudio again, that memory is still being taken up and RStudio is still painfully slow. I've also tried restarting my computer, and doing  Session -> Clear Workspace or File -> Quit Session with no success. This is doing my head in. What should I do?",Why does R still hold large objects in memory even after closing RStudio down and even shutting down my computer?,7ylfem,new
"I'm given a 2x2 table and I'm told to make a list, but I do not know if I am doing it correctly.    
Column 1 is Name and Column 2 is ""Courses.    
Column 1/Row 1 is ""James"" and column2/Row1 is ""Math, Physics, Chemistry"".    
Is my code below correct?  I feel it's not because when I try to get the ""Physics"", with [[1]][[2]], it doesn't work 


    a <-list(name = ""James"", Courses = c(""Math"", ""Physics"", ""Chemistry""))    
    b <- list (name = ""Peter"", Courses = c(""English"", ""History"", ""Sociology""))    
    Student_Data = list(a,b)",How to make a simple list,7yjrmw,new
"I have a dataset of global travel numbers and I want to subset it for a specific region using the origin and destination variables.

In plain English, I want the new dataset to include all observations where

the **origin** is ""Antigua"" OR ""Barbados"" OR ""Jamaica"" etc

OR

the **destination** is ""Antigua"" OR ""Barbados"" OR ""Jamaica"" etc

So far I haven't found tutorials/examples that quite address this type of scenario.  Any ideas?


ETA:  Thank you all!  I was getting close to a couple of these options but this makes it clearer.  I will try them and report back.

Here's some tuneage for you:

https://www.youtube.com/watch?v=WsidcB-24JU
",noob question about subsetting data,7yhkiz,new
"guys do you know how to do this one :  Create a matrix mat with p = 10 columns and n = 100 rows. Every column of the matrix represents a
sequence of 100 coin flips, where the probability of heads (1) is 1 divided by the index of the column.
Then use apply() to find the means and standard deviations of every column.
b) Now suppose that we will again do p = 10 sequences of coin flips, but this time we will continue flipping
until we have flipped heads 10 times. This means that the length of every sequence will vary, which
makes it difficult to store in a matrix. Use a list to store the sequences of flips.
c) If you try using the function mean() on the list it will return NA and a warning message (try this).
Similarly, apply() will not work, since there are no columns or rows to apply the function over. Instead,
try using lapply() and sapply(). How does their output differ?",R exercises,7yf1up,new
"So,  i need to make a confront with the winner of the mach A and the winner of the mach B. Also the winner of mach C and the winner of mach D. The probability of this match fallow the same logic. My question is, how i take the result of the 4 previous match for make the fallowing matchs?
Ps. Im new on R, so i know that i make a few mistakes.

pA = 9
pB = 1
pC = 10
pD = 2
pE = 17
pF = 4
pG = 20
pH = 5
M1 <-c(""A"",""B"")
M2 <-c(""C"",""D"")
M3 <-c(""E"",""F"")
M4 <-c(""G"",""H"")
Confronto1 <-function(n) {
  
  sample(M1,size = n, replace = TRUE, prob = c(((pA)/(pA + pB)), ((pB)/(pA + pB))))
 
}

Confronto2 <-function(n) {
  sample(M2,size = n, replace = TRUE, prob = c(((pC)/(pC + pD)), ((pC)/(pC + pD))))
}
Confronto3 <-function(n) {
  sample(M3,size = n, replace = TRUE, prob = c(((pE)/(pE + pF)), ((pF)/(pE + pF))))
  
}
Confronto4 <-function(n) {
  sample(M4,size = n, replace = TRUE, prob = c(((pG)/(pG + pH)), ((pH)/(pG + pH))))
  
}",Using a result of a function on another function,7y8hlk,new
"Hi all

I’m fairly new to R but what I’ve seen so far is great. I’ve got a medical dataset where a group of patients were randomly assigned to either receive a treatment or placebo. Overall there was no effect, and I’m now try to see whether there was an effect in certain subgroups, and then plot the survival difference in each group to display this. I found the ‘subgroup’ package a little tricky to follow but could try again; I have run a Cox regression with the treatment, a variable, and then both together, but couldn’t quite understand how you can create an interaction between a continuous and categorical variable. Any help is much appreciated, thank you!",Subgroup interaction by treatment,7y4fs1,new
"So I have a normal distribution graph and I want to shave all the area under the curve between certain points. I found a single guide on how to do it but I don't fully understand it and thus I can't seem to apply it to my charts (also it seems to use the polygon, which I'm not sure if that's what I want).

Does anybody know of any specific commands or packages that I can use for what seems should be a simple task?

Thanks

Here's my code:

    #actual code thats not working
    #goal is to mark area under curve between 79 and 120
    lbound <- (79-94)/6.8
    ubound <- (120-94)/6.8
    curve(dnorm(x,94,6.8), xlim=c(70,120), main=""normal density"")
    cord.x <- c(lbound,seq(lbound,ubound,.01),ubound)
    cord.y <- c(0, dnorm(seq(lbound,ubound,.01)),0)
    polygon(cord.x,cord.y,col='skyblue')
    
    --
    #code example that I am following  
      curve(dnorm(x,0,1),xlim=c(-3,3),main='Normal Density')
    cord.x <- c(-2, seq(-2,-1,.01),-1)
    cord.y <- c(0, dnorm(seq(-2,-1,.01)),0)
    polygon(cord.x,cord.y,col='skyblue')        ",How can I shade under the curve for a normal distribution?,7y0yf9,new
"I'm looking for software that can estimate and create graphics for  PLS regression model. I'm familiar with smartPLS, but I prefer to work in R. I have been playing with the packages 'pls' and 'plspm'. Am I missing any other good options? 

Thanks",Partial least squares regression,7xv71i,new
"drop = FALSE by default when using subset (), but what is the use of the argument? 

I tried looking it up using the help function, but it didn't clear anything up for me... ",What does the drop argument in subset () do when it equals true?,7xrwnt,new
"I would like to create a new data table in R, where if two values in the same column of anohter data table are equal, the values in the next column of those observations that were equal are paired into one variable.
For instance:

    award            actor year
    1: 10th_Annual_Critics__Choice_Awards__The_2005      Aiken__Liam 2005
    2: 10th_Annual_Critics__Choice_Awards__The_2005        Bain__Bob 2005
    3: 10th_Annual_Critics__Choice_Awards__The_2005   Bardem__Javier 2005
    4: 10th_Annual_Critics__Choice_Awards__The_2005 Bello__Maria__I_ 2005
    5: 10th_Annual_Critics__Choice_Awards__The_2005     Berlin__Joey 2005
   
Liam Aiken, and Bob Bain both attended the same award, so in a different data table I would like to have and entry of something like ""Aiken_Liam Bain_Bob"", as well as one pair for all the people who attended the same award (Aiken + Bardem, Bardem + Berlin, and so on).
I was thinking of approaching this with a while loop loop like:

    i <- 1
    j <- i + 1    
    while(dt.awards.actor[i,]$award == dt.awards.actor[j,]$award){
          w <- paste(dt.awards.actor[i,]$actor, dt.awards.actor[j,]$actor))
          print(w)
          i <- i + 1
        }

However, the code above returns me all the pairs for ""Bain_Bob"", while skipping over ""Aiken_Liam"", and also that while loop stops searching when it finds the pairs for ""Bain_Bob"" (it does not search for anyone else's pairs). Also how can I code so that I get the show to which both actors attended, and turn the output into a data.table? Maybe using an lapply, or an apply function?",How can I create a data table by combining values of one variable in a different data table based on comparing the values of another variable in r?,7xpzg7,new
"I have two lists of data, one with 5 values other with 7 values. How exactly can I run an ANOVA test in R? Thanks, I'm new.",How can I run an ANOVA test with uneven sample sizes?,7xngxh,new
"hello, im a `R` newbie and im trying to use the `bigmemory` library for kmeans clustering so that it will be memory efficient.

    > library(bigmemory)
    > data <- read.big.matrix(file=""test.csv"", header=FALSE)
    > km <- kmeans(data, 5)

however i got this error message, 
`Error in as.vector(data) :
  no method for coercing this S4 class to a vector`

Are there other helper functions to properly coerce the bigmemory data to a vector? thanks

    

","using ""big.matrix"" on silhouette function",7xj6m7,new
"I've been racking my brain with this problem for a couple of days, and can't seem to find a clean solution to it. I was wondering if anyone had any thoughts here. 

Fundamentally I am trying to represent single letter codes (for amino acids, if anyone was curious) into numerical values. Originally I thought I would just sort the letters alphabetically, and assign each a number value and throw it into a loop. But that seems to be introducing unwanted variance in comparisons. 

Some background, I am working with some test data. Here is a small subset: https://imgur.com/d6Jq4i4 You can see that in all but column 5 all the single letter codes are identical. I wanted to represent those all with a 1, and in column 4 where there is variation, each letter would have its own number - in later cases if there are any repeats of the same letter they should be represented by the same number. 

My hope is that I can compare the level of 'uniqueness' at each position (i.e. column) without artificially creating variance. But I can't seem to find any way to convert these letters to numbers effectively. So far I can only find ways to extract the unique numbers, but I care about repeats at each position. 

I'm sorry if this is a bit of a ramble, but I'm at my wit's end, and have been having difficulties even putting my problem into words! Thank you in advance for any advice!",help converting single letter codes to numbers,7xfbat,new
"I have a function: `session$files$download(path = ""/user/ExampleData/my_file.csv"",filename =""my_file.csv"")` which downloads files from a remote system using RESTful api. Instead of downloading the file onto my local machine or when using HPC I just want to send the contents into another function like a read_csv. The function says it can take additional arguments like so: `download( path = , filename = , ...)` but I think it really needs to be wrapped. Any ideas of a function I can add or wrap with? I've seen the stdout() function but I either don't understand it or its not what I need at all.",Wrap a download function to send contents to a read_delim function,7x9mgx,new
"For example, I have a file that, when read in, object.size() returns the number 1363704 for (so 1.36 Mb?), but in the folder it says 880 Kb? They're not even close to being the same.",How come looking at the info about file in its folder is different to when I've read it in and called object.size()?,7x78b3,new
"I have an issue that seems simple but I'm not entirely sure how to go about it. Basically I need to remove transaction pairs if there is a refund/reversal. So I basically have two identical rows, but they have a different transaction code and all the numericals are inverse/negative.

I have been toying around with ABS to try and convert the negatives to positives so the rows will then match and then I will figure out how to remove them both. While I am foolishly fighting what should be a simple task, abs(), I put the question to you guys who are better at this than me. Below is a sample of what the tbl looks like.

https://imgur.com/a/XYW0V

EDIT replaced table with image.","Financial Data type question, duplicate entry removal",7x76pd,new
"I am new to R and wishing I had started earlier.  I get a new excel spreadsheet with 300 observations and 40 variables each week I read in with read_xls.  I have been analyzing one spreadsheet at a time.  I would now like to 1) pull in multiple spreadsheets and 2) store them combine so I can study how the data is changing week to week.  I am wondering if 1) there is a way to pull in multiple spreadsheets (everyone in a directory) with a single function (read_excel_all) or if I have to loop through them reading one at a time doing a rbind and 2) how should I store the data?  I was thinking that I would pull in a new spreadsheet each week, write it out to a combined spreadsheet and do that each week adding the new data to the old data.   Using excel as a DB.  I used to use DB2 to store my data before I retired (no longer have access) and am wondering if using excel files is a dumb idea that has problems and limitation I don't understand yet.  I want to get some guidance on how to proceed so I don't realize there was a much better way but I failed to ask.",Advice on Process and Structure,7x2139,new
"Is there a way to bring values stored in R into a SQL query being run through dbGetQuery?

Say for example I have a series of serial numbers in a data frame and I want to use those in my SQL where statement.

Thanks!",Using R vectors inside dbGetQuery?,7x1kl8,new
"Hi,

I am trying to use R to build a script which can do equal width binning on multiple columns rather than just one. So I ended up writing a code which can does something similar(clumsy), however, I am not able to write a function so I can call it. Here is my code:
//Following is the code for the function, which I will call with the //name of the four columns I want to do binning on.
MultiVarBins <- function(data_file, bin_no, col_name1, col_name2, col_name3, col_name4)
     {
     df_sorted <- data_file[order(col_name1,col_name2,col_name3,col_name4) , ]    
     total_rows_in_file <- nrows(df_sorted)
     df_sorted$Bin <- rep(1:bin_no,len = total_rows_in_file)
     return(df_sorted)
 } 
When I am calling this function
MultiVarBins(School,""Performance"",""Ethnicity"",""Gender"",""Attendence"")
//School is the name of the file where I have 5 Columns: Student Id, Performance, Ethnicity, Gender and Attendence. 
It gives me an error: Error in order(data_file$col_name1, data_file$col_name2, data_file$col_name3,  : 
  argument 1 is not a vector 

I was able to able to this without using a function as commands one by one, however, I am trying to make it reusable. 

So if someone can help me in figuring out how I can make it work, it would be awesome!!
Also, if there is a way for binning a file using multiple columns as input, like stratified sampling of binning, I would really appreciate that as well :)
Here is the excel file: https://docs.google.com/spreadsheets/d/1l56rCN-GZOSbBKP75HFQb50Hcg_Jx2MJD4aWMwa2q7A/edit?usp=sharing",Need help in building multi-column binning using R,7wxwyq,new
"For example, in the same column, I have 15 minutes, 2 minutes or 5 seconds. Is there any way to convert everything to seconds when loading the csv file?",Any way to read a time column with different units from a csv file?,7wpigg,new
"I know there are three types of build-in classes in R. S3, S4 and reference classes. But I'm still somewhat struggling. It may be because I'm trying to hammer an R nail with a hammer used for more traditional OOP languages, but I realized that I could use an example.

This is a very simple python code that showcases basic classes abilities:

    class Rectangle:
    	def __init__(self, a, b):
    		self.a = a
    		self.b = b
    	def Area(self):
    		return(self.a * self.b)
    
    class Square(Rectangle):
    	def __init__(self, a):
    		self.a = a
    		self.b = a
    
    myRectangle = Rectangle(2, 4)
    mySquare = Square(3)
    
    print(myRectangle.Area())
    print(mySquare.Area())

How would you port this code to R? Using all three class types?

Thanks in advance.

---

EDIT: Based on comments, this is what I came with (though keep in mind guipier's comment about LSP):

    rm(list=ls())
    
    Rectangle <- function(a, b) {
        structure(list(a = a, b = b), class = ""Rectangle"")
    }
    
    Square <- function(a) {
        structure(Rectangle(a, a), class = c(""Square"", ""Rectangle""))
    }
    
    area <- function(x) {
        UseMethod(""area"")
    }
    area.Rectangle <- function(x) {
        x$a * x$b
    }
    
    myRectangle <- Rectangle(2, 4)
    mySquare <- Square(3)
    
    area(myRectangle)
    area(mySquare)
    ",I'm still struggling with classes in R,7wo6ls,new
"How good is the [R Programming course](https://www.coursera.org/learn/r-programming/home/welcome) from Johns Jopkins on Courserea. I have got zero experience in R and I would like to learn it from the scratch. I am also planning on buying the certification for the course so I would like to know if it is worth the investment. I'll also be working on R in my job in a few months and I would like to be ready and know at least the basics. I've got prior programming experience and am quite good in SQL.

I would like your opinion if you've taken the course and if you found it useful(or even if you haven't taken it). Do you find the course covers most of the essential basics while being friendly to a new-comer at the same-time? Or do you think there are better courses which I'd rather take? Any additional learning resources that'd go well with this course? 

Your feedback is welcome. :)",How good is the R programming course from Johns Hopkins on Coursera?,7wfjc4,new
"I have the randomly generated number .492. I know the z score of this number is .02 as given by the standard normal cumulative probability table. However, I have to generate about 24 random numbers 0-1 and find corresponding z scores for each of them so I don't want to have to look at the table after generating every number. I want to be able to just put my program in a repeat loop until enough values have been generated. 

Is there some code I can use to turn my number into the correct z score? I have tried 

L <- .492

scale(L)

as well as 

Test <- .492

scale(Test,center = TRUE, scale = TRUE)

but these only spit out the same .492 that I put in. 

EDIT:

Eventually found qnorm and that was what I was looking for.",Turning random numbers into corresponding Z scores,7wf4uy,new
"I'm learning R Programming at Harvar MOOC on edX, and I got an assessment that involved the ! Operator. I got the assessment right but not sure if I got the utility of the operator right. 

The exercise asked to use mean function on  a data frame that contained NA entries (it had some examples). 

What I did was assign is.na(dataset) to an object (ind) and then use the mean function like this:
mean(dataset[!ind]) 
And then the answer was correct!

 What I understood ! Operator does is this:
Take the true values from a logical vector previously assigned and exclude them on the function I was running. So it will make the average on the dataset entries excluding those who are TRUE on the ind object.

Am I right or the function of !  is another?
",Help on the ! Operator.,7wetp2,new
"Suppose I have two dataframes: **df_addresses** contains street addresses (including 'city' and 'region' columns), and **df_coord_db** lists cities along with their geographical coordinates. My goal is to look up the city/region name from each row of df_addresses in df_geo, and return the lat/long coordinates.

I've been using the following code:

    f_lookup <- function (x) { 
      df_coord_db[which((df_coord_db$city %in% x[1]) & 
                        (df_coord_db$region %in% x[2]))[1], 
                  c('latitude','longitude')]
    }
    temp <- apply(df_addresses[,c('city', 'region')], 1, f_lookup)
    temp <- bind_rows(temp) # delist
    df_addresses <- (cbind (temp, df_addresses)) # combine

Function f_lookup is passed 'city' and 'region' data from each row of df_addresses, then `which((df_coord_db$city %in% x[1]) & (df_coord_db$region %in% x[2]))[1]` gives the index of the first match from the cities database (the database has more than one entry per city, hence the first element only), and then the 'latitude' and 'longitude' corresponding to this index are returned by the function. This creates a termporary list of dataframes, which I then have to delist (with dplyr), and finally recombine with the original dataframe.

It works, but let's be honest — it's far from being elegant. I wonder, is there a better way to do this kind of dictionary lookup in R?",What's the best way to look up and return data from one dataframe to another?,7w718q,new
"I'm new to plotly and I'm having an issue with layering a bar graph onto an area chart without the colors mixing. I want the bar graph to remain one solid color throughout. I've tried playing around with opacity, and switching the order of the layers but nothing is working. https://imgur.com/a/EwLLS

    #create hold bar graph
    plot_ly(x = (c(J.Thomas$period)),
            #add agent data
            y = c(J.Thomas$hold.duration),
            type = 'bar', 
            color = I(""#7F7F7F""),
            name = ""Agent Average"") %>%
        #add average line
        add_trace(y = c(J.Thomas$avg.hold.duration),
                  type = 'scatter', 
                  mode = 'lines',
                  line = list(shape = 'spline'),
                  color = I(""#C00000""),
                  name = ""Overall Average"") %>%
        #add white space
        add_trace(y = c(J.Thomas$hold.bottom.yellow.line),
                  type = 'scatter',
                  mode = 'lines',
                  fill = 'tozeroy',
                  color = I(""#FFFFFF""),
                  name  = ""white space"",
                  showlegend = FALSE)%>%
        #add yellow area chart
        add_trace(y = c(J.Thomas$hold.top.yellow.line),
                  type = 'scatter',
                  mode = 'lines',
                  fill = 'tonexty',
                  color = I(""#f3eb6f""),
                  name  = ""yellow space"",
                  showlegend = FALSE)%>%
        #add orange area chart
        add_trace(y = c(J.Thomas$hold.orange.line),
                  type = 'scatter',
                  mode = 'lines',
                  fill = 'tonexty',
                  color = I(""#e6955f""),
                  name = ""orange space"",
                  showlegend = FALSE)%>%
        #add red area chart
        add_trace(y = c(max(J.Thomas$hold.red.line)),
                  type = 'scatter',
                  mode = 'lines',
                  fill = 'tonexty',
                  color = I(""#db686f""),
                  name = ""Red space"",
                  showlegend = FALSE) %>%
        layout(
            xaxis = list(range = c(min(J.Thomas$period),max(J.Thomas$period))),
            yaxis = list(range = c(min(J.Thomas$hold.duration ) - 25 ,
                                   max(J.Thomas$hold.duration) + 25 ))
        )",Plotly colors overlapping issue,7w6z45,new
"So I am trying to get the sums of positive drug tests from some data. Please help me figure out the code. I coded Neg and Pos as 0 and 1 so a sum should work. The problem is that I get the same sums when I run the entire dataset, the first filter, or the second filter each with less cases than the first. I ended up having to get the sums from Excel where I can confirm the sums are not the same for subset.

    df_urine %>%
      select(Client_ID, THC50, COCN, AMPH, METH, OPIA, BARB, BENZ, CREAT, OX, PCP) %>%
      replace(is.na(.), 0) %>%
      summarise_all(funs(sum))

    df_urine %>%
      select(Client_ID, THC50, COCN, AMPH, METH, OPIA, BARB, BENZ, CREAT, OX, PCP) %>%
      filter(n() == 1 & Client_ID == 102 | 105 | 109 | 112 | 114 | 122 | 124 | 126 | 128 | 131 | 133 |
               134 | 135 | 137 | 138 | 139 | 200 | 201 | 202 | 206 | 207 | 208 | 209 | 211 | 212 | 213 |
               214 | 215 | 217 | 218 | 219 | 224 | 225 | 230 | 232 | 234 | 240 | 242 | 243 | 244 | 246 | 247) %>%
      replace(is.na(.), 0) %>%
      summarise_all(funs(sum))

    # Filter based on Baseline to 6mo comparison N33
    df_urine %>%
      select(Client_ID, THC50, COCN, AMPH, METH, OPIA, BARB, BENZ, CREAT, OX, PCP) %>%
      filter(n() == 1 & Client_ID == 101 | 103 | 105 | 108 | 112 | 113 | 114 | 115 | 121 | 122 | 124 |
               125 | 126 | 128 | 201 | 204 | 206 | 208 | 210 | 211 | 212 | 213 | 214 | 215 | 216 | 218 |
               224 | 225 | 230 | 231 | 232 | 234 | 238) %>%
      replace(is.na(.), 0) %>%
      summarise_all(funs(sum))
",Select Cases not working,7w5h8d,new
"I've been writing some of my own R functions for a statistics course of mine, such as for calculating common distributions.

When I invoke ls(), however, there's little organization. The functions are all just ""there"".

Is there any way to group certain functions by category under ls()?",Is it possible to group custom R functions into categories/packages/groups?,7vyghr,new
"For the life of me, I can not figure out how to take a .csv file, that has a Subject, Body, and Date header of customer feedback via email, and get the information contained in say, ""Body"" into a word cloud.  Any help would be massively appreciated.  I've gone online and can not find a solution despite two days of efforts. 

So for example:
Subject	Body	Date
Help	Why can't I get R to run this data	2/1/2018
Help More	It's really frustrating	2/3/2018

NOTE: I've tried a lot of different methods, but still get the same issues as what I'll show below.  
EDIT:  So specifically, I named the file: ""word.""  I have four field Name, Desc, Subj, Date.
I wrote the following:

> library(tm)

Loading required package: NLP

> library(SnowballC)

> library(wordcloud)

Loading required package: RColorBrewer

> jeopQ <- read.csv('word.csv', stringsAsFactors = FALSE)

> jeopCorpus <- Corpus(VectorSource(jeopQ$Desc))

> jeopCorpus <- tm_map(jeopCorpus, PlainTextDocument)

> jeopCorpus <- tm_map(jeopCorpus, PlainTextDocument)

> jeopCorpus <- tm_map(jeopCorpus, removePunctuation)

> jeopCorpus <- tm_map(jeopCorpus, removeWords, stopwords('english'))

> jeopCorpus <- tm_map(jeopCorpus, stemDocument)

> wordcloud(jeopCorpus, max.words = 100, random.order = FALSE)

Error in simple_triplet_matrix(i, j, v, nrow = length(terms), ncol = length(corpus),  : 
  'i, j' invalid


And as you can see, got an error.  Now, ideally, I would like the .csv file to completely import all fields and make everything available for the wordcloud, but the examples I found online don't let me do that.  Thoughts?

Thank you again for the help

",.csv File Email comments to word cloud,7vwtf6,new
"Hi! I have a repeated measures-type data frame (several observations for one id) and I'm trying to recode a variable. I have an ifelse test and I want the true-action to be the following: choose the highest value of variable x for a each id (x2) ""cluster"". I tried using max(x|x2) but it doesn't understand the ""given"" (|) part. Any ideas? ",R question,7vv4pm,new
"Done with the basics...  Just finished reading and practicing  stuff at http://tryr.codeschool.com 

I would like to learn more and reach at least intermediate level.

Can somebody guide me, what's next? I need to be be good at this within a month.",Beginner's Guide,7vtptn,new
"I've got some code that I'm running in RStudio; it takes up ~2 Gb while it's running. However, it reached the end of the script about ten minutes ago, but still my computer is sluggish and I can see RStudio is still by far the dominant process, still taking up 2 Gb.

Why is this and what can I do to prevent it?",Why does RStudio still eat up so much memory long after my code has finished running?,7vprcs,new
"Hi,

I am looking for a way for create a .txt file of everything that is done during an R session - what code is ran through the console, what errors/warnings there were (if any).

I read about sink() but, i haven't been able to fine usage of it for something more that a single line of code at best.

I use an additional piece of software called ACL which can make calls to the Windows command prompt. I call the R environment from there and launch my script. 

All i need is the R console pasted in a file automatically at the end of my script. Does anyone know a way? (code examples are highly appreciated) ",Creating a log of everything that goes through in an R session,7vnoxn,new
"I have been using R in Arch Linux for quite a while. But now the following snippets of code are giving the following errors-

D <- read.csv(""some_file.csv"", sep = "";"")
View(D)

Error in .External2(C_dataviewer, x, title) : unable to start data viewer In addition: Warning message: In View(D) : unable to open display


plot(D$Temperature ~ D$Hour)

Error in .External2(C_X11, d$display, d$width, d$height, d$pointsize, : unable to start device X11cairo In addition: Warning message: In (function (display = """", width, height, pointsize, gamma, bg, :
unable to open connection to X11 display ''

Why is this happening? Things were working fine before. I am using R version 3.4.3 on x86_64 system.

On a terminal-

echo $DISPLAY

gives output-

wayland-0

Thanks!
",Visualisation Error in R,7vi2zx,new
"Honestly, I thought this was going to be an easier one. But I'm kind of stumped here. 

I even went as far as to try and write the plot to stdout (assumed it would output gibberish to the console, but the data would be correct), execute the entire thing with a script and try and capture the output somewhere else.

Hacky? Yes, but I had hoped it would work.",Is there a way to send plots easily?,7vde1l,new
Please take compare and contrast this language it's supporting packages like shiny and tidyverse with those the two softwares mentioned. ,What can I do in R that I can't do in Tableau/Power BI? What can I do in Tableau/Power BI that I can't do in R?,7vd5yj,new
"I have a function and a dataframe with a column full of state names. I need to pass each state name to the StateInfo function in one line using lapply. How would I go about parsing through the dataframe in one line and using lapply to solve this? Thanks.

    StateInfo <- function(stateName) {
      state_info <- filter(any_drinking, state == stateName)
      write.csv(state_info, file = paste(""output/"",stateName,"".csv"", sep=""""),row.names=FALSE)
    }",How to use lapply?,7vbmo8,new
"I have a very long file showing two columns; one contains character strings, the other contains numbers. It's too large a file to read in in one go. The thing I'd like to do must be done alphabetically - i.e. work with only the rows where the first character of the strings is 'a', then do 'b', then 'c', and so on.

Is there a way I can select rows like this without having first read the whole file in?",How to deal with this large file?,7v9u7n,new
"Hi there, my question is rather a trivial one. However, as I'm making first steps into r programming, an obstacle seems huge.
I have an XML file with details of a training. 
What I've already done is:
1. extracted XML into list with xmlToList()
2. extracted the Track node, which interests me, with a $ operator. That gives me a list of Trackpoints.
3. extracted data from nodes of Tracpoint, with sapply.

Most of Trackpoints look like that and contain complete information:
><Trackpoint>
>	<Time>2018-02-01T05:49:45Z</Time>
>	<HeartRateBpm>
>		<Value>89</Value>
>	</HeartRateBpm>
>	<Position>
>		<LatitudeDegrees>52.177288</LatitudeDegrees>
>		<LongitudeDegrees>21.0680731</LongitudeDegrees>
>	</Position>
>	<AltitudeMeters>146.375784482</AltitudeMeters>
>	<DistanceMeters>0.0</DistanceMeters>
>	<Extensions>
>	<TPX xmlns=""http://www.garmin.com/xmlschemas/ActivityExtension/v2"">
>		<Speed>0.245659</Speed>
>	</TPX>
>	</Extensions>
></Trackpoint>

Sadly, many Trackpoints are missing crucial data and looks like that:
><Trackpoint>
>	<Time>2018-02-01T05:49:29Z</Time>
>	<HeartRateBpm>
>		<Value>77</Value>
>	</HeartRateBpm>
></Trackpoint>

And while applying sapply to a skewed Trackpoint, I get an error:
>Error in matData[, ""AltitudeMeters""] <- unlist(sapply(trackData, ""["",  : 
  number of items to replace is not a multiple of replacement length

**Questions**:
* Is there a way to omit those skewed records?
* The better solution, and also the harder, would be to fill NA or zeros for missing fields.
Please, give me any hint.",Parsing skewed XML,7v6lh4,new
"    library(rpart)
    library(rpart.plot)
    heart = read.csv('heart.csv')
    heart$heart.disease = factor(heart$heart.disease)
    tree = rpart(heart.disease~., data=heart)
    prp(tree)

The plot that this outputs is very blurred. How to get a clearer image?",How to increase the quality of the plot in so that the nodes are visible?,7uqoy7,new
"I'm using write.table to make a .csv file and my p-value of <2e-16 is being rounded to 1. Since the value is certainly not 1, is there a way to specify the number of decimals (e.g. 0.0000) so that R ends up writing the value as zero instead?  

The old 'options(scipen=999)' didn't help here.  

Likewise, 'format(table,scientific=F)' didn't work either.",How to fix scientific notation being rounded to 1 when using write.table?,7uq7u6,new
"I'm trying to capture [this summary output](https://pastebin.com/raw/EkKyGiRP) from the 'mediation' package into a data.frame [like this](https://pastebin.com/raw/4NBYL0r8). The tidy in the 'broom' package doesn't work with the 'mediation' package yet, which is why I'm hoping there's another way to capture the data.",Capture summary() into data.table?,7uov6f,new
"I'd like to combine several months of data into a single dataframe. Currently I have the following code (just an example, real code is much longer):

    vec <- c(""0115"", ""0215"", ""0315"")
       #where each value represents January 2015, February 2015, and March 2015 respectively
    links <- paste0(""http://www.irs.gov/statistics/tax-stats-table/"",vec,""c.txt"")
       #so that I can import each month of data through the loop)
    
    temp.file <- tempfile()
    for (i in 1:length(vec)){
       download.file(links[i], temp.file[i], mode = ""wb"")
       irs <- read.csv(temp.file)
    }

The console shows that it downloads all three links, but my ""irs"" dataframe only has one month's worth of data. Can someone tell me where I'm going wrong? Thanks!",Trying to import multiple datasets at once using a for-loop?,7uornk,new
"I'm creating an R package. All dependencies are installed. The source code is (as far as I can tell) correctly annotated for roxygen2. 

Within the package root, the following commands are successful:

Documenting the package works:

`> devtools::document()` 

Building the package works:

`> devtools::build()` 

Installing the package fails:

`> devtools::install()` 

    ** R
    ** data
    ** preparing package for lazy loading
    ** help
    *** installing help indices
    ** building package indices
    Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec,  : 
      line 1 did not have 18 elements
    ERROR: installing package indices failed

I'm at a loss at to why. Are there any troubleshooting tips for this? 

",Creating R package: ERROR: installing package indices failed,7um1e1,new
"Hey, I'm trying to get standard deviation from my data frame where in the first column I have different values and in the 2nd column there is the occurence of each value.

I'm thinking that I might need to make a new dataframe/column where I have each value appearing as many times as it occurs, but I can't find how to make it any other way than manually inputting every value.  

Is there some other simpler way of doing this new dataframe or just counting the sd from the current data.",Getting standard deviation when I have value in column A and occurence rate in column B,7uhbaq,new
"I'm learning R in school and am just toying around with various functions. I'm trying to run this basic if-else function:

    x <- 7
    if(x > 5){
      if(x > 10){
        print(""x > 10"")
      } else {
        print(""5 < x <= 10"")}
    } else 
      if(x < 0 ){
        if(x < -10){
          print(""x < -10"")} 
        else {
          print(""-10 <= x <= 0"") 		
        } else {
          print(""0 <= x <= 5"") 
        }
      }

And I'm getting this error:

    > x <- 7
    > if(x > 5){
    +   if(x > 10){
    +     print(""x > 10"")
    +   } else {
    +     print(""5 < x <= 10"")}
    + } else 
    +   if(x < 0 ){
    +     if(x < -10){
    +       print(""x < -10"")} 
    +     else {
    +       print(""-10 <= x <= 0"") 		
    +     } else {
    Error: unexpected 'else' in:
    ""      print(""-10 <= x <= 0"")            
        } else""
    >       print(""0 <= x <= 5"") 
    [1] ""0 <= x <= 5""
    >     }
    Error: unexpected '}' in ""    }""
    >   }
    Error: unexpected '}' in ""  }""
    >

What gives? I've got all the brackets in place. Any help would be greatly appreciated!","Super basic, but can someone help me with this if-else function?",7u6wbu,new
"I have some big data frames of the following form:

    ##    terms1   count1   terms2   count2   terms3   count3     
    ## 1          the 51124        the 48771           the 9752
    ## 2          and 30087        and 22400           you 5872
    ## 3         that 12441        for  8758           and 4526
    ## 4          for  9907       that  8492           for 4038
    ## 5          you  8056       with  6356          that 2542
    ## 6         with  7896       said  6194          with 1841
    ## 7          was  7610        was  5746          your 1769
    ## 8         this  7143       from  3863          have 1752
    ## 9         have  6067        his  3860           are 1720
    ## 10         but  5666        but  3704          this 1682

What I would like is to combine the counts for the words that any of the 3 termsX columns have in common (and also retain any term-count pairing that might only appear in one of the three files). I'd like to end up with something that has two columns rather than six, that would show, for example:  

    ## term count
    ## the 109647 
    ## and  57013
    ## ... ...

and so on. 

What's the best way to do this?",Fastest way of combining these columns?,7u1vrv,new
"I'm trying to write code in R that will allow me to submit a query on http://nbawowy.com/ and scrape the resulting data. I'd like to be able to input values for at least the ""Select Team"", ""Select Players On"", and ""Select Players Off"" fields and then submit the form. As an example, if I select the 76ers as my team, and Ben Simmons as the ""Player On"", the resulting query is found here: http://nbawowy.com/#/z31mjvm5ss. I've tried using the following code, but it provides me with an unknown field names error:


library(rvest)

url <- ""http://nbawowy.com/#/l0krk654imh""
session <- html_session(url)

form <- html_form(read_html(url))[[1]]

filled_form <- set_values(form,
                      ""s2id_autogen1_search"" = ""76ers"",
                      ""s2id_autogen2"" = ""Ben Simmons"")

session1<-submit_form(session, filled_form, submit='submit')



Since I can't seem to get passed this initial part, I'm looking to the community for some help. I'd ultimately like to navigate the session to the resulting url and scrape the data.",Submit site form then scrape results,7ty8g9,new
"
I have data with one column and many rows:

     aColumn
     i1406, j9875, r4563, f5674
     l5764, r4563
     r9786, r4563, p9876, t5674, f4563

I would like to separate each value between commas somehow so that each value has a row. I would like to keep duplicates.

How can I get this output?

    i1406
    j9875
    r4563 
    f5674
    l5764
    r4563
    r9786
    r4563
    p9876
    t5674
    f4563",How do I pull apart values in rows of strings and put each on a separate line?,7ty58f,new
"It's been a while since I've used R and am having some trouble. I'm experiencing the following:

    string<-c(""wrong answer"", ""wrong answer"", ""wrong"", ""wrong answer"")

    string<-sub(""wrong"", ""wrong answer"", string)

    string

    [1] ""wrong answer answer"" ""wrong answer answer"" ""wrong answer""        ""wrong answer answer""

I want to only replace the elements whose entire contents is ""wrong"" so it doesn't end up repeating information in other elements.

Is there a quick and simple way to do this using R's base programming?
",I'm looking for something similar to Excel's Replace>Match Entire Cell's Contents,7twlqa,new
"I'm trying to estimate the memory use of my algorithm, and having called gc() I get the following output:

    ##            used  (Mb) gc trigger  (Mb) max used  (Mb)
    ## Ncells  5765974 308.0    9968622 532.4  5765974 308.0
    ## Vcells 51576243 393.5   88955300 678.7 51576243 393.5

What am I supposed to make of this? 

The documentation brought up by ?gc isn't much help, nor is google much use. I don't know why the 5th and 6th columns are identical to the 1st and 2nd, or if the (Mb) columns are supposed to be the same as the previous column with some conversion factor applied (the first two columns in the first row differ by a factor of 18.72 which makes me think that isn't the case). Also the meaning of Ncells and Vcells is unclear and the R Internals manual offers no clarification - am I to take the sum of one of these columns? I have no idea which number(s) in this table I should be most interested in.",Interpretation of gc() output?,7twf55,new
"Hi,

Problem: Bin 50 students with different attributes in a way that each class gets the same mix of students based on grade, attendance, ethnicity. 

I am guessing some sort of reverse k-mean with fixed cluster size or random stratified samples algorithm should do it. Any pointers where I can find similar R script?",R package for reverse k-mean binning,7tv7mq,new
"I'm calling a function I've made where the set of operations is identical every time, but the time required to run this code is not constant or even close to it - the repetitions I've done range between 0.19 seconds and 0.32 seconds to complete. They don't involve any random sampling, just take the same input, do the same thing with it and return the same output.

What is it that causes the difference in run-time? I wondered if it could be that my laptop is running other stuff in the background, but when I look at my task manager there is still plenty (>50%) of unused memory available.",Why might I get different run-times when repeating identical calculations?,7tu90k,new
"It's possibile to log on HDFS instead of a local file?
Below how as I assumed it would work...

**Local File**

      library('log4r')
      # Create a new logger object with create.logger().
      logger <- create.logger()
      # Log on local file
      logfile(logger) <- './log/test.log'
      # Set the current level of the logger.
      level(logger) <- 'INFO'
      # Log an error
      error(logger, 'An Error Message')

**Not Working! - HDFS file**

      library('log4r')
      # Create a new logger object with create.logger().
      logger <- create.logger()
      # Log on local file
      logfile(logger) <- 'hdfs://<cluster-node>:8022/log/test.log'
      # Set the current level of the logger.
      level(logger) <- 'INFO'
      # Log an error
      error(logger, 'An Error Message')

",log4r on HDFS,7tt4lm,new
"Here's my code and I suspect it's slow as hell:

    # terms_vec1 = a vector containing lots of words
    # terms_vec2 = another vector containing lots of words
    matched_terms_vec <- vector()
    for(current_term in 1:length(terms_vec2)){
      term_value <- terms_vec2[current_term]
      
      if(term_value %in% terms_vec1 == TRUE){
        matched_terms_vec <- c(matched_terms_vec, term_value)
      }
    }

Can I use any of the '-apply()' functions to do this quicker? ",What would be an alternative to a for-loop here?,7tjz4g,new
"I'm trying to find a more idiomatic R approach to the following small task: one data frame looking like

    customer1 NA NA
    NA 1 2
    NA NA NA
    NA 3 4
    customer2 NA NA
    NA 5 6
    NA 7 8
    NA NA NA

which needs to be converted to:

    customer1 1 2
    customer1 3 4
    customer2 5 6
    customer2 7 8

I already have a naive implementation of this which:

* cleans up the data (NA rows)
* goes over each row and sets the first element (if NA) to the customer name
* removes rows where the first element !is.na(), but the rest are

I'm looking for a more idiomatic R approach if that's possible - what I have is pretty iterative and I'm sure it can get better
",data frame transformation,7tezv5,new
"Hello !   
I'm starting R language, and I'm having trouble with boxplots.   
I have a CSV file containing three colums: 

    index  value  output    

Where value is a number between 0 and 1, and output is either ""A"" or ""B"".    
I want to get two boxplots of the data, one for each letter, and I can't manage to do it.   
   
My ""best"" try was to extract two subsets and try to plot them, but it only plot the first subset inside the boxplot command:   

    xc <- read.csv(""tab.csv"", row.names=1)
    A <- subset(xc[2], xc[3]==""A"")
    B <- subset(xc[2], xc[3]==""B"")
    boxplot(A,B)    
   
Thanks for any help !     
________________________   
EDIT: Found the solution, for anyone needing:    
   
    boxplot(xc$values~xc$output, data=xc)    
  
No need for the subsets :)
",Sort a CSV in a bloxplot,7tcjh0,new
I've been using TuneR which is great for reading in midi files. But not so much for writing midi files. Nor is it great for visualizing track information. Looking for something that resembles a very stripped down version of a digital audio workstation.,Any good R packages for interacting with midi files?,7t99g8,new
"edit: Zillow ***A***PI

I've been working on a project where the goal is to take a two-column CSV of street addresses and zip codes, read it into R, then perform a Zillow query for each one (GetDeepSearchResults, for example), parse the output, and store the parsed output in a dataframe to be written to a CSV (and placed right next to the existing data).


***caveat: I can only call one address/zip combo at a time through the zillow API, so anything that violates that is off the table immediately.***

As of this point, I have about 85% of the work done. I have i) a bit of code that can, one-by-one, query those address/zip combos from a dataframe as well as ii) a tentative way of putting that input back into a dataframe,

    library(ZillowR)
    library(rvest)
    library(dplyr)
    library(DT)
    
    # this commented section is what I would use instead of creating the dataframe manually below, just for clarity
    # data1 = read.csv('Addresses.csv', header = F, colClasses = 'character')$V1
    # data2 = read.csv('Addresses.csv', header = F, colClasses = 'character')$V2
    # data = data.frame(street = data1, city.state = as.character(data2))
    
    data = data.frame(
    	street = c('ADDRESS1',
                 'ADDRESS2',
                 'ADDRESS3'),
    	city.state = c(rep('ZIP', 3)))
    
    get.zillowdata = function(df, address, city.state){
    	require(ZillowR)
    	set_zillow_web_service_id('API KEY')
    	results = do.call(rbind, lapply(1:nrow(df), function(i){
    		z = tryCatch({
    		zdata = GetDeepSearchResults(address = df$street[i],
                      citystatezip = df$city.state[i],
                      zws_id = getOption(""ZillowR-zws_id""),
                      url = ""http://www.zillow.com/webservice/GetDeepSearchResults.htm"")
    		return(zdata)
    	},
    
        error = function(cond) {
          message(paste(""No Data Available:"", df$street[i], df$city.state[i]))
          return(NA) # Choose a return value in case of error
        },
    
        warning = function(cond) {
          message(paste(""Zdata caused a warning:"", df$street[i], df$city.state[i]))
          return(NA) # Choose a return value in case of warning
        },
        # print processing message to screen
        finally = {
          message(paste(""Processed Address:"", df$street[i], df$city.state[i]))
          message(paste(i, ""of"", nrow(df), 'processed'))
          }
        )
    	}))
    
    if(nrow(results)==nrow(df)){
    	results = cbind(df, results)
    
        print(paste('Original data had', nrow(df), 'rows. Returning a dataframe with', nrow(results),
        'rows. Returned dataframe has', sum(is.na(results$amount)), 'missing zdata values.'))
    
      return(results)
    }
    	else(print(""Error: nrows(df) do not match nrows(zdata)""))
    }
    
    get.zillowdata(data)
    ` 
and also iii) a parser for the XMLnode response that you get when you perform a query through the Zillow API which picks out specific child values (zestimate, square footage, lot size, etc; whatever you specify)

    library(ZillowR)
    library(xml2)
    library(RCurl)
    
    set_zillow_web_service_id('API KEY')
    output123 = GetDeepSearchResults(address = 'STREET ADDRESS', citystatezip = '0ZIP CODE', zws_id = getOption(""ZillowR-zws_id""), url = ""http://www.zillow.com/webservice/GetSearchResults.htm"")
    
    results <- xmlToList(output123$response[[""results""]])
    
    getValRange <- function(x, hilo) {
      ifelse(hilo %in% unlist(dimnames(x)), x[""text"",hilo][[1]], NA)
    }
    
    out <- apply(results, MAR=2, function(property) {
      zpid <- property$zpid
      links <- unlist(property$links)
      address <- unlist(property$address)
      z <- property$zestimate
      zestdf <- list(
        amount=ifelse(""text"" %in% names(z$amount), z$amount$text, NA),
        lastupdated=z$""last-updated"",
        valueChange=ifelse(length(z$valueChange)==0, NA, z$valueChange),
        valueLow=getValRange(z$valuationRange, ""low""),
        valueHigh=getValRange(z$valuationRange, ""high""),
        percentile=z$percentile)
      list(id=zpid, links, address, zestdf)
    })
    
    data <- as.data.frame(do.call(rbind, lapply(out, unlist)),
                          row.names=seq_len(length(out)))

But I'm a little stuck at this point. How can I put these together so that I include the parsing at the end of the api call part and make sure that both the call and the parser get iterated over the full list of addresses/zips (leading to a new data frame with the same amount of rows as the original, populated by the zillow data)? My code right now isn't in any particular order, so feel free to move things around if you decide to tackle this, and if anyone needs additional information, I'm happy to clarify! 

Thanks very much in advance.
","Looking for some ""last mile"" advice on how to put this code together; the topic is: iterating a Zillow ZPI call / output parse function in R over a dataframe of addresses/zip code combos",7t6env,new
"Case identifier|Start time (in UNIX time)|End time (in UNIX time)|Activity name|Start date (human time)|End date (human time)|
--:|--:|--:|:--|:--|:--|
1|1396374800|1396374800|Arrival|04/01/2014 17:53|04/01/2014 17:53|
1|1396375110|1396375265|Vitals|04/01/2014 17:58|04/01/2014 18:01|
1|1396375430|1396382749|Infusion|04/01/2014 18:03|04/01/2014 20:05|
2|1396347660|1396347660|Arrival|04/01/2014 10:21|04/01/2014 10:21|
2|1396349131|1396350275|BloodDraw|04/01/2014 10:45|04/01/2014 11:04|
3|1396340626|1396340626|Arrival|04/01/2014 08:23|04/01/2014 08:23|
3|1396340626|1396346056|Exam|04/01/2014 08:23|04/01/2014 09:54|
4|1396345339|1396345339|Arrival|04/01/2014 09:42|04/01/2014 09:42|
4|1396346299|1396346415|Infusion|04/01/2014 09:58|04/01/2014 10:00|
5|1396344360|1396344360|Arrival|04/01/2014 09:26|04/01/2014 09:26|
5|1396365709|1396366068|Exam|04/01/2014 15:21|04/01/2014 15:27|
6|1396342500|1396342500|Arrival|04/01/2014 08:55|04/01/2014 08:55|
6|1396344405|1396344892|BloodDraw|04/01/2014 09:26|04/01/2014 09:34|
7|1396372737|1396372737|Arrival|04/01/2014 17:18|04/01/2014 17:18|
7|1396372737|1396376487|Exam|04/01/2014 17:18|04/01/2014 18:21|
7|1396377128|1396377128|Vitals|04/01/2014 18:32|04/01/2014 18:32|
7|1396377831|1396378301|Pharmacy|04/01/2014 18:43|04/01/2014 18:51|
7|1396378596|1396381732|Infusion|04/01/2014 18:56|04/01/2014 19:48|
8|1396350660|1396350660|Arrival|04/01/2014 11:11|04/01/2014 11:11|
9|1396357200|1396357200|Arrival|04/01/2014 13:00|04/01/2014 13:00|
9|1396357687|1396357844|BloodDraw|04/01/2014 13:08|04/01/2014 13:10|
9|1396360827|1396363804|Exam|04/01/2014 14:00|04/01/2014 14:50|

Currently, trying to figure out the following question:

Add a column (to every event) with the remaining time (i.e., the time between the last event that is related to the case, and the start time of the current event).


I've looked up online, and gotten to here - https://stackoverflow.com/questions/30606360/r-subtract-value-from-previous-row-group-by - but it's a little different because there isn't a singular column value, rather it's start time - previous row end time. 


Appreciate the help! ",Difference between start and end times in rows.,7t14r2,new
"I have a problem with the following code. I'm scanning through a data frame and when I've hit the row I'm interested in, I can successfully print it out. However, when I try to print out just one element/column entry of this row, it gives me nonsense. 

## Code:

    # Scan through current data frame of terms and their frequencies:
      for(i in 1:nrow(DF)){
        # Determine the start of the current term in the data frame:
        current_prefix <- substr(DF[i, 1], 1, prefix_length)
    
        # If the start of the current term in the data frame matches the prefix:
        if(current_prefix == prefix_to_match){
          current_term <- as.character(DF[i, 1])
          current_freq <- as.numeric(DF[i, 2])
          vec_matched_terms <- c(vec_matched_terms, current_term) 
          vec_matched_freqs <- c(vec_matched_freqs, current_freq) 
      
          if(current_term == ""no surprise""){
            print(DF[i, ])
            print(DF[i, 1])
            print(DF[i, 2])
          }
        }
      }
  
      print(""!!!???"")
      print(vec_matched_terms)
      print(vec_matched_freqs)



## Output of this code:


          terms_vec freqs_vec    percentages_col cumulative_percentages_col
    151 no surprise        13 0.0619047619047619                       29.9
    [1] no surprise
     20259 Levels: n a n â<U+0080><U+009C>this n aftra n austin n awh n ballas ... nzt saving
    [1] 13
    67 Levels: 0 1 10 100 106 11 114 12 124 13 132 134 135 14 15 16 ... 
    [1] ""no surprise""
    [1] 10
    [1] ""!!!???""
    [1] ""no surprise"" ""no such""     ""no sense""   
    [1] 10  6 66

The quantity I'm interested in is the frequency, which is the second column of my data frame. When I print out the whole row, this is the 13 seen underneath 'freqs_vec'. This part works correctly, print(DF[i, ]) prints out the row as it looks in the data frame.

However, immediately after I do print(DF[i, ]), I do print(DF[i, 1]) and  I do print(DF[i, 2]). It gives me the correct phrase (""no surprise"") and number (13) back when, but is accompanied by all these levels. This I don't know how to stop or what consequences it might have, but using as.character() and as.numeric() hasn't got rid of this info about levels being somehow attached to the actual quantities I care about. That's the first problem, and I'm guessing it's related to the main problem.

The main problem is that I'm supposed to have assigned the values of DF[i, 1] and DF[i, 2] to current_term and current_freq, but when I print these out, I find that current_freq holds different numbers to what I'd expect -
this number has changed from 13 to 10 by being assigned to current_freq. 

What is going on here?",Whole row of data frame can be printed correctly but trying to print only one entry in that row gives me nonsense?,7sxf2q,new
"I'm used to using a drive letter file structure in windows (e.g. setwd(""H:/csv/"") ), but can someone tell me how to reference a directory when working on HPC clusters? Is it something like either setwd(""/user/home/csv/"") or setwd(""~/user/home/csv/"") ? I've not been able to find any specific examples yet googling and search stackoverflow directly. I didn't even think it was possible to reference relative directories in R.",Loading/writing data in HPC job?,7ssnaf,new
"Im new in the world of coding, but i have some experence on c++. But in R i don[t know where i can find a awnser for this project. I like to create a tournament with 8 teams, like A,B,C...H. The tournament is like a Quarter-finals of the World cup( The teams will be divide in two separate sides, with four teams each (live A, B, G,H) and (C,D E,F). Then we have 2 matchs, for exemple (A x G) and (B x H). The winner of mach 1 plays against the winner of mach 2. ). I wanna give each team some probability of ""winning"" the match, and i like to repeat the process like 100 times. Someone knows where i can find a material to learn how to make thism or at lest the name of this progran?",Help on a project,7ss9a8,new
" was able to do the calculation, but have no idea how to use R, or many functions. Can you please help me? The golf scores of two competitors, A and B, are recorded over a period of 10 days. Golfer A claims that her game is better than that of Golfer B. Use the following data. Day Golfer 1 2 3 4 5 6 7 8 9 10 A 87 86 79 82 78 87 84 81 83 81 B 89 85 83 87 76 90 85 78 85 84

Test the claim that Golfer A is better than Golfer B using R. I just need to code and show theoutput (which shows the test statistic value and the p-value). Use α = 0.05.",R Programming,7sntci,new
"I've got a repeat loop polling an api for live data every 6-10 seconds and plan on making a parallel thread to reactively display this data over time with shiny.

The problem (I'm assuming) is because I'm saving this data as a set of csv files I may get a collision with the reactiveFileReader. 

Is there a way to read actively updating data without causing an issue with the thread that may attempt to write to an open file. Or s the solution to create some kind of timing rules for the two separate functions.


",Reading/writing actively updating files.,7sh7lg,new
"Hello! My finance professor is having all of the students learn R as well as Excel functions. We've only talked about R for about 15 minutes, but I'd like to get a head start and gain some familiarity with the program. 

I did a quick Google search for some practice problems and got an example that was a function called ""sum.of.squares"". 

sum.of.squares <- function(x,y){

x^2 + y^2
}

When I put that in, I get a function in my global environment called sum.of.squares. 

Now, I try to call it by entering:

sum.of.squares (37,22)

Then pressing control + enter while that line is highlighted. It worked for me earlier, but now it just returns ""sum.of.squares (37,22) "" 

Any pointers on where I'm going wrong would be greatly appreciated.","First day of R, struggling hard.",7sc60c,new
"I have a table with two columns, 100 values for 'x' and 100 values for 'y'.

I accidentally found out about something like ""levels"", but I don't understand what are they for. I tried to use '?levels' help, but it doesn't say anything that is:

> levels provides access to the levels attribute of a variable. The first form returns the value of the levels of its argument and the second sets the attribute.

So, levels provide access to levels, very tautological description... but what are levels itself? 

I tried to google for it, but didn't found anything useful. I also noticed that levels seem to have the same value as values in table, but if these values are already in table, then what are levels for? Why to keep the same thing twice?

Also, looks like while trying to extract some data, the levels are left there as ""rubbish"":

https://puu.sh/z7ege/f88ccc1ff7.png

Anyone knows and could explain me what are levels exactly? And why are they needed for? Can one somehow get rid of them?
Or maybe it's already explained in details somewhere, but I just don't know where to look for it?

*****

^^Best ^^Regards,

^^Evans","What are ""levels"" in tables? What are they for?",7s7f7j,new
"Hi,

I work in the field of medicine and genetics. I've been recommended R as a useful tool for statistics and processing big data (eg genomics). My goal is to eventually use R for any data processing task, from basic statistical tests for research papers, to data science, and machine learning.

I'm surprised at the amount of books out there, especially bad/obscure ones ... 

Can you guys recommend an outline for 3, to read one after the other, without excessive overlap (ie wasting time and effort) ? 

For now, I'm ""only"" interested in being fluent in R and learning advanced statistics using R. Here's my thinking :

1. Getting Started with R: An Introduction for Biologists.
Started using this last week. Very gentle introduction, exactly what I needed ... On my way to finish it in a couple of days.

2. The book of R / The art of R programming.
Both are clearly recommended by everyone, but which one would be best in this context ? Given that one is twice as long as the other ...

3. Discovering Statistics Using R, by Andy Field.
Actually started reading it a few weeks ago, without knowing any R. Realized it was more of a stats book than an R book ... But apparently great statistics material. Any other recommendations for an advanced, comprehensive statistics book using R ? I have only basic background in statistics.

Thank you.
",Learning R and advanced statistics : advice on reference books ?,7s4t04,new
"I'm trying to follow along with this [exercise file](http://www.bio.ic.ac.uk/research/crawley/statistics/exercises/R1Plots.pdf). Everything seems to work fine except for the part on Logarithmic axes. I can never get R to convert it into log form. It just plots it out regularly, even if I copy straight from the exercise file. Is there something wrong with this material, my data, etc? Any help would be appreciated.

Here is the data from the plotdata.txt that I have. It was a download file.

x|y
:--|:--
1|11
2|12
3|9
4|7
5|5
6|8
7|4
8|4
9|5
10|3",Learning R. Having problems with Logarithmic axes,7s1cw3,new
"So I was trying to create an R shiny app which, upon uploading two files (a raster and a shapefile) it would execute a source script and output a couple of results. To be more specific, for example, I want to do the following

    ras=brick(readline())
    poli=readOGR(readline())
    poli@proj4string=CRS(""+init=epsg:2100"")
    plot(ras)
    plot(poli, add=T)

And as until this point I've written this with Shiny

UI:
    library(shiny)
    library(raster)

    shinyUI(pageWithSidebar(
  
      headerPanel(""Header1""),
  
      sidebarPanel(
        fileInput('layer', 'Choose Layer', multiple=FALSE, accept='tif'),
        fileInput('shp','Choose shp', multiple=T, accept='.shp'))
      ),
  
      mainPanel(
       plotOutput(""mapPlot""), 
       plotOutput(""shapefile"")
     )
    )

Server:
library(shiny)
library(raster)
library(maptools)

    shinyServer(function(input, input2, output, output2){
  
      output$mapPlot <- renderPlot({
    
        inFile <- input$layer
    
        if (is.null(inFile))
          return(NULL)
    
        data <- brick(inFile)
    
        plot(data)
        })
    
        output$shapefile 
        renderPlot({
      
          inFile2 <-input$shp
          if (is.null(inFile2))
            return(NULL)
          data2 <- readOGR(inFile2)
          plot(data2)
      })
  
  
    })

and I get the following line:

**Error : unused argument (mainPanel(plotOutput(""mapPlot""), plotOutput(""shapefile"")))**


Is there something that I do wrong?

**UPDATE** So, I dubbuged my code and I am quite sure that now I have a problem using the wrong inputs, but fear not, I will solve that as well.

Here is the code:

UI

    library(shiny)
    library(raster)
    library(rgdal)
    shinyUI(fluidPage(pageWithSidebar(
     headerPanel(""Header1""),
     sidebarPanel(
        fileInput('layer', 'Choose Layer', multiple=FALSE, accept='asc'),
        fileInput('shp','Choose shp', multiple=T, accept='.shp')),
     mainPanel(
        plotOutput(""mapPlot""),
        plotOutput(""shapefile"")
      )
    )))


Server

    library(shiny)
    library(raster)
    library(rgdal)
    options(shiny.maxRequestSize = 30*1024^2)
    shinyServer(function(input,output,session){

      inFile<-input$layer
      if (is.null(inFile)){
        return(NULL)}
      data <- brick(inFile)
  
      inFile2 <-input$shp
      if (is.null(inFile2)){
        return(NULL)}
      data2 <- readOGR(inFile2)
  
      output$mapPlot<-renderPlot({
        plot(data)})
    
       output$shapefile<-renderPlot({plot(data2)})
  
  
    })",Working with R Shiny for the first time,7ryroq,new
Something similar to PRAW for python?,Is there an R package for reddit analysis?,7rw73d,new
"I'm just getting started with R and I don't want to make any mistakes in installing critical packages I want to learn to use.  Should I be worried about these errors and warnings?  Thanks.. 

An example of some of the errors;

    *** copying figures
    ** building package indices
    ** installing vignettes
    ** testing if installed package can be loaded
    * DONE (testthat)
    Making 'packages.html' ... done
    ERROR: dependency ‘gdtools’ is not available for package ‘svglite’


and
    
    Error in download.file(url, destfile, method, mode = ""wb"", ...) : 
      download from 'https://mirror.las.iastate.edu/CRAN/src/contrib/data.table_1.10.4-3.tar.gz' failed
    In addition: Warning messages:
    1: In download.file(url, destfile, method, mode = ""wb"", ...) :
      downloaded length 2195456 != reported length 3071833
    2: In download.file(url, destfile, method, mode = ""wb"", ...) :
      URL 'https://mirror.las.iastate.edu/CRAN/src/contrib/data.table_1.10.4-3.tar.gz': status was 'Transferred a partial file'
    Warning in download.packages(pkgs, destdir = tmpd, available = available,  :
      download of package ‘data.table’ failed
    trying URL 'https://mirror.las.iastate.edu/CRAN/src/contrib/htmlTable_1.11.1.tar.gz'
    Content type 'application/x-gzip' length 170724 bytes (166 KB)
    ==================================================
    downloaded 166 KB    

and
    
    ERROR: configuration failed for package ‘curl’
    * removing ‘/usr/lib/R/library/curl’
    * installing *source* package ‘openssl’ ...
    ** package ‘openssl’ successfully unpacked and MD5 sums checked
Warnings at the end;

    Warning messages:
    1: In install.packages(""ggplot2"", dependencies = TRUE) :
      installation of package ‘curl’ had non-zero exit status
    2: In install.packages(""ggplot2"", dependencies = TRUE) :
      installation of package ‘httr’ had non-zero exit status
    3: In install.packages(""ggplot2"", dependencies = TRUE) :
      installation of package ‘gdtools’ had non-zero exit status
    4: In install.packages(""ggplot2"", dependencies = TRUE) :
      installation of package ‘covr’ had non-zero exit status
    5: In install.packages(""ggplot2"", dependencies = TRUE) :
      installation of package ‘multcomp’ had non-zero exit status
    6: In install.packages(""ggplot2"", dependencies = TRUE) :
      installation of package ‘svglite’ had non-zero exit status
    7: In install.packages(""ggplot2"", dependencies = TRUE) :
      installation of package ‘Hmisc’ had non-zero exit status
    ","Getting started with R, just installed ggplot2 (install.packages(""ggplot2"", dependencies=TRUE) ) ..........lots of warnings?",7rqv77,new
"I am in the process of starting a data analysis blog on my personal website. I have come across some workflow resources like [blogdown](https://bookdown.org/yihui/blogdown/), but I wanted to inquire if anyone else has created an R blogging workflow that they like.

**Situation:**

  - The blog will be powered as a Django application (the website is deployed and running on AWS)
  - Django will handle user navigation, templating, and everything up to the final R document 

**Requirements:**

  - One source of truth for the organization of blog text and visuals (ideally a single document)
  - Ability to display interactive (Shiny, Plotly) visuals in the blog post

**My idea so far:**

Each blog post gets a directory (and GitHub repo) with all the data, cleaning scripts, and an **R-Markdown file**. The .Rmd file is rendered to HTML when done. The HTML file is rendered by Django as a textfield. I like this workflow because it is a typical data analysis project workflow, then all Django has to do is pick up the rendered R-Markdown file. But I am unsure if the interactive visuals will run once it is on the web server.

tl;dr How do I make a Django-powered analytics R blog with minimal overhead?
",Designing an elegant workflow for a data analytics blog,7romsy,new
"Hello all, 
 
I was trying to import some data from a csv file and [plus signs showed up](https://imgur.com/a/LPbCB) after I ran the command, but if I set up a working directory and do it that way, everything works fine. I'm just playing around with R, wondering where the command went wrong in the picture? Thanks in advance. ",Read CSV file?,7r607o,new
"I currently have the following situation:


green <- t(combn(1:14, 2))

1|2|
:--|:--|
1|3|
1|4|
and so on.

blue <- t(combn(1:14, 3)), which will give the following table:

1|2|3|
:--|:--|:--|
1|2|4|
1|2|5|

and so on.

My goal is to merge and duplicate each row so that the table becomes the following:

1|2|1|2|3|
:--|:--|:--|:--|:--|
1|2|1|2|4|
1|2|1|2|5|
1|3|1|2|3|
1|3|1|2|4|
1|3|1|2|5|
1|4|1|2|3|
1|4|1|2|4|
1|4|1|2|5|

I want to duplicate each row for one of the columns and merge the other column to each duplicated row (hopefully the exam shows it better).

Thanks!

",Merging/Duplicating two columns,7r5fpn,new
"What is the standard/set of best practices for R6 documentation? What's the proper way to do this?

I'm not sure that this has been settled yet. The best I can come up with is this example: https://github.com/r-lib/processx/blob/bc7483237b0fbe723390cbb74951221968fdb963/R/process.R#L2

which I found in this thread, at the bottom:

https://github.com/r-lib/R6/issues/3


The latest from Dr. Wickham appears to be this comment from a few months ago:

https://github.com/klutometis/roxygen/issues/388

Can someone show me the light?",What is the status of R6 documentation?,7qzd0f,new
"Greetings,

Fairly new to R, so apologies in advanced for the poor explanation.

I have some highly-dimensional datasets with few response observations of many (50) predictor variables that I will be generating partial least squares models from. I want to loop an interval-type PLS calibration for all possible combinations of starting and ending point along a continuous range of predictors (e.g. 1-51; 2-51; 3-51....1-50; 1-49; 1-48 etc...).

For this, I have a matrix of responses, a matrix of predictors, and a matrix of the possible starting and ending combinations (n = 1275). I would like to run a PLS calibration for each possible combination and extract the RMSE values (absolute minimum for all possible components), but am not sure how to automate this with a loop. Any suggestions? Thank you!",PLS Variable Selection with Continuous Variable Windows,7qw57a,new
i need to find confusion matrix for decisiontree ,how to find confusion matrix for decisiontree,7qvk7w,new
"im getting the below error , when i try to execute this code
""> table(predict(m, dataset[,-14]), dataset[,14])""

Error in table(predict(m, dataset[, -14]), dataset[, 14]) : 
  all arguments must have the same length",need help,7qs1u7,new
"Hey all,

I'm working with an existing code that makes use of purrr v. 0.2.2's by_row function. The code exists on a server so I'm trying to download all of the packages to my local machine so that I can work on it in R Studio. I'm struggling to download purrr v. 0.2.2. Newer versions of purrr have deprecated by_rows, so this is the version I need for my code to run.

So far I've tried the following two methods to install the package:

    # Method 1:
    library(devtools)
    install_version(""purrr"", version = ""0.2.2"")

    # Method 2:
    packageurl <- ""http://cran.r-project.org/src/contrib/Archive/purrr/purrr_0.2.2.tar.gz""
    install.packages(packageurl, repos=NULL, type=""source"")

However, each method dies the same way, with the following error:

    C:/Users/MyUsername/Documents/R/win-library/3.4/dplyr/include/dplyr/main.h:11:19: fatal error: plogr.h: No such file or directory
     #include <plogr.h>
                       ^
    compilation terminated.

So at this point I'm not sure if there's any additional things I could try to get this to work correctly. Does anyone have any suggestions on how I can get the version downloaded?","Need help downloading R package ""purrr"" v. 0.2.2. I keep getting errors when trying on my Windows machine.",7qlwuy,new
"I'm trying to model the following scenario:  

I have 6x6 grid (ie 36 spaces) as well as 8 red and 8 yellow alternating tickets. I'm trying to build a database where I'd have a 36 columns, each one representing one of the spaces. What I want is let's say there is just one yellow ticket, I want all the possible combinations (ie Y,0,0,0....), where Y = yellow, R= red. This becomes more complicated since if there are 2 Y and 3 R, there would be a lot more combinations. I'm trying to use the combn function, but I'm not getting  very far.

Thanks!",Possible combinations,7ql33x,new
"Hello everyone!
My goal is to create a random football fantasy league schedule, given 8 teams. Every 7 matches the calendar is repeated, for a total of 35 games. 
Our fantasy league is based in 4 direct matches between two teams each round , and depending on the points made you can score 0,1,2,3 or more goals. Who scores the most goals in that round between the two wins; each win is worth 3 points, each draw 1 point, each defeat 0 points.

As you can see, the randomness is given by the fact that with different schedules you can win, draw or lose certain games (depending on the opponent encountered on that day).

I already have data on goals scored by all teams, divided into ordered vectors, so my aim is to create a calendar in which the teams are randomly matched, and given the goals made in every round see the new ranking. I am interested both in the single simulation, that in the average ranking after a lot of simulations.
At first I thought that the best team turned out to be simply the one that scored the most total goals, but then I noticed teams that score many goals on some days (the average goals scored are 2, there are those who do 6 in a single game) and many few in the others.



How can I simply manage to do this with R?

P.S. I know that this question is not really useful, it is just a silly curiosity!",Football fantasy league schedule in R,7qe2jf,new
Any past experience or resources I can read?,is R good for agent based modeling?,7qaj92,new
"I'm trying to add some data to an oracle database, and with the dbWriteTable function, the field.types argument seems to be ignored when creating a new table.  I tried a host of things, short of writing a DDL for the table before loading.  I have found very little documentation of field.types and examples, though there is a lot of dbWriteTable documentation.  Anyone else have experience with writing to an oracle database that can lend a hand?  Thanks!",Oracle Datatypes not written correctly,7pymub,new
"I have a loop that runs on a bunch of csv files and generates rolling statistics (e.g. means) on them. New source files are constantly being added. My current loop script runs through all the files each time I run it. That is extremely time consuming.  

Can someone point me to any examples of loops that can be run multiple times and only append to previous results as new data is found? Basically I'm looking for a 'if X exists in Y output csv file, then skip X' type of thing.",R loop that appends to previous loop output?,7pv65e,new
"Hi Reddit. For a project at work, I am importing financial data into R from a CSV file. There are 27 columns: first column is for the Dates and the 26 beside it are titles of the investments. The first column, the date column, is not in ISO format. The dates rare written in the following format: ""12/29/17"". 

What is the most efficient way to change this column of dates into ISO format and have this data become a time series?",Converting dates to ISO,7ptyji,new
"Here's my code (very simple):

    time <- c(296.605, 296.628, 297.637, 298.646, 299.654, 300.665, 301.674, 302.683, 303.691, 304.701, 305.713, 306.721, 307.73, 308.739, 309.748, 310.758, 311.768, 312.777, 313.786, 314.798, 315.81, 316.82, 317.829, 318.837, 319.849, 320.86, 321.869, 322.879, 323.889, 324.901, 325.911, 326.92, 327.931, 328.941, 329.951, 330.962, 331.972, 332.981, 333.99, 335.0, 336.008, 337.019, 338.03, 339.041, 340.054, 341.063, 342.074, 343.084, 344.097, 345.109, 346.12, 347.13, 348.142, 349.155, 350.167, 351.178, 352.191, 353.207, 354.218, 355.229, 356.244, 357.258, 358.282, 359.295, 360.308, 361.323, 362.338, 363.352, 364.366, 365.376, 366.388, 367.401, 368.415, 369.428, 370.442, 371.454, 372.468, 373.484, 374.499, 375.514, 376.529, 377.545, 378.56, 379.574, 380.591, 381.606, 382.619, 383.634, 384.655, 385.671, 386.685, 387.699, 388.715, 389.731, 390.746, 391.765, 392.783, 393.797, 394.81, 395.825, 396.843, 397.86, 398.878, 399.895, 400.909, 401.925, 402.94, 403.957, 404.972, 405.986, 407.002, 408.022, 409.036, 410.055, 411.076, 412.09, 413.104, 414.12, 415.138, 416.153, 417.169, 418.197, 419.212, 420.226, 421.247, 422.264, 423.281, 424.299, 425.314, 426.332, 427.349, 428.37, 429.388, 430.402, 431.426, 432.441, 433.462, 434.481, 435.501, 436.518, 437.535, 438.55, 439.571, 440.594, 441.61, 442.629, 443.646, 444.663, 445.681, 446.699, 447.717, 448.734, 449.751, 450.766, 451.786, 452.809, 453.828, 454.846, 455.868, 456.886, 457.905, 458.923, 459.942, 460.966, 461.987, 463.008, 464.024, 465.043, 466.06, 467.082, 468.103, 469.119, 470.138, 471.157, 472.175, 473.193, 474.211, 475.231, 476.25, 477.274, 478.308, 479.329, 480.349, 481.373, 482.393, 483.412, 484.434, 485.456, 486.478, 487.503, 488.522, 489.542, 490.564, 491.591, 492.614, 493.641, 494.661, 495.682, 496.7, 497.725, 498.753, 499.773, 500.797, 501.817, 502.842, 503.866, 504.888, 505.913, 506.937, 507.96, 508.981, 510.007, 511.027, 512.051, 513.072, 514.096, 515.118, 516.147, 517.17, 518.196, 519.218, 520.243, 521.265, 522.29, 523.312, 524.338, 525.366, 526.392, 527.419, 528.444, 529.47, 530.495, 531.515, 532.537, 533.56, 534.582, 535.607, 536.632, 537.658, 538.697, 539.723, 540.751, 541.774, 542.796, 543.82, 544.846, 545.87, 546.893, 547.92, 548.946, 549.972, 550.993, 552.017, 553.047, 554.073, 555.098, 556.125, 557.153, 558.181, 559.209, 560.234, 561.259, 562.285, 563.316, 564.341, 565.365, 566.391, 567.421, 568.442, 569.467, 570.495, 571.521, 572.551, 573.58, 574.604, 575.632, 576.657, 577.682, 578.709, 579.736, 580.772, 581.802, 582.832, 583.863, 584.894, 585.921, 586.952, 587.982, 589.011, 590.044, 591.079, 592.11, 593.142, 594.172, 595.202, 596.234, 597.265, 598.292, 599.329, 600.362, 601.389, 602.418, 603.445, 604.473, 605.505, 606.537, 607.567, 608.595, 609.629, 610.664, 611.691, 612.721, 613.754, 614.786, 615.813, 616.847, 617.88, 618.908, 619.939, 620.974, 622.007, 623.037, 624.072, 625.1, 626.13, 627.159, 628.19, 629.221, 630.258, 631.296, 632.33, 633.369, 634.403, 635.437, 636.47, 637.501, 638.534, 639.57, 640.597, 641.633, 642.664, 643.693, 644.727, 645.758, 646.797, 647.828, 648.861, 649.895, 650.928, 651.961, 652.994, 654.023, 655.053, 656.084, 657.116, 658.145, 659.188, 660.225, 661.261, 662.302, 663.334)
    score <- c(3141, 3142, 3204, 3273, 3317, 3369, 3415, 3469, 3508, 3560, 3606, 3674, 3711, 3761, 3820, 3866, 3916, 3968, 4029, 4099, 4151, 4209, 4265, 4316, 4378, 4428, 4481, 4517, 4560, 4621, 4685, 4738, 4792, 4842, 4899, 4950, 4987, 5047, 5104, 5165, 5204, 5263, 5319, 5367, 5429, 5480, 5549, 5598, 5648, 5702, 5758, 5805, 5843, 5887, 5936, 5968, 6023, 6070, 6128, 6176, 6236, 6263, 6301, 6346, 6393, 6444, 6484, 6527, 6579, 6614, 6665, 6707, 6759, 6784, 6816, 6860, 6902, 6939, 6977, 7024, 7065, 7096, 7136, 7176, 7215, 7259, 7296, 7343, 7389, 7414, 7458, 7479, 7511, 7551, 7595, 7645, 7680, 7725, 7763, 7808, 7851, 7891, 7943, 7984, 8023, 8052, 8087, 8151, 8195, 8230, 8268, 8320, 8359, 8394, 8422, 8461, 8504, 8556, 8605, 8642, 8681, 8726, 8765, 8806, 8862, 8899, 8927, 8972, 9023, 9053, 9095, 9130, 9170, 9225, 9249, 9278, 9319, 9359, 9407, 9445, 9469, 9520, 9550, 9600, 9642, 9686, 9731, 9765, 9801, 9846, 9876, 9909, 9960, 9995, 10034, 10082, 10115, 10165, 10213, 10260, 10307, 10345, 10383, 10422, 10468, 10511, 10542, 10592, 10619, 10668, 10714, 10751, 10796, 10839, 10884, 10924, 10961, 11013, 11046, 11083, 11121, 11168, 11213, 11250, 11278, 11325, 11365, 11415, 11459, 11509, 11555, 11606, 11642, 11684, 11738, 11792, 11851, 11893, 11942, 11984, 12034, 12097, 12147, 12188, 12264, 12314, 12355, 12399, 12455, 12508, 12564, 12622, 12675, 12721, 12789, 12847, 12896, 12941, 12998, 13022, 13078, 13140, 13185, 13252, 13309, 13364, 13417, 13481, 13543, 13584, 13645, 13691, 13751, 13812, 13865, 13928, 13972, 14034, 14084, 14148, 14202, 14254, 14325, 14385, 14449, 14504, 14597, 14649, 14712, 14767, 14829, 14880, 14942, 15019, 15085, 15155, 15222, 15274, 15350, 15421, 15474, 15535, 15582, 15653, 15716, 15776, 15835, 15898, 15980, 16042, 16089, 16144, 16207, 16290, 16356, 16424, 16485, 16557, 16632, 16683, 16763, 16851, 16913, 16987, 17041, 17119, 17185, 17257, 17313, 17393, 17455, 17520, 17580, 17632, 17701, 17758, 17821, 17895, 17967, 18036, 18120, 18182, 18249, 18305, 18372, 18449, 18516, 18580, 18649, 18711, 18775, 18828, 18900, 18944, 19011, 19057, 19135, 19196, 19252, 19330, 19400, 19465, 19531, 19591, 19657, 19697, 19742, 19768, 19791, 19807, 19819, 19825, 19833, 19842, 19842, 19857, 19866, 19872, 19884, 19887, 19901, 19899, 19912, 19909, 19922, 19928, 19929, 19937, 19938, 19936, 19939, 19951, 19959, 19958, 19962, 19961, 19972, 19973, 19974, 19983, 19988)

    plot(time,score,type=""l"")


Here's my problem. I would like to have the derivative of this line. I've searched for the problem but most people suggest solutions where there is a derivative of a *function*. However, I'm not working with functions but with raw data. Is my problem solvable? I'm currently lost on what to do so help would be appreciated.",[Help] I have a line graph and want to have the derivative of that line,7pq1tt,new
"The standard R function 'sort' is about as twice as fast as a very fast Haskell sort function (for 10 000 ints in the range from 1 to 1000).

In which language is that sort function implemented? In C or fortran? ",In which language is the R function 'sort' implemented?,7poodx,new
"Hey all!! 
I'm sure this is old news here but I've been using it and it's solved a few of my problems with generating combined plots and, like a Jehovah's witness, I wanted to spread the good news.  The package ""patchwork"" allows you to combine multiple ggplots as simple as adding then together like a + b + c. 
Here's a link. It works phenomenally and resizes each chart to be the same by default even if theres a legend, unlike the grid extra package. 

https://github.com/thomasp85/patchwork/tree/master/R",Patchwork package,7pieqc,new
"I'm looking to make a raster file from a list of longitude and latitude coordinates. I have a world oceans raster that I'd like to project to but it just isn't working. I can get the points to plot but when I create the raster I run into issues, I'm probably missing something simple.

oceans <- raster(""oceans.tif"")

pts <- read.csv(""pts.csv"")

coordinates(pts) <- ~longitude+latitude #its labelled as this in the csv rather than x and y

proj4string(pts) <- proj4string(ocean) #i have tried this both with and without proj4string with no luck

r <- raster(pts)","Long, lat csv to raster",7phzbd,new
"I really want to learn ggplot2 and need to have the tidyverse package for that. I have tried installing tidyverse many different times and then loading the tidyverse library but it has never worked. The packing installs, but it doesn't install everything it's supposed to. I get 'tidyr' but not 'tidyverse.' [Here is a screenshot](https://imgur.com/a/5lJTu) of what I am seeing. I am assuming the fact that there is a FALSE for the ""needs_compilation"" column is the problem, but I don't get what that is. 

I just updated my R studio to the latest version and this is still an issue, so please help :) I really need to learn this stuff but can't without access to tidyverse.

If it makes a difference, I am using a work computer so that it probably has strict security on it.",PLEASE HELP! Why won't tidyverse install or load in R for me?!,7pg4dz,new
"For example, the following places each replicate into a separate column

`data <- replicate(20, rnorm(10,10,1)`

Same thing with 'apply': 

`samples <- apply(t(data), 1, function (x) sample(x, 5, replace = FALSE))`

Unless I transpose the result, the samples will be placed in columns. Is there any way to change the behaviour of 'replicate()' and 'apply()' to place data into rows without 't()'?
",Why do 'replicate' and 'apply' put results into matrix columns rather than rows?,7pdrom,new
"I'm trying to create a simple dot plot from a vector of numbers that looks like this: https://i.imgur.com/3LZITNm.png

However, mine looks like this: https://i.imgur.com/5QJrqsa.png


Is there a way to squish it down?  I'm not sure what it's trying to show with the vertical axis of the graph.  This is my vector, by the way: (18.76,21.31,20.60,21.79,19.36,22.31,20.08,23.53,       19.39,20.65,18.89,20.38,22.95,22.97,19.25,21.76,      22.06,19.87,18.06,21.19)

I'm very new to R, but I've already spent way too long looking for a way to do this.  Help is appreciated!",Simple dot plot (how to remove height?),7pbgz2,new
"Hi all! I am having an issue with the aggregate function that I could really use help with!

so my data is a spreadsheet of parts ordered for the past few months. the parts are notated by VPN, the problem is that they were further subdivided based on what warehouse they were going to. 

VPN	               dec17	     nov17	         oct17	sept17
00AY240-AO				
00AY240-AO				
00AY240-AO				
00AY240-AO				
00AY240-AO				
00AY764-AO				
00AY764-AO				
00AY764-AO				
00AY764-AO				
00AY764-AO				

there's numbers in those spaces but i didn't think i should put our internal info on the internet, apologies, i know this makes it harder to help.

so as you can see i now have several entries of the same part type. i need to aggregate these parts into just one entry and then sum up the different entries made in the same month.

I've tried using the aggregate function which has gotten half the job done. it aggregates the parts but i can't get it to sum up the columns by VPN.

This is the code i'm using on RStudio:
ahastyexperiment <- aggregate(. ~ VPN, book3, FUN = function(sumMonths){sum(book3$nov17, book3$dec17, book3$oct17, book3$sept17, book3$aug17)})

it probably has to do with my function but i'm just not good enough to know exactly how to fix it. 

any help at all is greatly appreciated!",Help with the aggregate function,7paplc,new
"Hi guys, 

I'm trying to make a heatmap of some correlations and have been playing around with some of the scripts found here:
https://rstudio-pubs-static.s3.amazonaws.com/240657_5157ff98e8204c358b2118fa69162e18.html

I'd like to make a plot which shows the correlation coefficient, but leaves the insignificant correlations blank.

I've make this:
cor_5<-rcorr(as.matrix(mtcars)) # using mtcars example data
M<-cor_5$r
p_mat<-cor_5$P

corrplot(M, type = ""upper"", 
         p.mat = p_mat, sig.level = 0.05, insig = ""blank"", #remove correlations at p-value significance level
         addCoef.col = ""black"")  # Add coefficient of correlation

This is a pretty trimmed back removing the nice looking bits, easy to add. The problem is, it removes the colour from the plot for insignificant correlations(which I want), and it adds the coefficient on (which I want) but it also adds the coefficient to the blank, insignificant, correlations (which I don't want). How can I get rid of these?

I'm hoping it's a simple one-liner.

Cheers guys.





",correlation heatmap with coefficient and insignificant blank,7p0aoi,new
"Hi,

I don't know R very well and I have a one-time assignment I need help with. I have a [spreadsheet of voting results in the 2016 Democratic primaries](https://docs.google.com/spreadsheets/d/1WXo8o3dOV7LC0zOjYggrzc7IkgbdXKBNZD1CcH11efI/edit?usp=sharing). I need to make a bar graph displaying Sanders's average performance by type of election (primary or caucus). 

This is what I have:

> > Primary2016$SandersPercent = (Primary2016$Sanders / (Primary2016$Sanders + Primary2016$Clinton)) * 100

> > library(ggplot2)

> > Primaries = Primary2016[which(Primary2016$Type == ""Primary""),]

> > Caucuses = Primary2016[which(Primary2016$Type == ""Caucus""),]

And then I'm not really sure what to do. I've been playing with:

> > ggplot() + geom_col(Primaries, aes(y=SandersPercent, x=Type)) + geom_col(Caucuses, aes(y=SandersPercent, x=Type))

But it hasn't been working...I've been getting an incorrect result or the following errors:

> > Error: stat_count() must not be used with a y aesthetic.

> > Error: ggplot2 doesn't know how to deal with data of class uneval

Thanks for your help!",Help with quick bar graph in R,7otgug,new
"Dear people of R!

I need your help. I am planning to do an interactive ebook for learning statistics and it would be really convenient if I could do it using R. I need advice on which tools would be best for a task like that. I have used Sweave before, but I can't do interactive plots with it, so that's a problem. I am not very familiar with Shiny, but as far as I know, it's main purpose is putting R on web, which could be an option, but let's call it Plan B.

What other options do I have? What have you used, do you have any suggestions for me?

Any help will be appreciated!",Tools for an interactive ebook with R,7oq9c8,new
"I’m helping a friend with his homework, and I took stats this summer but forgot most of it. The question is asking: Write code to obtain 10000 realizations (data points) of the random variable X+ Y
X is a random variable distributed according to a standard normal distribution
Y is a random variable distributed according to a uniform distribution on [0,1]
I’m thinking maybe they want a data frame to hold 10000 values of X and Y using rnorm and runif ",Homework question?,7ooyjy,new
"Keep getting this error message when running ""library(Rcmdr)""

Error: package or namespace load failed for ‘Rcmdr’:
 .onLoad failed in loadNamespace() for 'Rcmdr', details:
  call: structure(.External(.C_dotTclObjv, objv), class = ""tclObj"")
  error: [tcl] invalid command name ""tk_messageBox"".

Any help is appreciated, I am new to this as its required for a class.",Help! Can't run R commander on Mac OS High Sierra (10.13.2),7on73z,new
"Hello there!

I am a complete newbie in terms of R, with some overall knowledge of statistics. I am currently working on a project drawing on the ESS8 dataset (http://www.europeansocialsurvey.org). For those of you who don't know, this is an open and free to use dataset based on surveys in several European countries. 

Let me get to the case: As I have been fiddling and learning R the last few weeks, I have learned to visualise using ggplot2, but I am having problems visualising the data from the ESS8 dataset, because it is stored as factors. Every respondent has a unique ID, and they rate various questions between for instance ""Not at all"" by 2-9, and ""Absolutely"", meaning the factors contain both ""integers"" (not really in R, but) and strings. This is a headache, from my perspective, since calculating a simple mean is hard, and visualising it is even harder.

Anyone know how to do that? I mean, every factors does have a number attached to it somehow, but I am not sure whether one can access the data by referring to those numbers. 

Anyone words of advice? ",Visualisation and factors,7ojyp8,new
"While studying ROC curves, I came across the idea of misclassification costs and prior probabilities. ROC tells us about the sensitivity and speficity, while not considering the cost and priors. I wanted to know, if there is a way that we can combine both cost and priors, or consider them jointly in our ROC curve?


Thank you",Costs and Priors with ROC Curves,7ofeov,new
"Some of my R code is infuriating me - I'm attempting to select words out of a large column of words and store them in a vector, but they are somehow becoming numbers by the time I'm finished looping and print out the vector's contents. 

Here's the relevant bit of code:

    # Function definition
    find_terms_for_current_prefix <- function(DF, prefix_to_match){
    vec_matched_terms <- vector()
    vec_matched_freqs <- vector()
    prefix_length <- nchar(prefix_to_match)
  
   
    # Scan through current data frame of terms and their frequencies:

    for(i in 1:nrow(DF)){
    # Determine the start of the current term in the data frame:
    current_prefix <- substr(DF[i, 1], 1, prefix_length)
    
    # If the start of the current term in the data frame matches the prefix:
    if(current_prefix == prefix_to_match){
      vec_matched_terms <- c(vec_matched_terms, DF[i, 1]) 
      vec_matched_freqs <- c(vec_matched_freqs, DF[i, 2]) 

      print(paste(""^^^ PREFIX MATCHED TO A TERM!!!!!: "", DF[i, 1]))
    }
    }

    print(""inside find_terms_for_current_prefix: head(vec_matched_terms):"")
    print(head(vec_matched_terms))
    
    df_prefix <- data.frame()
    df_prefix <- cbind(vec_matched_terms, vec_matched_freqs)

    df_prefix  
    }


The important part is inside the if-statement:

    print(paste(""^^^ PREFIX MATCHED TO A TERM!!!!!: "", DF[i, 1]))

That line of code prints out the word I'd expect to see - right after it has supposedly been added to vec_matched_terms. However, immediately after that for-loop, when I do

        print(head(vec_matched_terms))

I find that vec_matched_terms contains numbers rather than the expected words. Numbers that do not exist anywhere in the column of words.

What's even more maddening is that this doesn't happen if I pass a different data frame (one that the current one is a subset of) to this function.

What is going on here? ",Words inexplicably becoming numbers and causing problems?,7oe7cc,new
"Hello,

I've just started working with decision trees using R. I could not understand one concept with regard to trees. If I have 2 or more input variables which are highly correlated, how does R deal with them while growing trees?
Also, what do trees do if I have a variable in which all the values are the same?

Any help with these queries is appreciated.

Thank you",Understanding correlation in R,7o5ss4,new
"I've been using the table function to create frequency charts. However, with each column, a number of entries are spelled the same way but with the first letter capitalized.

When I use the table function, it treats these as separate groups. I'm aware of tolower; however, I have a large number of columns, plus the final data frame will look less professional if it is in all lower case.

This is why I'm simply looking for a way to create a frequency chart that ignores letter casing.",Is there a way to make a frequency table that is case insensitive?,7nytd7,new
"Hi everyone,

Just getting into stats, go easy on me.
I'm having problems with the values I am obtaining from shapiro-wilk test from statgraphics and R.

DSstack <- data.frame (""Samples"" = c(14837.288,
13916.173,
13511.358,
13574.06,
12966.612,
12810.408,
14808.713,
14565.446,
14413.504,
14287.306,
13217.298,
14468.81,
15854.957,
15375.769,
15279.526,
15478.065,
14853.356,
15582.586,
14704.742,
14160.951,
14364.272,
14736.435,
13574.946,
13624.038))

shapiro.test(DSstack$Samples)

The values I've obtained from R was 

Shapiro-Wilk normality test
data:  DSstack$Values
W = 0.97224, p-value = 0.7225

The values I obtained from Statgraphics were

Shapiro-Wilk 
W= 0.971592,  p-value =  0.704232

If anyone has any idea why this could happen it would be greatly appreciated. I would also like to know if the difference have any significance or negligible. This question is strictly for why there is a difference in the values and not the necessity of performing normality tests. I would try it in SAS but I don't have access to that.

tldr. Shapiro-wilk test giving different values for R and statgraphics.

",Shapiro-Wilk test Statgraphics and R,7nmyup,new
"What I want to do is print a variable using the paste() function, the reason is that I have created my variables and I have to write a line which fetches the values of a variable using a pattern. For example the line:

    paste(""x."",v1,sep = """")
 
prints out

    [1] ""x.v1"" 

which is a character variable, but I want to do is print(x.v1) which prints out the value of the variable x.v1 instead of the character variable with the value ""x.v1"". 

If that is too complicated, a simpler way to put it is to automate the print() function based of a variable which changes based on a decision making algorithm and a couple of variables.",Fetching variables,7mumv0,new
"Hi there, I am fairly new to R so I would have a question about conditional statements if anyone can help as I am really not able to solve it. 

I would need to create a new column in my dataframe assigning a value to a group of cases based on multiple conditions. I am looking to categorise an entire week (i.e. all Dates within the week) based on the Holiday day the week included. So if there was a Holiday on Monday, the entire week would be defined as MondayHoliday week in the new column. The data I have is structured by date and each date has values for the Week_ID (unique ID for a whole week, eg. 01, 02, 03 etc..); Day (eg. Monday, Tuesday etc...); Type of Day (if day was ""Normal"" or ""Holiday""); Type of Week (defines if week included a holiday day or not, ""Normal"" or ""Holiday"" week)

At this Point, my major issue is in applying the same value to the entire week (all Dates within the week) based on multiple conditions...Any hints or pointers would be much appreciated! :)
",Multiple conditionals for Groups based on value,7mtb1d,new
"I have a data frame, and I want to delete all rows if the value of a specific column is zero. What is the easiest way to do that??? Thanks in advance",Delete entire row if column contains zero,7mo56h,new
"My aim is to create a reactive shiny leaflet app based on two user inputs: income and percentage willing to save per year in order to render a new map that would tell them how many years they would need to save in order to buy a dwelling in that area. I already have a column in my dataset for years needed to save, but I'd like to overwrite that with the new user inputs.

I'm having a problem joining the user inputs to my out map. Any suggestions would be greatly appreciated :)

UI:

ui <-tabsetPanel(
    tabPanel(""Application"",fluidPage(theme = ""bootstrap.css"",

 h1(""2016 Housing Landscape"",  align = ""center""),

leafletOutput(""map1"", height = ""600px"", width = ""100%""),
h3(""Here I've mapped out blah blah blah""),
  #gimme a title
  absolutePanel(id = ""controls"", class = ""panel panel-default"", fixed = TRUE,
                draggable = TRUE, top = 60, left = 20, right = 20, bottom = ""auto"",
                width = 330, height = ""auto"", style='padding:15px',

                numericInput(""num1"",h3(""Income""), value = 0),
                numericInput(""num2"",h3(""% Willing to Save per Year""), value = 0),
                actionButton(""recalc"", ""Go!""),
                #gimme a drop down to select variables from the shapefile 
                #boundaries dataset
                selectInput(""variable"", ""Variable"",
                            names(CTVan16@data)[11:15]),
                #gimme some colour options from colourbrewer
                #selectInput(""colourbrewerpalette"", ""Color Scheme"",
                           # rownames(subset(brewer.pal.info, category %in% c(""seq"", ""div"")))
                #),
                selectInput(""classIntStyle"", ""Interval Style"",
                            c(""Jenks Natural Breaks"" = ""jenks"",
                              ""Quantile"" = ""quantile"",
                              ""Equal Interval"" = ""equal"",
                              ""Pretty"" = ""pretty""))



      )
    )
)


server <- function(input, output, session){

  yrsav <- function(income,pct_save,mean_dwelling_cost){
    downpayment <- 0
    if(mean_dwelling_cost <= 500000) downpayment <- 0.05
    else if(mean_dwelling_cost <= 999999) downpayment <- 0.1
    else downpayment <- 0.2
    dec_save <- pct_save/100
    return ((mean_dwelling_cost * (dec_save+downpayment))/income)
  }

  #2016  

  points <- eventReactive(input$recalc, {

    i <- 0
    for(i in (c(1:length(CTVan16@data$Average.Dwelling.Cost)))){
      CTVan16@data$Years.Needed.to.Save[i] <- yrsav(input$num1,input$num2,CTVan16@data$Average.Dwelling.Cost[i])
    }

    }, ignoreNULL = FALSE)

  output$map1 <- renderLeaflet({
    leaflet(CTVan16) %>% addProviderTiles(""CartoDB.Positron"") %>%
      setView(-123.116226, 49.246292, zoom = 10) %>%
        addPolygons(data = points(),
                    stroke = F, 
                    fillOpacity = 0.5,
                    smoothFactor = 0.5,
                    opacity = 1,
                    fillColor = ""white"")
  })",How to create a shiny reactive leaflet map with for loop?,7mgow0,new
"I made [a curated list of awesome Shiny Apps for statistics \(ASAS\)](https://github.com/huyingjie/Awesome-shiny-apps-for-statistics). 

The goal is to 
1. help teachers teach basic statistics to their students.
2. help self-learners to visualize statistics concepts.

I hope that teachers can use this page as a reference in the coming spring semester.

 Any feedback would be appreciated!",A curated list of awesome Shiny Apps for statistics (ASAS),7mgoia,new
"I'm a SAS user trying to use R.

In SAS, a PROC SUMMARY will calculate the subtotal for every combination of classification variables, (including the grand total). The NWAY option can also limit the size of combinations. For example, I can output all combinations of 3 variables among 14 total variables, and sum something. Is there a similar function in R ?

Thanks.",Equivalent to SAS Proc Summary (i.e. subtotals for all combinations) ?,7madmo,new
I want to create a PHP application where it calls some R scripts that perform data-intensive calculations (that entail manipulating data frames) and store into a MySQL database. Then the application would pull from the database and display the computed results. What's the best way to achieve this? Should I use AWS's Elastic Beanstalk? Can I run both PHP and R scripts on EC2? ,Best way to integrate R into a PHP application???,7m9606,new
"Hi, I'm a newb. I have a data set that has daily records and I want to make a ggplot of the the values over a given month, plotting each month sequentially. For instance, if I had 100 years of data on temperatures in a given city, I'd want my x-axis to be the months, and the y axis to be the temperatures. 

My data set is a csv with two columns, date and temperature. 

My first instinct is to make a series of if statements with this data, for instance:
    jan<-select(data$month, 1)

etc for each month. But there *must* be a better way to do this. Right?",Best way to summarize data by month over a given time period,7m6uuq,new
"Hi, 

As titled, is it possible to configure RStudio such that, only script-result will be shown instead of both script commands and script-result?

The purpose to display R-output results in a more coherently readable way.

Thanks!","RStudio : how to output script-result only, without displaying the respective script commands, in console ?",7m0hsu,new
"Hey, super basic R question. 
I'm trying to (obviously) get a vector from 10 to min. 10 in steps of 1 without typing it out manually. ","Why does seq(10, -10, 1) give an error message?",7lvhjf,new
"So I want to want to save my split raster to my R environment (as compared to your working directory) for faster access and so I ran into the following  [code] (https://stackoverflow.com/questions/29784829/r-raster-package-split-image-into-multiples) from stackexchange, but ,again, I don't want the rasters to be saved in my working directory but in my ram instead, is there a way to do that?",Splitting a raster into multiple ones,7lq9vm,new
"I am a R self-learner and have grasped the basic syntaxes of R.
I learn via visiting various online R tutorial website and youtube channel. The teachings are excellent but not so complete in coverage. 

I want to gain a more in-depth learning on R.

Is there any more advanced R websites or ebook ( preferably a free one ) you can recommend? 

Thanks!

",Request for good R self-learning resources,7ln44w,new
"Hi Team,

I have yet again found myself in a position where I am calling on the power of the interwebs for help. The data I have is part numbers that are broken down into their component parts. Some of those component parts are broken down into a smaller level that is not on the next line of code, but could be found somewhere else. Using the part number ""Server"" for example, that is broken down into 3 parts: 0040204, 988018902, and CS2198. So I guess I need the code to put the top level assembly in the column to the left of the component parts that go into this assembly while keeping all other data intact. 

Please see the example code I have, this represents the input data that I receive:

    #input data
    df1 <- data.frame(PartNumber = c(""Server"", 0040204, 0040204,""Cust1"", ""Cust1"", ""Cust1""),
               SC = c(""M"", ""X"", ""X"", ""M"", ""M"", ""M""),
               ComponentNumber = c(0040204, 988019802,""CS9881"", ""M8857"", ""M8151"", ""Server""),
               SC2 = c(""X"", ""B"", ""B"", ""B"", ""B"", ""M""), 
               QtyPer = c(1, 2, 3, 4, 5, 6))

And the desired output, the code should produce an example like the below given the data I receive:

    #desired output
    df2 <- data.frame(PartNumber = c(""Server"", ""Server"", ""Server"", ""Cust1"", ""Cust1"", ""Cust1""),
               SC = c(""M"", ""M"", ""M"", ""M"", ""M"", ""M""),
               ComponentNumber = c(0040204, 988019802, ""cs9881"", ""M8557"", ""M8151"", ""Server""),
               SC2 = c(""X"", ""B"", ""B"", ""B"", ""B"", ""M""),
               QtyPer = c(1, 2, 3, 4, 5, 6))

Please ask if you need me to clarify!! Any input or pointers on how I might be able to do this would be greatly appreciated!!

Thanks in advance!

Edited for formatting, also labeled the data frames.",Trying to rearrange data into a more useful form :),7liqn4,new
"I want to get to an advanced level of skill in R. Right now I'd say I'm intermediate. I also want to add some cool projects that would look impressive on my resume.

However, I can't find or think of any project to do, even though I am aware of numerous databases on the internet. Any ideas on how I can even begin thinking about something like this? Any other words of advice?

Thanks",How can I figure out an R project to do?,7li3ls,new
"Hey all, 

so I'm an aspiring data analyst currently in college and looking to hone in my programming skills. I'm good with Python and just learned SQL, and CodeAcademy helped me with both, but I'm not finding resources to help me learn about R. 

Are there any ways I can learn R for free? Thanks in advance for responding. ","How Can I Learn R? (College Student, Help Please!)",7lfyl5,new
"My Google-fu is failing me. 

I have a segment of code that works but is far more inspired by my shell scripting days than the R universe I'm moving into. I just can't figure out an elegant way to do this in R. My problem is that I have a tar.gz file with tens of thousands of csv files. 90k is an average case. I don't have the disk space to store it ungzipped, so my goal is to process each file within the archive, while it's still archived.

What I have right now:

    MergedData<-foreach(i=1:nrow(runs), .combine=rbind.fill,.inorder=FALSE) %dopar% {
        #initializations
        asdf<-read.csv(pipe(""tar zxOf /home/chrysrobyn/foo.tar.gz job0001.csv""))
        #operations
        returnme
    }

When I kick this through 40 cores, it's a little tough on RAM.

Is there a better R way of doing this? Is there a less RAM intensive way to do this? The gunzip part seems singluarly tough on resources. I'm pretty sure uncompressing to RAM outside of %dopar% and then sending the variables to 40 threads is not going to be any more efficient.",R Style question: Reading a tar.gz with tens of thousands of csv files,7lb1d6,new
"I am writing a small webapp that shows some data.  However, recently I found that I calculated some data wrong, and that it required more computation than originally thought. No biggie, I thought, I'll just compute the values and add them to the csv file.

So here is the issue. I have a data-file and a shiny app. Originally my data file that I used had 13 columns. I then add 3 columns of values to this data file with the information that I need. I then run the shiny application, but it crashes, giving me the error in the title. This happens even if the new columns in the edited dataset are never used (in other words, without actually changing my calculation - the only thing that is changing is my dataset). If I then return to my original dataset, all is fine.

I have checked if the new code and dataset work outside of Shiny, and it works just fine.  I also have the latest version of Shiny.",Error using Shiny: [on_request_read] connection reset by peer,7la9r2,new
"I'm trying to make a perspective plots (3D plots) for a set of data that I have. I have multiple sets of data to plot and want to have the color range of all the plots be standardized. So basically the way the each plot is colored should take into account the range of z-values of all the plots.

I'm quite new to R and need some help with this so if anyone can help, it would be much appreciated.

Thanks",Standardized Color Scale Bar for Persp Plot,7l7ktn,new
I'm coming back to R after years of working in SAS where memory management isn't as much of an issue. Is there a preferred method like processing data in chunks or is there a package that handles bigger than memory data well? ,What's the current best practice for dealing with data too big to fit in memory?,7l71r7,new
"Hi fellow reddit-R usersm
it's my first time on reddit so excuse me if i say something wrong or do something wrong.... 
I have to use R for school and after I reinstalled windows I lost my files so i had to redownload R. This new version 3.4.2 if im not mistaken, does not let me execute Rcmdr. I downloaded the packages but I get this: ( i want to load Rcmdr and not Rcmdr misc) Ive been reinstalling packages and even R many times, and nothing works.I even tried downloading other versions of R ,but then the commander package doesnt work cuz its built for the newer version...
 Im a complete R noob i guess. but this is my output:

Loading required package: RcmdrMisc
Error: package or namespace load failed for ‘RcmdrMisc’:
 object ‘print.rcorr’ is not exported by 'namespace:Hmisc'
Error: package ‘RcmdrMisc’ could not be loaded

I hope someone can help me...

PS: i used to have a R.exe shortcut in my searchbar (running windows 10!) but not anymore since my computer formatted.
Thanks in advance!",Problem executing Rcmdr,7l43fi,new
"I have a template Rmd file and want to generate reports given different parameters.

My data is in a single csv file around 2.5gb but each report only requires a subset from the whole csv file.

How would you parallelise this in windows without each process having to read the whole csv?",Parallel rmarkdown reports in windows,7kzbtj,new
"I'm working on a project using social media data with a few desired key search terms.  I've already figured out how to do this with Twitter, scraping all tweets with that combination of terms, but I'd really like to be able to scrape tumblr posts with those terms.  (Text and images both, but I'll start with text if that's easier.)  Does anyone have any solutions?",Scrape data from tumblr with R?,7kz25c,new
"I'm working through R for Data Science, and put this code into my script:

flights_dt %>% 
  mutate(minute = minute(dep_time)) %>% 
  group_by(minute) %>% 
  summarize(
    avg_delay = mean(arr_delay, na.rm = TRUE),
    n = n()) %>% 
  ggplot(aes(minute, avg_delay)) +
    geom_line()

However, I get the error: Error: ggplot2 doesn't know how to deal with data of class uneval

But, when I do the code like this:

flights_dt_fixed <- flights_dt %>% 
  mutate(minute = minute(dep_time)) %>% 
  group_by(minute) %>% 
  summarize(
    avg_delay = mean(arr_delay, na.rm = TRUE),
    n = n())

ggplot(flights_dt_fixed, aes(minute, avg_delay)) +
  geom_line()

Then it works perfectly fine. This is really aggravating. What is wrong with the first line of code? How can I make these charts quickly without having to assign objects?",Can't Make a Graph from a Pipeline,7kxa56,new
Does anybody have any links to data analysis scripts that are a good examples of writing R code?,"Examples of neat, easy to follow, well formatted R project with good code?",7kue31,new
"Hi, 
Let me preface this by saying that I am a high school student who learned about the existence of R about a week ago, so I am probably using none of the right terminology here. Luckily, I do not think my problem is too complicated.

So, I am doing a math project in school on the coastline paradox. I am automating the process of using different rulers on different coastlines to find out the fractional dimension of a coastline. I used this code:
http://rspatial.org/_sources/cases/rst/2-coastline.txt  - the code is explained step by step here: http://rspatial.org/cases/rst/2-coastline.html

This one is for the UK and I wanted to do one on Iceland. After tinkering a bit with the code (basically replacing all the instances where UK was written with ISL) I was able to get a plot of Iceland's coastline with rulers of different lengths projected on to it, with the only problem being that the lengths of the rulers and the total amount of times the rulers were used was nowhere to be seen on the plot. When I used the code for the UK this all showed up. You can see what I mean here: https://imgur.com/a/VF3Qz
So, basically, I just want the text to show up on the plot like it does on the UK plot.

This is my code for Iceland: https://pastebin.com/t3zaJ0yZ

Any help is appreciated!
Thanks.

",Problem with code - coastline problem,7khqw3,new
"hello! I am new to R and to this subreddit, so I hope you'll excuse me if I'm not doing this properly.

I am writing a fairly simple function and would like to select a column of a data frame based on an argument entered by the user into the function. it looks something like this:

    function(input_column_name)
    data <- data.frame()
    data <- read.csv(""data.csv"")
    print(data$input_column_name)

Unfortunately, this is returned as NULL, not as a vector with the contents of the selected column. When I run the code on the console, using the actual column name, the code works. So there is something I'm missing when trying to use the regular $ syntax with the input variable. What do I do?

I fully recognize that I may be misusing terms here, so I'm happy to add additional clarity. Thanks!",how to index based on input arguments,7k7nb4,new
"Hi, I am University of Illinois student and I have a final project due a some time that has to be constructed solely using R. I am looking for some help regarding this language. Please DM if you think you, or know of someone, that can help.",College student looking for some help on a R coding project,7jvhro,new
"Hi guys!
So I'm new to R and I'm trying to learn it for my statistics class and I have this seemingly simple problem that I can't really figure out. I have a data frame with 3 columns and about a thousand rows and I want to extract the values from the third row as long as they meet a criterion from my second column. 
So for an example; the second column is the height of a person and the third is this person weight and what I want is a vector with the weight of every person with the height 170 cm.
Can anyone help here? It's greatly appreciated! 

I've tried Dataone<-subset(people, height == 170, weight) but this gives me a data frame (or is it called a list?) with one column with the data that I need. The problem is that I can't take some statistical measures like mean, var and so on if it's a data frame like this. Thanks!",Extract information from data frame,7joniu,new
"Hello R programmers,
I am working on my thesis and trying to save the output of a cluster analysis as a text file or csv file. Can anybody help me, i have tried all i can but no way.",I am stranded!,7j8ozg,new
"In response to [this SO question](https://stackoverflow.com/a/47759816/1003565) I wrote a function and put it into a [gist](https://gist.github.com/Dasonk/2b62e333251404d517100c3262ea19fd) that will create a callback to alert you when some summary (dim, nrow, length, etc...) changes for a specified object.

If you're heavily modifying objects and want to get notifications about what new dimensions are so you can have a spot check this might be useful for you.",Made some code to help monitor changes in objects and wanted to share,7j5mlm,new
Is there a package to create customized tables like in the tweet here : https://twitter.com/NylonCalculus/status/939165083158171648,Output customized tables,7j2jum,new
"So, I hope this is within the rules here, but if not, my apologies. I've started learning R with hopes of jumping careers out of marketing. I've never had a job that had anything to do with programming/coding/etc. I've heard from several people having a portfolio of things you've done/can do with the language are almost essential. Is this the case and what kind of things should go in there? I think I'm at a level where I can start doing this, and help reinforce what I know through practice and trial/error",Creating a portfolio,7i8yv9,new
"Working on a dynamic model and trying to streamline my bosses code. We repeatedly call the same nested loop structures: 
for(int tb=0; tb<15; tb++) { 
    for(int dr=0; dr<5; dr++) { 
      for(int tx=0; tx<2 ; tx++) { 
        for(int hv=0; hv<9 ; hv++) { 
           for(int rg=0; rg<2; rg++) {
...
}}}}}

I feel like I once saw a way to set this to its own function or something that could be called in one line as opposed to this repeated multi-lined code (it's called like this upwards of 100 times in the model). Any one have advice?",Shortcut for Calling Nested Loops?,7i6nid,new
"I'm very new to R, and I'm trying to write a function that I can't figure out, but is probably very simple. 

I have a string, and I need to extract ONLY the digits that follow a specific subset of that of that string.  For instance, if my string is: 
`smalldog123.isverycute_morewords98765` and the substring is `smalldog`, I need a function that will return the integer `123`. The substring will remain consistent in all the calls I make, so another example: `smaldog62.08f_cat` will return `62`.  Essentially I need it to find the substring `smalldog` and return all the digits that immediately follow, and stop as soon as a non-digit is found.  I've tried playing around with `stringr` but can't get it to work :/

This will be used on a string, not a list of strings.

Thanks in advance!",Beginner question - extracting specific digits from string after substring,7i6kgm,new
"This is just a conceptual question that I'm unsure of. I always thought that identical strings would get transformed into identical factors when reading in a file, however, I've just performed a small test which suggests otherwise:

    > test.df <-read.csv(""test.csv"", header = FALSE)
    > test.df
         V1    V2    V3
    1   one   two three
    2   one   one   two
    3 three three three
    > data.matrix(test.df)
         V1 V2 V3
    [1,]  1  3  1
    [2,]  1  1  2
    [3,]  2  2  1

It appears that the factors present in each row aren't equal to one another. Why is this?

Additionally, is there a way to make is so that the factors are equal?","When read.csv transforms strings to factors, do identical strings in different columns get identical factors?",7i4pw1,new
"Hello. So I'm trying to code a column of answers as either Correct, Incorrect, Don't Know, or Refused. I constructed [this function](https://imgur.com/wW1WDyS), then applied that function to a column using sapply while specifying what the correct answer is. The values are generally what I expect them to be except that the Refused values seem to code as Incorrect for some reason. Is there something obvious that I'm doing wrong? ",Code not catching a case,7i3wjh,new
"I'm creating an R package with several files in `/data`. The way one loads data in the R package is to use the `system.file()`, 

    system.file(..., package = ""base"", lib.loc = NULL, mustWork = FALSE)

The file in `/data` I would like to load into an R data.table has the extension `*.txt.gz`, `my_file.txt.gz`. How do I load this into a data.table via `read.table()` or `fread()`? 

Within the R script, I tried :

    
    #' @import data.table
    #' @export
    my_function() = function(){
    
        my_table = read.table(system.file(""data"", ""my_file.txt.gz"", package = ""FusionVizR""), header=TRUE)    
    
    }

This leads to an error via `devtools` `document()`:

    Error in read.table(system.file(""data"", ""my_file.txt.gz"", package = ""FusionVizR""), header = TRUE) (from script1.R#7) : 
      no lines available in input
    In addition: Warning message:
    In file(file, ""rt"") :
      file("""") only supports open = ""w+"" and open = ""w+b"": using the former

I appear to get the same issue via `fread()`

    #' @import data.table
    #' @export
    my_function() = function(){
    
        my_table = fread(system.file(""data"", ""my_file.txt.gz"", package = ""FusionVizR""), header=TRUE)    
    
    }

This outputs the error:

    Input is either empty or fully whitespace after the skip or autostart. Run again with verbose=TRUE.

So, it appears that `system.file()` doesn't give an object to the file which I could load into an R data.table. How do I do this? 
",R package: read in data via system.file() and read.table() from R data.table,7i2xox,new
"I have the following 2 matrices, 

A = rbind(
  c(1,2,3,-1,0,0),
  c(2,1,-1,0,-1,0),
  c(0,0,1,0,0,-1)
)


b = c(10,20,4)

where I am trying to solve Ax = b.

If I try to solve it using qr.solve(A,b), I get 

16.666667 -9.333333  4.000000  0.000000  0.000000  0.000000.

However, for this particular problem, I need to obtain a positive solution, for example, like x = (30,5,15,75,30,11), but it can be anything, as long as each element is positive.

Thanks!",Solving system of equations?,7i1psq,new
"I would like to interact with [StatsD!](https://github.com/etsy/statsd/blob/02eae13e67056f42f87bba1e671469c7807fb08b/README.md) from R.  

StatsD is...

> A network daemon that...listens for statistics...sent over UDP or TCP
  
It accepts data in a certain format:
> The basic line protocol expects metrics to be sent in the format:

>    <metricname>:<value>|<type>

From a Linux command line you can send a line like this:

    echo ""foo:1|c"" | nc -u -w0 127.0.0.1 8125

In Python you can send a line like this:

    import socket
    soc = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    soc.sendto(""foo:1|c"", (""localhost"", 8125))

I'm really looking for an R equivalent of the Python method, rather than making a direct call to R's [`system()`!](https://stat.ethz.ch/R-manual/R-devel/library/base/html/system.html) function.  My search-foo may be off, but I haven't found a way good way to do this from R.  Can anyone show me an example of how you might go about this in R?  Or is this something you can't really do from R?",How to interact with statsd from R?,7hv3ur,new
"I have [a data frame column](https://puu.sh/yAigt/31d5ad2220.png) that I formatted to date/time with:  

░test1$filenames <- as.POSIXct(test1$filenames, format=""%Y-%m-%d %H:%M"")  

Is there a way to check for and list out any contiguity issues (i.e. missing hours)? The column is 30,000+ hours of data.",Check contiguity of date/time column?,7huymc,new
"I've created a t-SNE plot of the top 10,000 subreddits from reddit data extracted for January of this year. [The plot can be seen here](https://i.imgur.com/ssKtRbj.png).

t-SNE was performed using the tsne() function from the package ""tsne"", and I plotted the returned result with the base function plot(). This plot is good because you can see that there are distinct clusters of subreddits found in the data. However, as I have it now, that's really all one can take away from this graph, there is no way to see what sorts of subreddits comprise each cluster.

My first idea was to color code each point according to some predefined labeling system which would be independent from each cluster. However, I'm not sure how to implement this, so I'm not actively pursuing this idea.

My second idea, which I feel is much more doable, is to present the data in an interactive way. I think it would be cool to be able to hover a point to see a description of the subreddit's name and maybe some other cool characteristics like the number of comments in that subreddit. However, I don't have any experience working with such a package.

Does a package exist which allows interactive plotting? Would this be a good way to visualize my data?",Interactive plotting for t-SNE?,7hsj7a,new
"Sorry about formatting, I'm on mobile.

I have daily data spanning about 13 years of objects and their stati. For example, on Day X, Object1 is in Status Q, on Day X+1, Object1 is in Status Y, etc, for about 60 different objects. Status and Object are both of class character and Date is Date class.

I've been trying to plot this where the x-axis is Dates, the y-axis is Objects, and the fill is based on the Status on that day. I haven't had any success McGyvering ggplot2::geom_rect(), but I have had some success with ggplot2::geom_bar():

    pl  <- ggplot(data) +

        geom_bar(aes(x = Date, y = Object, fill = Status), stat = ""identity"") +

        scale_fill_manual(values = statuscolors) +

        scale_x_date(date_breaks = ""24 months"", date_minor_breaks = ""12 months"")

    print(pl)

The problem is, the Object labels on the y-axis are all clustered towards the bottom of the page and  seems not to be in the same order as the data is plotted on the chart. Also, some of the data is chopped off in the left and right edges and it's all overlapping. I feel like I'm overlooking something simple. Is there an easier way to get this type of chart?",Is there a way to make a horizontal bar chart of non-numeric data over time?,7hrwrj,new
"Hi,
I'm looking for some direction on a clean easy way to pull longitude and latitude for business names, city, state, and zip. Ideally something like Google maps API.

I have come across some resources, but they are either outdated, or ways to get avoid getting an google API key. 

If you know of a full proof method (lol @this question) please let me know. ",Batch geocoding help,7hqbzv,new
"Hi,
I have data in each row containing multiple pairs of x-y coordinates. For instance, Participant 1 has the values, x-1, y-1, x-2, y-2, x-3, and y-3. 

Example: Participant 1, x-1, y-1, x-2, y-2, x-3, y-3, other data fields
  
I'd like to convert this row/observation into multiple rows, so that each row has only one pair of x-y values. So in the new dataset, participant 1 would have three rows: 
Participant 1, x-1, y-1, other data fields
Participant 1, x-2, y-2, other data fields
Participant 1, x-3, y-3, other data fields

Doing this manually would be a nightmare. Any suggests to user TidyVerse or any other approaches in R?",Forming new rows from multiple columns,7hjj3q,new
"Hi all, 

I have a dataframe, most columns are numbers but there are a few with words and some individual cells with ""."", which I assume is ""NoData"".

I'm trying to loop through the entire dataset, performing pearsons correlation between each and every dataset.

Please could someone advise me on how to do this?

After searching every link on google, I can't seem to get it to work. 

I'm getting desperate lol.

Thankyou guys, it really is appreciated!

","loop through dataframe, performing pearsons correlation",7hjf97,new
"I have a dataset about incomes from various countries, and I need to fit various distributions for each country (32 in total).

    couh = function(x){
    subset(hfile, HB020==x)}
This is the function that I wrote, from which I obtain the data for a single country. For example couh(""IT"") will give me the dataset (13 variables in total) relative to Italy.

With the single line:

    fitdistr(couh(""IT"")$HX090, ""gamma"" )
I obtain the result for the single country for the variable HX090.

Therefore I wrote down this:

    country=c(""AT"", ""BE"", ""BG"", ""CH"", ""CY"", ""CZ"", ""DE"", ""DK"",   
          ""EE"", ""EL"", ""ES"", ""FI"", ""FR"", ""HR"", ""HU"", ""IE"",    
          ""IS"", ""IT"", ""LT"", ""LU"", ""LV"", ""MT"", ""NL"", ""NO"", ""PL"", ""PT"",
          ""RO"", ""RS"", ""SE"", ""SI"", ""SK"", ""UK"" ) #vector of countries

    for (i in 1:32) {
    gamma_HX090[i] <- fitdistr( couh(country[i])$HX090 , ""gamma"")}

If I analyze the vector, what I got is:

    gamma_HX090[1]
    $estimate
    shape      rate 
    2.9428002 0.1188236 


    gamma_HX090[2]
    $method
    shape      rate 
    4.0833994 0.1789531 


    gamma_HX090[3]
    $sd
    shape      rate 
    2.5242069 0.7944228 


    gamma_HX090[4]
    $cor
     shape       rate 
    3.47468759 0.07417582 

And so on until 32. Basically the vector contains the information about the parameters, but not about things that I am interested in (like sd and loglik).

What can I do to in order to have all these informations in a single object (or multiple object in one step)?",Using fitdistr() routine for multiple factors in a single dataset in R,7hjb6a,new
"Hi. Im doing an online course of R and I need to read an excel that is in the page. I downloaded it and saved it as csv. Then i put the same directory where I saved it in R and when i try to read it, gives me an error
> read.csv(""datos.csv"")
Error in file(file, ""rt"") : cannot open the connection
In addition: Warning message:
In file(file, ""rt"") :
  cannot open file 'datos.csv': No such file or directory

If it can help for something im using Rstudio and im from Spain. Thanks a lot",Problem reading csv. A bit urgent,7hbn5o,new
"Hi,

I would like a function that returns my own custom error message when connection to a mysql database fails.

Here is my code


library(dbConnect)

ConnectToDb <- function(a,b,c,d) {
  
  con <- dbConnect(MySQL(), user = a, password = b, dbname = c, host = d)
  
}

ConnectToDb(""root"", ""password"", ""databasename"", ""localhost"")

I would like it to say print ""Connection made"" if the connection is successful and ""Please confirm your login details"" if one input is wrong for example.

Right now R returns ""Error in .local(drv, ...) : 
  Failed to connect to database: Error: Access denied for user 'root'@'localhost' (using password: YES) "" if i enter a wrong password.

Can someone write that for me?

Ty",Error handling while connecting to MySql Database,7hagg1,new
"I'm new to loops but I'm hoping they can help me manipulate my data into a better structure.  

I've imported several .csv files via:  

░setwd(""H:/r_data_compile_test/csv/"")  

░temp = list.files(pattern=""*.csv"")  

░for (i in 1:length(temp)) assign(temp[i], read.csv(temp[i],sep="";""))  

I'd like to order each [stored object](https://puu.sh/yyldW/e8ea7c949f.png) by a column named 'Solar.System.ID', and then pull a column named 'Faction.ID' from each into a new data frame (i.e. some sort of ncol+1 loop). The ordering ensures that all the row data will match up correctly in the new data frame.  

[This is an example of doing it manually](https://pastebin.com/raw/YRTBdFkB), and [this is what the data frame ends up looking like](https://puu.sh/yyoNe/f041a40aa6.png).  

EDIT: [This code](https://pastebin.com/raw/fKb8RG9T) nearly accomplishes what I'm seeking, but how would I add a gsub line in to remove 'systems_'; remove the '.######.csv'; and turn the characters - and _ into . in the row.names?",Loop to order data frames and pull same column from each into new data frame?,7h8lck,new
"I have a dataframe called J2012Full where two of the rows (row 1611 and row 1420) have NAs in all of the relevant positions. I want to remove these rows because it is making my analysis not work properly, so I run these commands: 

J2012Full <- J2012Full[-1420, ]

J2012Full <- J2012Full[-1611, ]

I don't get an error message when I execute these commands, but these rows are still present in the data set. I can't just do na.omit on the whole dataframe because almost every data row has an NA at least somewhere; it's just that I am only using a small number of the columns, so the NAs in the other rows aren't important. 

Is there something obvious I'm missing? Is there another way to do this besides that method? Some of the other rows with NA values WERE successfully removed using that method, so I don't know what makes these two different.",Rows not being removed,7h5oj2,new
"None of the diagnostics are being displayed, even though I enabled all of them in the global options. Running 3.4.2. Why is this happening?

EDIT: Resolved. Diagnostics didn't work until I saved the project as a file. Interesting.",No Diagnostics in RStudio Script Editor?,7h0fxj,new
"hello, i am completly new to R and programming. It would be very helpful for me if someone can recommend me good and very complex tutorial on R. i have tried tutorial on udemy but it is rather short and shallow.",complex guide for learning R,7gxord,new
"Hi

I am having a problem with my code. I am trying to find solutions to the problem a/b + c/d + e/f = 0 and a/b * 1 + c/d * 2 + e/f * 3 = 2.5 for given a/b.

When a/b = 1/5, my code comes up with c/d = 1/10 and e/f = 7/10. Which is satisfies both my requirements since 1/5 + 1/10 + 7/10 = 1 and 1/5 * 1 + 1/10 * 2 + 7/10 * 3 = 2.5.

But when i check wether the last statement is true, my code returns a false.

               if(a/b + c/d + e/f == 1){
                        if(a/b * 1 + c/d * 2 + e/f * 3 == 2.5){
                                print(""= 2.5"")
                        }
                        else{
                                print(""!= 2.5"")
                        }
               }

a = 1, b = 5, c = 1, d = 10, e = 7, f = 10

Should I use some strange constructions like converting the answers to a string first and then comparing them?

Thanks very much!


UPDATE: using toString() on both sides of the == works. But that is a very ugly fix.",2.5 != 2.5? my if statement fails.,7gtqh5,new
"Hi,

I have two data frames: airports and routes

I want to lookup the country in which each airport is based:

See the columns for airports and routes below

    Airports:
    Airport ID Airport Name City Country IATA ICAO Lat Long

    Routes:
    Airline ID Airline Identifier Source Airport IATA Source Airport ID source_country Destination Airport IATA

Essentially I want to fill source_country in routes with the country column from airports. I have tried the following to no avail: Note that I have used IATA for the matches since it is in both data frames

    routes_clean$source_country<-(lookup(airports_clean$Country),with[match(routes_clean$`Source Airport IATA`, airports_clean$IATA)])

Appreciate any tips or advice.

e_conomics",Issue with lookup,7giumb,new
"So I've broken something, and it doesn't seem to be the generic R calls, but something else. 

I'm using package network, and it has a built in 'get.neighborhood' function. 

I create an adjacency matrix, make a network from it, and try to run get.neighborhood(nw, 1) and get an error message. 

* num_rows<-log10(100)

* adjacency.matrix<-create.ring.network(num_rows)

* nw<-matrix(adjacency.matrix, directed = FALSE)

* get.neighborhood(nw, 1, type = ""combined"")


**Error in get.neighborhood(nw, 1, type = ""combined"") : 
  object 'getNeighborhood_R' not found**


Edit: nevermind, what happened was I created some sort of local get.neighborhood function rather than the one that was built in. This happened by using fix(get.neighborhood) or something. I only noticed because when I went back to install the packages one by one, I noticed a message that said, ""get.neighborhood is masked in '.GlobalEnv'","In package network, in function get.neighborhood, suddenly getting error 'getNeighborhood_R not found'",7gatco,new
"I have some C code in my R package which I place into `/src`. It compiles correctly and works. 

Following the tutorial on creating R packages http://r-pkgs.had.co.nz/src.html#src

and how to execute C functions via `.Call()`.

The shared object `sharedobj.so` is created upon compilation of the C code. It is located here: 

    /my/path/to/package/src/build/haredobj.so

So, I would like to test the function in R using `.Call()`. Within R, I run  the following


    > dyn.load(""/my/path/to/package/src/build/haredobj.so"")

which outputs the error: 

    Error in dyn.load(""/my/path/to/package/src/build/haredobj.so"") : 
      unable to load shared object '/my/path/to/package/src/build/haredobj.so':
      /my/path/to/package/src/build/haredobj.so: cannot dynamically load executable

So that doesn't work. I then try `library.dynam()`:

    > library.dynam(""haredobj.so"", package=""AwesomePackage"", lib.loc = ""/my/path/to/package/src/build/"")
    Error in find.package(package, lib.loc, verbose = verbose) : 
      there is no package called ‘AwesomePackage’

That's odd, because I can load `library(AwesomePackage)` and execute commands. 

What am I doing wrong?

",dyn.load() and library.dynam() error for compiled C in R package: cannot dynamically load executable,7g9s6u,new
"Hello,

I'm trying to add regression line equations & R2 values onto my graphs. Half a year ago, I've used [this code presented in Stackoverflow](https://stackoverflow.com/questions/7549694/adding-regression-line-equation-and-r2-on-graph) succesfully. However, it isn't working anymore, and I get the following error message:

     Error in as.data.frame.default(data) : 
     cannot coerce class """"lm"""" to a data.frame 

I used this line in ggplot2 to present the regression line in equation. Using simply lm_eqn(lm(a~b, df)) isn't working either.

      annotate(""text"", Inf,Inf,hjust=1.1,vjust=1.5, label = lm_eqn(lm(spc ~ H.cwd)), 
      colour=""black"", size = 1.7, parse=TRUE)+


Any suggestions why the lm_eqn code isn't working properly anymore? Thanks for your help in advance.

// [Here's a pic](https://i.imgur.com/P8sUKlF.jpg) of the graphs I made earlier when the code still worked",Adding Regression Line Equation and R2 on graph,7g6mm9,new
"Is it possible to have several things in a single loop?  

I know how to do a calculation on several rows of data, capture and format the summary into a single table line, and write/append the table to a .csv file. I've been repeating this code and changing the beginning/ending data rows by +1 but am hoping there is a way to loop this instead of creating a long script of nearly identical lines.  

EDIT: This is an example of one section. What I've been doing is copying and changing the numbers, but that isn't feasible now since the data has more than 30,000 rows now.  

EDIT2: I've got the loop working via having done this https://pastebin.com/raw/M7i6G84j but the problem in the outpu
https://pastebin.com/LDtnqdvP  
  
I load the mediation and purrr libraries in a separate script before this part.  

  

EDIT2: I've got the loop working via this https://pastebin.com/raw/M7i6G84j but as you can see in the resulting .csv it generates, I didn't know how to get the first column to change according to the nrows https://pastebin.com/raw/jw90Jmv9  

In this line...: 

░ Template.timelapse.table[nrow(Template.timelapse.table)+1,] <- c('Template.timelapse.1_336.Mediation',Mediation.DF[1,2],Mediation.DF[1,3],Mediation.DF[1,4],Mediation.DF[1,5],Mediation.DF[2,2],Mediation.DF[2,3],Mediation.DF[2,4],Mediation.DF[2,5],Mediation.DF[3,2],Mediation.DF[3,3],Mediation.DF[3,4],Mediation.DF[3,5],Mediation.DF[4,2],Mediation.DF[4,3],Mediation.DF[4,4],Mediation.DF[4,5])

...can I change the 

░'Template.timelapse.1_336.Mediation'

part to something like 

░'Template.timelapse.+nrow+_+nrow+x+.Mediation'

where it builds that piece using the top/bottom row numbers of the data it just used? ",Multiple functions in an R loop?,7g2sg2,new
"I am fairly new to R, I took several courses on Udemy and have been working with my own data sets in R.

Are there any good places to learn how to create an interactive dashboard?

The end goal is to be able to create a multi page interactive dashboard with some drop down filters to adjust the outputs.

I am looking for 2 things, An in-depth tutorial and second some best practices on how to organize the data and display the data for high level execs in these dashboards. 


EDIT:: is there a way to save these files as an HTML file and keep the functionality. I am trying to create an internal Dashboard that I can just place the HTML file into a network drive with out actually hosting anything. Just so a few execs can open the html file and view the outputs.",Tutorials for Creating Dashboards,7frzzf,new
"EDIT: I HAVE RESOLVED THIS PROBLEM MYSELF AND PLACED A SOLUTION IN THE COMMENTS FOR FUTURE GOOGLERS

Hi, would love to get all of your input on the best way to approach this problem. Please let me know if you have a good approach here!
Data organized as such:

X | Y
-|-
A | 20
B | 15
C | 14
D | 30
E | 54

Would like to generate a bar graph (ggPlot) comparing C (14) to the average of all of them (26.6). Any thoughts on the best approach? Thank You!","Hoping to make a Bar Chart Comparing one value vs the Average of Many, any insight?",7frzq8,new
"I want to learn r so that my classes for next semester will be easier to manage(I'll be using 2 for two of them, taking 4 classes in total). I've been doing some research but there's just so much to manage and I don't even think I installed R right on my computer!

Also, if this isn't the subreddit for this post, PLEASE LINK ME THE ONE THAT IS! I'm so tired of making posts and then people telling me this isn't the right subreddit for the post but not telling me which one would be a better fit. Drives me fucking nuts.",Would someone here be interested in being a tutor for me?,7feqla,new
"I'm undertaking some R tutorials and learning Booleans and Loops (if, else, for) but it's so difficult to just try and comprehend the right coding to do a problem like:

""find the mean of the democratic vote count of the years 2004 and 2008 in each county of Georgia from the pres dataset.""

I'm driving myself insane trying to do this, I'm even trying to dissect it on pen and paper, but it's making things to much harder to try and understand what set of code will unlock the answers.

Perhaps I am thinking about coding wrong? Perhaps I am dissecting the question incorrectly?
Perhaps I dont fully understand when I use for, if, parenthesis and brackets?

Is there a chance I can learn this well, or am I doomed to be completely overwhelmed by it all? ",Why is learning to code so difficult?,7f5axk,new
"I'm trying to estimate 4 parameters with the generalized method of moment estimation in R, using the package `gmm`. My distribution is a tempered version of the Positive Linnik.

This is what I wrote in R:


    g2 <- function(theta,x) {
    
        tau <- seq(1, 100, 10)
      x <- matrix(c(x), ncol=1)
      x_comp <- x%*%matrix(tau,nrow=1)
      emp_lap <- exp(-x_comp) 
      the_lap <- Lpar(theta,tau) 
      gt <- t(t(emp_lap) - the_lap)
      return(gt)}
    
    t0 <- c(lam = 50, del = 10, the = 0.3, gam = -0.6)
    
    print(res <- gmm(g2,it0,t0)) #it0 is my dataset


Where


    Lpar = function(theta,tau){
      
      lam <- theta[1]
      del <- theta[2]
      the <- theta[3]
      gam <- theta[4]
      
        the_lap <-  (1 - lam * del * ((the + tau) ^ gam - the^gam))^(-1 / del)
        return(c(the_lap))
       }

is the Laplace transform of my random variable. My ""empirical laplace"" is emp_lap.

If I run the code I obtain this error:

    Error in AA %*% t(X) : requires numeric/complex matrix/vector arguments
    In addition: Warning message:
    In ar.ols(x, aic = aic, order.max = order.max, na.action = na.action,  :
      model order:  1 singularities in the computation of the projection matrix results are only valid up to model order 0


Anyone knows where am I wrong??

Thanks in advance.",Use of gmm with Laplace transform in R,7f0fzx,new
"Im using column() to separate my shiny app into 2. (column(6), column(6)). I put an image at the first column(6) and it looks nice on my PC but when I use my laptop (smaller screen and reso) and open the app, some of the sentences from the second column overlap the first column. How do i make this go down or consistent for any device?",How to resize image and proper column() in Shinyapp?,7epuby,new
"Need help as my homework is due soon. cannot get this last bit. I have attempted to encode all the rules of monopoly and am not getting a logical answer. Speeding is 3 doubles in a row which results in going to 10 (Jail)

CChest has 2 cards that effect movement (1) = Jail
(2) = go

Chance has a similar pattern .


Listed is my code below:


simulate_monopoly <- function(n,d) {
  
  die1 = sample(1:d, n, replace = TRUE)
  die2 = sample(1:d, n, replace = TRUE)
  
  rolls = die1 +die2
  #Do chance and commuinity chest Sample outside of the loop
  
  position = numeric(n+1) #Store position
  position[1] = 0
  position = c(rep(0, n))
  NewPosition = c(rep(0,n))
  Chance = sample(1:16, 1, replace = TRUE)
  Chest = sample(1:10, 1, replace = TRUE)
  
  i = 1
  for (i in 1:n){
    
    NewPosition[i] = rolls[i] + position[i]
    NewPosition[i] = NewPosition[i] %% 40
    position[i+1] = NewPosition[i]
  
    if (die1[i] == die2[i] && die1[i+1] == die2[i+1] && die1[i+2] == die2[i+2]&& die1[i+3] != die2[i+3])     
    {NewPosition[i+3] = 10
    
    NewPosition[i] = rolls[i] + position[i]
    NewPosition[i] = NewPosition[i] %% 40
    position[i+1] = NewPosition[i]}

    if (NewPosition[i] == 2 || NewPosition[i] == 17 || NewPosition[i] == 33){
      
    Chest 
      
      if (Chest == 1){
        NewPosition[i+1] = 10
      }  
      else if (Chest == 2){
        NewPosition[i+1] = 0}
      else {NewPosition[i+1] = NewPosition[i]}  
    
      
    NewPosition[i+2] = rolls[i+2] + position[i+2]
    NewPosition[i+2] = NewPosition[i+2] %% 40
    position[i+3] = NewPosition[i+2]}
    
  
    if (NewPosition[i] == 7 ||NewPosition[i] == 22 || NewPosition[i] == 36){
      
      Chance
      
        if (Chance == 1){
          NewPosition[i+1] = 10}
      
        if (Chance == 2){
          NewPosition[i+1] = 0}
        if (Chance == 3){
          NewPosition[i+1] = 11
        }
        if (Chance == 4){
          NewPosition[i+1] = 24
        }
        if (Chance == 5){
          NewPosition[i+1] = 39}
        
        if (Chance == 6){
          NewPosition[i+1] = 5}
        
        if (Chance == c(7||8)){
          if (NewPosition[i] == 7){
            NewPosition[i+1] = 15
          }
          else if (NewPosition[i] == 22){
            NewPosition[i+1] = 25}
          else if (NewPosition[i] == 36){
            NewPosition[i+1] = 5
          }
        }
        if (Chance == 9){
          if (NewPosition[i] == 7 || NewPosition[i] == 36){
            NewPosition[i+1] = 12}
          else if (NewPosition[i] == 22){
            NewPosition[i+1] = 28}
        }
        if (Chance ==10){
          NewPosition[i+1] = NewPosition[i+1] - 3 
        }
      NewPosition[i+2] = rolls[i+2] + position[i+2]
      NewPosition[i+2] = NewPosition[i+2] %% 40
      position[i+3] = NewPosition[i+2]
  }  
  }
  return(NewPosition)  
  }
    
sim_10000 <- simulate_monopoly(10000,6)

barplot(table(sim_10000))



",Last minute help needed (Monopoly Simulation Problem),7ek0qs,new
"I'm trying to use the package AcceptanceSampling to use the code 

     find.plan(PRP=c(0.005, .995), CRP=c(?,?), type=""normal"")

I know:

* the density of something is required to be at least 0.65 g/cm^3 

* lots=5000

* AQL=0.01

* LTPD=0.05

What do I put in the CRP?",Acceptance Sampling Help,7ef95o,new
"I have a series of xlsx files in a folder. The files are all named Headcount (date).xlsx. I am using the below code to generate a list of dataframes for the files. I then compile it into one larger data frame for manipulation. I would like to add a column to each dataframe and have it be the date for each file.


    headcount.data.files
    headcount.data.files <- list.files(pattern = "".xlsx"")
    headcount.list <- lapply(headcount.data.files, function(x){
            y <- read_xlsx(x,skip = 1)})
    headcount.list <- lapply(headcount.list, function(x) {
            x[c(1:(nrow(x)-3)),]})                       
    #combind lists to one data frame
    headcount.df <- bind_rows(headcount.list)

    ",Importing Multiple xlsx files into a list then using part of file name to pull date into a column,7ee7gr,new
"

So if I wanted the list to be 5 in length, and have values from 0 to 3

OK : 

    0, 1, 1, 2, 3
    
Not OK (there is no 2 in the following list) : 
    
    1, 1, 2, 3, 3

Something along the lines of 

    sort( trunc( runif(amount_to_create, min=0, max=10 ) ) )

Seems to work, but I'm not sure how to ensure that I get every value within the
range

thanks
",Create a list of random integers with each value,7e08zb,new
"I am trying to standardize data into 8 characters like this 42XX0001. My data is a mix of 42XX01, 42XX855, and 42XX4444. I need to insert 0's  after the 42XX to get a total length of 8 characters. Sample data below.

    spatdat<-data.frame(""ID""=c(""42XX234"", ""42XX01"", ""42XX1"", ""42XX34"", ""42XX0234"", ""42XX1222"",""42XX45""), ""Value""=runif(7, min=0, max=100))",Standardizing data: Inserting characters into a character string.,7domvm,new
"I'm trying to generate [this](http://www.hardballtimes.com/images/uploads/stk_pct_R.png). 

My data is presented as follows:

plate_x|plate_z|calledstrike|
--:|--:|--:|
-1.438163337|2.900503544|0|
-0.521163337|2.761503544|1|
-0.842063337|0.741503544|0|
-0.090963337|3.568703544|0|
-1.194063337|2.286503544|0|
-0.988863337|3.621203544|0|
-0.382963337|3.012803544|0|
-0.784363337|3.151703544|0|

(1) My first step is generating the bins that each pitch (x and z), regardless of called strike, correspond to. Because there are ~350K pitches, how would I generate 720 (30 for z, 24 for x) bins that correspond to the pitches without a million ifelse?

(2) The next step would be for the same boxes to generate when it's called a strike, and then generating the percentage, by dividing strikes  by total pitches in the zone.

(3) Finally, how would I plot the bins with percentage, and the bar on the side?

Thanks!",Binning x and y coordinates,7dnwtp,new
"So I'm trying to use rvest to scrape news articles from a website. I have little experience using R, and I'm used to urls that look like ""www.website.com/search/query/1"" this website just shows its URL as ""www.website.com/search"" regardless of query or how many pages you are into results. If I want to scrape multiple pages of results in this case what do I do?

(The website is in Chinese, but here it is for anyone curious: https://tw.appledaily.com/search)",How to use rvest on URLs without query strings?,7dj2br,new
"Hi all,

I am working on an interactive map in Leaflet right now and I'm running into an issue. My markers contain unique information of different dimensions in the popups (ie. different number of rows, custom text formatting) but I would like for them to cluster as one layer on the map. I feel like this should be a simple task but I can't find any information online that points me in the right direction. This SO post sounds identical to my issue, but unfortunately has no responses. It would be nice if I could partition markers into separate groups which would all cluster together, but I'm okay with them existing as one group. The issue is that I created each marker separately and I'm not sure how to add all the markers in one fell swoop. https://stackoverflow.com/questions/47326507/clustering-multiple-layer-groups-together-in-leaflet-r

Thanks in advance for any help!",(Leaflet) Combine multiple markers into one group,7di09w,new
"Hi, I am creating a small Rshiny app that reads in a csv file, does some simple processing of the data in the file then returns the results as a csv file with the same name as the user submitted file. But I cannot figure out how the downloadHandler function works. Can someone tell me what am I doing wrong in this code

    library(shiny)
    
    doprocessing <- function(wb){
      #some code here to modify wb
      return(wb)
    }
    
    ui <- fluidPage(
      fileInput(inputId =""file"", label = ""Input a file"", multiple=F,
                buttonLabel=""Browse"", placeholder = ""No file selected""),
      actionButton(inputId = ""submit"", label = ""submit""),
      downloadButton(outputId = ""outfile"", label = "" retrieve file"")
    )
    
    server <- function(input, output, session)
    {
      worksheet <- reactiveValues()
      observeEvent(input$submit,
                   {
                     worksheet$wb <- read.csv(input$file$datapath, stringsAsFactors = F)
                     worksheet$newwb <- isolate(doprocessing(worksheet$wb))
                   })
    
      output$outfile <- downloadHandler(filename = function() {input$file$name},
                      content = function(file){write.csv(file, input$file$datapath)},
                     contentType = input$file$type)
      }
    
    shinyApp(ui = ui, server = server)                                                                        ",(Rshiny) downloadButton/downloadHandler help,7dg608,new
I have 2 separate and different size dataframes that I want to combine so that I can write them on the same excel worksheet. Is there a quick and easy way to do this without coercing the dataframes to be the same size and merging that way?,merging 2 different sized data frames for presentation,7dcgu1,new
"Does anyone know how to force R to install a local package with 'arch - x64'? I am installing a package with C++ dependencies and using mingw.

I have tried using the options --no-multiarch  and --merge-multiarch during my commandline install, but I still get R saying: 

*** arch - i386, which leads to an error

and says, ""skipping incompatible C:/PROGRA~1/R/R-34~1.2/bin/i386/R.dll when searching for -lR"".
",R Studio choose default arch during install.,7da3oy,new
"Hey guys, I'm pretty new to R. I'm currently doing an assignment for a math course where doing some simple excercises with R gives you extra credits in the class im taking. 
The bad part though is that our teacher didn't explain us anything at all about this programming language. He just gave us some scripts and told us to understand how to use them to solve some equations he gave us. Sadly I'm just not understanding how to do this intuitively so I wanted to ask for some help here by posting a few examples and I'll try to do the rest of the assignments by myself. 
The equations are the following (note: we need to solve them only graphically): https://gyazo.com/60e790b4adbef1c9067f0476ea1e345c
Thank you for the help in advance :) ","How to solve simple equations, inequalities and partial sums with R.",7d69mf,new
"I would like to count the frequency of column by groups

I would like to count frequency in this order (a,b,c,d,e) but some have no value.
Please look at the picture example for better understanding 

how can i count the input data and make the output data? currently i have been successful in counting board and alight but i cannot count variables that are not in the list.

Thanks in advance!

",Count frequency of column based on list i make by group,7cxp8m,new
"Hi guys, Im new to shiny and still learning it from [here](https://deanattali.com/blog/building-shiny-apps-tutorial/). When I try to do this to my dataset, I get an error for ggplot using xInput and yInput. I want to be able to choose which column from my dataset (filter1()) to be used as x-axis and fill(geom_bar). 

This is the plot code that get an error on server side:
    output$testPlot <- renderPlot({ggplot(filter1() , aes(x = input$xInput, fill = input$yInput))+geom_bar()})

    filter1 <- reactive({if(input$uniqueInput == 'Filter'){return(oriUnique)}
    if(input$uniqueInput == 'Not Filter'){return(ori)}})

filter1() is the dataset used after i discard all the unique first name. Here is the snippet code on UI side:
    radioButtons(""uniqueInput"", ""Filter Similar Name?"", choices = c(""Filter"",""Not Filter""),
    selected = ""Filter""),

    selectInput(inputId='xInput', label = 'x axis label', choices = c('sex','subject','occupation'))

Does the error is caused by the ggplot code or 'selectInput' cant be used to change the column of the dataset? only the instances inside the data? 

",Why does it produce error?,7cuv8n,new
"I have a data set whose data is stored as follows: 

[My data!](https://imgur.com/CJ260RR)

It goes like this until the year 2010. In other words, I have 20 years of data - 240 data points - stored as a matrix whose lines are the years and the columns are the months from January to December. 

I would like to know how to convert this data into a time series, with the first occurrence taking place in Jan. 1990, and the last in Dec. 2010. 

So far all I have found are examples of converting a data frame into a time series. However, the data frames would have a specific column which to convert. *Not in this case*. 

How can I accomplish that? Would I be able to accomplish this with either the zoo or the xls packages? 

Thanks a lot.  ",How to convert data stored in matrix-like form to time series format?,7csu59,new
"I have an extremely large sparse matrix of terms as rows and documents the terms are found in as columns. The matrix's dimensions are 48955 by 937805. Additionaly, I have a vector of 1000 terms which I want to use to filter the rows so that the new matrix will be only 1000 by 937805. For my first attempt to filter the rows I tried this:

    # Sparse matrix.
    sparse.matrix.full

    # Vector of 1000 terms.
    important.terms

    # Filtering out rows with rownames found in vector of 1000 terms
    sparse.matrix.filtered <- sparse.matrix.full[rownames(sparse.matrix.full) %in% important.terms,]

I think that this should work in theory, however, because of the large size of the sparse matrix, I get the following error:

    <sparse>[ <logic> ] : .M.sub.i.logical() maybe inefficient
    Error in asMethod(object) : 
      Cholmod error 'problem too large' at file ../Core/cholmod_dense.c, line 105

Next I tried to break the problem down and work line by line. I implemented this code to drop lines from the matrix if the rownames weren't found in the vector of important terms:

    # Getting number of rows of sparse matrix.
    sparse.matrix.full.nrow <- nrow(sparse.matrix.full)

    # Dropping sparse matrix rows which rownames not in vector of important terms.
    for (i in 1:sparse.matrix.full.nrow) {
        if (!rownames(sparse.matrix.full)[i] %in% important.terms) {
            sparse.matrix.full <- sparse.matrix.full[-i,]
        }
    }

Again, I would think that this should work. However, it doesn't behave asa expected. I would have thought that after this code was run, it would have the dimensions 1000 by 937805, when instead it had dimensions 24723 by 937805. If I run the same block of code again on the reduced matrix, the dimensions are further reduced to 12617 by 937805, then 6574 by 937805, then 3569 by 937805, then 2082 by 937805, the 1386 by 937805, then 1099 by 937805, then 1010 by 937805, and then finally 1000 by 937805.

It looks like eventually the matrix is reduced to the required dimensions, however, why doesn't the code do it fully the first time, and require the same code to be run multiple times?

Is there a better way to implement this?",Odd issues attempting to subset large sparse matrix.,7civxk,new
The estimator for generalized least squares is given by [this equation](https://wikimedia.org/api/rest_v1/media/math/render/svg/cc6def71cb9c0a746e21a3ae20b593f2aa6da1a7). What function and how should I use if I know the Ω variance matrix (as well as X and y)? Where in `lm` or `glm` should I input this?,Estimating GLS with known variance-covariance matrix,7cfsqb,new
"As part of a data set I have a location variable, and wanted to represent where these were on a map. 

I have data in this form : 
    
    > df$location[seq(1,5000,500)]
     [1] Fort Myer, Virginia                 Debrecen, Hungary                  
     [3] Territory of New Guinea             Near Las Vegas, Nevada             
     [5] Wemmershoek Mountains, South Africa Cross Bay, Russia                  
     [7] Off Cape Paterson, Australia        Zeya, Russia                       
     [9] Gauhati, India                      Near Cuito, Angola                 


I'm a bit unsure how I would go about converting something like this into longitude and latitude information in order to use as a plot though. 

I found this post : https://stackoverflow.com/a/40144196/3130747

I'm just wondering if there were any alternative approaches to this kind of thing that are worth looking into. 

Thanks",Convert location names to points for map plotting,7cffcd,new
"as the title says I am using lapply to load multiple xlsx files into R however I need to remove the last 3 rows of each sheet. Can someone help me.

code is below:

    data.files <- list.files(pattern = "".xlsx"")
    data <- lapply(data.files, function (x) read_xlsx(x, skip = 1))",Loading multiple .xlsx files into a list with lapply but each sheet has footers,7ccwnw,new
"

Following [this
post](https://www.reddit.com/r/Rlanguage/comments/7c4vbb/ggplot_alter_the_x_axis_density/?st=j9vbr3ou&sh=cefed0bb)
I thought that I should make something with a reproducible example.

* Here's the code for this example : http://vpaste.net/lS5Ft
* Here's the original graph plotted using base r : https://i.imgur.com/ljP0vA6.png
* Here's the  graph plotted using ggplot2 : https://i.imgur.com/hRUa9uL.png
* This is the graph plotted using the code that I've provided : https://i.imgur.com/7ztIjl2.png

# Problem

The x axis *ticks* are too densely packed in, something which the base r plot
seems to handle automatically but ggplot doesn't.

I'm not sure how best to handle / control this.

## Using `scale_x_discrete`

Using this I'm able to do *something* with the axis, but it doesn't seem to be
behaving as I would expect.

For example - for the following : 

    ## Create a plot of the data for total number aboard each year
    p <- ggplot(aboardYears, aes(yearLevels, aboardYearTotal))
    breakV <- seq(1910,1990,by=20)
    p + geom_point(aes(size = aboardYearTotal))+  scale_x_discrete(breaks=breakV)

I would expect to have the x ticks as 

    tick 1 : 1910
    tick 2 : 1930
    tick 3 : 1950
    tick 4 : 1970
    tick 5 : 1990
 
But this isn't the case, instead I get this output : https://i.imgur.com/GYCk4Ky.png

This is the code that generated that output : http://vpaste.net/kFqpm


# So...

I'm not sure how to go about sorting this. I've tried to use the `limits`
parameter of `scale_x_discrete`, but that didn't really work how I would have
liked either.

I'm not sure how to get this to behave in a manner similar to the default behaviour.


Thanks
",Adjusting the tick values in ggplot sensibly,7c8f1v,new
"Sorry if i'm not using the correct phrasing, i'm not sure what i should say exactly... 

But in this graph : https://i.imgur.com/ljP0vA6.png , just made with the standard plot, the x axis density is automatically handled 

With this ggplot one : https://i.imgur.com/hRUa9uL.png , it looks a bit more fancy but the x labels are all shoved into each other. 

If anyone knows how to help this, and what i should refer to this as, that would be great. 

thanks",ggplot - alter the x axis density (?),7c4vbb,new
"Hello again,

I'm trying to subset rows from my data frame if the columns defined in vector have value of 1. I have been using the following, with df = my dataframe and lehto = the vector which defines the columns.

    lehtolajit<-df[df[lehto]==1,]


However, for some reason this code gives the proper values for the first three rows, while all the rest are NA. There are no NA values in my df. The values in df are all numeric.

Here's an example of what the returned df looks like:

           species.y decay dia empty Amyllapp Antrmell Antrseri
    2764         Blt     1  14     0        0        1        0
    7060         Blt     3   4     0        0        1        0
    7149         Blt     2  12     0        0        1        0
    NA          <NA>    NA  NA    NA       NA       NA       NA
    NA.1        <NA>    NA  NA    NA       NA       NA       NA
    NA.2        <NA>    NA  NA    NA       NA       NA       NA
    NA.3        <NA>    NA  NA    NA       NA       NA       NA",Subset rows if columns defined in a vector have certain value (returns NA for some reason?),7bzzs9,new
"Is there a way to just open up a tab for a new variable and enter the values of the matrix like in matlab?

or maybe put the dimension and then just substitute the na's with the corresponding values? ",Entering values of a matrix,7bymgx,new
"Creating a years variable from string format

I have a column :

    9/11/1903
    17/12/1905
    18/6/1919
    9/9/1921
    13/17/1922
    3/4/1928



If i run `typeof` on one of these it returns integer

I would like to create a new variable in that same dataframe with just the years as
    
    1903
    1905
    1919
    1921
    1922
    1928
    

I'm not sure how to go about this though... I considered creating a for loop,
iterating over them as strings and saving back as integers or something but this
seemed like a poor approach.

What's the best way to do this? 

I just want to be able to plot / evaluate things based on the years basically, i'm learning. 

Thanks!
",Creating a years variable from string format,7bv5dh,new
"I have a string that I want to check for multiple requirements. Namely, I want to check that it is between a certain number of characters in length, contains at least one uppercase character, one lowercase character, and one punctuation character.

I know how to do this using multiple regex matches, checking one requirement at a time. However, is it possible to check all of these requirements with a single regex?",Test multiple requirements of a string with a single regex?,7bozmg,new
"hello all,

 I'm completely new to R, coming from Matlab, and I'm trying to figure out a small R code snippet. I'm translating a piece of code from R to Matlab for the sake of contributing to open source software and also learning how to work with R. This might be trivial, so I apologise in advance for my ignorance. 

An example of a code snippet im working with is as follows:

    B=rbind(
		c(1, 2, 3, 4),
		c(1, 2, 3, 4),
		c(1, 2, 3, 4),
		c(1, 2, 3, 4)
		
    A = c(1, 2, 3, 4)
    R_function_output <<- function(A)
	{
		return(polynomial(c(
			sum(B[,1]*c(1,A)),
			sum(B[,2]*c(1,A)),
			sum(B[,3]*c(1,A)),
			sum(B[,4]*c(1,A))))
			)
	}

    deriv(R_function_output(A))


I assume that the equivalent code in Matlab for setting the variables A and B is:

    B = [1,2,3,4; 1,2,3,4; 1,2,3,4; 1,2,3,4;]
    A = [1,2,3,4]

and the function definition is:

    function M_function_output = function(A,B)

    M_function_output = [ [1 A] * B(:,1) ,...
                    [1 A] * B(:,2) ,...
                    [1 A] * B(:,3) ,...
                    [1 A] * B(:,4) ] ;
                           
    end


I tested the `M_function_output ` and the `R_function_output ` and they are equivalent. 

My questions are: 

The `polynomial` function in R is from the `polynom` package. I noticed that polynomials are defined in *increasing* order in R whereas in Matlab they are defined in *decreasing* oder. Therefore we need to use the flip left to right function `fliplr` in Matlab to sort out the correct order in polynomial representation. The Matlab function for polynomial differentiation is `polyder`. So reasonably, `deriv(R_function_output(A)) ` in R should be equivalent to `polyder(fliplr(M_function_output(A)))` in Matlab. This is not the case, and I do not know what it is that I'm missing. 

Any help will be greatly appreciated. 

A.


Edit: Problem solved! Problem was temporary lapse of sanity from my part. I needed to reverse the output of `polyder()` in order to have an equivalent representation. In other words `deriv(R_function_output(A)) ` == `fliplr(polyder(fliplr(M_function_output(A))))` for a direct comparison. 


 ",help with understanding a code piece (translate into Matlab),7bl4go,new
"I have created a utility maximization function that takes an expression and other numerical values as inputs and finds an optimal point in budget set. I want to graph indifference curve which optimal point on it. 
So here is my problem. I want to change the given expression (e.g (2*x^3 ) + (x*y)+y^2 ) to an equation of y with my output optimal point such as x=1, y=2. With example points , the equation equals to 8 and I want every (x,y) points which evaluate expression to 8.As a result, (2*x^3 ) + (x*y)+y^2 )= 8. Lastly , rearranging it like y=...  is crucial because i want to graph it with curve() function. How can i change it for every expression?",Inverse of a function,7bkj35,new
"Hi there

I'm looking for more GitHub repos of how to use mocks in R for code testing. This is really fascinating, and I'd love to show my collaborators more examples. 

Thanks for any recommendations!",Example repos of using mocks for testthat code testing,7bgw2x,new
"Trying to run a mixed model using the lmer function in the lme4 package. My data set has 10535 observations, but the model output is showing 9949 observations. There are no missing values in the data. Any idea on why the model is removing these? thanks!

edit: error in title, should be lme4",lmd4::lmer function dropping observations,7bg0kj,new
"Please be patient with me as I'm a total noob, but I'm really trying to learn.

I'm trying to make a choropleth map for my country, and found an R package on Github that handles it excellently. However, I'm working on a university computer and I don't have write privileges on any drive but M://, so whenever the package tries to install on C:// it obviously throws an error. This hasn't been a problem since I can just specify a libpath as an argument on install.packages, but devtools::install_github does not seem to have such an argument.

I tried using 
> with_libpaths(new = ""M:\\R\\win-library\\3.2"", install_github('diegovalle/mxmaps'))

But I got an error message saying 

> with_libpaths' is deprecated. Use 'withr::with_libpaths' instead.

I take this to mean that I need to install the ""withr"" package in order to use that? However, I keep getting errors when trying to install that package. First, I got ""Warning in install.packages :  installation of package ‘withr’ had non-zero exit status"" because of the not having access to C:// issue. I usually bypass this by installing directly from the binaries, but when I try that it tells me ""Warning in install.packages :  package ‘withr’ is not available (for R version 3.2.2)"".

Other than updating my version of R (which will be a nighmare since I don't have installation privileges on this machine), how else can I either install withr or find another way to specify the directory to install the package from github?",Having trouble installing a package from Github,7bcbcp,new
"I found a solution that works for my webscraping problem. And I'm taking the site down - I realized that webscraping may not be in line with the terms and conditions of said site.


However, I was only doing that for learning purposes - I would like to rephrase the question I had about error handling.

When attempting to scrape any site with a typical chain command such as in

    read_html(page) %>% html_nodes('css node') %>% html_nodes('maybe.another.css.node‘) %>% html_text  %>% str_trim(side = ""both"")

Sometimes a single page may be coded differently than all the others, and the css pointer won't point in the right direction. In that case, it will result in a character vector of 0. Even if other vectors didn't mess up, the lapply loop will throw an error when you're binding the vectors together in a data frame. All the scraping will be for not, the lapply function will throw a huge error in your face.


When trying to get the potential ""character(0)"" values to simply spit out NA values so they don't ruin my data frame, I initially used an ""ifelse"" construct.  It didn't seem to work, and the real solution was wrapping the html_nodes() function to deal with NA instead.  Is it only possible to deal with NA values from read_html by putting an NA handler around that function? 


  ",Webscraping issue - only getting 1st value from my pipeline,7bbzbo,new
"Hi everyone!

I am currently in a dilemma. I would like to code R to do something that seems simple but I have yet to find a solution to.

I have 25 numbers (lets say 1 through 25 for simplicity's sake). I would like R to generate all potential combinations of these numbers at various lengths (so a length of 1, 2, 3, etc...). However, some numbers have important rules. Like number 6 cannot occur without 7, or 8 cannot occur when 9 is present, etc. Usually I would just ask R to generate all possible combinations and eliminate the ones that are different, but there are lots of rules I would like to apply.

Could anyone point me in the right direction with how to go about doing this? Thank you so much in advance! Everything I have found so far has been about generating combinations with certain number sets but not about rules. ",Generating combinations with rules?,7baxf3,new
Is there a way to use a sharepoint location as my working directory?,Using a sharepoint location as WD,7b9zmj,new
"I'm creating an R package using `testthat`. Many of the functions I am working with require a file as input and/or write a file to output. 

Currently, my R package directory structure looks roughly like:

    - R_package_name
        -/tests
            -/testthat.R
            -/testthat
                -/test_package.R

As an example, functions in this category would be `read.table()` and `write.table()`. The former reads in some file, the latter writes it. 

What is the standard for creating ""example files"" for tests with `testthat` given the R package structure? I could create very small example files as inputs in the `tests`

Let's say I'm doing a test for `write.table()`:

    test_that(""check write.table"", {
        
        df = data.frame( n = c(2, 3, 5), s = c(""aa"", ""bb"", ""cc""), b = c(TRUE, FALSE, TRUE))
        expect_identical(write.table(df), ???)
    
    })",How to work with “example files” using testthat in R?,7b9s0j,new
"I've tried using RForcecom but wasn't able to figure it out. Has anyone ever been able to successfully download a report from Salesfore through R? Also -- does anyone know if I need an admin account? I was able to connect to Salesforce, but couldn't navigate through the API/syntax.",Having Trouble Downloading Salesforce Reports through R -- RForcecom package,7b8ll6,new
"Hi! So I'm having trouble coding for a section of my analysis:

I need to create a variable that determines how close is to a cutoff. The cutoffs are: 10,188, 13,584, and 16,980. I need to use these cutoffs to create a single variable that characterizes the difference from the closest population cutoff. Then following the original analysis, standardize this measure by dividing the difference with the corresponding cutoff and multiply it by 100.

Just a starting point would be greatly helpful!",Regression discontinuity in R,7b8dne,new
"Create a Dendrogram using the below packages:  
  
install.packages(""rpart"")
install.packages(""rpart.plot"")
install.packages(""RGtk2"")
install.packages(""rattle"")
install.packages(""RColorBrewer"")
install.packages(""fancyRpartPlot"")
  
But I am having a an issue trying to rotate the data. Here is a breakdown:  

  mydata<-Adjusted_Cluster_Data[,-c(1,1)] # removed column with names.  

  Cluster_Scaled<- scale(mydata) #Standardized data set  

  Cluster_d <- dist(Cluster_Scaled, method = ""euclidean"")  

  fit <- hclust(Cluster_d, method=""ward.D"")   

  plot(fit, labels = Adjusted_Cluster_Data$`DP Name`,cex = 0.8)

  
So i have my chart up but i want to rotate the data so the labels are read from top to bottom instead of left to right. Is there a way to do this without using dendextend?  


*Edit for someone that runs into the same issue. Your data needs to be a data frame. Solved the issue by using the below.  

    Cluster_D = data.frame(Cluster_d)
    rownames(Cluster_D) <- Cluster_D[,1]
    Which allowed me to then use:
    D.Industry <- dist(scale(Cluster_D[, -1]), method = ""euclidean"")
    H.Industry <- hclust(D.Industry, method = ""ward.D"")
    dend<- as.dendrogram(H.Industry)
    plot(dend, horiz = T)

  ","Trying to rotate a dendrogram, having trouble",7b87d3,new
"Hey guys!

I'm relatively new to R, and I'm using it for bioinformatic analysis. I have obtained a dataset from a database, which is a comprehensive list of bacterial species. I have created another dataset comprised of the species I am interested in. I wish to use my created dataset to 'pick out' the relevant species from the larger dataset. Does anyone have any idea how I'd go about doing so?

I understand that select parameters can be picked out using 
data.frame(ds$A, etc.) where ds is my dataframe and A would be the row I'm trying to pick out, but is there any easier way of doing it other than listing? (There are over 1200 items on my relevant list)",Use R to pick out relevant titles from a dataset,7b7x1r,new
"I'm SUPER new to R, and I've really only used basic stats commands (hist(), boxplot(), lm(), etc.). But I've got this idea stuck in my head (not really stats related) that I want to test out. I've set up two data sets A and B, and I want to check all elements a in A for this property:
There does not exist a b in B such that a-b is a prime number.
I know how to set up a loop to check numbers in a certain range, like 1:1000, for primality, but I'm not sure where to go from here. Any help is appreciated!
Feel free to let me know if this problem is more appropriate for another programming language. I am very inexperienced, but I'm eager to learn.",Need help setting up a loop,7b2nzs,new
"Hi everyone - I have recently started a class at my local university where we are learning how to create models in R. I am using this class to determine if I like this area enough to continue to pursue it. This week's homework assignment is super difficult for me. I was wondering if anyone here could help me get started with the second problem or provide a place that could help me? If the entire solution is available that would be much appreciated. Thanks.

I also understand that their are several ways to go about the second problem, but I have no idea how to start.

If it matters, I am taking this class for a grade, so I understand not wanting to cheat, but I don't care what my grade is in the class, I am here to learn. Any help is appreciated.

Questions: https://imgur.com/gallery/DuR03 

Data for Question 2: https://imgur.com/a/A5GNv",Help Setting Up a Predictive Model,7b2g3d,new
"I need to plot time against conductivity, but the time in my data set is presented as ""10/31/2017 9:15"" and so on...( with dates going back to 6/9/2017 0:01)
How can I save my Time column with this format? I know the format would be ""%m/%d/%Y %H:%M""  but I'm not sure what function to use

Help would be much appreciated!


",Plotting date/time data,7b03tm,new
"using a disease.data set, my task is to figure out the linear discriminant analysis but I have no prior knowledge in doing this, and I'm finding the function documentation difficult to understand. There are 195 rows and 25 columns/attributes.

I have done the following already

Then I split disease into a matrix with only numeric columns. 23 attributes

X <- disease[,sapply(disease,is.numeric)]

Then I split disease into a vector with only the label ""status"". This is the label with output of 0 or 1.

Y <- disease[,""status""]

I plotted it, and figured out two attributes that seem fitting for LDA, which are attribute 2 and attribute 20.

Then I partitioned the data like so: 
Training set: Both attribute and label 
Test set: only matrix of attribute

diseaseIndexes = sample(1:nrow(disease), size=0.6*nrow(disease))
PTrain <- disease[diseaseIndexes,c(""MDVP.Flo.Hz."",""status"")]
PTest <- disease[-diseaseIndexes,""MDVP.Flo.Hz.""]

How would I perform LDA that takes the test and training sets as arguments and gives me a vector of labels predicted for the test set?",How do I perform LDA on my Data?,7aymqa,new
"I'm to get to this result: https://imgur.com/a/EDIWN, where each box is part of a 5x5 grid with numeric information. Suppose I have the numeric information for each box, how would I go plotting this into a 5x5 grid? Thanks! ",Coding a 5x5 grid with numeric information,7awczk,new
"Hello, I have a large list of urls I want to scrape (150000 urls) I can currently parse the data I want sequentially, however I would prefer to do this in parallel. I am currently using rvest to scrape. If anyone has experience using rvest in parallel I would greatly appreciate the help.   ",Parallel web-scraping?,7atdhk,new
"Hi All,

In my free time, I've been working on a personal project to predict when my local lake will freeze.  It's a pretty simple problem, but am not finding a clear solution.  I've put together data from the us noaa national climatic data center and a local university.

I've got: min and max temps by day, and lake freeze dates going back to 1939. 

Data:
http://www.mediafire.com/file/pv3ka7usvp5ju49/temps_and_freeze_dates.csv

Any thoughts on best way to do this?",predicting lake freeze,7at6pg,new
"Hello,

I would like to draw a ggplot of NMDS solution with particular groups of species written in different font-faces while also avoiding overlapping of the species labels. I tried putting the species groups each in their own data frames and while the font-faces are different, the species labels overlap. 

    #### NMDS ####
    inh.nms<-metaMDS(inh.sp,k=2,trymax=100)
    inh.scores <- as.data.frame(scores(inh.nms)) 
    inh_sp.scores <- as.data.frame(scores(inh.nms, ""species""))
    inh_sp.scores$species <- rownames(inh_sp.scores)

    inh_sp.lehto<-inh_sp.scores[inh_sp.scores$species %in% lehto,]
    inh_sp.uhis<-inh_sp.scores[inh_sp.scores$species %in% uhis,]
    inh_sp.muut<-subset(inh_sp.scores,!(inh_sp.scores$species %in% lehto))
    inh_sp.muut<-subset(inh_sp.muut,!(inh_sp.muut$species %in% uhis))

    #### plotting ####
    inh.ORD.e<- ggplot() +
    geom_text_repel(data=inh_sp.muut,aes(x=NMDS1,y=NMDS2,label=species), size=2, segment.size=0.1,segment.color=""#CCCCCC"") + 
    geom_text_repel(data=inh_sp.lehto,aes(x=NMDS1,y=NMDS2,label=species), size=2, segment.size=0.1,segment.color=""#CCCCCC"", fontface=""italic"") + 
    geom_text_repel(data=inh_sp.uhis,aes(x=NMDS1,y=NMDS2,label=species), size=2, segment.size=0.1,segment.color=""#CCCCCC"",fontface=""bold"") + 
    coord_fixed() +
    coord_cartesian(xlim = c(-1.5, 1.0)) +
    theme_bw()+
    theme(panel.background = element_blank(), 
        axis.text=element_text(size=18,family=""serif""),
        axis.title=element_text(size=18,family=""serif"",face=""bold""),
        legend.title=element_text(size=18,family=""serif""),
        legend.text=element_text(size=18,family=""serif""),
        plot.title=element_text(size=12),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        plot.background = element_blank())


    grid.arrange(inh.ORD.e,ncol=1)

Also, [here's a pic](https://i.imgur.com/btDuqPb.png) of what the result looks like now. You can't make the species names due to the overlapping caused by using three separate geom_text_repel commands.","In ggplot, use geom_text_repel and write subsets of data in different font-faces",7aruaw,new
"I have a large data set with a variety of columns, but the relevant ones are ""rank"" and ""score."" In this table is a bunch of scores of students and their corresponding rank (in order). I want to create a grouped box plot that compares the top 100 students' scores with the entire group of students' scores, but I only know how to create a grouped box plot for data that varies on a categorical variable.

Is there a way for me to do this without editing the .csv file in Excel? I'm trying to think of ways on my own, but I'm still really new at R. I created a new data set containing the top 100 students, but I'm not sure how to create a grouped box plot, rather than just two separate box plots. Is there a way to create graphs using data from two different data sets? 

Also, is there a way for me to add a new column with a certain value given the value in another column. For example, is there a way for me to create a new column with the value ""top"" if the student/row was in the top 100 of all students and otherwise show ""bottom?"" I can do this in Excel, but was unsure if I this is possible in R. 

Any explanations on either of the two above methods is greatly appreciated, or if you have an even better way! Thanks for the help, sorry if this is a noob question (I tried Google but didn't get anywhere). ",Creating a grouped box plot using subsets of a single data set?,7aoumd,new
"I'm once again looking at some legacy R code, trying to read the user's mind. It looks like they are using Python style, whereby they define an empty R vector, and then use a for loop to append the results to a vector.

    library(data.table)
    dtable = read.table(""path/filename.txt"",header=TRUE,sep=""\t"",check.names=FALSE)

After defining this data.table, here is what was 
Here is what is being done:

    empty_vector <- c()
    
    for(i in 1:nrow(dtable))
    {
    empty_vector <- append(empty_vector,strsplit(dtable[i,6],"":"")[[1]][2])
    }

This is a rather large `data.table`, with +500K rows. 

(1) We shouldn't be using a for loop. There is a data.table way to do this. 

(2) So, defining an empty vector and appending results to this vector is not R. What is the ""R approach"" to this?

EDIT: I think the programmer was thinking of something like this in Python:

    empty_list = []    ## equivalent to R vector

    for i in range(10):
        empty_list.append(i)

    print(empty_list)   ## now [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

How would someone do something like this, given this is R and we are iterating over rows of a data.table?

",Appending data.table rows into an empty vector---doing the right data.table thing,7amukz,new
"Should I be using LaTeX or R for creating random number-based worksheets and solution sheets for students?

This is what I'm trying to create now in LaTeX. https://imgur.com/a/KYEIt

But I want the exercises and solutions to be on *separate* pages and [this is proving so hard that nobody from StackExchange is offering me a solution](https://tex.stackexchange.com/questions/399064/two-font-sizes-and-xdef). 

Separating the exercises from solutions strikes me as a task that ought to be trivial to program and it has been for me in [other cases](https://www.sharelatex.com/project/59ee8710f41d5451ffb99464).

I'm a total programming newb, but another programmer has told me that LaTeX and TikZ are very nasty, old-fashioned, and fussy languages. I already know some LaTeX and TikZ [I hate them] and will master them if I have to, but I know nothing about R. Perhaps R is an easier language in which to make these worksheets?

What do you think?",R vs LaTeX for Worksheets & Solution Sheets?,7alhpm,new
"I'm currently creating an R package, and my scripts require before any analysis is done that 3-4 text files be loaded. Normally, I would run the scripts with the following:

    library(data.table)
    session_data = read.table(""/path/name/to/filename.txt"")

and then refer to `session_data` throughout the analysis. 

However, in order to release this as an R package, I believe that these files must be downloaded at the time on the package installation. 

(1) Normally, how are text files distributed in R packages? Are these gzipped? Where are they placed? 

According to http://r-pkgs.had.co.nz/data.html, all .text files should be `inst/extdata` I guess. However, it's not clear to me how to ""link"" to this data within the R package. Also, users would be able to access these text files, which I'm not sure is really necessary or desired. 

How have other packages dealt with this? (Is there a size limit?)

(2) In this case, should the function loading the text file be executed about loading the R library, `library(package_name)`? Is there more appropriate option? 

",How to release an R package with several text files?,7ag8au,new
"I have quite a large csv file of data I'm pulling from, and every time I try to plot it I get this error:
Error: cannot allocate vector of size 17.6GB

Here's my code- pretty simple I think. The middle point is just removing some bad outliers.

    data <- read.csv(""temp_data.csv"", header = TRUE)
    library(dplyr)
    mutate(data, tempc = ifelse(abs(lag(tempc)-tempc)>18, NA, tempc))
    plot(data$tempc ~ data$yr, type = ""l"", main = ""McMurdo Temperature"", xlab = ""Year"", ylab = ""Temperature (C)"")

Any help would be appreciated! I thought it might just be an issue with my computer being weak and sad, so I went to use a pretty high powered PC at my university's library, but I still got the same error. Also for reference, the csv is 2 columns with 48650 rows, all numeric.",Error: cannot allocate vector of size,7adiz0,new
"So I am querying a Database using R-SQLquery. But the output is too large ( warning message), even when I increase the R memory limits. How can I tackle this problem.",R SqlQuery gives too big file size. How can I tackle it ?,7a8vu4,new
"Hi all, 

I'm new to R and trying to get my data: 

    Date <-c('3/13/2017 6:21', '3/20/2017 6:28','3/13/2017 6:22','3/20/2017 6:28',' 3/13/2017 6:23','3/20/2017 6:28','3/13/2017 6:24',' 3/20/2017 6:28', ' 3/24/2017 6:28')
    Enabled_value<-c(0,1,0,1,0,1,0,1,0)
    Helper<-c('39RTU1','39RTU1','39RTU2','39RTU2','39RTU2','39RTU3','39RTU3','39RTU4','39RTU4', '39RTU4')

to look like:

    Helper      Date(Enabled Value =0)     Date (Enabled Value =1) 
    39RTU1       3/13/2017 6:20            3/20/2017 6:28
    39RTU2       3/13/2017 6:21            3/20/2017 6:28
    39RTU3       3/13/2017 6:22            3/20/2017 6:28
    39RTU4       3/13/2017 6:24            3/20/2017 6:28
    39RTU4       3/24/2017 6:28

As you can see, I have timestamps for each observation - each row should be an instance (i.e. moving from Enabled_value from 0 to 1, and if the last Enabled_value for the unit = 0, there should be a new line (see 39RTU4 below). 

I have already done extensive work reducing this data set (from 500k to 2k rows). 

I'm trying to use `tidyr` and `dplyr`, but my `spread` keeps running errors. 

    > sorted_data1<-spread(sorted_data,Enabled_Value,Helper)
    Error: Duplicate identifiers for rows (1340, 1342)

Any and all help would be greatly appreciated.
",spread() in R - need help!,7a6nyd,new
"I made this code in the spring and for some reason it is not working anymore and R doesn't draw the plots. When I try to use grid.arrange to draw them (or if I just try to use loess itself), I get the following warning message:

Warning messages:
1: Computation failed in `stat_smooth()`:
argument ""trace.hat"" is missing, with no default 

Here's a piece of the code that used to work flawlessly:

    sc.occpt.ptre<-ggplot(subset(sc, species %in% c(""Ptre"")), aes(x=sizeclass, y=occpt)) +
     geom_smooth(method=loess, color=""black"", size=0.5)+
     coord_cartesian(ylim=c(0,2.5))+
     theme_pub2()+
     theme(axis.title.y = element_blank())+
     theme(axis.title.x = element_blank())+
     scale_x_continuous(breaks = seq(10, 45, by = 5))+
     annotate(""text"",-Inf,Inf,hjust=0,vjust=2,label=""Populus tremula"",family=""sans"", size=1.7)+
     annotate(""text"",-Inf,Inf,hjust=-0.07,vjust=4,label=""Spearman's rho = 0.25, p = 0.007"", family=""sans"",fontface=""italic"", size=1.7)

and I use this code to draw the plots:

    grid.arrange(sc.occpt.ptre, sc.occpt.bsp, sc.occpt.blt, sc.occpt.pabi, sc.occpt.psyl, sc.occpt.all, ncol=2, left = textGrob(""Occurrences per CWD item"", rot=90))

I can't figure out how I should put the argument trace.hat in my code nor why I suddenly need it in the first place. I installed the latest version of both R and Rstudio with no help in this matter.

Thank you in advance! I'm going crazy with not figuring this out.","loess function not working - ""argument trace.hat is missing with no default""",7a30g1,new
"i have two data frames, one called x and one called y.

x column names: 'LandUse', 'LocationSetting', 'ParameterName', 'LocalDate', ArithmeticMean'

y column names: 'LocalDate', 'year', 'month'

Data frame y was created using the data from x, so the LocalDate columns should all match exactly. However, any kind of join function I attempt (left, right, inner) all result in the row count skyrocketing to over 350k rows, and all of the months seemingly become January (if I query how many unique objects are in the 'month' column, the result is 1).

Can someone help me get these two to merge properly? My end result is to extract all rows for each month and do some arithmetic on the 'ArithmeticMean' column.

Thanks","joining two data frames increases row count 6091 to 352,106?",7a14ab,new
"I'm pretty new to Shiny and Spark.

I want to deploy a ShinyApp with a spark connection.  Everything works how it should when I just hit RunApp, but whenever I try to publish it, I get the error: ""Error in value[[3L]](cond) : 
  SPARK_HOME directory '/usr/lib/spark' not found
Calls: local ... tryCatch -> tryCatchList -> tryCatchOne -> <Anonymous>
Execution halted""

This directory exists on my cluster, so I'm not sure why it's not finding it.
Here's the code I'm trying to publish.


    library(sparklyr)
    library(shiny)
    library(ggplot2)
    library(rmarkdown)


    Sys.setenv(SPARK_HOME = '/usr/lib/spark')
    config<- spark_config()
    spark_install(version = ""2.2.0"")
    sc<-spark_connect(master = 'yarn-client',  version = '2.2.0')
    tbl_cache(sc, 'output_final_v2')
    output_tbl2<-tbl(sc, 'output_final_v2') 


    ui <- fluidPage(
  
      textInput(""name"", ""Enter Shortname"", ""furycat""),
      textInput(""item_name"", ""Enter Item Name""),
      selectInput(""month"", ""Choose Month"", choice= c(""January"",""February"",""March"", ""April"", 
                                                 ""May"", ""June"", ""July"", ""August"", ""September"", 
                                                 ""October"", ""November"", ""December"")),
      selectInput(""dow"",""Choose Day of Week"", choice = c(""Monday"", ""Tuesday"", ""Wednesday"",
                                                     ""Thursday"", ""Friday"", ""Saturday"", ""Sunday"")),
      numericInput(""count_customers"", ""Enter Number of Customers:"", 2),
      numericInput(""views"", ""Enter Number of View Book Form:"", 30),
  
  
      plotOutput(""plot1""),
      plotOutput(""plot2""),
      plotOutput(""plot3"")
  
    )

    server <- function(input, output, session) {
  
  
      C2<-reactive( output_tbl2 %>%
                  mutate(views = input$views)%>%
                  filter(input$name == shortname)%>%
                  filter(input$dow== dow)%>%
                  filter (input$month == month)%>%
                  filter (input$item_name == item)%>%
                  filter (input$count_customers == count_customers)%>%
                  collect)
      output$plot1 <- renderPlot({
    
        p1<-ggplot2::ggplot(data = C2() , aes(x=price_per_customer, y=final_probability)) + geom_line() + 
    ggtitle(""Probability of Purchase"") + labs(y=""Probability"",x= ""Item Price"")
    print(p1)
     })
  
  
      output$plot2 <- renderPlot({
    
        p2<-ggplot2::ggplot(data=C2(), aes(x=price_per_customer, y=((views*final_probability)*price_per_customer))) + geom_line() + geom_hline(aes(yintercept = max((views*final_probability)*price_per_customer))) + ggtitle(""Projected Revenue"") + labs(y=""Expected Revenue"",x=""Item Price"")  
    print(p2)
    
      })
  
     output$plot3<-renderPlot({
    
    p3<-ggplot2::ggplot(data=C2(), aes(x=price_per_customer))+ geom_line(aes(y=(views*final_probability)*price_per_customer)) + geom_line(aes(y= (((views*final_probability)/price_per_customer)))) + ggtitle(""Iso-Profit vs Expected Volume"")
    
    print(p3)  
      })
  
  
    }

    shinyApp(ui, server)
",Can't get sparklyr to connect to shiny,79w9c9,new
"I'm currently using the lda function to perform linear discriminant analyses. The first argument that the function takes in is a formula of the response and predictor variables in the equation, I'm not sure of the correct wording to use, but this argument is given without quotes like this:

    lda(Y~., data = example.df)

I have a vector of strings corresponding to different formulas which I'd like to use in this function, which I'd like to call like:

    lapply(formula.vector, function(x) lda(x, data = example.df))

However, the variable holding the formula strings is not getting interpreted, so the function throws an error saying:

    'x' is not a matrix

Does anyone have any ideas of how I can get this to work?","Issues using a variable in place of a formula in a function (lda, package = MASS)?",79u0l5,new
"I want to plot a pair of summary statistics using a pie chart.

I have a single category and I want the size of the pie slice to reflect the relative counts.  I would also like to have the height of the slice reflect the average value of an associated metric.

Currently, I am trying to use a combination of sqldf and plotrix to accomplish this.

    sumTbl <- sqldf('select category, count(*) as ct, avg(price) as aPrice from source group by category')

    pie3d(sumTbl$ct, labels = sumTbl$category)

These lines give me a nice 3d pie chart that sizes the slice by count.  But when I include a height statement and set it equal to my aPrice the result doesn't render worth a damn.

Thoughts are appreciated.

Edit:  I should have written solutions are appreciated, your distaste for pie charts doesn't assist with this particular issue",Pie charts with two data dimensions,79pi5r,new
"Hi all,

I am having a problem with making a contour plot. I was following instructions from [this discussion on stackoverflow](https://stackoverflow.com/questions/19339296/plotting-contours-on-an-irregular-grid) but filled.contour() is throwing the following error:

    graphics:::filled.countour(x = rownames(absorption_df),
    								y = colnames(absorption_df$y),
    								z = absorption_df,
    								color.palette = colorRampPalette(c(""blue"", ""yellow"", ""red"")),
    								xlab = ""depth"",
    								ylab = ""time"",
    								main = ""Absorbed solar irradiance"",
    								key.title = title(main = ""Energy flux (j/s)"", cex.main = 1))
    
    Error in get(name, envir = asNamespace(pkg), inherits = FALSE) : 
      object 'filled.countour' not found

I am using RStudio version 1.0.153 on Windows 10.
Does anybody understand why this happens?

Thanks very much!",Error: object 'filled.contour' not found,79mm43,new
"I am new to R and I am trying to create a simulation with:

8 nodes

each has a binary attribute called ""smoking"" (0 for no, 1 for yes)

each has an attribute called ""friendsSmoke"" which is equal to the number of 'friends' which has a value of 1 for the attribute ""smoking""

each has an attribute called ""friendinfluence"" which is randomly generated with an integer value of 0~3 inclusive

each has 3 connections (predetermined with a .cvs(?)) to other nodes; each connection is bidirectional and connected nodes are 'friends'

the attribute ""smoking"" changes from 0 to 1 if the attribute ""friendinfluence"" is equal to ""friendsSmoke""



I would like to run this simulation to simulate the change in human behavior based on relations but I am new to R and I don't know were to start and I couldn't find any tutorials online. Sorry that I wasn't able to provide anything more. Please help me with this code, many thanks.
",How do I create an influence model simulation in R?,79k7bn,new
"TL;DR at the bottom

Hi everyone, I have been learning R for a week and am surprised how simple it is thus far yet very powerful. I have noticed it has gained a lot of traction among professionals and firms and is a soaring demand for it. The reason I'm learning it is because I am going into the field of finance namely investing/trading stocks and FX, I then learnt about R and immediately thought of the potential.

Now I'm not sure if this is the right place to ask these kind of questions, sorry since I'm brand new. But I must ask as to why this is a highly regarded programming language.

1. It doesn't compile applications? (Except with shiny package)

Is there any reason why statisticians would want to use this instead of something like excel? I mean the simplicity of the graphs are nice and all but it seems most of it can be done with excel with understanding its syntax and the fact that R can't compile niche applications without the shiny package makes me wonder what the appeal is in the first place to all industry experts, maybe somebody could clarify.

2. Do you need knowledge of the field you are doing statistics for when you program R?

What I'm asking is this a job for people who both need an intimate understanding of their discipline (i.e. finance, marine biologist etc) while also being fluent in the R language? Because I can imagine this isn't the case for people who might be programming in C++ for a certain industry but they don't have a clue about it, they just program it so it works the way it should for their intended client.

TL;DR Why is it highly regarded when it can't compile standalone programs without the shiny package and do you need to have deep knowledge of an industry if you want to program R for them in the first place.
",Specifics regarding r in the industry,79dwq5,new
"Its been like 30 times in a row with restart on my computer.  

ive tried removing all objects that i know longer need up to that point and only keep the necessary ones to free up memory.

and it still freezes.

my only thoughts is that i need to clean up my disk space.  im sitting with only 50gb of free ram

what is causing it to freeze is simply using rpart() over a dataset with 35k lines",Rstudio keeps crashing running the same script that i need for work!,79de4y,new
"I have an end user request where they want to specify the first two splits. 
From a business point of view, it makes sense to do so.
I am not seeing how this can be done in rpart, cforest, rforest, partykit.
help?",Possible to force a split in R tree packages like rpart or party?,79akig,new
"

I have some data, and I wanted to make a post with some code that someone else
would be able to run... But I've no idea how to go about that. Obviously sending
the whole dataset around is quite clumsy.


I have a dataset that has around 5500 rows in it, so I wanted to extract say 5
elements in order to ask a question about them.

I've tried to use this post :

https://stackoverflow.com/a/5963610/3130747


# So

Here is the `head` of the vector that I'm currently interested in

    > head(acd$Date)
    [1] 9/17/1908  7/12/1912  8/6/1913   9/9/1913   10/17/1913 3/5/1915
    5100 Levels: 10/10/1933 10/10/1938 10/10/1944 10/10/1946 10/10/1955 ... 9/9/2005
    >

I want to get the first 5 elements so that I can put them in a script, and ask
some questions.


Using the instruction from that stack post :

    a = dput(droplevels(head(acd$Date,5)))


Then I have `a`

    > a = dput(droplevels(head(acd$Date,5)))
    structure(c(4L, 2L, 3L, 5L, 1L), .Label = c(""10/17/1913"", ""7/12/1912"",
    ""8/6/1913"", ""9/17/1908"", ""9/9/1913""), class = ""factor"")
    > a
    [1] 9/17/1908  7/12/1912  8/6/1913   9/9/1913   10/17/1913
    Levels: 10/17/1913 7/12/1912 8/6/1913 9/17/1908 9/9/1913

So these elements should be identical to those of the original vector shouldn't
they?

Yet when I test for equality I have the following

    > a[1] == acd$Date[1]
    Error in Ops.factor(a[1], acd$Date[1]) :
      level sets of factors are different

Some type checking :

    > typeof(acd$Date)
    [1] ""integer""
    > typeof(acd$Date[1])
    [1] ""integer""
    > typeof(a)
    [1] ""integer""
    > typeof(a[1])
    [1] ""integer""



*******************************************************************************

If anyone could help with this I'd be really grateful, as I can't even ask a
meaningful question at the moment.

Thanks


### Note

I originally made [this post](https://i.imgur.com/9EwAP7r.png) and deleted it (
there hadn't been any response) as I thought that I could be more specific.

",Please can someone help me to actually make a post with reproducible code?,799pw0,new
"Can I create a new environment at the beginning of my script and assign all my variables into that environment? I figured that might make it safer code?

So it'll be something like -

A.env <- new.env()

A.env$VarA <- 1.0

print(A.env$VarA) ...

Any pitfalls in following this approach?",New environment for script,796ugf,new
"Sorry for the title, I'm not sure how to phrase this though. 

i have a data frame and one vector ( column? ) is full of dates, so day/month/year

I would like to create a Year variable from this... So it will still be within the same data frame

So I'd then have Date and Year in that dataframe

I'm hoping that makes sense, sorry the language isn't very accurate yet. 

cheers",Create a new variable from existing variable in a data frame and save it to the data frame,796sem,new
"My objective is to include country info in a csv that has only coordinates of over 1,200 entries. Can I achieve this through R? Thank you in advance",Is there a way I can include Country info in a database file through R?,78yr4o,new
"Hey there, hopefully this is the right place to post. I'm trying to install R on Linux but have been unable to. Every time I attempt *sudo apt-get install r-base-dev* I get the following:
    
    Reading package lists... Done
    Building dependency tree       
    Reading state information... Done
    Some packages could not be installed. This may mean that you have
    requested an impossible situation or if you are using the unstable
    distribution that some required packages have not yet been created
    or been moved out of Incoming.
    The following information may help to resolve the situation:
    
    The following packages have unmet dependencies:
     r-base : Depends: r-base-core (>= 3.4.2-1xenial1) but 3.2.3-4 is to be installed
              Depends: r-recommended (= 3.4.2-1xenial1) but it is not going to be installed
              Recommends: r-base-html but it is not going to be installed
    E: Unable to correct problems, you have held broken packages.

I've gone through a couple installation tutorials but they all seem to be the same. Here's the path I've taken to install:

    $ sudo sh -c 'echo ""deb http://cran.rstudio.com/bin/linux/ubuntu xenial/"" >> /etc/apt/sources.list'
    $ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E084DAB9
    $ sudo apt-get update
    $ sudo apt-get install r-base-dev

To preemptively answer some questions:

* Yes, I am running xenial

* Yes, the xenial repository has been added to /etc/apt/sources.line

* This error happens when I try to install r-base and r-base-dev, but *not* r-base-core. That seems to have installed correctly (*r-base-core is already the newest version (3.2.3-4*)

* I've tried multiple mirrors from the R site 

* When I attempt *sudo apt-get install r-recommended*, I get the same error but with the following line added `Depends: r-cran-boot (>=1.2.19) but it is not going to be installed`
    
* When I try *sudo apt-get install r-cran-boot*, I get the same error with only the r-base-core line

* I have also tried `sudo add-apt-repository ppa:marutter/rrutter` per a couple forum posts I saw, but to no avail

Thanks for your help.","Unable to install R on linux: ""Depends: r-base-core (>= 3.4.2-1xenial1) but 3.2.3-4 is to be installed""",78x78p,new
"I currently have a data frame that was read from a csv file. It has two columns, year and temperature. The temperature data has some pretty bad outliers, so I'd like to be able to set up a filter that basically:

-compares each point to the point above (or above and below) it
and

-if the point is >15 degrees different from the point above, makes the value NA (or deletes it, something like that)

Thanks in advance! I'm  very new to R (and programming in general) and I can't seem to make anything I found online work for this.",Filtering out points more than x amount greater than previous point,78x1ia,new
I would like to connect the data from OLAP. How can I do?,How to connect OLAP in R?,78t9ok,new
"Hi, I'm pretty new to R and I'm trying to run cor.test or a similar function across multiple data frames that I have arranged in a list. The list contains 36 data frames labelled Model 1 through 36, each with 2 factors. I am trying to run a correlation to determine P value and correlation coefficient between the 2 factors in each data frame. I'm looking for the output of P value and coefficient for each of the 36 ""models"". I have tried multiple different for loops and lapply but I'm still very shaky in my understanding of these so it's completely possible I've just messed up my syntax somewhere.
Any help would be greatly appreciated and thank you very much in advance!",Need help with running a correlation across multiple data frames in a list,78t34c,new
"I'm using RStudio, and trying to knit my file to hand in my assignment. I installed the package ""readxl"" to read in a couple of excel files, and it worked fine in the actual coding of the assignment. But when I go to knit the file, I keep getting the error:

>Error in library(readxl): there is no package called 'readxl'

This has been frustrating me for over an hour and I just can't fix it. I can see the readxl package to the right of the console, in the ""packages"" tab. Any help will be much appreciated","Error when trying to knit file, RStudio claims package doesn't exist",78rwux,new
"Hi all. I have the following problem. let me type the code I'm working on and explain what I'm trying to do below:

> x1=8000

> x2=8000

> x3=7000

> x4=11000

> p=0.5

> Ux <- function(x,r){

  > U <- (x^(1-r))/(1-r)

  > return(U)

> }**

> solve((p*Ux(x1,r))+(p*Ux(x2,r))=(p*Ux(x3,r))+(p*Ux(x4,r)),r) **I dont think ""solve"" is the right formula, but I don't know which is**


I'm trying to calculate the coefficient of relative risk aversion (CRRA). My goal is to find an ""r"" such that p*U1+p*U2 = p*U3+p*U4, where  U= (x^(1-r))/(1-r)


I don't know if that makes any sense... thanks in advance for any help!
",I need help figuring out how to use the equivalent of solver/goalseek (from excel in R),78g5vo,new
"Hello,

Can someone help me in parsing one of number of huge text files in R into nice rows and columns as I am really struggling. It is basically a huge table of X/Y Coordinates and other information that I want to plot. This issue I have is there are thousands of line and it is formatted oddly, or at least annoyingly, some in columns some in rows, and then its fixed character spacing for the column. I am currently having to do it by hand splitting the file into parts (because there is too many rows for Excel or Office), importing it to excel slicing it all up, reformatting and then doing the plots in R and it is very cumbersome and complicated.

See example:

    T12345678       1 8  4951521116.74N0020739.44E 440362.65782305.2  48.32271748037
    C12345678       121  4951521116.62N0020741.53E 440402.15782301.0  48.32271748037
    R   1 440402.35782309.3 0.0   2 440401.35782309.6 0.0   3 440400.35782309.8 0.01
    R   4 440399.45782310.1 0.0   5 440398.45782310.4 0.0   6 440397.55782310.7 0.01
    R   7 440396.55782311.0 0.0   8 440395.55782311.3 0.0   9 440394.65782311.5 0.01
    R  10 440393.65782311.8 0.0  11 440392.75782312.1 0.0  12 440391.75782312.4 0.01
    T12345678       1 8  4951521116.74N0020739.47E 440363.25782305.2  48.32271748039
    C12345678       111  4951521116.91N0020741.67E 440405.05782309.9  48.32271748039
    R   1 440402.85782309.3 0.0   2 440401.85782309.6 0.0   3 440400.95782309.9 0.01
    R   4 440399.95782310.1 0.0   5 440399.05782310.4 0.0   6 440398.05782310.7 0.01
    R   7 440397.15782311.0 0.0   8 440396.15782311.3 0.0   9 440395.15782311.6 0.01
    R  10 440394.25782311.8 0.0  11 440393.25782312.1 0.0  12 440392.35782312.4 0.01   

This style is then repeated for going on 1.6 million rows.

As you can see there is three ID's (T/C/R) each T row then has fixed spacing so it would be as follows:


T | Bar | text | text | text | text | text | text | text | text | text | text | text 
---|---|----|----|----|----|----|----|----|----|----|----|----
T | 12345678 | 1| 8 | 4951521116.74N| 0020739.44E| 440362.6| 5782305.2| 48.3227| 17| 48| 03| 7 

C | Bar | text | text | text | text | text | text | text | text | text | text | text 
---|---|----|----|----|----|----|----|----|----|----|----|----
T | 12345678 | 12| 1 |4951521116.62N| 0020741.53E| 440402.1| 5782301.0| 48.3227| 17| 48| 03| 7 

R | Bar | text | text | text
---|---|----|----|----|----
R | 1 | 440402.3| 5782309.3| 0.0

The 'R' line is a bit more difficult because on the same row there are actually 3 data values that need to be put into separate rows, so the first ID is missing; for each row then the following would be the result (R in ***Bold Italics*** I am making up because its not in the dataset example but you'd need it to then have nice rows of data).

R | Bar | text | text | text
---|---|----|----|----|----
R | 1 |440402.3| 5782309.3| 0.0

R | Bar | text | text | text
---|---|----|----|----|----
***R*** | 2 |440402.3| 5782309.3| 0.0

R | Bar | text | text | text
---|---|----|----|----|----
***R*** | 3 |440402.3| 5782309.3| 0.0


I believe I want to do something like this... *bare with me I am just voicing a concept of an idea it* - do you think something like this would be possible?
    
    If Row Starts with an T then Put in Table T Values, Col spacing is Col 1 =  1 Char, Col 2 = 8 Char, Col 3 = 1 Char etc etc, 
    
    If Row Starts with a C then put in Table C Values, Col spacing is Col 1 = 1 Char, Col 2 = 8 Char, Col 3 = 1 Char etc etc
    
    If Row Starts with a R then Put in Table R Values, Col spacing is Col 1 = 1 Char, Col2 = 8 Char, Col 3 = 9 Char, Col 4 = 3 Char. Then continue and split that data onto a new row for next 4 values and then split again and put the next 4 values in the following row.

Maybe all into one table is easier? Or some other form I am open to any and all suggestions... Thanks for your help everyone.",Please help me split my text file into useful tables,78f0wz,new
"Hi, a friend of mine is really interested in R recently, and as his birthday is coming up, I want to get him a book on it. He has a little experience with a few other languages (java mainly, but also python, c, ruby), so nothing too basic. He has a maths degree so the maths, stats part doesn't have to be thoroughly explained. He is also looking for a job in data analysis, so essentially a book that will be useful to learn R from, and showing best practices would be great.",Recommended books,786y4z,new
"I am having trouble understanding what to do and how to exactly go bout it for my statistics class. Our tutor had surgery half way through , and our student helper got throw in the gauntlet as our new tutor and the way she explained things was quite confusing to me as I still learning stats and R. If anyone would be able to help work through this assignment and make sure I'm on the right track and understanding whats I am doing/need to do. Any help would be appreciated as I pretty lost haha
Thank you",Need some help understanding my assignment,7845gq,new
"Hi. So my column ""STAR Level""  has values ""No STAR Level"", ""STAR 1"", ""STAR 2"", STAR 3, and ""STAR 4"". Im trying to assign these values from 0-4. Then, I'm trying to find the max value of this variable when grouped by another variable. When I try use the max function in summarize, I just get the value of NA in each spot in the column. Not sure what I'm doing wrong.

STARLevel2<-rep(NA,dim(OCDEL)[1])

STARLevel2[STARLevel==""No STAR Level""]<-0

STARLevel2[STARLevel==""STAR 1""]<-1

STARLevel2[STARLevel==""STAR 2""]<-2

STARLevel2[STARLevel==""STAR 3""]<-3

STARLevel2[STARLevel==""STAR 4 - Acc""]<-4

OCDEL%>%

  group_by(LegalEntityZipCode)%>%

  summarise(count=n(),maxSTAR=max(STARLevel2),prop=NSprop(NegativeSanctions))

",Help with assigning numeric values to strings in a column (imported from R),7829f4,new
"I need to do some pretty basic analysis of two tables ASAP--stuff that would be fast and easy in SQL--but i need to do it in R instead. Can anyone tell me the fast and easiest way to perform these two SQL queries in R?

SELECT variable1, COUNT (variable 2) AS v2, COUNT(DISTINCT v3) AS v3
FROM table
GROUP BY variable1

SELECT A.variable1, COUNT(DISTINCT A.variable2) AS av2,
B.variable1, COUNT(DISTINCT B.variable2) AS BV
FROM table1 A
LEFT JOIN table2 B ON A.variable2 = B.variable2
GROUP BY A.variable1, B.variable1
ORDER BY B.variable2 DESC, av1 ASC

I know someday I will learn to love R, but right now I'm frustrated and in a hurry. THANK YOU!",Emergency help needed on basic stuff (i hope)--table operations,77v1w3,new
"It would be nice to have, especially for beginners like myself.",Suggestion: Discord server,77rwpc,new
"I'm working through building a model for a call arrival forecast, I would want to calculate how accurate a given model is to the actuals arrival pattern given that I could predict the #of calls for a total day with 100% accuracy. To do this, I could calculate the area between the curves (actuals vs model) and see which is the smallest on average for all parameter options for the model.Now I should be able to calculate an equation which passes through the all the points by solving a system of equations of the form y= a(x)n + b(x)n-1+ ...+ and then performing numerical integration and subtracting the results to obtain the area. Is there a better way go about this? Is there a good package in R which might make these calculations a bit easier to perform?",calculate error of model in forecast,77r6jc,new
"hey all. when attempting to start up R from the command line, i'm thrown the following error:

/opt/anaconda/lib/R/bin/exec/R: error while loading shared libraries: libreadline.so.6: cannot open shared object file: No such file or directory

However, anaconda's install of python starts up just fine:

Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 13 2017, 12:02:49) [GCC 7.2.0] on linux Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.

I'm running manjaro currently. any help would be appriciated.
",Anaconda install of R via r-essentials not starting up,77plyj,new
"The main table is 34 x 86 (33 Across, 85 Down - without headings).

So I'm creating matrices of 2 columns, year and then data, out of a full data set of 33 columns/33 sets of data. In total I need 33 matrices, with year in the first column and then the different columns from the full data set. In other words, first matrix will have data from column one and so on and so on. 

Each column from the data set is a different length so the matrix must be customized to the right length with the right years, essentially the coding would have to be something along the lines of ""if the row in (named column, they're stuff like PW3F05 etc) says ""NA"" delete row and corresponding year"".

Does anybody have any idea how I should go about creating these loops? I am unsure how to create a loop that creates individual matrices and pulls the separate data. 

Thanks in advance for all of your help. ",How do I write a loop to create multiple matrices pulling data from one larger table/data set?,77nwv6,new
"Hello,
I am trying to estimate 4 unknown parameters in R with the Maximum Likelihood Estimator.

My probability density function is actually:

    h <- exp(- the * x) * (x^(gam / del - 1) / (lam * del)^(1 / del)) * 
    mlf(-(1 - lam * del * the^gam) * x^gam / (lam * del), gam, gam / del, 1 / del)
where mlf is the Mittag Leffler function (you need MittagLeffleR package)


So i wrote this code in R (yvec is the vector of observations):

    x=yvec

    LL <- function(the,gam,del,lam){
  
    h <- exp(- the * x) * (x^(gam / del - 1) / (lam * del)^(1 / del)) * 
    mlf(-(1 - lam * del * the^gam) * x^gam / (lam * del), gam, gam / del, 1 / del)
    #
    -sum(log(h))}

    library(stats4)
    mle(LL, start=list(the=2,gam=0.1,del=1,lam=2))

But what i got is:

    ""Error in optim(start, f, method = method, hessian = TRUE, ...) : 
    initial value in 'vmmin' is not finite""


Maybe is because i have not fully understood wich are the values of the parameters that i have to put into mle()

Where am i wrong?

Thanks a lot for the reading",optimization with R,77lxp7,new
"For an assignment, I have three variables (we'll call them A, B & C). I have to create a table that includes variable names, mean, median, & standard deviation.

I realize this must seem like a really dumb question but I've spent two days trying to figure this out and I've yet to find any resource (written or online) that can explain this to me.

EDIT: As a last resort, I'm using the stargazer package to generate a table that includes additional columns (eg for min value, max value etc). Is there a way to specify which columns to include or to leave out?",...How do I make a table?,77i9m3,new
"Hello,


I am trying to get the maximum likelihood estimation of a function to be later used as a variable in my model. The function has four unknown parameters and two known variables. If we let the unknowns be u1, u2, u3, and u4, and the two variables x1 and x2, it goes like this:

Qit(u1, u2, u3, u4) = [(u3)(x1it*u1)^(1-u4)  +  (1-u3)(x2it*u2)^(1-u4)] ^ (1/(1-u4))



the data for x1 and x2 is time varying (about 100 observations). I am essentially trying to estimate u1, u2, u3, and u4 in order to be able to use the entire function as a variable in my main RE model. How do I go about doing that in R? I am fairly familiar with the software but Ive never done MLE.



Thanks for taking the time to read!",MLE in R,77fjwd,new
So I am doing call center analysis. I have in one column durations of calls which are in format like this: 00:02:34. How can i convert them into proper format so I can do something with them? Thank you very much.,Manipulating time format in R,77esrf,new
"Hi all, 

I've just joined Stackoverflow so I can't post anything there yet. 

I've got a folder of CSVs - each CSV name is the store ID (i.e. 10001.csv). 

Each CSV has several columns (separated here by a comma) - (i.e. 10001 Chicago RTU 01 Stage 01 Command, 10001 Chicago RTU 01 Stage 02 Command, 10001 Chicago RTU 01 Setpoint, 10001 Chicago RTU 01 Zone Temperature, 10001 Chicago RTU 02 Stage 01 Command, etc.) 

The content of the cells need help with formatting and I'll sort through that on my own, but now I am expecting them to be character strings. 

Ultimately I need each RTU stage (there are 1-4 stages (compressors)) separated out into their own data frame. 

I don't really know how to start - any thoughts? ","help starting: seperate each CSV into data frame based on substring in column name, operate on data frame",77enso,new
"I'm trying to make an Rmd file for a shiny HTML document, my first ever attempt. I have a code chunk where I call inputPanel(), in which have added a few calls to selectInput(). This much works fine, I hit 'run' and a working document appears where I can select the desired numbers from drop-down lists as intended.

However, I then want to add a chunk where I use the numbers chosen. For now I'd just like to print those numbers using a later code chunk. When I attempt this via print(paste(...)) I get an error:

> Operation not allowed without an active-reactive context. (You tried to do something that can only be done from isinde a reactive expression or observer.)

So how do I pass my interactively-inputted numbers to this printing-out code chunk? I expect the solution to be a trivial one but my google searching isn't going well.

I have found that I can do:

> current_value <- reactive(input$variable)

and when I then just repeat 'current_value' on its own to output its value, it gives me the correct number when the document loads - but I still can't do anything with it. 

When I ask what the class of current_value is, class(current_value) returns ""reactiveExpr"" ""reactive"". When I try to turn current_value into a numeric object, I get an error:

> cannot coerce type 'closure' into type 'double'.

So how am I supposed to actually get the value of current_value into a useable form?",R markdown with shiny: how do I access / use interactively-entered values later in the code to do calculations with them?,77aenl,new
"How can I use a for loop to calculate the mean of the previous 5 years starting from Year 6/1951? Need to calculate mean of Year 6/1951 using the numbers from 1946 to 1950, then using 1947 to 1951 to get Year 7/1952

""year"",""bdeadbes"" ""1"",1946,295541 ""2"",1947,396708 ""3"",1948,472363 ""4"",1949,434321 ""5"",1950,546501 ""6"",1951,393740 ""7"",1952,147221 ""8"",1953,96986 ""9"",1954,69107 ""10"",1955,29888 ",Help - For Loop in R!,7798zc,new
"I’m looking to automate some of our reporting with R, and I’d like to keep the whole process end-to-end in R. Unfortunately many reports depend on an excel pivot table, and while there are several libraries that help you read or post data to excel, I don’t see any info on manipulating pivot tables inside excel using R. Any information, links etc would be greatly appreciated!",Reading data out of an excel pivot table,7794os,new
"Hello,
I have a dataframe

df1 <- data.frame(""Date"" = (as.Date(c(""2015-01-01"", ""2015-01-02"", ""2015-01-03"", ""2015-01-04"", ""2015-01-05""), origin = ""1970-01-01"")))

That displays:

Date

2015-01-01

2015-01-02

2015-01-03

2015-01-04

2015-01-05

and another dataframe

df2 <- data.frame(""FirstDate"" = as.Date(c(""2015-01-01"", ""2015-01-02"", ""2015-01-01"", ""2015-01-03"", ""2015-01-01""), origin = ""1970-01-01""),
                  ""SecondDate"" = as.Date(c(""2015-01-01"", ""2015-01-03"", ""2015-01-03"", ""2015-01-04"", ""2015-01-05"")))

That displays:

FirstDate      SecondDate

2015-01-01     2015-01-01

2015-01-02     2015-01-03

2015-01-01    2015-01-03

2015-01-03     2015-01-04

2015-01-01     2015-01-05

I want to find how many of the pairs each of my original dates fit into. This should display list this

df3 <- data.frame(""Date"" = (as.Date(c(""2015-01-01"", ""2015-01-02"", ""2015-01-03"", ""2015-01-04"", ""2015-01-05""), origin = ""1970-01-01"")),
                  ""Inside"" = c(3, 3, 4, 2, 1))

Date           Inside

2015-01-01     3

2015-01-02     3

2015-01-03     4

2015-01-04     2

2015-01-05     1

I believe there should be a way to do this without loops but can not get anything to work. If you have an idea it would be greatly appreciated!",completely stuck,771w5l,new
"So in R I am looping to read in all my files that end in .dat and do a certain function. fileNames <- Sys.glob(""*.dat"")
for (fileName in fileNames) { ..... However for the first file I need it to grab the 1st value in a data frame and the second file I need it to grab the 2nd value... you get the idea. Do you know how I could do this? 

**solved* thanks so much everyone!",Looping files,76zt7t,new
"I'm trying to parallelize a part of my code on our server with the foreach package. I'm reasonably new to R (I've been doing everything in MatLab before, but my collaborator only wants to use R).

The issue I'm running into is that a gigantic data matrix is duplicated for 24 times for the 24 cores I'm using and this data matrix only fits in to memory twice. 
However, each iteration only needs one column of the data. Is there a way to limit this duplication? ",foreach loop and memory management,76yvvt,new
"I want to have a nice clean code to extract ticker names from website. 

    library(tidyverse)
    library(rvest)

    url <- ""https://www.stockwatch.pl/gpw/indeks/wig,sklad.aspx""
    webpage <- read_html(url)
    ticker_names <- webpage %>% html_nodes(""strong"") %>% html_text

This is almost good but at the end I have a bit of information that is excessive, how can I subset the resulting character vector to only parts that interest me, which can be easily done in additional line of code by using ticker_names[1:388], but I would much rather have it all in one pipe.",Magrittr pipe on character vector,76tka4,new
"Hi, my dataframe (df) looks like:

    MONTH   YEAR   COUNTY1   COUNTY2   COUNTY3
    Jan      2004    100      200        300
    Feb      2004    100      200        300
    Mar      2004    100      200        300
    April    2004    100      200        300

I would like to plot a line graph, with each line representing the individual county variable, while the x axis is based off of both the month and year columns. Any help would be greatly appreciated.",Beginner Question: How to plot multiple lines on a graph,76shyz,new
I figured that I might ask before writing a lengthy comment asking for help in a specific package. ,"Has anyone here worked with the package ""Geomorph"" before?",76poqo,new
"I mean every time you load a workspace, you still have to use the library() function to call the specific library when starting a new session?",Saving a R workspace doesn't save the libraries loaded?,76c1q0,new
"If I try to construct a decision tree model using the rpart() function as follows, I find it has an overall accuracy of about 76%.

> modfit_rpart <- rpart(classe ~ ., data = training_subset, method = ""class"")

However, if I try doing the same thing with the train() function and specifying the method = ""rpart"", I find I only have 50% accuracy:

> modfit_train_rpart <- train(classe ~ ., data = training_subset, method = ""rpart"")

I also have tried incorporating cross-validation as follows:

> modfit_train_rpart2 <- train(classe ~ ., data = training_subset, method = ""rpart"", trControl = trainControl(method = ""cv"", number = 10))

This makes no difference, I find the accuracy remains 50% after apparently applying 10-fold cross-validation. 

What could be the reason for these functions to behave so differently and for my cross-validating to have no effect?","Big difference between rpart() and train(..., method = ""rpart"") and attempts at cross-validation appear to fail?",766w7e,new
"I am new to R, but I made a map of the fastest growing businesses in the US by location using multiple packages. What I cannot seem to do is separate the points by industry type (25 types in all). I would like to use something like: col=rainbow(25) and assign them each to different colors as well as with a legend but I am not sure where to go from here as far as using industry type to describe different points. The data: https://data.world/aurielle/inc-5000-2017

Thanks


    library(ggmap)
    library(raster)
    library(zipcode)
    library(dplyr)
    library(plyr)
    attach(business)
    ZipCount <- as.data.frame(table(unlist(business$zip)))
    zipindustrycount <-  within(business, {
      count = ave(Industry, zip, FUN = function(x) length(unique(x)))
    })

    View(zipindustrycount)

    View(ZipCount)




    usa_center = as.numeric(geocode(""United States""))
    USAMap = ggmap(get_googlemap(center=usa_center, scale=2,         
    zoom=4), extent=""panel"")

    ZipCount <- merge(as.character(ZipCount$Var1), zipcode,     
    by.x='zips', by.y='zip')

    require(zipcode)
    data(zipcode)
    zipcode
    ZipCount$Var1 <- clean.zipcodes(ZipCount$Var1)
    zips <- data.frame(zip = c(ZipCount$Var1))
    ZipCountNew <- merge(zips, zipcode, by.x= 'zip', by.y='zip')

    View(ZipCountNew)

    lonlatcount <- count(ZipCountNew, c(""latitude"", ""longitude""))

    View(lonlatcount)

    for (i in 1:nrow(lonlatcount)) {
      latlon = geocode(lonlatcount[i,1])
      lonlatcount$longitude[i] = as.numeric(latlon[1])
      lonlatcount$latitude[i] = as.numeric(latlon[2])
    }

    USAMap +
      geom_point(aes(x=longitude, y=latitude, 
    color=business$Industry), data=lonlatcount, 
    fill=as.factor(lonlatcount$freq), col=""red"", alpha=.1, 
    size=as.numeric(lonlatcount$freq)*2) + 
    scale_size_continuous(range=range(lonlatcount$freq))
",Mapping business locations by industry type,75yf9d,new
"I am trying to find an easy way to convert Long/Lats into UTMs.  I found a video that runs through the process and it seems fairly simple to follow, but when I run it I keep getting an error of unknown projection ID.  This is the code.  

    Locations<-read.csv(""ControlLongLat.csv"")
    Locations=subset(Locations, select=c(ID, Long, Lat))
    Locations

    LongLatToUTM<-function(x,y,ID,zone){
    xy <- data.frame(ID=ID, X=x, Y=y)
    coordinates(xy) <- c(""X"", ""Y"")
    proj4string(xy) <- CRS(""+proj=longlat +datum=WGS84"")
    res <- spTransform(xy, CRS(paste(""+proj=utm+zone="",zone,""        
    ellps=WGS84"", sep='')))
    return(as.data.frame(res))
    }

    x=LongLatToUTM(Locations$Long, Locations$Lat, ID=Locations$ID,18)

And this is the error I'm receiving

    Error in CRS(paste(""+proj=utm+zone="", zone, "" ellps=WGS84"", sep = """"))                      
    : unknown projection id 


Any help would be greatly appreciated.

Thanks!


   ",Converting Long/Lat to UTM,75s440,new
"I love Rstudio, Especially the new release. But I was wondering what other developer environments people here use. I've come across emacs + ESS, Visual Studio, and more lightweight editors like Atom/VS Code with a bunch of extensions added in. What setup do you all use?",Alternatives to Rstudio for an R development IDE,75ne6z,new
"I'm thinking about purchasing this book: https://www.amazon.com/gp/product/1788397878/

Curious if anyone else has something they would recommend.",Good resource/book for Neural Networks in R?,75lli6,new
Is there a way to see the source code for the centralimputation and manyNA functions in the DMwR package?,DMwR package,75ixue,new
"Sorry if this is a stupid question. I tried googling it but couldn't find an answer.

I need to calculate the population standard deviation of my population. I believe sd() calculates sample standard deviation. Is there a formula to directly calculate population in standard deviation? I was just planning on working backwards from sample sd, but I figured there was a straight way on R. ",Calculating Population Standard Deviation?,75hzpt,new
"Could anyone help me with this question? I am a beginner and have no idea how to write this loop. 

We may want to create a data-set based on raw data - in this case weather stations. Attached is data from weather stations in the US in 2009. Your goal is to make a loop that creates 12 .csv files that contain weather station level means for each month’s maximum daily temperatures. HINT: The best way to collapse (take the mean across multiple observations of the same variable) data in R is the 'summaryBy' command.",Basic R Question on Loops,75dkko,new
"Just curious if anyone has come across a good resource for more robust, aesthetic, shiny apps?",Best Guide For Advanced Shiny Development?,75aprf,new
"I am relatively new with R. I am just starting to play around with ggplot2 and Plotly. Here is my code:
    

    library(ggplot2)
    library(plotly)
    library(plyr)
    
    Sys.setenv(""plotly_username""="""")
    Sys.setenv(""plotly_api_key""="""")
    
    stats <- read.csv('RMFFstats.csv')
    
    subTD <- subset(stats,Season=='2016-2017' & Starter==1 & Pass.TD>0)
    
    TD1617 <- ddply(subTD, .(Team,Name), summarise, Pass.TD=sum(Pass.TD))
    
    pl <- ggplot(TD1617,aes(Team,Pass.TD, fill = Name)) + geom_bar(stat = 'identity', position = ""stack"") +theme(legend.position = 'none')
    
    print(ggplotly(pl))
    
    chart_link = api_create(pl, filename=""RMFFtdsNEW"")
    chart_link        

I have the plotly login information filled in when I execute my code. I am using some fantasy football data I have scraped from one of my leagues: [data](https://i.imgur.com/dOSWL4i.jpg). For some reason when I make the grpah in Rstudio it looks exactly like I want it to: [Rstudio Graph](https://i.imgur.com/E3OaDOF.jpg). But, once I sign into Plotly and check it out on the site my x axis labels aren't the team names, they are numbers: [Plotly Graph](https://i.imgur.com/Sgu14f7.jpg). What am I missing here? There must be a disconnect in my code or the way it publishes to Plotly, has anyone else run into this issue?
 ",ggplot2 and Plotly bar chart help,759unm,new
"How do I exclude the variable column from being fed with the rest of the subsetted dataframe to the user defined function?

Note the variable is what subsets the dataframe for the user defined function.
",Excluding the variable column from ddply function?,756ola,new
"Hi, and thanks in advance. I'm brand new to R, so much so that I actually have no idea whether this question is easy or hard.

I have a dataset that I need to reshape for a specific analysis. It's currently a row-level dataset, with an ID  column and many (15+) additional columns that are mostly flags (0,1) or (yes/ no), but where a few have more responses (a few are over 10 options, etc).

I need to output another dataset with every possible combination of flags, one unique combination per row, each with a distinct count of IDs that meet the conditions in that row. Additionally, I need to include counts where the flag could be either condition (so to restate, that's a count where 0=TRUE, another count where 1=TRUE, and a third count where 0=TRUE or 1=TRUE--but in all combinations for all variables). 

In other words, I need to produce all the same results you could get if you were visualizing the distinct count in Excel or Tableau or whatever and had a user filter available on every variable. And yes, in normal circumstances that is just what I'd do, but that's not an option this time around (the reasons are legal/ business related and out of my control).

Obviously I could go through the arduous process of manually typing in every possible SummaryBy()...but surely there's a better way? Is there a function that just does this?  Also, I actually have many projects where I could use a function like this, so the more versatile the answer, the happier I'll be.

Thanks!

example below:


ID | Flag1| Flag2| Flag3
---|---|----|----
1| 0| 0| 1
2| 0| 1| 0
3| 0| 0| 0
4| 1| 1| 1
5| 1| 0| 1
6| 1| 1| 0


needs to become:

Flag1| Flag2| Flag3| count
---|---|----|----|----
0| 0| 0| 1
0| 0| 1| 1
0| 1| 0| 1
0| 1| 1| 0
1| 0| 0| 0
1| 0| 1| 1
1| 1| 0| 1
1| 1| 1| 1
all| 0| 0| 2
all| 0| 1| 2
all| 1| 0| 2
all| 1| 1| 1
....
etc. Obviously this table will be very tall but I don't know what else to do given the constraints of this project.
 

",How to summarize a column by every possible grouping of other columns?,7560b8,new
"Has anybody been able to export a model fitted with nls to PMML? I'm fitting a model as follows and would like to be able to save the result to PMML:
 
    fit <- nls(log10(y) ~ log10(x1*a + x2*b + x3*c), ... )",NLS + PMML?,74xs3y,new
"Hi all,

Let's describe a hypothetical situation. Let's say that you work in cooperation with two Uni professors, and one is using Linux, but the other one is using MS Windows. Now, R is multiplatform language so it's not a big deal. After some time, they ask you if you could provide implementation for their statistics in form of a R package. The trick is that it must be insanely fast and well optimized. Naturally, you chose to write it in C++, which is fine because now we have Rcpp to bundle it more easily. But, that multiplatform thingie is no longer true. Sure you could build a package with the compiled sources for Linux and get .so file inside your package, and do the same for MS Windows and get .dll. But now you're stuck with two different (but conceptually the same) packages - one for each platform.

Let's now generalize. If you're not working with two professors, but creating a package that a lot of people can use, you don't have the option to place them at a single computer or something similar. Also, how do you get it in CRAN if you have two packages with the same name and purpose?

TL;DR: how to create one single R-package with C++ (Rcpp) that works on both Linux and MS Windows?",Can one build a package for both MS Windows and Linux with Rcpp?,74ul77,new
"I have a tricky file that I need to import to R, and I'm struggling with the best way to do so. Here is an example of the first 10 lines of the file:

    15.26	14.84	0.871	5.763	3.312	2.221	5.22	1
    14.88	14.57	0.8811	5.554	3.333	1.018	4.956	1
    14.29	14.09	0.905	5.291	3.337	2.699	4.825	1
    13.84	13.94	0.8955	5.324	3.379	2.259	4.805	1
    16.14	14.99	0.9034	5.658	3.562	1.355	5.175	1
    14.38	14.21	0.8951	5.386	3.312	2.462	4.956	1
    14.69	14.49	0.8799	5.563	3.259	3.586	5.219	1
    14.11	14.1	0.8911	5.42	3.302	2.7		5		1
    16.63	15.46	0.8747	6.053	3.465	2.04	5.877	1
    16.44	15.25	0.888	5.884	3.505	1.969	5.533	1

As you can see, there is a problem in the 8th line. This causes all of the tabs to be shifted, and I don't get the correct columns when importing into R.

    > seeds <- read.delim(""seeds_dataset.txt"", header = FALSE)
    > seeds[1:10,]
          V1    V2     V3    V4    V5    V6    V7 V8
    1  15.26 14.84 0.8710 5.763 3.312 2.221 5.220  1
    2  14.88 14.57 0.8811 5.554 3.333 1.018 4.956  1
    3  14.29 14.09 0.9050 5.291 3.337 2.699 4.825  1
    4  13.84 13.94 0.8955 5.324 3.379 2.259 4.805  1
    5  16.14 14.99 0.9034 5.658 3.562 1.355 5.175  1
    6  14.38 14.21 0.8951 5.386 3.312 2.462 4.956  1
    7  14.69 14.49 0.8799 5.563 3.259 3.586 5.219  1
    8  14.11 14.10 0.8911 5.420 3.302 2.700    NA  5
    9     NA  1.00     NA    NA    NA    NA    NA NA
    10 16.63 15.46 0.8747 6.053 3.465 2.040 5.877  1

Any help is appreciated!

________________________________________

EDIT:

I just realized that the alignment of the tabs doesn't show up when I paste the text into reddit, but when I look at the text file on my computer, there is a empty space where the 5 in row 8 is. the 5 and the following 1 are each moved one column to the right, where the 1 makes it's own column. There are similar issues like this throughout the file.",Importing an unorganized tab-delimited file?,74ql4v,new
"https://imgur.com/a/6iKWm

I tabled out 4 different metrics by date and tried to merge then with 4 merge commands. It did not work well. Help!

woo <- merge(xx, cdates, by.x = ""dates"",by.y=""Var1"",all.y=TRUE, all.x=TRUE)

woo <- merge(woo,date.tab,by.x = ""dates"", by.y = ""Var1"", all.y=TRUE, all.x=TRUE)

woo <- merge(woo, off.tab, by='dates', by.y = ""Date"", all.y=TRUE, all.x=TRUE)

woo <- merge(woo, show, by = 'dates', by.y = 'Dates',all.x = TRUE, all.y=TRUE)

woo <- woo[,c(1,3,4,5,6)]

woo <- aggregate(dates, data = woo, FUN=sum)","Oh god, how do I consolidate these rows? (Amateur Merger)",74ocbi,new
"The websockets package doesn't work with newer versions of R and httpuv is related to websocket servers, not clients.  I need to connect to the Cryptocompare websocket, or a similar one.  I'm specifically looking for pricing data and network hashrate data.  I currently use their API, which is too slow for my needs.

If you can solve this problem, I'd be happy to send you $20 USD worth of your choice of cryptocurrency.  

Thanks for reading!


Cryptocompare websockets info: https://www.cryptocompare.com/api/#-api-web-socket-

Old version of websockets: https://cran.r-project.org/src/contrib/Archive/websockets/



Edit:  Someone helped me solve my problem in a different way.  Thanks to all who helped!",$20 USD worth of any cryptocurrency (that is available on Bittrex) if you can help me connect to a websocket in R,74lhfq,new
I'm just wondering if there is a package in R which mimics many of the more common excel functions.  ,Is there an excel functions package?,74ff1z,new
"Is there a package that can do this easily? I found scale(), but its calcs don't match my own from excel. I'm new to R, and I know I can write a simple equation to transform the data, but I don't feel confident yet to do so.
Any help is greatly appreciated.",Calculate z-scores for a variable,74dlic,new
"Hey everyone, first time submitter here. I'm a moderately experienced Stata programmer, fairly new to R. I really like R and would like to use it more. I don't understand very well what different levels of RAM, processing power, and software may offer.

* I'm currently running Stata MP 14.2 6-core on a Xeon 3.6 GHz processor. 64 GB RAM. (Not sure what other specs may be needed.)

Generally speaking, this software on this machine can chew up and spit out nearly any data set. The only thing I've tried that took more than 30 seconds was a for-loop with 100M+ observations (only about 1000 variables, but still).

Since I find R more intuitive than Stata, and it's a lot easier to find good, uncondescending help for R, my question is:

* Is there a number of observations beyond which a basic version of R doesn't make sense to use, in the same way that Excel stops making sense at some point? 
* Is there a number of variables beyond which that would be true? 
* Is there an easy way to soup up R such that it could compete with Stata on a dataset with 100M observations and thousands of variables?

Please forgive any inconsistencies or failure to address any relevant information. My favorite thing about the R community to this point is that it is friendly and very rarely condescending.",R versus Stata,74a49v,new
"say I have a list of 20 numbers and I want to generate a new list of all possible summations I can achieve from summing 2 or more of these numbers (can include the two trivial cases of summing 0 or 1 numbers). Any idea how I can go about that? Ideally I would want a list of all possible summations, as well as the numbers that were summed to get that number. ",algorithm to give all possible sums from a list of numbers,748nhv,new
"Let's say I have a character vector:

x <- c(""one"", ""two"", ""three"")

I want to enclose each of these terms with [ ].

result <- c([one], [two], [three])

What's the best way to do this?",Appending Symbols Around Character Vector,7446xw,new
"Is there a easy way (like using JSON) to fetch data from Dynamics CRM using R?

This needs to be free so no Azure solutions.",Connecting to MS Dynamics CRM using R,74008t,new
"Hi, 

I have a large list item that consists of text from 11 files. What I want to be able to do is take each of the lists and split by a specific pattern, storing each of the output rows in a matrix with the filename and each output line. 

For example list item x is a file called sample1.txt, it consists of 100 lines of text seperated by a given character. Eventually creating a matrix with two columns, one being the file name and the other being each line from the text file.

I had this working on one file using readChar to read the file and then a combination of unlist and strsplit to create a matrix. Now I can't quite think how to do this in R and avoid using a for loop. Any suggestions would be appreciated.

Thanks!",R list to matrix,73s4qp,new
"Any help would be greatly appreciated, and I'm offering reddit gold in return, thanks!",Can anyone help me to create a function to do cross validation for ridge regression in R?,73rxdw,new
"Hi guys,   
I am quite new to R so this is probably a stupid question, but I couldn't figure out how to do this. This is the code:  
  
    liste <- c(""package:stats"",""package:graphics"",""package:datasets"")  
    lsp <- function (package, all.names = FALSE, pattern) {
        package <- deparse(substitute(package))
        ls(pos = paste(package), all.names = all.names, 
            pattern = pattern)
    }  
    
    for (things in liste){
         print(lsp(things))
    }
  
So my problem now is that I get the following warning:  
  
    Error in as.environment(pos) : no item called ""things"" on the search list  
  
This means the function passes the string ""things"" instead of the variable things(in the for loop).  I don't know how to fix this. Any advice would be appreciated 
  
Thanks for your help in advance  
Edit: if I call the lsp function like this: lsp(package:stats) this executes fine and does what I want. So the function is working correctly
",Problem passing a variable to a function,73l4n9,new
"Hi there,
i am currently trying to find a solution for the following problem:

Here is my Code:

    library(dplyr)
    library(datasets)

    data(mtcars)

    zyl <- group_by(mtcars, cyl, gear)


    per.zyl <- summarize(zyl, Mittelwert = mean(mpg), 
                              Anzahl = n(), 
                              Median=median(mpg), 
                              Minimum = min(mpg), 
                              Q25 = quantile(mpg, c(.25)), 
                              Q75 = quantile(mpg, c(.75)), 
                              Maximum = max(mpg))

    per.zyl

This is already not that bad, but i need to display the summary statistics for all possible group combinations of cyl and gear. For example for the group cyl = 8 | gear = 4. This will be a line filled with zeros or NAs. ""Drop = False"" does not work in the dplyr environment. 

With my Code above i get the following output:

    # Groups:   cyl [?]
        cyl  gear Mittelwert Anzahl Median Minimum    Q25    Q75 Maximum
      <dbl> <dbl>      <dbl>  <int>  <dbl>   <dbl>  <dbl>  <dbl>   <dbl>
    1     4     3     21.500      1  21.50    21.5 21.500 21.500    21.5
    2     4     4     26.925      8  25.85    21.4 22.800 30.900    33.9
    3     4     5     28.200      2  28.20    26.0 27.100 29.300    30.4
    4     6     3     19.750      2  19.75    18.1 18.925 20.575    21.4
    5     6     4     19.750      4  20.10    17.8 18.850 21.000    21.0
    6     6     5     19.700      1  19.70    19.7 19.700 19.700    19.7
    7     8     3     15.050     12  15.20    10.4 14.050 16.625    19.2
    8     8     5     15.400      2  15.40    15.0 15.200 15.600    15.8
    
Instead I need:

    # Groups:   cyl [?]
        cyl  gear Mittelwert Anzahl Median Minimum    Q25    Q75 Maximum
      <dbl> <dbl>      <dbl>  <int>  <dbl>   <dbl>  <dbl>  <dbl>   <dbl>
    1     4     3     21.500      1  21.50    21.5 21.500 21.500    21.5
    2     4     4     26.925      8  25.85    21.4 22.800 30.900    33.9
    3     4     5     28.200      2  28.20    26.0 27.100 29.300    30.4
    4     6     3     19.750      2  19.75    18.1 18.925 20.575    21.4
    5     6     4     19.750      4  20.10    17.8 18.850 21.000    21.0
    6     6     5     19.700      1  19.70    19.7 19.700 19.700    19.7
    7     8     3     15.050     12  15.20    10.4 14.050 16.625    19.2
    8	   8	  4		 0      0	   0	     0	         0	    0	      0
    9     8     5     15.400      2  15.40    15.0 15.200 15.600    15.8
    




Any ideas how to solve this issue?

Thanks in advance and have a nice day!

Zalatann
",Need help with dplyr: Show all possible group combinations,73kmt9,new
"Hi!

I studied some econometrics in uni and some basic statistics. But I'm rusty. I have also got some very limited experience with R. I have been googling around but feel that there's often a 'gold standard' site which communities know about and googling doesnt highlight. Does anyone have any suggestions for sites that have a good flow and teach me about data analysis and regression in R? Thanks heaps.",Looking for a comprehensive but digestible tutorial set on data exploration and linear regression in R,73kh2k,new
"I've needed to create R Markdown documents for work recently, and I've noticed that some types of figures, biplots, really mess up the created pdf when rendered. The pdfs have been freezing on the pages with these graphics, and I'm wondering if I can fix this problem by compressing graphics included in the knitted file?",Is there a way to compress graphics in R Markdown?,73ifyp,new
"I'm certainly missing something really stupid, but I don't know R and have had to cobble some stuff togetheter for work.

It needs to be order() rather than sort() as I'm sorting >1 column in the actual script.

    ds <- ChickWeight
    attach(ds) #Sorted by Chick, Time
    
    #ds returns 
    ds <- ds[order(weight),]
    
    ds$weight #expected order
    paste(weight) #original order

I'm guessing that order() only affects the return when I'm returning directly from the dataframe - any advice would be gratefully received!",Reordering a data frame,73a5fo,new
"I have a shiny app that reads from my dropbox, but looks to be down now, is there a way to read from dropbox?",Read from Dropbox no longer working?,736ra4,new
"I have a dataset where I've trained a model to predict a categorical outcome (it's done via train() with method = ""rpart"" if i hat matters) that has 5 levels (A,B,C,D and E).

I've then used predict(), passing it my model and also the 'testing' portion of the data that was set aside beforehand (which contains 20 observations for me to predict an outcome for).
 
When I then pass the resulting object to table(), it returns something that appears sensible:

A  B  C  D  E 

1  3  0  5 11

So, so far so good. I have my 5 levels ABCDE, and 1+3+0+5+11 = 20, which matches the size of my 'testing' dataset (let's just say it's stored as 'testing_dataframe').

However, I then want to generate a confusion matrix. So, I pass the object generated by predict() to confusionMatrix(), along with another argument that I've seen done in other examples, which is of the form

> testing_dataframe$name_of_outcome_column_in_training_data

At this point I get an error:

> Error in confusionMatrix.default(prediction, testing_dataframe$name_of_outcome_column_in_training_data): the data cannot have more levels than the reference

This makes no sense to me, because the 'data' (i.e. what we're calling 'testing_dataframe' here) should have no levels at all - the column for the outcome has no values in it, they're left blank so they can be predicted.

Does anyone have any idea of the way forward? ",Predicting with Caret - confusionMatrix() giving me annoying error?,733g6p,new
"head of my df looks like this:
 
     MONTH AIRLINE ARRIVAL_DELAY
         1      NK            25
         1      NK            43
         1      HA            15
         1      B6            20
         1      B6            85
         1      B6            89

I previously used the table function to create a new df that was a frequency counted for all ARRIVAL_DELAY's.
Now I want to do the same thing but grouped by each airline. Sorry, I'm kind of an R noob, trying to practice my DF manipulation and DPLYR skills.",Having trouble figuring out how to count the frequency of a numeric string grouped by a factor of another string in my df,732a5g,new
"So I am an R newbie and I am taking an online modeling/analytics course which uses R as the programming language. A lot of the problem set solutions include the following lines:

# Setting the random number generator seed so that our results are reproducible
# (Your solution doesn't need this, but it's usually good practice to do)

set.seed(1)

What exactly does this line of code mean? I kind understand it but want further clarification on it. Thanks!",What does set.seed() actually mean?,7308vw,new
"How do I put this data:
V1 V2 V3 V4

1 426 609 556 600

2 253 236 392 395

3 359 433 349 357

4 432 431 522 600

5 405 426 513 513

6 324 438 507 539

into this code:

> data <- as.matrix(data)

> datanew <- data%*%t(C)

> onesampletest(data=datanew, mu0=c(0,0,0), alpha=0.05)

[1] ""T2: 116 critical: 10.93""

> Snew <- C%*%S%*%t(C)

> xbarnew <- C%*%xbar

> outputSimul <- onediminterval(xbar=xbarnew, S=Snew, alpha=0.05, n=n, option=""Simul"")

[1] ""Var1:(135.7,283)""

[1] ""Var2:(-114.7,-5.38)""

[1] ""Var3:(-78.7,53.1)""

> outputBonf <- onediminterval(xbar=xbarnew, S=Snew, alpha=0.05, n=n, option=""Bonf"")

[1] ""Var1:(150.5,268.1)""

[1] ""Var2:(-103.7,-16.41)""

[1] ""Var3:(-65.4,39.8)""

 
to test for treatment effects using a repeated measure design.","I don't know how to code in R. My professor provided some example code for a problem, but I don't know how to incorporate a data set into it.",72zpkf,new
"Today, data scientists are generally divided among two languages  —  **R** and **Python**.

**What is the best way to integrate both languages in one data science project? What are the best practices?**

Beside git and shell scripting additional tools are developed to facilitate the development of predictive model in a multi-language environments. For fast data exchange between R and Python let’s use binary data file format **Feather**. Another language agnostic tool **DVC** can make the research reproducible  —  let’s use DVC to orchestrate R and Python code instead of a regular shell scripts: **[Best practices of orchestrating Python and R code in ML projects](https://blog.dataversioncontrol.com/best-practices-of-orchestrating-python-and-r-code-in-ml-projects-f28f3a879484)**
",Best practices of orchestrating Python and R code in ML projects,72nh2n,new
"I'm pulling in a bunch of tables from an SQL database to figure out what's in them (I don't have a list of what each table is) and I have several that take a really really long time to pull the data. How can I tell the script ""if it takes longer than n seconds to pull a table, stop pulling the table and move on to the next table."" Also does anyone know how to pull a subset of a table directly? Sorry I'm new to pulling data like this. Here's my code so far.

#grab table names
tablenames <- as.data.frame(sqlTables(con))

tablenames <- tablenames[ , 3]

#pull each table 
for (a in 1: nrows(tablenames){

    query <- paste0('select * from ',tablenames[a])

    x<-as.data.frame(sqlQuery(con, query))

    #rename each dataframe as its table name

    do.call(""<-"",list(tablenames[a],x))

}

thanks",need code to stop if its taking to long to run,72d6xa,new
"Hi All! for this to make sense please see my first post:
https://www.reddit.com/r/Rlanguage/comments/70cq2l/trying_a_new_way_to_measure_accuracy/

Now that I have thousands of lines of variances calculated for my data I was wondering if anyone has any suggestions on how I could possibly plot these variances I found. Of course, plotting them all on the same graph would be messy so I was thinking about plotting the top 5 or ten parts on a graph. Issue I have is that I can't find any good graphs to plot this data with, I would also have to plot it by month. 

I was thinking about exploring the GGplot2 package as it seems to be the undisputed king of data visualization.

I'm open to all ideas and suggestions!",Proper way to display variances?,729846,new
"Completely new to R programming and Shiny, I've created some very basic reactive tables and wanted to try graphs. However, the examples I found pull data from some other source. I wanted to allow the user to input their own X and Y coordinates onto a scatter plot. Would the syntax be similar to a reactive table?",Help with User Inputted Graphs,71vxun,new
"I'm running a for-loop to create multiple dataframes, and I want to name them each something according to a list of names I have. How can I use assign variable names to a dataframe using a list of pre-assigned names? 
 
For clarification, I want to set the actual name of the dataframe and not the columns in the dataframe",changing the name of a dataframe using a list of names,71t27g,new
"I have several files exported out of a database system. The file type says Microsoft Excel 97-2003 Worksheet (.xls) but when I go to open the file manually I get a popup saying ""The file format and extension of <filename> don't match. The file could be corrupted or unsafe...."" and I have to manually click yes to get the file to open. I then have to go to save as and it defaults the file type to webpage, and I have to change it to excel and save it so I can properly read in the file for processing. I'm trying to come up with a workaround so that R does this whole process (sans exporting the file from the system itself) Any ideas? ",Script to open file and save as different file type,71cwgl,new
"I'm a beginner coder but I'm trying to use R in my materials data processing.

I have a simple question, I know that I can index out a column in a data.frame as a numeric using logical indexing

dat<-dataframe$columnheader

class(dat)

gives numeric

But I get a data.frame object when I do numeric indexing

dat<-dataframe[1]

class(dat)

Gives back a data.frame and I can't convert it to numeric using as.numeric()

I'm now trying to do processing on data that requires my to pull pairs of columns as numeric objects. I'm trying to do that with a for loop, but I can't do that using vector indexing. I know there must be a really simple thing I'm missing - can anyone point it out to me?

",[basic] How to call a column from a data.frame as a numeric,716anx,new
Best R webinars and/or training (preferably live)? Thanks!,Best R webinars and/or training (preferably live)?,7162a6,new
"Formatting is kinda messed up, please see the formated text here: https://imgur.com/mnuQ8U8

Hello!


I have a data frame that has several columns and rows, something like:

        -----  |  Jude  | Mike   |Jessie | etc...
        Bio    |  85     | 45      | 80 
        Math |  23     | 89      | 85
        Chem|  95     |90       |34


And another datafame, with the same col and row names but has logical values:

        -----  |  Jude  | Mike   |Jessie | etc...
        Bio    |TRUE   |FALSE  |TRUE 
        Math |FALSE  |TRUE   |TRUE
        Chem|TRUE   |TRUE   |FALSE


And I'd like to use the two dataframes and apply a function (sum, mean or whatever) on the first dataframe based on the second dataframe logical values. In example, if I'm to sum the first dataframe based on the second one I will get:

        -----  |  Jude  | Mike   |Jessie | etc...
        Sum  |178     | 179    | 165



Please help me to figure out how it can be done in R!


Thank u :)",Sum dataframe values based on logical dataframe [HELP ME],711fp0,new
"I have a data.table (we'll call him Randall).  I then do an action on it like:

    Randall[,.N,.(Country,State,County,Town)]

and save this result as a new data.table (Act <-Randall[,.N,.(Day,Hour,Minute,Second)] )

Randal has time series also, so then my question is, How do I use Act to perform calculations on Randall to avoid for-looping.  So say I want to do:

    [pseudo-code]:
    for(C in Randall$Country){
      for(S in Randall$State){
        for(c in Randall$County){
          for(T in Randall$Town){
            make_a_timeseries(Randall[CScT, subset_of_data])
            forecast(that_subset)
    }}}}

I initially played with some sapply's and Act, (for a different task) but with this many parameters, it's slogging, and I know there has to be a better way.

Or, is for looping (which I thought was blasphemous in R) actually how you would do it?  Any way to make it time-efficient is really what I'm after (memory efficiency is no concern on this data-set)

Asking for a friend(literally), but with apologies, as I'm fairly new to ""thinking vectorially"" as I've programmed in c for over 20 years and have gotten very comfortable in my for-loop rut.

-------------------------EDIT 0------------------
Clarification for ""What I'm trying to do"":

Let us say that Randall has these columns:

    Country,State,County,City,Date,Year,Week_Num,Hits,Misses,Ammo,random_int

And that my code inside the for loop(pseudo, cos it's quicker):

    {
      Randall_Slice<- Randall[CScT,]      # Calling it RS for short
      TimSer <- ts(Randall_Slice, start = c(RS[1]$Year,RS[1]$Week_)Num), end=c(RS[.N-F]$Year,RS[.N-F]$Week_Num), freq = 52)
      seasdec = stlm(TimSer, some args)
      fc <- forecast(seasdec)
      pred <- c(rep(NA,len_new),summary(fc)$'Point Forecast'[2:(forecast_weeks+1)])
      resids = slice[,Some Cols]
      some extra stats stuff that can be moved out of for loop to after everything else is done
    }

",Using a data.table (or frame) to act on another data.table (or frame),70yqwe,new
"I'm trying to create an HTML file using rmarkdown, but the HTML is not displaying the results I'm expecting.

I AM NOT USING THE IDE.

I have installed the following successfully:

    install.packages(""rmarkdown"")

    library(""rmarkdown"")

    install.packages(""knitr"")

    library(""knitr"")

I have also installed Pandoc.
Was getting this error: ""Error: pandoc version 1.12.3 or higher is required and was not found (see the help page rmarkdown::pandoc_available).""

1) installed Pandoc
2) found the folder Pandoc was installed in
3) used command
    Sys.setenv(RSTUDIO_PANDOC=""c:/Users/user_me/AppData/Local/Pandoc"")

I'm using 
    rmarkdown::render(""c:/Users/me_user/Desktop/RScripts/RMD Files/my_rmd_document.txt"")

to render the HTML.

I'm using a copy of this RMarkdown document as ""my_rmd_document.txt"".

http://rmarkdown.rstudio.com/demos/1-example.Rmd

from this page

http://rmarkdown.rstudio.com/lesson-2.html

The only changes I've made are to replace the lines referencing the image command with

    plot(0,1)

and

    image(volcano)

and added the following section:


```{r}
dim(iris)
```

Here are the issues:

This

{r include = FALSE} library(viridis)

is displayed in the web browser.

The code for the plot, image, and dim commands displays and looks like code, but doesn't display results.  The code doesn't seem to run.  I don't get the plot, the image, or the results from the dim command.

If anyone has any ideas I would really appreciate it.

Thank you
",RMarkdown,70wt4g,new
"Hi guys, complete newb to R here. I've looked around on google, but I can't figure this out so I came here.

Basically I have a VM that has no internet access. I've downloaded various packages that I need to install to a local directory (C:\R)

I'm wanting to install these packages without internet access and to a global location. Can someone help me on how I would accomplish this. I've figured out how to install locally, but not with a global path also. I can only install to the My Documents location.

Any help would be appreciated.",Help Installing Packages,70rzkl,new
"Hello all! I'm a beginner with R and I'm wondering how to best convert date data into a form that I can use on the x-axis of a graph.

I currently have data that looks like this:

Year          Month     Day    Hr    Value     Value     Value....
####       #           #        #     #          #           #

I'd like to convert it to decimal form for the most accuracy on my graph. Any ideas on how best to do this? I know this is probably a simple question, but as I said I'm still very much a beginner.

Thanks in advance!",Converting date columns to decimals?,70oqlo,new
"I'm trying to build a heatmap (colours remains static so it's really just a background) with categorical data where the X axis is a range of 5 categories (least likely to happen to highly likely) and the Y axis with another 5 categories (low impact to high impact)

I have built this (https://imgur.com/MR3pONK) base foundation and would like to be able to plot labeled data points overtop of the heatmap depending on which categories they have been labeled with. 

There will be few data points (under 20) drawn on the heatmap and my google searches have not been successful. My next attempt may to be creating a background and just figuring out how to sort and order them depending if they fall within the same space. 

Any tips or ideas to point me in the right direction would be much appreciated. 

This is what I have made to far for testing:
library(ggplot2)
library(grDevices)
library(reshape2)
library(RColorBrewer)

bg<-matrix(c(1,2,3,4,5,
             2,3,4,5,6,
             3,4,5,6,7, 
             4,5,6,7,8,  
             5,6,7,8,9),
           nrow=5,ncol = 5, dimnames = list(c(""Low"",""Medium Low"",'Medium','Medium High','High'),
                                            c(""Low"",'Medium Low','Medium','Medium High','High')))
bg.melted<-melt(bg)

names(bg.melted)<-c('Impact','Likelyhood','Value')
hm.palette <- colorRampPalette(rev(brewer.pal(11,'RdYlGn')),space='Lab')

ggplot(bg.melted,aes(x = Impact, y =Likelyhood,fill = Value)) + 
  geom_tile() +
  coord_equal() +
  scale_fill_gradientn(colours = hm.palette(100),guide = F)
",'Heatmap' with data points,70dqm3,new
"Hi All, any and all help would be appreciated. This example is over simplified of course but the two data frames below will help explain what I am trying to accomplish.

    #Sales
    sales <- data.frame(""part""=c(1:2,5), ""region""=c(""region1"", ""region2"", ""region6""), ""Qty""=c(10,40, 100), ""Date""= c(""2017-09-15"", ""2017-08-15"", ""2017-07-15""))
    #forecast
    forecast <- data.frame(""part""=1:3, ""region""=c(""region1"", ""region2"", ""region3""), ""Qty""=c(15,40,50), ""Date""= c(""2017-09-15"", ""2017-08-15"", ""2017-07-15""))
    sales
    forecast

This is kind of hard to explain just by typing so I will try my best. 
I am trying to measure accuracy of the forecast fore each part number with 2 separate criteria being region it is forecasted in and date, I am still somewhat a novice at R Code so that is why I am looking for help here. Essentially, I am trying to find the variance between the forecast and sales (Sales - Forecast) of the two data frames above. Once accomplished, the forecast from part 1 region 1 would be subtracted from sales of part 1 region 1 because they share the same date and region. Please see the desired output. Also note, because there was no forecast for part 5, it was subtracted by 0 because there was no forecast and because there was no sales for part 3, the variance is -50 because there was no sales.

    #desired output
    output <- data.frame(""part""=c(1:3,5), ""region""=c(""region1"", ""region2"", ""region3"", ""region5""), ""Variance""= c(-5, 0, -50, 100), ""Date""=c(""2017-09-15"", ""2017-08-15"", ""2017-07-15"", ""2017-07-15""))
    output

If you need me to clarify further please let me know. Any help would be appreciated!!",Trying a new way to measure accuracy,70cq2l,new
"Hello! I'm trying to track inventory locations and validate our reports using GPS data. 

I latitude and longitude coordinates that are connected to product IDs. Each product ID is tied to a current storage location. I want to have R validate these locations based on a 'geofence' of sorts. 

Right now, I'm able to plot the gps locations but I don't know how I would get started on the geofences part and R returning True or False based on the bounds I select for each products 'storage location'... does anyone have general leads? 

Thanks! ","I'm looking to track GPS pings, any suggestions how to approach it?",70c4er,new
"I have to learn R Studio for two of my graduate classes. The one I am in right now is starting from the start, but I'm finding it still moves too fast.

I am way new to writing scripts and I don't understand what's going on when I try to look up 'beginner' videos on Youtube. Hell, I don't even understand the words the authors are using to describe what they're doing half of the time.

What is the best resource you can think of to start from as much of a scratch as you can possibly get? If it helps, I am a physical geography student who has a data science class. We're using RStudio to model statistics.",good resource for an absolute beginner?,6zy9os,new
"[This is a project I've been working on](https://github.com/ben519/DataWrangling). It's a guide on how to do a number of common operations using pandas (Python) and data.table (R) via examples operating on four very basic tables.

I'm pretty good with R and so-so with Python, but I frequently need to port stuff from R to Python. So, one of the features of my project is a cross-reference showing how every operation can be done in BOTH R and Python.

I've also included some files with objectives (stuff like, join transactions to users), but without the answers so you can try to fill this out like it's a practice worksheet.

Lastly, some notes:

* I'm using data.table version 1.9.7 (very soon to be 1.9.8 - I spoke with the developers). It has a few nifty features not in data.table 1.9.6 which is the current version on CRAN
* I left some of the python objectives blank. If any of you advanced python users want to help out, be my guest. Otherwise I'll try to fill these in soon

Enjoy",My Comprehensive Guide to Data Wrangling with R (and Python),558iev,top
"Dear R users and enthusiasts,

After several months in the public domain, the first major version of the ‘crypto’ package was just released on CRAN with some new features and bug fixes.


The R package that provides historic OHLC crypto currency market data for ALL coins and exchanges.

The ‘crypto' package is the R resource to go to for anything crypto currency related and includes a variety of different functions to extract data about the crypto currency markets. 


Featured on Kaggle as the 35th most popular dataset, it is quickly becoming the go-to resource for crypto currency market information in the data science community.
				
- `crypto_history()`		Retrieves OHLC historical crypto currency data  
- `crypto_prices()`		Retrieves current crypto currency prices  
- `crypto_list()`			Retrieves list of all crypto currencies  
- `crypto_exchanges()`	Retrieves all crypto exchanges and their listings  
- `crypto_xts()`			Converts/summarises historical data into xts objects  
- `daily_market()`		Time series market data perfect for charts and visualisation  
- `global_market()`		Global market time series for all coins or alt-coins

> Now featuring enhanced localisation support for different encoding standards.


CRAN:	[https://CRAN.R-project.org/package=crypto](https://CRAN.R-project.org/package=crypto) 

Github: 	[https://github.com/JesseVent/crypto](https://github.com/JesseVent/crypto) 

Kaggle: 	[https://www.kaggle.com/jessevent/all-crypto-currencies](https://www.kaggle.com/jessevent/all-crypto-currencies) 


All suggestions, comments and feedback are welcome,

Thanks",crypto R package: Historical cryptocurrency market data for all digital currencies,8mzq9v,top
"Hi all,

Just wanted to pose a general question to other r users outside of my field. I’m an RA doing a masters in ecology. Like many of you, I’ve been using R daily for a couple of years now, and I consider myself pretty darn good at it. Like many r users, I work on really specific things (spatial habitat analyses, wildlife mark recapture analyses etc) that I need to know for the work I’m currently doing. That said, like many other r users, I’ve gotten really good at learning how to do new things in r efficiently which I think is a skill in itself. The job market in the wildlife field is limited.

My question is this: Are there many job opportunities out there for folks doing general data analysis, manipulation, etc in R? Trying to be realistic about my future in this field, and would like to try and expand my horizons if necessary. I’m not a programmer, and any coding I’ve done has been in a statistical setting. Any thoughts?

Also, sorry for the grammar/spelling. I’m currently a little drunk. ",Job opps for folks with solid R coding skills?,8t8hx1,top
"A while back I made a post asking about a cheat sheet for R Shiny (under a different account) and while I did not get that, I given some great advice on how edit my Shiny programs using CSS without actually learning CSS. It's actually a very easy concept and doesn't take much additional coding at all.

I decided to create a small tutorial/cheatsheet to help anyone else that wants it. It includes images and gifs to help you get started. Then it has a handful of examples you can use and a small template to quickly edit your progams.

​

[Here](https://github.com/thomaskellough/Personal-Projects/tree/master/shiny-css-cheatsheet) is a link to my Github with it! Let me know if you have any questions.","""Cheat Sheet/Guide"" for CSS to Shiny",99zkmy,top
thank you based hadley. that is all.,%>% is the greatest thing ever.,4s3k9l,top
"I made [a curated list of awesome Shiny Apps for statistics \(ASAS\)](https://github.com/huyingjie/Awesome-shiny-apps-for-statistics). 

The goal is to 
1. help teachers teach basic statistics to their students.
2. help self-learners to visualize statistics concepts.

I hope that teachers can use this page as a reference in the coming spring semester.

 Any feedback would be appreciated!",A curated list of awesome Shiny Apps for statistics (ASAS),7mgoia,top
"I forgot to ask, how much R did you learn before you started using it at work?

Edit: Added question.","Those of you that often use R at work, what do you do?",4z7d43,top
"I just learned about the '[melt](http://seananderson.ca/2013/10/19/reshape.html)' function from library(reshape2) that lets me make ggplot-ready data.frames directly from named numerics.

Are there any other simple tricks or packages out there that make your life in R infinitely easier?

Side-note: I'm in the field of bioinformatics",Got any epic R tips and tricks ?,3df93i,top
"I am starting a new job as a Data Scientist soon. I come from a CS background and so have extensive experience with many programming languages. To date, I have done all of my statistical and ML work through Python, but have rarely used any R. I have been asked to become more familiar with it before I start the job - what are some recommended online resources to gain a reasonable knowledge in R?",Best free online course for learning R?,8qiny8,top
I've been learning R for about half a year now and I really don't wanna mess around with Python. Just bc I want to master the packages in R and be able to use them with fluidity. Was learning Ruby before this for Rails ofc. Am I missing out on anything not using Python? And are there any cases where people use both of them together? ,R vs Python,6x12p4,top
"I know that there is a discussion thread dedicated to Python automation of office tasks. But, I was wondering if anyone is using the R language to automate their office tasks? If you have any, could you please share them?

Here is mine: I use the R language to automate Excel function across multiple files (thousands of them).",What are some office tasks you've automated using R?,6cvyqe,top
"I wanted to start a thread with some good introductory materials for anyone starting to learn R. Feel free to share additional resources and advice or requests for either.

Can download R [here](http://www.r-project.org/)


Can download Rstudio (a powerful and easy to understand interface for running R) [here](http://www.rstudio.com/)


A [brief tour of R](http://www.youtube.com/watch?v=AbRxKfUGMY8&list=PL0cNPtWZWKMRmB6D9QhUyR-gOHoD3qRxt) for Beginners


My first 15 minute project was to recreate [this chart](http://chartsnthings.tumblr.com/post/36978271916/r-tutorial-simple-charts)


[Manuals and Introduction](http://cran.r-project.org/manuals.html) to R


Videos for [a 4 week course](http://blog.revolutionanalytics.com/2012/12/coursera-videos.html) introducing programming in R

[Beginner tips](http://blog.revolutionanalytics.com/beginner-tips/)


[Companion Book](http://www.amazon.com/Software-Data-Analysis-Programming-Statistics/dp/1441926127/ref=pd_sim_b_1)



""Let no one be slow to seek wisdom when he is young nor weary in the search of it when he has grown old. For no age is too early or too late for the health of the soul. And to say that the season for studying philosophy has not yet come, or that it is past and gone, is like saying that the season for happiness is not yet or that it is now no more... So we must exercise ourselves in the things which bring happiness, since, if that be present, we have everything, and, if that be absent, all our actions are directed towards attaining it."" 
- Epicurus",Everything you need to get started learning R,1m2oic,top
"Hi all,

I've found a few R style guides which suggest using `<-` not `=` for assignment, but none of them tell me *why*.

I've searched this sub for insights, and https://www.reddit.com/r/Rlanguage/comments/2fv52q/r_style_do_you_use_or_for_assignment/ suggests a range of opinions - including the interesting ""`<-` for assignment; `=` for definitions"".

I'd like to understand when I can/should break the rules! What's the thinking behind this commonly-stated preference?","What's the *rationale* behind the preference for ""<-"" over ""=""?",8at85x,top
"Anyone know how to make the last plot in this article using ggplot2?

https://www.economist.com/blogs/graphicdetail/2017/08/daily-chart-10",Cool plot in The Economist,6u8yld,top
https://devopedia.org/r-plotting-systems,Get an overview and compare the different plotting systems in R,8ikdwz,top
"Hell RLanguage.  Awesome R shiny is a curated list of r shiny resources in the following areas:

- [Resources](https://github.com/grabear/awesome-rshiny/blob/master/README.md#resources)

- [General](https://github.com/grabear/awesome-rshiny/blob/master/README.md#general)

- [Community](https://github.com/grabear/awesome-rshiny/blob/master/README.md#community)

- [Deployment](https://github.com/grabear/awesome-rshiny/blob/master/README.md#deployment)

    
- [Tutorials](https://github.com/grabear/awesome-rshiny/blob/master/README.md#tutorials)

- [Tools](https://github.com/grabear/awesome-rshiny/blob/master/README.md#tools)
    
- [Packages](https://github.com/grabear/awesome-rshiny/blob/master/README.md#packages)
    
- [Integrations](https://github.com/grabear/awesome-rshiny/blob/master/README.md#integrations)

- [People](https://github.com/grabear/awesome-rshiny/blob/master/README.md#people)

- [Books](https://github.com/grabear/awesome-rshiny/blob/master/README.md#books)

- [Galleries](https://github.com/grabear/awesome-rshiny/blob/master/README.md#galleries)

- [App Examples](https://github.com/grabear/awesome-rshiny/blob/master/README.md#app-examples)

- [Contributors](https://github.com/grabear/awesome-rshiny/blob/master/README.md#contributors)

I'm currently working on updating the list for 2018 with a few others.  If anyone here knows of something that we're missing, we'd really appreciate a [PR](https://github.com/grabear/awesome-rshiny/pulls) or a comment on the [2018 update issue](https://github.com/grabear/awesome-rshiny/issues/61).",[Help Wanted] Awesome RShiny list - 2018 update.,86nd3w,top
I'm pretty familiar with R and want to learn python by myself. It just seems super confusing to get started and wondering if anyone knows a crossover tutorial for R users.,Python for R users? Tutorials?,8d6xsy,top
Bored and taught myself to make shiny apps today. Curious if anyone actually uses these at work though and some examples if so,"Does anyone actually use Shiny at work? If so, how?",6y2upp,top
"I've been using this method in R to save files for awhile and was surprised to hear from some R programmers that they have not heard of it. 

Basically, a .rds is an R specific format to save R objects. This includes data frames. The way you do this is by using the saveRDS() function, with the readRDS() function to pull ito R.

Huge pros for .rds is that they write fast, read fast, and also save the classes and formatting of all your data. Downside is that it is R specific and can't be opened in Excel, like a .csv can.

If you have a process that writes files that you would rarely use and writing tends to slow down your speed, .rds will save you a ton of time.

Here's a quick script to highlight the speed of .rds:

https://pastebin.com/RX9TaKjs

With results:

""Writing .csv...""

""Time spent: 50.452399969101""

""Writing .rds...""

""Time spent: 2.92019987106323""

""Reading .csv...""

""Time spent: 11.4528000354767""

""Reading .rds...""

""Time spent: 0.92140007019043""

Above times are given in seconds.

The .rds reading/writing is orders of magnitude faster and more convenient for use in R. Hopefully this is useful and let me know if anyone has something to add or refute.

EDIT: Another thing I forgot to mention is that the size of an .rds file is a small fraction of a .csv. The .csv file generated is 51,758KB, while the .rds file is only 297KB. 0.5% the size.",PSA: Saving To .rds Format,6slpg0,top
"[Spatial Data Analysis in R](https://gormanalysis.com/spatial-data-analysis-in-r/)

Since [sf](https://github.com/r-spatial/sf) is replacing the current dominant package for spatial data analysis (sp), I decided to learn it and write a post about it on my blog to help others.  Enjoy",I wrote a blog post on getting started with spatial data analysis in R using the new sf package,6qu20s,top
"I'm just learning R with the intention of leveraging its (from what I hear) superior charting capabilities.  I've been going through tutorials on the language and am feeling fairly comfortable with the syntax, I'd like to now start playing around with some charts (ggplot2, etc) and thought it would be very helpful if I could see a whole bunch of examples of what is possible and then pick a few different ones and work backwards to build them with my data.  

Is there anything out there like this?

Also, would very much appreciate any suggestions for good youtube tutorials on charting.

Thanks!","Are there any websites that have a really big gallery of impressive R charts? (Also, good youtube video series?)",5a8l4z,top
"Feeling a little overwhelmed with, say, all the different kinds of apply and sequencing. That's alright, I don't mind being overwhelmed! But the question occurred to me learning a bit about plyr and dplyr, where someone might suggest ""just go right to plyr/dplyr when working with data frames"" or maybe someone has the opinion that you might as well always use data.table instead of data.frame, or maybe some library handles dates so extremely well that there's never a reason to not use it, etc...

I don't know, just a thought while I'm having lunch.",For a new R programmer: what in the base should everyone know? What in the base is handled better by other libraries?,42nwl1,top
"When indexing into something, how do you know when to use `[[index]]` vs `[index]`?

I'm a bit confused by the difference, since there isn't really a programming language equivalent of this type of operator. I think `[index]` means ""return a list of results"" whereas `[[index]]` means ""return one result"", but I'm not sure.",Beginner question involving `[[ ]]` vs `[ ]`,9cwrza,top
"Hi everyone,

I need to self-learn R for work (economist), with the purpose of creating matrices. What is the best resource to get a feel for the language? I have no prior knowledge or experience with programming.

Many thanks,

",Self-learning R. Best resource,5e2j56,top
"If you want to pull API data into R, it can be hard to get started. Most development work with APIs occurs in other languages so there often times aren't packages for integrating an API in R. This means you have to do it yourself. 

If you aren't familiar with APIs, [this article explains](http://blog.intrinio.com/api-business-care/) what they are and why you might want to use them for data collection.

If you have never used an API before, [this article explains paging](http://blog.intrinio.com/api-paging-limits/), one of the hardest parts of working with an API.


Here is some sample code showing exactly how to pull in the historical stock price of a stock using [Intrinio's API](https://intrinio.com/). You can [view this code here as well](http://www.r-fiddle.org/#/fiddle?id=mUzX3d22):

    #Cleaning up the environment

    rm(list=ls())


    #Skip this installation if you already have httr installed. This package makes using APIs in R easier
    install.packages(""httr"")
    #Require the package so you can use it
    require(""httr"")

    #Skip this installation if you already have jsonlite installed. This package makes parsing JSON easy
    install.packages(""jsonlite"")

    #Require the package so you can use it
    require(""jsonlite"")


    #Create variables for your usename and password, get those at intrinio.com/login. Replace them here or the code 
    #won't run! They need to be in """"
    username <- ""Paste_API_Username_Here""
    password <- ""Paste_API_Username_Here""

    #These variables will be pasted together to make our API call. You can replace the ""stock"" variable with any US 
    ticker symbol
    base <- ""https://api.intrinio.com/""
    endpoint <- ""prices""
    stock <- ""AAPL""

    #Pasting them together to make the API call. The result should look like this if you view 
    #it:""https://api.intrinio.com/prices?ticker=AAPL""
    call1 <- paste(base,endpoint,""?"",""ticker"",""="", stock, sep="""")

    #This line of code uses the httr package's GET function to query Intrinio's API, passing your username and 
    #password as variables
    get_prices <- GET(call1, authenticate(username,password, type = ""basic""))

    #The content function parses the API response to text. You can parse to other formats, but this format is the 
    #easiest to work with. Text is equivalent to JSON
    get_prices_text <- content(get_prices, ""text"")

    #This line of code uses the JSONlite function fromJSON to parse the JSON into a flat form. Flat means rows and 
    #coloumns instead of nested JSON
    get_prices_json <- fromJSON(get_prices_text, flatten = TRUE)

    #Converting the data to a dataframe
    get_prices_df <- as.data.frame(get_prices_json)

    #The original JSON is actually a list. One item in the list, total_pages, tells us how many pages of data there are in 
    #total. 
    #The API limits each page to 100 results, so if there is lots of data, you need to call multiple pages. 

    pages <- get_prices_json$total_pages

    #Since we already have the first 100 results in a data frame, this for loop starts with the second page of data and 
    #continues
    #until all pages have been returned. Each time a new page comes back, we add it to the first data frame we made

    for(i in 2:pages){
  
      #Making an API call that has page_number= at the end. This will incrememnt by 1 in each loop until we have all 
    #pages
      call_2 <- paste(base,endpoint,""?"",""ticker"",""="", stock,""&"",""page_number="", i, sep="""")
  
      #Making the API call
      get_prices_2 <- GET(call_2, authenticate(username,password, type = ""basic""))
  
      #Parsing it to JSON
      get_prices_text_2 <- content(get_prices_2, ""text"")
  
      #Converting it from JSON to a a list we can use. This actually gives us a list, one item of which is the data, the 
    #rest is information about the API call
      get_prices_json_2 <- fromJSON(get_prices_text_2, flatten = TRUE)
  
      #This grabs just the data we want and makes it a data frame
      get_prices_df_2 <- as.data.frame(get_prices_json_2)
  
       #Now we add the data to the existing dataframe and repeat
      get_prices_df <- rbind(get_prices_df, get_prices_df_2)
  
    }",Using an API in R,6jlbh9,top
"So I'm fairly new to R and, generally speaking, a very lazy person. I recently started using the equals sign instead of the arrow in R and it hasn't caused me any problems. What are the potential problems of doing this as I go forward","What are the drawbacks to using the "" = "" instead of ""<-""?",6iquuu,top
"Is there anything similar to [100-numpy-exercises](https://www.labri.fr/perso/nrougier/teaching/numpy.100/index.html) for R? If not, should we create it?
By the way, there also seems to be one for [Julia](https://github.com/chezou/julia-100-exercises).",100-R-exercises,4m9gvg,top
"R was the first programming I learned (as an Econ/stats person, it was a natural choice). And sure, learning how to program didn’t happen overnight. But I just don’t see why people say R has a “steep learning curve.” As I’ve started to delve into other languages like Python, I actually think learning R is far easier. Maybe I’m just weird though. So, why exactly does R have this reputation?",Why do people say R has a steep learning curve?,979ebq,top
"How good is the [R Programming course](https://www.coursera.org/learn/r-programming/home/welcome) from Johns Jopkins on Courserea. I have got zero experience in R and I would like to learn it from the scratch. I am also planning on buying the certification for the course so I would like to know if it is worth the investment. I'll also be working on R in my job in a few months and I would like to be ready and know at least the basics. I've got prior programming experience and am quite good in SQL.

I would like your opinion if you've taken the course and if you found it useful(or even if you haven't taken it). Do you find the course covers most of the essential basics while being friendly to a new-comer at the same-time? Or do you think there are better courses which I'd rather take? Any additional learning resources that'd go well with this course? 

Your feedback is welcome. :)",How good is the R programming course from Johns Hopkins on Coursera?,7wfjc4,top
"Hey all!! 
I'm sure this is old news here but I've been using it and it's solved a few of my problems with generating combined plots and, like a Jehovah's witness, I wanted to spread the good news.  The package ""patchwork"" allows you to combine multiple ggplots as simple as adding then together like a + b + c. 
Here's a link. It works phenomenally and resizes each chart to be the same by default even if theres a legend, unlike the grid extra package. 

https://github.com/thomasp85/patchwork/tree/master/R",Patchwork package,7pieqc,top
Does anybody have any links to data analysis scripts that are a good examples of writing R code?,"Examples of neat, easy to follow, well formatted R project with good code?",7kue31,top
"Hello Reddit!

I recently wrote a command-line interface to the R package manager because I was annoyed with having to open up the R console every time I wanted to install, uninstall, or reinstall a package. It's at the point of basic functionality (I use it all the time), and I thought other people might be interested in using it. Hopefully it saves you a few keystrokes!

It's called **Rpkg**, and you can get it on GitHub here: https://github.com/gwerbin/rpkg

One day it will include all sorts of fancy features like cross-repo package search (e.g. seamlessly combine CRAN, devtools Github installer, and BioConductor packages), ""dangling dependency"" cleanup functionality, and so on. Today it's a bare-bones tool a long way off from there. I'm looking for feedback and collaborators as much as I'm looking for users! So if you like the idea, please don't hesitate to submit a pull request. If you don't like the idea, I'd love to know why.

Note that this is (by design) a *very* thin wrapper for the underlying R functions like `install.packages()`, and it makes no attempt to parse or manipulate the output from those functions before passing them onto the user. For the curious, here's what it looks like in use:

    $ Rpkg install purrr
    Installing package into ‘/usr/local/lib/R/3.4/site-library’
    (as ‘lib’ is unspecified)
    trying URL 'https://cloud.r-project.org/src/contrib/purrr_0.2.3.tar.gz'
    Content type 'application/x-gzip' length 126170 bytes (123 KB)
    ==================================================
    downloaded 123 KB

    * installing *source* package ‘purrr’ ...
    ** package ‘purrr’ successfully unpacked and MD5 sums checked
    ** libs
    ** R
    ** inst
    ** preparing package for lazy loading
    ** help
    *** installing help indices
    *** copying figures
    ** building package indices
    ** installing vignettes
    ** testing if installed package can be loaded
    * DONE (purrr)

    The downloaded source packages are in
    	‘/private/var/folders/4j/n8nxnsy12y92t475g318yptm0000gn/T/RtmpvHCMSP/downloaded_packages’

    $ Rpkg uninstall purrr
    Removing package from ‘/usr/local/lib/R/3.4/site-library’
    (as ‘lib’ is unspecified)",A command-line interface to the R package manager,6uc9ex,top
Hi is there any significant performance difference between TF & Keras in Python vs in R? Im kinda lazy on having to learn new language to implement DL,tensorflow and keras in R,6fxz0m,top
I am taking R courses on DataCamp. Is there any website that I can use (as a beginner level) to practise with real live datasets to practise?,Sites to practise my R skills?,5189g3,top
"My employer gave me a choice between Shiny and some javascript library. I m equally familiar with Js and R. Can you tell me more about how widespread the use of shiny is? Any big project built with shiny?

Dunno if I should learn Shiny (I do like R as much as I like js). 

",How widespread is the use of Shiny?,5whb2o,top
"I am not a statistician, nor a programmer. But I perform statistical analysis using R, and I am at my fourth project.

The thing is that I repeat code a lot, which led me to organize the code in functions to make my code tidy. However, now the functions are bothering me...

I was wondering what is the best practice in this case? Should I encapsulate all my utility functions within a class? Any suggestions?

Thanks.",Organizing my R script,5sy0lj,top
I developed an app using shinyapps.io that runs the resolution mechanic for the roleplaying game I am developing.,What have you programmed in R solely for your own amusement?,8e85g2,top
"I am a Data Analyst at a national financial software company.  Right now I use VBA and SQL exclusively for my job.  


A typical request would be something like:
 ""Hey, CYANBD, can you give me all the transaction numbers that match that this certain specific criteria?""  This requires me to manipulate HUGE spreadsheets, think a handful of spreadsheets all 200k-300k rows long.  


vLookups and formulas won't work unless I cut down the spreadsheets quite a bit, so I end up writing VBA loops to get the data how I need it.  I've found this way has its own limitations.


I also spend a large portion of my time creating macros that utilize custom user interfaces to manipulate data and create reports for people throughout the company.


I'd like to expand my programming knowledge (being an expert in VBA doesn't go very far) and I'd like to be better at my job at the same time.  That said, if I don't need to do any statistical or predictive analysis, and I just primarily work with very large data sets and creating custom interfaces, would there be any benefit to learning R?",Should I learn R?,85ojr0,top
"Hello, I am a software developer of 9 years trying to get into R, and Machine Learning.

Does anyone have any recommendations for some good books that could teach the syntax of R. Maybe use a few data science functions/libraries. And then have a full machine learning tutorial? Anything more recent for R 3.0 would be perfect!

Thanks.",Good R Books with a Machine Learning Example?,5ntagb,top
"I'm not sure if something like this exists, but I've been googling and can't really find anything.

I'm not good at all with CSS. I've been learning R Shiny recently and I want to stylize my UI. I went through a bunch of bootstrap themes that you can download and use as a source file, but I still want the option to edit specific things. I don't mind going through the bootstrap.css file and changing the colors/size of things as needed, but I'm actually having a hardtime understanding what is what.

Is there a cheat sheet somewhere that shows a widget/label or whatever in R Shiny and then says what it's called in the CSS file?  Or is there an easier way to stylize with having zero styling experience? 

Thanks in advance!",Looking for a CSS cheat sheet that can help me with R Shiny,98xmom,top
"Hi all! I was browsing the candidates in the primaries for my local House elections (MA-3rd district) and noticed that there's a *ton* of overlap between their campaign platforms. It made me wonder, what's the real difference between these candidates? 

As a new R user (started learning through DataCamp last October), I thought this might make a fun project to try out web scraping, comparing strings, interactive report generation, and whatever other concepts I might be able to squeeze in! So far, I've used rvest (in combination with SelectorGadget) to grab as much of the platform text as I could for each candidate, then various commands from stringr (combined with rebus) and base R to clean/organize the data into lists.

Anyway, all that was very satisfying to do (I almost feel like I have some idea what I'm doing!), but now that I've gathered the data, I'm feeling a little stumped on how to go about the real analysis. I think my fundamental questions would be: 

* What are the most repeated words/phrases among platforms (and how often do they occur)?
* What unique words/phrases are used by each candidate (and which candidate uses the most unique words/phrases)?
* How *specific* does each candidate get on the issues (recognizing that this may be the hardest question to answer programmatically, although I think a good starting point would be which platforms mention things like ""House Bill"" or ""H.B."")?

Does anyone have any experience working with data in this way? What packages would be helpful? What would be the optimal way of organizing the data? All input is more than welcome; I'm just excited to be building something!

I'm more than happy to share code/data/whatever, which would also be a learning experience since I've never done that before! Thanks for reading. :)",My first R project: Platform differences,8pkh7a,top
"Introducing a BETA release of dashboardthemes - an experimental R package designed to provide custom theme options for Shinydashboard applications.


More details are given in the below links:


Blog post: https://nik01010.wordpress.com/2018/03/05/introducing-dashboardthemes/


Github repo and detailed instructions: https://github.com/nik01010/dashboardthemes


Please read the disclaimer before using this package.

Feel free to provide any comments or feedback.

N",Introducing dashboardthemes - experimental themes for Shinydashboard,829t92,top
"I already know many languages, and have a practical knowledge of machine learning and data science with Python. I’m looking to expand my skills in statistics and pick up R at the same time.

Are there any resources out there that target my demographic?",Learning R as an experienced programmer,823ybl,top
"Hi!

I studied some econometrics in uni and some basic statistics. But I'm rusty. I have also got some very limited experience with R. I have been googling around but feel that there's often a 'gold standard' site which communities know about and googling doesnt highlight. Does anyone have any suggestions for sites that have a good flow and teach me about data analysis and regression in R? Thanks heaps.",Looking for a comprehensive but digestible tutorial set on data exploration and linear regression in R,73kh2k,top
"What is your R journey like? How did you got interested, learn, struggle and master the language? How did you continue to improve on it? ",What is your R journey like?,58jhvr,top
"Can anyone suggest some good material for learning how to create maps in R?

Similar to what this guy did: https://www.kaggle.com/benhamner/d/benhamner/2016-us-election/hillary-clinton-county-results-map/code

Obviously the source code is available but I'm looking for a general walk-through or at least an explanation of some of the relevant packages so I'm not forced to try to reverse engineer his work. 

Any help is much appreciated, thanks.",Crash Course in Mapping with R,4w8zt9,top
"I have several R scripts currently written in a procedural programming style that should be re-written in OOP to use S4. I was hoping to look at several examples before doing this. 

Does anyone have any examples on GitHub? I would much appreciate it.",Does anyone have before and after R code re-written using S4 methods?,4qiu3d,top
"I am just getting into R and bought R for Everyone. The book suggests using RStudio, but I am used to Atom. Thoughts are appreciated! ",What IDE do you use for R?,8xeufu,top
"hello, i am completly new to R and programming. It would be very helpful for me if someone can recommend me good and very complex tutorial on R. i have tried tutorial on udemy but it is rather short and shallow.",complex guide for learning R,7gxord,top
"I'm thinking about purchasing this book: https://www.amazon.com/gp/product/1788397878/

Curious if anyone else has something they would recommend.",Good resource/book for Neural Networks in R?,75lli6,top
"Hi guys

As you know Microsoft bought R language back in 2015? Their product includes r server, r client, r open and sql server learning machine.

I don't know much on the enterprise side of using R. Can anyone provide an overview and a simple explanation of these services?

Edit: thanks /u/_wintermute for pointing out Microsoft buying Revolution.

",ELI5 Microsoft R products,672h42,top
"The default colors for RStudio are way too bright for me. RStudio does allow them to be changed (Tools -> Global Options -> Appearance -> Editor theme). But the options are limited, and the dark themes aren't high-contrast enough for me.

It turns out that the theme colors are handled by a series of css files located in `ProgramFiles//RStudio//www//rstudio//`.  By editing these css files, you can manually change the colors. Each css file belongs to one theme. To do this yourself:

1) Backup all of the css files.

2) Open up one of the `.cache.css` files in your favorite text editor. (They look like they are named randomly, so you have to find out which file belongs to which theme.)

3) Replace the color hex codes with something that will pop out at you (An all-orange theme is in the comments). Save the file. This will overwrite the theme colors for that file. 

4) Start up RStudio, head to (Tools -> Global Options -> Appearance), and look through each theme until you find the all-orange one. Now you know which theme corresponds to that css file. 

5) Undo the all-orange theme (or restore from backup), save again, and go back into the Appearance box. If the theme is close enough to what you'd like, move on to step 6, otherwise consider going back to step 2 with another css file.

6) Start changing the hex color codes for whatever you want to change, save, then check the Appearance box. 

When you're done, select the new theme, and you're all set!

If you want the [theme](http://imgur.com/a/ADsd3) I ended up making, the css is in the comments.",Want to change the Editor's theme?,606mlf,top
"Just curious what theme you tend to use, and if you find there's a standard one that you prefer. I'm trying to pick a dark theme to use and get used to instead of chrome. ",What's your favorite RStudio appearance/theme?,5cswko,top
I am wanting to learn more about R and geospatial data users. This is motivated by one of our users (I work at a satellite data API startup) who created this R-wrapper for our product in git (https://github.com/amsantac/SkyWatchr) If anyone knows any specific communities for this or must-reads it would be quite useful! Thanks.,Looking for R users who work with geospatial data.,5609v3,top
"I have an entrance exam/assessment coming up for a master's program. The program says it requires a basic understanding of R as a prerequisite. We were told where to show up, to bring a computer with R, and that we have an hour to complete it. That's all we are being told. I am a little worried as I feel my R skills are very basic and I really have no idea what they'll ask us to do. Does anyone have any idea what they could be asking us to do to demonstrate a basic understanding of R?

Edit: Just had the assessment. For the program it was split into 3 sections, one of those being based on R. It was very basic, how to read in data and do some basic things with that data. We had to separate the data, plot it, t test. Really simple. Thanks everyone for your help.",Assessment of R skills?,4r9xfo,top
"DuckDuckGo's focus is to become the best search engine for programmers, and we'd love your help improving our open-source R language Instant Answers. There's currently a [cheat sheet](https://duckduckgo.com/?q=R+Cheat+Sheet&ia=cheatsheet), and we want to get some great feedback from the Reddit community for the developer, laurenancona.  


If interested in helping us improve, please check out the following:


* Visit the [R language IA's page here](https://duck.co/ia/view/r_cheat_sheet)
* Click on the ""Example Queries"" to see the IA in action. 
* Perform other test queries that you expect would be or should be covered by the Instant Answer
* Create an issue via Github for bug or suggestions with the ""Create Issue"" button on the IA page.

[Our docs have a checklist](http://docs.duckduckhack.com/maintaining/feedback.html)
of things the community looks for with every new Instant Answer.


thanks!

-Bill",Help improve DuckDuckGo's R-related searches,4gr9bj,top
"My area (finance) is slowly adopting other applications beyond Excel in data analysis and predictive analysis - R and Python are the top two that have emerged.  In order to sell these applications to business end-users, I think it is absolutely imperative that they integrate with Excel and spreadsheets.  Otherwise, no one will feel comfortable with our models, especially if they can't interact with it in a spreadsheet.

I've been learning more R and Python simultaneously from scratch. I've gotten more accustomed to using Python and having it called from Excel via xlwings.  As I get more experienced in it, I can see it being a powerful tool in data, automation, and modelling tasks that I can transfer to others fairly easily via Excel and xlwings.

I've been asked to assess the feasibility of using R in the same way with Excel, and I'm honestly not that familiar with integrating Excel with R.  Does anyone have any experience integrating Excel with R?  How did it turn out?  Is one language more advantageous over the other in terms of working with Excel?  We eventually would like to use these languages for predictive analysis as well - is there any advantage to one language over the other in this regard?",R vs. Python for operationalized processes?,9744ot,top
"Hi,

Grad student learning R for the firs time here.

What is the detailed explanation of the difference between recalling subsets through a list\[\] or list\[\[\]\]?

I read that list\[\[\]\] will break the list structure, so that length(list\[\[\]\]) would give you ""How many elements/vectors(?) are within that list""

vs.

length(list\[\]) will give you length of 1 (Because the length of that new list is 1?)

Is there an easy way to understand this?

Currently going through Arrays, Matrices, Lists, Factors and Data Frames.  I'd like to get a concrete / strong foundation of how their characteristics before beginning to work with them.

Thank You!",list[] vs. list[[]] subsetting,95d4z1,top
"Hello all,

I’ve been using mlr a little to learn about machine learning, but recently found out about caret.

The way I understand it is that both are wrappers to various ML packages, but have slightly different approaches. Although mlr appears to also wrap some things from caret - so maybe we can sort of consider mlr a superset of caret.

I’m of a mind to stick with mlr for that reason, to save having to switch or learn both. But I’ve also heard the author of caret has joined the tidyverse guys - so maybe this will become the de facto standard now. 

Any views on the pros/cons of the two packages, which covers more stuff, which has a more streamlined approach, which is more flexible/easier etc etc?",mlr or caret,8x0e1i,top
"I have a dataframe/datatable that is like this:

     A     B
     a1   b1
     a2   b1

and a vector: `v1, v2, v3`

I am trying to get a result like this:

     A     B     C
     a1   b1    v1
     a1   b1    v2
     a1   b1    v3
     a2   b1    v1
     a2   b1    v2
     a2   b1    v3

Having trouble googling this, if anyone could point me in the right direction I would be very grateful. ",In R how to expand a dataframe with a vector?,8rt3s7,top
"The [Hack for the Sea](https://hackforthesea.tech) Crew is proud to present this year's challenge statements and data sets.

They are, as follows:

* [How does a changing coastal watershed impact coastal waters?](https://hackforthesea.tech/GLO/challenge/1)
* [Can you predict where and when cod spawning will occur?](https://hackforthesea.tech/GLO/challenge/2)
* [Can you design a mooring that's both eelgrass and user-friendly?](https://hackforthesea.tech/GLO/challenge/3)
* [Can an individual whale be identified based on its blowhole?](https://hackforthesea.tech/GLO/challenge/4)

The event is all ages and open to anybody who is ready and willing to provide their skills to help the oceans. Also, while the summit will be held in person, the community is open and involved year round. Join us!",Data Sets and Challenge Statements Released for Hack for the Sea,8qyv96,top
I was thinking data mining my email for common requests via a word cloud given an email mailbox surrounding s specific business activity.,What is a simple practical beginner use for R in the business office?,8ko9tq,top
"I am trying to get a handle on what most R programmers believe to be best practice in regards to style. Also, I'm not a big fan of some of the rules Google and Hadley have, so I want to know how much of a faux pas it is to use my own style rules. 

Packages that can reformat your code to match style guides (*formatR*, *styler*) exist, so you could theoretically keep copies of your scripts that use a custom style and then use those packages to reformat them when you need to share outside your team. Keeping up with all the copies does seem difficult, but I could see some advantage if you find your custom style easier to read for some reason.

I don't like some of the rules Google and tidyverse have for object naming. For instance, I don't understand why objects have to be lowercase. I am learning SQL now and really like how readable it is. Because functions are capitalized (at least if you follow style conventions), it's easier to see what the tables and variables are at a glance. Highlighting from the text editor (I have maxed out RStudio's highlighting capabilities) helps, but so does the capitalization. I detest SQL code that does not use caps.  ",Do You Follow a Style Guide? Why or Why Not?,8df1n7,top
"Hey everyone, first time submitter here. I'm a moderately experienced Stata programmer, fairly new to R. I really like R and would like to use it more. I don't understand very well what different levels of RAM, processing power, and software may offer.

* I'm currently running Stata MP 14.2 6-core on a Xeon 3.6 GHz processor. 64 GB RAM. (Not sure what other specs may be needed.)

Generally speaking, this software on this machine can chew up and spit out nearly any data set. The only thing I've tried that took more than 30 seconds was a for-loop with 100M+ observations (only about 1000 variables, but still).

Since I find R more intuitive than Stata, and it's a lot easier to find good, uncondescending help for R, my question is:

* Is there a number of observations beyond which a basic version of R doesn't make sense to use, in the same way that Excel stops making sense at some point? 
* Is there a number of variables beyond which that would be true? 
* Is there an easy way to soup up R such that it could compete with Stata on a dataset with 100M observations and thousands of variables?

Please forgive any inconsistencies or failure to address any relevant information. My favorite thing about the R community to this point is that it is friendly and very rarely condescending.",R versus Stata,74a49v,top
"Hello again Reddit!

A couple weeks ago I released my R command-line package manager **[Rpkg](https://github.com/gwerbin/rpkg)** on GitHub, and the feedback was generally positive [here on Reddit](https://www.reddit.com/r/Rlanguage/comments/6uc9ex/a_commandline_interface_to_the_r_package_manager/).

Today I'm releasing v0.4, which I would say is the first true minimum viable  release for general-purpose use. You can now do all of the following right from your shell prompt:

- Install and uninstall CRAN packages
- Search CRAN packages
- Check for outdated packages
- Upgrade individual outdated packages, or upgrade every outdated package at once
- Print package info to the console

Installation is easy: just `git clone` and `ln -s`, then you're good to go!

As before, I have high ambitions for this package. One day you will be able to comfortably browse Bioconductor and CRAN right from the console, clean up dangling dependencies, as well as integrate with existing packages like Packrat, Checkpoint, Bundler, and Devtools. Right now it's bare-bones, but I'm always grateful for feedback and suggestions. Thanks for reading and let me know what you think!",Rpkg: command-line interface to the R package manager - v0.4 update!,6y9stq,top
"Hardcore vimmer using Nvim-R, but am curious if Rstudio may be one of the rare cases to make the switch. ",R in Vim or Rstudio?,6sn05b,top
"So I just finished my semester where I worked a lot with R in my Data intensive computing class. I'm very strong in EDA, basic machine learning(regression) linear,logistic, basic algos. I'm good with cleaning, data visualization. But what's next for me? I'm coming from an object oriented background but I really really like data science. What more can I do with this language?",What's the next level for me in R programming?,6de5gr,top
"On one hand, I feel like the course itself does very little to actually teach and prepare me for even its own assessements. 

""Hey, here's a programming assignment that requires functions and operators we haven't introduced to you. Best of luck!""

On the other hand, being forced to look at other people's code for the assignments and googling line by line is really teaching me how to find the information on my own.

At least it introduced me to swirl. The fuck would I do without swirl to get me through this.

</rant>",I can't decide if I hate the Coursera R programming course or if this is truly the best way learn,5v36sv,top
Hi everyone! I'm an undergrad student and my main exposure to stats is an intro stats course and a psyc stats course where we used SPSS. I just started a class that uses R and I'm all but completely lost. I've tried finding some sites to explain the basics but it still feels like it's over my head. Could someone please guide me in the right direction with some links or something? Thank you!,Total beginner who is totally lost. Please help.,5pt3ot,top
"I have an intent to do things that you're not supposed to do in R. Context: I want to generalize the behavior of functions like `sum()` where `sum(1,2,3,4,5)` returns 15. I've already read the [source code](https://github.com/wch/r-source/blob/trunk/src/main/summary.c#L51-L113) and R accomplishes this by punting the problem to C where C takes in a pointer to an array of numbers (the arguments) and sums them at that point. I want to do the following:

given a suitable operator function for reduction `op`, infix or otherwise, e.g.:

    op = c
    op = `+`

define a function foo such that:

    foo(a, b) = op(a, b)
    foo(a, b, c) = op(op(a, b), c)
    foo(a, b, c, d) = op(op(op(a, b), c), d)
    foo(a, b, ...) = op(... op(a, b), ...)

so if op was plus then

    foo(1, 2, 3, 4, 5) == sum(1, 2, 3, 4, 5)

and if op was concat then

    foo(1, 2, 3, 4, 5) == c(1, 2, 3, 4, 5)

This would get more interesting when you let `op` be a more complex function that doesn't have an R primitive, such as 

    op = function(a, b) a ^ b

which would compute power towers or (where I'm really building this example for), taking a page out of SQL and doing a massive merge operation on several data.frames at once, in order, using `op` to merge successive files into my master result.

    op = function(a, b) {
      a_parsed = strsplit(a, "";"") %>% unlist
      a_file = a_parsed[1]
      a_key = a_parsed[2]
      b_parsed = strsplit(b, "";"") %>% unlist
      b_file = b_parsed[1]
      b_key = b_parsed[2]
      return(merge(a_file, b_file, by.x = a_key, by.y = b_key))
    }
    merged_result = foo(""file1;key1"", ""file2;key2"", ""file3;key3"")


Don't ask how I'm getting string filenames into data.frames for the purpose of `merge`. I won't actually be using the base R merge function but rather one modified to read files directly from the hard disk.

This is my current implementation of `foo`:

    recursiveDots = function(first, second, ...) {
      dots = list(...)
      if (length(dots) == 0) {
        return(op(first, second))
      } else {
        third = dots[[1]]
        remainder = dots[-1]
        return(recursiveDots(op(op(first, second), third), remainder))
      }
    }

This, of course, is totally screwing up my type system because I'm converting and then indexing into dots (...) as a list. I need to index dots as a list in order to peel out one argument at a time, but I need to pass it back into `recursiveDots` as dots (...), but that would cause an infinite loop without being able to **remove** an argument from dots (...).

Ideas?",How can I abuse dots (...)?,4fwe7c,top
"Hello, it just occured to me after many years of trying various languages for various reasons, and never really *enjoying* any of them, that I am quite happy coding in R! 

I think it's some combination of: the scoping rules and functional-ness seem reasonable to me, all the great packages (and seriously the fact that I've never once had the slightest hiccup installing one, but that could be luck), RStudio and swirl() make for a supremely ideal learning environment (I wish there was a name for this sort of learning model, it makes *so* much sense for programming, see also [rubykoans](http://rubykoans.com/) for ruby and [this](https://github.com/jesyspa/linear-cpp) for c++, others probably too-- do you know any?) 

Just wasting some time, so what do you like/dislike about R? I've never gone too terribly deep into theory of computation/etc, so anyone who has opinions on R's architecture or semantics or whatever it would be called, on a deeper level, I'd be interested to know! ",Do you like programming in R? Is R an 'interesting' language?,4cnr0k,top
"I've never made a game before, so it's really diving in, especially since I'm not great at R yet either! But it seems like a fun project that could potentially tie in a lot of areas that are interesting to me.

The first thing I need is a nice REPL, and though the one that comes with R could work I suppose, it might be nice to have a finer control from within that over what's happening with the prompt/input/etc. Color for instance. I tried to search for a package like this but didn't see anything. 

Also I have to think about the interface. I'd like a multi-panel interface (so if I ""use proceduralMapMaker"" or something in-game, it will display in the graphics/maps panel) which makes me think of using shiny for all this. I'm firstly interested in just having something for myself, with having it work for other people a secondary concern. (A tertiary concern could be a multiplayer MUD type thing) 

I don't know, just an idle thought. If you have any suggestions on things to consider or libraries that may be helpful or interesting for this, let me know!",Thinking about trying to make a text adventure in R (with some graphical elements),4br3rs,top
"Hi guys,

I was looking to learn some R, mainly for personal use whenever I have to deal with a chunk of data and to make nice graphs. I've been looking around this sub, and most people suggest online video courses, but I'm usually not a big fan of those because it feels like a lot of waste time. 

What good book should I look at instead? I only know basic things about data analysis, but I don't mind if it's a little more advanced on the programming side.

Thanks!",Suggestion for a book to learn R,3wib3v,top
"Hi, I'm sorry if this isn't an appropriate question, but I was wondering why people choose R over Matlab.

At my University within the Machine Learning group everyone tends to use Matlab, and so far all my experience with statistics / ML has been using Matlab.

I was wondering what the advantage was of R over Matlab, or what your personal preference is and why?",R vs. Matlab,3prdsi,top
"Are there any ""must see"" resources which describe the main difference between R and Python? Differences between the languages, etc. ?","Python programmer here trying to learn R. What ""gotchas"" should I look out for? Resources?",3ih5ga,top
"This sub is like a monastery, there's only 1,500 of us. Between shiny, data.table, and LaF I can be more productive in one day with 3 lines of R code than I ever have been with any other language. It's practically PHP on sterroids.

Seriously, what the hell is going on? Has this language always just been a kind of hidden paradise? Even /r/scala has over 5x the subs as /r/rlanguage, and that language is a god-forsaken mess. Is R just not hipster-cool yet, or do you guys get your news/updates/discussion from somewhere else other than reddit?",Why does R not garner more attention in the developer world?,31a693,top
"I'm coding a simple card game just as an exercise to learn programming with S3 classes. I've got a class ""Card""  which is a list of the card name, its text, and other relevant data.  Then I create the class ""Deck,"" essentially a list of cards.

So I can store an actual list of Cards, or just a store a list of card names as character strings (and use something like a dataframe as a lookup table to match the name to the associated Card object). Is one of these approaches considered better style than the other, or is it a case-by-case decision? Seems like the former might lead to clearer code, but the latter might be less memory-intensive?",OO style question,921x50,top
"Hi all, not an entire novice in R, but no expert either. I'm blanking a bit... so I'm bringing in excel sheets, and after some tidying I can get it to something like this: 

https://i.imgur.com/hUoB2qD.png


I want to split up the ""personnel"" so that the names are separated... easy enough with stringr:

https://i.imgur.com/uwawcHF.png


But now I'd like to break out the split-up names based on what is in the ""role"" column, sort of like a key-value pair I guess. and thus the wall I'm running into. I'd like to make it look like:

https://imgur.com/GHmwl01 

This feels like something I know I've done before but since I don't really use R daily so it's escaping me. A bit out of practice. Thoughts?",Data tidying basic problem,8a4950,top
"I've been working with some large files, and at the end of my script, I pass the objects they're stored as to rm(), in the hope that R will release that memory once my script has finished running. 

However, this doesn't happen - afterwards I still have >3 GB of my computer's memory taken up by my R session, and when I go into task manager and tell it to 'end task', I find that when I open RStudio again, that memory is still being taken up and RStudio is still painfully slow. I've also tried restarting my computer, and doing  Session -> Clear Workspace or File -> Quit Session with no success. This is doing my head in. What should I do?",Why does R still hold large objects in memory even after closing RStudio down and even shutting down my computer?,7ylfem,top
"Hi,

I work in the field of medicine and genetics. I've been recommended R as a useful tool for statistics and processing big data (eg genomics). My goal is to eventually use R for any data processing task, from basic statistical tests for research papers, to data science, and machine learning.

I'm surprised at the amount of books out there, especially bad/obscure ones ... 

Can you guys recommend an outline for 3, to read one after the other, without excessive overlap (ie wasting time and effort) ? 

For now, I'm ""only"" interested in being fluent in R and learning advanced statistics using R. Here's my thinking :

1. Getting Started with R: An Introduction for Biologists.
Started using this last week. Very gentle introduction, exactly what I needed ... On my way to finish it in a couple of days.

2. The book of R / The art of R programming.
Both are clearly recommended by everyone, but which one would be best in this context ? Given that one is twice as long as the other ...

3. Discovering Statistics Using R, by Andy Field.
Actually started reading it a few weeks ago, without knowing any R. Realized it was more of a stats book than an R book ... But apparently great statistics material. Any other recommendations for an advanced, comprehensive statistics book using R ? I have only basic background in statistics.

Thank you.
",Learning R and advanced statistics : advice on reference books ?,7s4t04,top
"I try to cluster my Facebook friends via R using this guide - http://jean-robert.github.io/2012/01/22/cluster-your-facebook-friends.html.
As far as I understood, only friends who use Facebook for developers will show up in here. Am I correct? If yes, are there any other means of clustering Facebook friends or followers?

Disclaimer: I am a newbie to R.
Thanks!",Facebook friends clustering via R,6mu15a,top
I am looking some R app for Android to do thing on my smart phone like QPython. ,Is there R interpreter for Android like QPython?,6jyqcb,top
"Sometimes you can click ""stop"" or ""interrupt"" or whatever and it will terminate the process right away. Other times, the process will essentially freeze and ask if you want to restart R. What determines this outcome?","Why are some functions ""interruptable"" while other functions require you to terminate / restart R?",68c6tz,top
"I have hundreds of *csv files. I would like to crunch some summary statistics for each one, and then record these statistics in a single dataframe/csv file, with each row from one csv. 

Let's say it's the following data frame from base R

    > mtcars
                         mpg cyl  disp  hp drat    wt  qsec vs am gear carb
    Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4
    Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4
    Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1
    Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1
    Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2
....

I might one to record the mean of `mpg`, i.e. `mean(mtcars$mpg)` is  `20.09062`. 

The row for the resulting data frame would be 
        
                 mean_mpg   max_mpg  ... 
    mtcars   20.09           33.9          ...
    df2         232             92.7          ...

I know how to `glob` all of the *csv files in a certain path together, `files = Sys.glob(""*.csv"")`

    for file in files:
        df = read.csv(file)
        mean = mean(df$mpg)
        ....

Now, I'm stuck. How do I write these values into a row for a giant summary csv? 

(Sorry for the n00b question, but I'm a bit lost)","How to process 100s of csv files, and write a single ""summary statistics"" csv, with one file per row?",64tf5a,top
"I have about 700k phone calls form a contact centre to analyze for repeats. The basic query is: 
concatenate the callers phone number and the call reason code, if they've called in the past 6 weeks ignore them, if they have not tell me how many times they phone in the next 6 weeks for the same reason.

I ran something similar earlier this year in Excel with a data set that was about a third the size and it took hours, I'm worried if I run this in Excel it'll just lock up my computer for the whole day.

If I run this in R will ti be able to handle this type of query better that Excel? It'd take longer to write the query in R but as I see this specific type of analysis a lot in my future it'd pay off in the long run if it can do it better.",I have a very large data set to analyze and before I spend hours in R can someone tell me R will be able to process it faster than excel?,5oj7sk,top
"I'm looking at a job posting for ""Manager, Advanced Analytics"" for a large retail chain.  It calls for ""Advanced level programming in R"".

I am definitely not at the advanced level, but I might want to be, someday.  But what does it mean, specifically?  At what point can you consider yourself advanced?","""Advanced level programming in R"" - what do you think this means?",5jek6d,top
"Hi. I hope you have been well.
I am a student finishing my master thesis and my thesis consisted in developing a R package to facilitate the use of Modern Optimization tasks. 
With this post I want to make the package public to any user who want's to use it. Also I want to publish the package in CRAN, in the future. 
https://github.com/joaoctm123/rmo
Also you have the official Manual: 
https://www.dropbox.com/s/4luyr528owpozl0/rmo-manual.pdf?dl=0 
I would be very happy if you use it. But also I would be very happy if you could fill a small form (only with 8 mandatory questions of multiple choice), so I can get a feedback from the package. https://goo.gl/forms/L5Oh6VyL0Tjtb1Lq2

You can install the package from R with those lines of code. 

install.packages(""devtools"")
devtools::install_github(""joaoctm123/rmo"") 
library(rmo) 

That's very easy to install. 
If you have any doubt don't hesitate in contact me. 
Thank's a lot for your time! 
João Maia",RMO - New R Modern Optimization Package,5815gk,top
"Hey! I'm starting to get started on R and also little bit of SQL because of interest in data analytics and related jobs. I have completed Swirl tutorial on Rstudio and basic course of SQL in university so I have some understanding how R works. Now I started Coursera's Data scientist toolbox course, no idea yet if it's any good..

My questions now are:

What is the most efficient way to start self-teaching R?

What is the estimated time of studying R before having satisfactory level to succeed in entry level data scientist jobs?

Any tips or other stuff I should be aware of?",Beginner questions,52w8km,top
"https://github.com/FrankPortman/bayesAB

My first open source R package so I welcome criticism. I made it as a result of having to work with A/B testing data day-in day-out at my old job and always hating the archaic hypothesis tests. Check out the vignette and submit issues if you find any!
",Would like some feedback and usage of my first R package,52hzov,top
"I work for a private research institution (University of Washington) doing scientific research, and there is a lot of collaboration that happens between labs and research institutions. I was wondering if anyone has a best practice for a website that can host the output html files of RMarkdown, in which I can give researchers passwords/permission to view, but not accessible to everyone. I know that RStudio has RPubs which is great, but everything is public and because our data is sensitive we want to keep it within circle until publication. Thank you!",Anyone have good ideas on where to host data RMarkdown output privately? (similar to RPubs but privately),52flgp,top
"Hello, I'm really out of my element with such a question, but I really like R, and like asking questions out of my element. Before R, I was learning Haskell, and besides finding out I love functional programming, I found out I loved strong static types! 

Would it be possible to add such a type system to R? It seems like it would be an extremely messy task to add something so fundamental to an already-existing language, without building it in from the ground up, but maybe I'm mistaken on that. 

Would any current features of R need to be lost for such an addition to be used/useful? Besides the obvious of not needing to be careful about types (arguably not a terrible loss!) 

Just a random question, thanks.","R, but with strong static typing?",43dm4t,top
"I'm aware of h2o, but I was wondering if there are others that are worth considering. I was kinda hoping there was an R package for tensor flow, but it doesn't look like it.",What are the best packages to use for deep learning?,40uuuv,top
"I was watching some very nice Pycon talks today, and I'd like to see some on R. I'm using R for college but I feel like I'm just running command after command without using R to it's full potential. Any good R talks to get me up to speed with the language?

Keyword ""talk"" and ""presentation"" does not yield any (useful) results on this subreddit unfortunately. And finding something on R with a search machine is incredibly difficult.",Any good talks on R?,32hnw4,top
"I have been using the rvest package to limited success on the website [transfermarkt.com](https://transfermarkt.com)

There is one page, however, which makes it incredibly difficult to use the SelectorGadget and create/grab usable CSS elements. This is the page: [https://www.transfermarkt.co.uk/arsenal-fc/ausfallzeiten/verein/11/plus/1?reldata=GB1%262016](https://www.transfermarkt.co.uk/arsenal-fc/ausfallzeiten/verein/11/plus/1?reldata=GB1%262016)

My biggest issues is that some of the squares in the matrix are color coded (not picked up by the selectorgadget) and other times have a URL embedded in them. A solution I suppose is to say IF a square has a URL, the player was involved in a game in some aspects. Another example of this is when they do not feature due to injury, and the injury is provided through a hyperlink.   


I am wondering if there are other packages which can look at CSS elements in terms of color or other widgets which grab more CSS elements. Or if rvest/selectorgadget which can work in this case. there might be an attribute ( html\_attri() ) which would work which I am unaware of. ",How best to scrape this web data,9511vj,top
"I'm about 12 courses into Datacamp, finishing three skill tracks (R Programming, Importing & Cleaning Data, Data Manipulation).  I've yet to take on a project, and I'm feeling the need for some practical application and exercises to keep me hungry.   I'm planning to jump into the Stats or DataVis track next, so that's exciting, but I still desire something tangible.  

I'm hoping y'all can give me some encouragement to stick with this and it'll benefit me eventually.  I need this!

Right now it's hard to see the positives over Excel, but I'm very comfortable with Excel and have written dozens of VBA macros that my team utilizes daily.  Thanks.","Somebody validate my efforts, give me hope please!",8qt5ms,top
"Looking into the job advertisements I see a lot of companies requiring R as one of their skills. But all of the benchmarks I have seen so far show that R is way slower in comparison to other options \(e.g. Python, Julia\). For example [this](https://www.ibm.com/developerworks/community/blogs/jfp/entry/A_Comparison_Of_C_Julia_Python_Numba_Cython_Scipy_and_BLAS_on_LU_Factorization?lang=en), [this](https://modelingguru.nasa.gov/docs/DOC-2625) and [this](http://www.laketide.com/julia-vs-r-vs-python/). So I'm wondering why R is so popular and if there are any benchmarks proving that R is fast enough or even faster?",Any benchmarks showing the benefits of R over other languages?,8ison9,top
"I posted this on StackOverflow, but I'm desperate for a solution so here it goes:

I am trying to download an excel file, which I have the link to, but I am required to log in to the page before I can download the file. I have successfully passed the login page with rvest, rcurl and httr, but I am having an extremely difficult time downloading the file after I have logged in.  (Unfortunately the website I am trying to download from is a proprietary site related to work, so I cannot provide a working example):  

    library(rvest)

    url <- ""https://website.com/console/login.do""
    download_url <- ""https://website.com/file.xls""
    session <- html_session(url)
    form <- html_form(session)[[1]]

    filled_form <- set_values(form,
                                          userid = user,
                                          password = pass)

    ## Save main page url
    main_page <- submit_form(session, filled_form)

    download.file(download_url, ""./file.xls"", method = ""curl"")

When I run the download.file command, the file pops up in my working directory, but it is not the file I am trying to download, and is actually just a corrupted .XLS file with no data.  

  

For reference, if I log in to the website via chrome, and paste the download link into the browser window after I have logged in, the file automatically starts downloading. If I do the same in IE, the file download dialog box pops up and asks me if I want to save the file.

Possibly relevant info:

* This is for my computer at work, where cookies are disabled, so I cannot use a cookie from my browser  

* I have tried using different methods with httr and rcurl based on numerous posts on SO to no avail.  

Thanks in advance for your time!",Downloading an excel file from an https URL after login,8f7u6f,top
"I mean every time you load a workspace, you still have to use the library() function to call the specific library when starting a new session?",Saving a R workspace doesn't save the libraries loaded?,76c1q0,top
"Hello. I've recently gotten back into using R, i was wondering if there are any guided projects that could be done. When i was using it in school, the labs would walk us through the program and help us accomplish what we needed to. I've tried looking for my old labs but cant find them. 

Currently i'm going through R101 course offered by Big Data University. I'll finish going through the course, but personally i learn best when it's actually applied. 

If anyone could point me in the right direction that would be appreciated. ",Any guided projects for R?,6bpm6y,top
"So I've been teaching myself R over the past few months and I'd like to start learning how to apply my knowledge to finance. The book I have the title looks like it would be good but I was wondering if anyone here could comment on its quality (or similar books). 

Thanks in advance! ",Can anyone recommend/not recommend Quantitative Trading with R by Harry Georgakopoulos (or similar books)?,69yh4v,top
"I know that when using regular R you are limited by the amount of RAM on your computer.  I was playing around with a large data set, and noticed that I could only pull a small portion of my data (~300,000 rows) into R without crashing my computer.  And even then doing some computations would still result in a crash.  I downloaded R Server and this allowed me to pull my entire data set, but looking at the task manager I could still see that my RAM was being used, and reaching its max.  How does R Server manage memory compared to just standard R?  How is it able to deal with larger data sets while still using the computer's RAM?  What's a better solution to use R on really big data?",Memory management in R and R Server,64frat,top
"As someone who only knows C/C++/Python...

What does the dot/period mean in R? Example:

    d.f <- data.frame(rating = c(""AAA"", ""A"", ""A"", ""AAA"", 
                             ""BB"", ""BB"", ""AAA"", ""A""))
Is ""d.f"" just a variable name, but data.frame is calling a function ""frame"" from a class named ""data""? I've also seen some code like this:

    a$names = foo
    a.names = bar
Which seems really confusing if in fact the dot is just part of a variable name in the second line...",Dot/period symbol in R,61bol3,top
"My wife is learning R programming. Are there any web sites which gives assignments and puzzles related to R? I know for other programming languages like Java there are plenty of sites. but I am not sure if there are sites for R.

Edit:: I am not looking for tutorials/courses/moocs. I am already aware of those. My question was specifically on programming exercises. Or Programming Kata types of resoures.",Programming Exercises for R,5ypx0p,top
is there any point in learning r shiny and all its applications now that tableau is out there?,is shiny useful? or have tableau and other data viz apps taken over?,5wgxaq,top
Hi I've been coding with R since few months. After going through books or videos I want to try and solve some problems or projects in R language. Do anyone have some resources for that. e.g hackerrank,Need Practice projects and problems on R,5tsr3m,top
"Hello,

I am a researcher in biophysics, who works with very small databases. 

I started learning R a few months ago, with the purposes of database analysis and figures composition for scientific papers and, most importantly, to detach from Graphpad Prism. I probably couldn’t have made a better decision. 

Unfortunately, I could not follow a proper real-life course, so I learnt some R basis from books and online forums, but the gaps in this approach are probably emerging now.

I have a few questions and curiosities:

1) Where do you keep your data? Do you have a central repository on your computer for all the .csv files (e.g. /User/Rdata), or you prefer to have every .csv separate in different projects? In the latter case, what do you do if you have to use the same dataset for multiple projects?

2) Do you use relative or absolute links to refer to files and folders?

3) Do you create “templates” for analyses that are often repeated? For example, if you analyse and plot a certain parameter (e.g. body temperature) in your projects, do you already have somewhere a template that needs marginal corrections, for example in the names of the variables, or you rewrite everything from the scratch every time?

4) Do you write the code for figures and analyses as RStudio Notebooks (Rmd) or as R Scripts (.R)?

I hope you don’t find these questions too basic.

Thank you for the answers,

Best regards.

 ",Suggestions on R data organisation,5o6h50,top
"Hello, I have taken 3 grad. level R courses and use it for all my stats stuff, but I have never ""built"" anything, I just ""use"" R (if that makes sense). I would like to start a hobby project and have my ideas all laid out, but where do I start? Here is the basic idea. 

In my learning project I would like integrate a few key ""skills"" I would like to develop, that I have done all separately but not together, they are:

* Continually running script that on a server, 
* Web scraping data (real time), 
* Analyze and output a graph to a file, 
* Based on analysis, use a site's API to make an update.

Based on these goal I have the idea of making a ""Bitcoin trading bot"". Again, this is just for fun/to learn, so it will be v. small amount of bitcoin. Can anyone help direct me in my first few steps? 

Thank you R community!","Been ""learning R"" for three years, finally ready to start my first real project, may I ask for a little direction in where to start.",5jl448,top
"Any suggestions appreciated :)

The data is hosted somewhere other than my app. It updates every day, and I'd like my app to always work on the current data if possible, but it's a very large file, so I think maybe using a database would be better. What do you all think?",R Shiny: Data Analysis on a large file (~600 MB csv) which I would like to update every day. Solutions? Should I use a DB?,5jgxis,top
"I'm a graduate student studying psychology, and I'm brand new to R. I've taken a couple day-long seminars on R and worked through a lot of swirl, and I've recently started reading [David Robinson's Blog, ""Variance Explained""](http://varianceexplained.org/). One of Robinson's posts is about simulating a hypothetical board game, and it led me to this idea that I could simulate monopoly rolls to find the squares that had the highest probability of being landed on. There's a few great features of this particular project--I can build off of some of the code Robinson already wrote; this problem has been solved analytically so I can check my results against the real numbers--so I figured what the hell.

[Here is the github link](https://github.com/l3vity/Monopoly-) for anyone who wants to check it out. You can tell just how much code is lifted from Robinson's blog and how much I contributed myself. I'm really curious to hear about more efficient ways to program this type of simulation (or just ways to clean up my code). Especially if anyone has recommendations for the chance and community chest cards (lines 52-131) because the only way I knew how to handle that was just to check over and over which card you drew and then to place you on the corresponding square.
","I'm brand new to R, and I just finished a simulator for dice rolls in Monopoly",5jgwr1,top
"R tutor has been excellent for me, but I'm looking to focus more on the visualization tools than real statistical analysis for now.

EDIT: Oh wow thanks guys! I will def come back whenever I have a problem google or stack exchange can't solve!",Best resources for learning R?,5hfdko,top
"I feel like a big dummy for this but i don't get the attraction to R. I'm considering changing jobs to a place that uses R and have been working on learning it and I'm just not getting the advantage. I think I'm just misunderstanding where in the life of my work it would fit in.

As a data analyst, I mostly work in SQL. In most cases I eventually pull my work product out of the database and drop it into a visualization tool (QlikSense, Tableau) or I drop it in Excel for my clients. When I started working in R I thought it would somehow stand in for SQL, to gather and transform the data into information. 

Based on what I've seen so far R must import any data that it's going to work on, so maybe not as the SQL stand in. I've seen that it has some barebones graphing and math capabilities but nothing that makes me think that it is ""just plain better"" than Python (a different language that I have been playing in) or just using Excel. It has some basic visualization but again, they see on par to or slightly worse than the other tools that I have mentioned.

Help me figure out what I'm misunderstanding, for those of you using R, where does it fit in your process?  What's the advantage over other tools available to you and what other tools or processes are you replacing?",using R to analyze data - I don't get it,58p758,top
"Hi all

Does anyone happen to have any experience with the Riot API and R? I'm working on a package that will pump out a bunch of stats for players, and it would be awesome if there were a way pull data into R directly (or semi-directly) from the API",Pulling League of Legends data from the Riot API,5679x5,top
"Does anyone on here know a package or use a R package or input to work on commercial credit card data in a a portfolio?
- for the purpose of reporting, tracking and performance analytics. 
- vintage analysis performed my monthly portfolio data expanding over years.

if you do, please recommend one. not all finance packages are suitable
Thank you",Using R for retail credit card portoflio performance and reporting,435a5w,top
"I'm trying to get a better grasp of how a package works and want to save all of its functions to a text file including the hidden functions (package:::hidden_function).  I've used this code to snag all of the visible functions: 
> objs <- mget(ls(""package:googleAuthR""), inherits = TRUE)

> dput(objs, file = ""myfile.txt"")

Anyone know how to get all of the hidden functions too? 
",How can I export all package functions to a file?,414rib,top
"I'm cross-posting this question to [/r/rlanguage](http://www.reddit.com/r/rstats/comments/39em7u/question_objectoriented_programming_in_r/) and [/r/rstats](http://www.reddit.com/r/Rlanguage/comments/39entq/question_objectoriented_programming_in_r/).

Abandon all hope, ye who enter here. I'm attempting to do OOP in R.

Namely, I want to *extend* a primitive type using `setClass()`. Specifically, I want to create a data.frame using my subclasses and then use the `class()` function to know which *sub-type* of each primitive class a given column might be. For example, let's assume I've already been successful with this (as far as I can tell) black magic to extend the type `numeric` with a class called `enum`. Perhaps I would like to have a type that is both level-defined (such as a factor) but whose level has equal semantic and syntactic meaning (like a number).

    > # [insert num -> enum setClass() black magic]
    > my.data.frame = mtcars
    > my.data.frame$cyl = as.enum(my.data.frame$cyl)
    > sapply(my.data.frame, class)
      mpg       cyl      disp        hp      drat 
    ""numeric"" ""enum""    ""numeric"" ""numeric"" ""numeric"" 
       wt      qsec        vs        am      gear 
    ""numeric"" ""numeric"" ""numeric"" ""numeric"" ""numeric"" 
     carb 
    ""numeric"" 

My specific use-case will be extending string instead of numeric but I figure the principle is the same.

I've gotten as far as this:

    > enum = setClass(""enum"", contains = ""numeric"")

This defines an object with has **one slot** for a numeric ""field"" in my new object, but I'm not sure if this is exactly what I want. If someone can inform me that this is, in fact, the solution to my problem then I'd be happy to hear it.

An example:

    > is.numeric(enum(5))
    [1] TRUE

Seems to be good.

    > enum(5)
    An object of class ""enum""
    [1] 5

The ""An object of class..."" line is a little unsightly but it is a small price to pay.

    > class(enum(5))
    [1] ""enum""
    attr(,""package"")
    [1] "".GlobalEnv""

Eww. Now I feel like R is somewhere between pitying and loathing me. Can I make that attribute go away?

Now for the *real* test:

    > my.data.frame = mtcars
    > my.data.frame$cyl = enum(mtcars$cyl)
    > sapply(my.data.frame, class)
          mpg       cyl      disp        hp      drat 
    ""numeric""    ""enum"" ""numeric"" ""numeric"" ""numeric"" 
           wt      qsec        vs        am      gear 
    ""numeric"" ""numeric"" ""numeric"" ""numeric"" ""numeric"" 

It... actually looks OK. In fact, it's so OK that I actually think I must have screwed something up along the line. Can anyone here give me a second set of eye-balls to verify that I'm doing this correctly?

Namely, in the following example I will use `str()` to inspect the enumerator vector in my data frame. I notice that it merely states that the `enum` class *contains* a numeric vector, not that it necessarily *extends* a numeric vector.

    > str(my.data.frame$cyl)
    Formal class 'enum' [package "".GlobalEnv""] with 1 slots
      ..@ .Data: num [1:32] 6 6 4 6 8 6 8 4 4 6 ...

In Java terms, I'm concerned about the difference between

    public class Enum extends Integer {
        public int value;
        public Enum(int value) {
            this.value = value
        }
    }

and

    public class Enum {
        public int value;
        public Enum(int value) {
            this.value = value
        }
    }

Could anyone here confirm or deny that I am correct in my usage of `setClass()`?",[Question] Object-oriented programming in R,39entq,top
"So, my goal here is to create an Shiny application which takes user's input, changes it into a matrix, then uses a pre-saved Keras model (basically saved weights) to predict a certain variable of his (and prints it). I am new to Keras and Shiny, so I'd appreciate any help.

    server <- function(input, output) {
      hisdata <- matrix(cbind(input$VK_001, input$VK_002, input$VK_003, input$VK_004,input$VK_005,input$VK_006,input$VK_006, input$VK_007, input$VK_008, input$VK_009,input$VK_010,input$VK_011, input$VK_012, input$VK_013,input$VK_015, input$VK_017, input$VK_018, input$VK_021, input$VK_022, input$VK_024, input$VK_025, input$VK_027, input$VK_028, input$VK_030, input$VK_031, input$VK_033, input$VK_034, input$VK_036, input$VK_037, input$VK_039, input$VK_040, input$VK_041))
      test_data <- hisdata
      model <- load_model_hdf5(""my_model_bft_003.h5"")
      test_predictions <- model %>% predict(test_data)
      output$oid1 <- renderPrint({x <- test_predictions[ , 1]
      print(x)
      })
    }
    ui <- fluidPage(
      
      # App title ----
      titlePanel(""Shiny + KEras!""),
      
      # Sidebar layout with input and output definitions ----
      sidebarLayout(
        
        # Sidebar panel for inputs ----
        sidebarPanel(
          
          # Input: numeric----
          
          numericInput(""VK_001"", ""Value:"", 10, min = 1),
          numericInput(""VK_002"", ""Value:"", 10, min = 1),
          numericInput(""VK_003"", ""Value:"", 10, min = 1),
          numericInput(""VK_004"", ""Value:"", 10, min = 1),
          numericInput(""VK_005"", ""Value:"", 10, min = 1),
          numericInput(""VK_006"", ""Value:"", 10, min = 1),
          numericInput(""VK_007"", ""Value:"", 10, min = 1),
          numericInput(""VK_008"", ""Value:"", 10, min = 1),
          numericInput(""VK_009"", ""Value:"", 10, min = 1),
          numericInput(""VK_010"", ""Value:"", 10, min = 1),
          numericInput(""VK_011"", ""Value:"", 10, min = 1),
          numericInput(""VK_012"", ""Value:"", 10, min = 1),
          numericInput(""VK_013"", ""Value:"", 10, min = 1),
          numericInput(""VK_015"", ""Value:"", 10, min = 1),
          numericInput(""VK_017"", ""Value:"", 10, min = 1),
          numericInput(""VK_018"", ""Value:"", 10, min = 1),
          numericInput(""VK_021"", ""Value:"", 10, min = 1),
          numericInput(""VK_022"", ""Value:"", 10, min = 1),
          numericInput(""VK_024"", ""Value:"", 10, min = 1),
          numericInput(""VK_025"", ""Value:"", 10, min = 1),
          numericInput(""VK_027"", ""Value:"", 10, min = 1),
          numericInput(""VK_028"", ""Value:"", 10, min = 1),
          numericInput(""VK_030"", ""Value:"", 10, min = 1),
          numericInput(""VK_031"", ""Value:"", 10, min = 1),
          numericInput(""VK_033"", ""Value:"", 10, min = 1),
          numericInput(""VK_034"", ""Value:"", 10, min = 1),
          numericInput(""VK_036"", ""Value:"", 10, min = 1),
          numericInput(""VK_037"", ""Value:"", 10, min = 1),
          numericInput(""VK_039"", ""Value:"", 10, min = 1),
          numericInput(""VK_040"", ""Value:"", 10, min = 1),
          numericInput(""VK_041"", ""Value:"", 10, min = 1)
        ),
      
      # Main panel for displaying outputs ----
      mainPanel(
        h4('Predicted values'),
        verbatimTextOutput(""oid1""))
        
      )
    )
    shinyApp(ui = ui, server = server)

​",Using Keras with shiny,99z53v,top
"Hello there! I want to simulate queue (M/M/1, M/M/C etc etc.) with poisson distribution, mean arrival/service rate. 

I have been told that R-programming is very good for this. I have have very low experience with this, so I would be quite happy if somebody could help me getting started with code, and get some results out. 

&#x200B;

Could somebody please help and assist me? :)",Queueing simulation in R-programming,99munj,top
"I am not the best when it comes to writing things in a very R-like style, but I've gotten better since learning data.table.  However, and interesting problem came to mind this weekend (while I was in Vegas of course).  Many problems I've encountered with production data, at least for the questions I'm asked, are similar, but a simple challenge came to mind.

What would be the most code efficient way to determine losing and winning rolls for a series of craps rolls:

1) assuming the data is in some sort of data frame
2) assuming that the first roll begins the series
3) assuming we're just looking at ""pass line"" betting (don't would be extra credit)

simple data set for testing would be:

    Obsnum = 1:10000
    roll <- replicate(10000,sample(1:6,1) + sample(1:6,1))
    DF <- data.frame(Obsnum,roll)
    DT <- data.table(Obsnum,roll)    # (if you speak data.table)

For those unfamilar with the rules of craps, here is how winners would be determined:
The dice are rolled on what is called ""the come out"" roll.  if the dice show 7, WIN, if the dice show 2,3,or 12 , LOSE.  If the dice show any other number, a POINT is established.  Then, for the next ?? throws, a loss or a win is determined by either making the POINT again (WIN) or a 7 (LOSS).  Since this can take an infinite number of throws, herein lies the problem.  (Perhaps there's an easy solution I don't know about and then I'll feel like an ass when someone posts ""hey, just use xxx"").  After a WIN or LOSS, the game ""resets"" back to the ""come-out"" roll.

Since 7 is important, I'm using `set.seed(7)`

Here's a baseline non-R-esque code for benchmarking:

    flags<- rep(""ROLL"",100000)
    come_out <- 1  # 0 is ""point cycle""
    point <- 0
    for(i in 1:length(DF$roll)){
      if(come_out){
        if (DF$roll[i] == 7 | DF$roll[i] == 11)
          flags[i] <- ""WIN""
        else if(DF$roll[i] == 2 | DF$roll[i] == 3 | DF$roll[i] == 12)
          flags[i] <- ""LOSE""
        else{
          flags[i] <- ""POINT""
          come_out <- 0
          point <- DF$roll[i]
        }
      }
      else{
        if(DF$roll[i] == point){
          flags[i] <- ""WIN""
          come_out <- 1
          point <- 0
        }
        else if(DF$roll[i] == 7){
          flags[i] <- ""LOSS""
          come_out <- 1
          point <- 0
        }
      }
    }
    DF <- cbind(DF,flags)


comments welcome, if I did anything wrong for the set up, let me know.  If I can find a savvy solution, I'll post it.

EDIT:  Please note that the data should be generated before your code takes over.  Imagine that you're handed the data-frame by your supervisor or something, not that you're generating the rolls or probabilities in your code.  This is a question about optimization of things that aren't simple ""shift""s or otherwise basic vectorization. (unless, like I say, I'm the idiot and missed something basic.)",R-esque code challenge?,95ffml,top
"
A person goes through a maze made of 32 T-intersections. At each intersection they can decide to turn either left or right; each time, on one side there will be a wall, while on the other side the maze will continue to the next intersection.

Their goal is to arrive to the end of the maze as soon as possible.

At each intersection, the person is aided by two cues, a visual cue and an auditory cue. **The cues are not always correct and not always in agreement**. Specifically, the cues can have different level of reliability. For example, in one maze the auditory cue may be correct 50% of the times, while the visual cue may be correct 25% of the times.  

The cues may be reliable at three different levels: 25%, 50% and 75%.  The reliability of cue does not change within one maze, but may change from maze to maze. Each new maze is a completely different situation. 

Since we have three different reliability levels, combining all of them we have a total of nine mazes.

I would like to model this maze in R. 

First I would need to generate nine mazes, with auditory cues and visual cues randomized according to their reliability level.

Then I would like to model the outcomes of a subject going through the maze according to a decision rule.

For example, let's say that subject A has the following decision rule: if in the first 10 trial one cue is correct more often than the other, he will always follow that cue for the rest of the maze.

Once the decision rule is set, I would have the subject go through the nine mazes and count how many times he made the correct decision. After that I could model a different decision rule.

I am a bit at loss on how to simulate this process! Any ideas or resources I could refer to?",Maze simulation in R,94ntt9,top
"Is there a tool similar to mypy, but for R? I would like to gradually annotate existing code (e.g. with comments or in some other way that doesn't change its runtime behaviour) and then check the code for type errors without running it. The only package I've found that is kind of similar to what I need is rtype, but it solves a rather different problem (and requires that I actually run the code). I also know that RStudio performs some kind of static analysis and can detect things like missing arguments, but I don't know how to accomplish what I need with RStudio either. I understand that writing a checker like that is hard. To be useful, it would need to know the types not only for R base but also for third party packages, which weren't written with static typing in mind. But maybe something like that exists. I would appreciate any hints.",A static type checker for R?,8w80ke,top
"I see this assignment in a script I am looking at:


counts.df <- NULL

This basically just means the variable count.df is assigned the value NULL right?

You can't have variable names with periods in python that is why I am thrown off by this and asking. Thanks","Coming from python, I just want to check something about periods being in variable names",8pd9sa,top
"I am using this example from the book ""Linear Algebra and Its Applications"" to produce the sample covariance matrix.

https://imgur.com/a/oceFrtw

This is my R-code

    M = cbind(c(1,2,1), c(4,2,13), c(7,8,1), c(8,4,5))
    m = apply(M, 1, mean)
    X = M-m
    X%*%t(X)/3

    >     [,1] [,2] [,3]
    >[1,]   10    6    0
    >[2,]    6    8   -8
    >[3,]    0   -8   32

This produces the same output as the book. But when I use the built in Cov to calculate the sample covariance I get something else.

    cov(M)

    >           [,1]       [,2]       [,3]       [,4]
    >[1,]  0.3333333  -2.166667   1.333333 -0.8333333
    >[2,] -2.1666667  34.333333 -22.166667 -1.3333333
    >[3,]  1.3333333 -22.166667  14.333333  1.1666667
    >[4,] -0.8333333  -1.333333   1.166667  4.3333333

How come?",Covariance of this data,8o2jl4,top
"I am using this http://r4ds.had.co.nz/data-visualisation.html#facets, trying to learn basic stuff. I am on the exercises where I have to make the plot on the right: https://imgur.com/a/XQqj0eJ

My attempt is on the left. 

I tried changing the size of the points but that doesn't seem to be right, how do I make them overlap like the example?

edit: My code: 
ggplot() + 
	geom_point(data = mpg, mapping = aes(x = displ, y = hwy), show.legend = FALSE) + 
	geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy, group = drv), se = FALSE)",Beginner R problem with point overlapping,8nsznr,top
"Hi, I'm trying to get the whole data from an infinite scroll table and then scrap it as stated in the title. My progress so far goes like this;

    library(rvest)
    library(RSelenium) 
    #https://github.com/ropensci/RSelenium/issues/172
    
    Url <- ""http://www.tjk.org/TR/YarisSever/Query/Page/Atlar? 
    QueryParameter_OLDUFLG=on""
     
    driver<- rsDriver()
    remDr <- driver[[""client""]]
    remDr$navigate(url = Url)
    #remDr$close()
    
    webElem <- remDr$findElement(""css"", ""body"")
    while(TRUE) {
      webElem$sendKeysToElement(list(key = ""end""))
      #Error in resContent[[""status""]] : subscript out of bounds
      #https://github.com/ropensci/RSelenium/issues/169
    }

It is a large table with around 70000 entries and only shows 50 of them per scroll. This code scrolls down something like 40 times, and gives that error that I've copied as a comment:

    #Error in resContent[[""status""]] : subscript out of bounds

Is there a way to solve this problem in RSelenium? Another thing I might be able to use is that as I scroll down in the browser and inspect, the newly loaded tables go like this;

    <tbody id=""tbody0"" class=""ajaxtbody"">...</tbody>
    <tbody id=""tbody1"" class=""ajaxtbody"">...</tbody>
    <tbody id=""tbody2"" class=""ajaxtbody"">...</tbody>

and adds a new one as I scroll. Could those id's be useful to get the information? Thanks in advance.",Loading an infinite scroll table,8mpejy,top
"Hi guys, I'm a highschool senior looking to major in nuclear engineering next year in college. Would you recommend learning R over the summer or is there a better program I night want to check out?",New comer to R,8k15to,top
"For rolling calculations (e.g. rolling mean), is there a traditional/standard way to refer to and/or label the values? For example, do I refer to a mean by both bounds (e.g. 2009-01-12 to 2009-02-12) or only the starting or ending boundary? I've been labeling my values with the starting limit thus far, and the plot subtitle says the range used in the rolling calculation.  

EDIT: No responses so I'm guessing there isn't a tradition yet.",Traditional/standard way to label rolling calculation,8hgioq,top
"So I've tried create a shiny app from scratch using geographic data, but my attempt had no success. What I tried to create was a simple app that will just take two inputs (a shapefile and a raster) and then plot them. But by using this [code](https://pastebin.com/sQPgfFBH) i ran into this error 
>Error in .getReactiveEnvironment()$currentContext() : 
  >Operation not allowed without an active reactive context. (You >tried to do something that can only be done from inside a >reactive expression or observer.)

Can anyone give me any advice on whether it is a logical or a syntax error because I am fairly new to Shiny
",Creating a map with R Shiny,83fi5v,top
"Hi 

New R disciple here. I'm trying to learn how to use R for Value at Risk and Expected shortfall (Conditional VaR) estimations through GJR-GARCH modelling.

Which libraries can help me out plus I'd appreciate some pointers with GARCH type modelling with R.

Thanks in advance.",Which R libraries best handle GJR-GARCH volatility modelling?,8326dd,top
Something similar to PRAW for python?,Is there an R package for reddit analysis?,7rw73d,top
"I am fairly new to R, I took several courses on Udemy and have been working with my own data sets in R.

Are there any good places to learn how to create an interactive dashboard?

The end goal is to be able to create a multi page interactive dashboard with some drop down filters to adjust the outputs.

I am looking for 2 things, An in-depth tutorial and second some best practices on how to organize the data and display the data for high level execs in these dashboards. 


EDIT:: is there a way to save these files as an HTML file and keep the functionality. I am trying to create an internal Dashboard that I can just place the HTML file into a network drive with out actually hosting anything. Just so a few execs can open the html file and view the outputs.",Tutorials for Creating Dashboards,7frzzf,top
"Hey guys, I'm pretty new to R. I'm currently doing an assignment for a math course where doing some simple excercises with R gives you extra credits in the class im taking. 
The bad part though is that our teacher didn't explain us anything at all about this programming language. He just gave us some scripts and told us to understand how to use them to solve some equations he gave us. Sadly I'm just not understanding how to do this intuitively so I wanted to ask for some help here by posting a few examples and I'll try to do the rest of the assignments by myself. 
The equations are the following (note: we need to solve them only graphically): https://gyazo.com/60e790b4adbef1c9067f0476ea1e345c
Thank you for the help in advance :) ","How to solve simple equations, inequalities and partial sums with R.",7d69mf,top
"Hello,

I would like to draw a ggplot of NMDS solution with particular groups of species written in different font-faces while also avoiding overlapping of the species labels. I tried putting the species groups each in their own data frames and while the font-faces are different, the species labels overlap. 

    #### NMDS ####
    inh.nms<-metaMDS(inh.sp,k=2,trymax=100)
    inh.scores <- as.data.frame(scores(inh.nms)) 
    inh_sp.scores <- as.data.frame(scores(inh.nms, ""species""))
    inh_sp.scores$species <- rownames(inh_sp.scores)

    inh_sp.lehto<-inh_sp.scores[inh_sp.scores$species %in% lehto,]
    inh_sp.uhis<-inh_sp.scores[inh_sp.scores$species %in% uhis,]
    inh_sp.muut<-subset(inh_sp.scores,!(inh_sp.scores$species %in% lehto))
    inh_sp.muut<-subset(inh_sp.muut,!(inh_sp.muut$species %in% uhis))

    #### plotting ####
    inh.ORD.e<- ggplot() +
    geom_text_repel(data=inh_sp.muut,aes(x=NMDS1,y=NMDS2,label=species), size=2, segment.size=0.1,segment.color=""#CCCCCC"") + 
    geom_text_repel(data=inh_sp.lehto,aes(x=NMDS1,y=NMDS2,label=species), size=2, segment.size=0.1,segment.color=""#CCCCCC"", fontface=""italic"") + 
    geom_text_repel(data=inh_sp.uhis,aes(x=NMDS1,y=NMDS2,label=species), size=2, segment.size=0.1,segment.color=""#CCCCCC"",fontface=""bold"") + 
    coord_fixed() +
    coord_cartesian(xlim = c(-1.5, 1.0)) +
    theme_bw()+
    theme(panel.background = element_blank(), 
        axis.text=element_text(size=18,family=""serif""),
        axis.title=element_text(size=18,family=""serif"",face=""bold""),
        legend.title=element_text(size=18,family=""serif""),
        legend.text=element_text(size=18,family=""serif""),
        plot.title=element_text(size=12),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        plot.background = element_blank())


    grid.arrange(inh.ORD.e,ncol=1)

Also, [here's a pic](https://i.imgur.com/btDuqPb.png) of what the result looks like now. You can't make the species names due to the overlapping caused by using three separate geom_text_repel commands.","In ggplot, use geom_text_repel and write subsets of data in different font-faces",7aruaw,top
"If I try to construct a decision tree model using the rpart() function as follows, I find it has an overall accuracy of about 76%.

> modfit_rpart <- rpart(classe ~ ., data = training_subset, method = ""class"")

However, if I try doing the same thing with the train() function and specifying the method = ""rpart"", I find I only have 50% accuracy:

> modfit_train_rpart <- train(classe ~ ., data = training_subset, method = ""rpart"")

I also have tried incorporating cross-validation as follows:

> modfit_train_rpart2 <- train(classe ~ ., data = training_subset, method = ""rpart"", trControl = trainControl(method = ""cv"", number = 10))

This makes no difference, I find the accuracy remains 50% after apparently applying 10-fold cross-validation. 

What could be the reason for these functions to behave so differently and for my cross-validating to have no effect?","Big difference between rpart() and train(..., method = ""rpart"") and attempts at cross-validation appear to fail?",766w7e,top
"I looked around for a guide for installing Rstudio on my Pi3 with a 64G card and couldn't find one that worked. Has anyone been able to do this? I know that I could use Rstudio Server on a different computer or try Rkward but I'm used to Rstudio at home/work  and I would rather not turn on my main computer just to keep the poorly ventilated room its in cooler, so if I can stick with Rstudio Desktop I would.

I found this [guide](http://herb.h.kobe-u.ac.jp/raspiinfo/rstudio_en.html) but it is for an older version (currently on 5.4.2 and so the cmake files are different) and I haven't been able to get them to work.

Any help is appreciated.
",Guide to install Rstudio or other IDE for R on Raspberry Pi 3,6pyoit,top
"I've always been casually interested in cryptography, and since I've been learning R for statistical analysis this last year, I wanted to try to put it to use for something a little different. 

Putting this together required me to learn a lot about how R deals with text strings and also the basics of regular expressions--things I never really needed to use when doing regression and so on for my classes. 

So here's what I wanted to do: take a body of text encrypted in a simple substitution cipher, like caesar or affine, and analyze the letter frequencies in that text, then compare them to the actual letter frequencies in standard English, then replace the former for the latter. The assumption is that over a sufficiently large enough body of text, it should to some extent decipher the text. 

However, it returns completely garbled gibberish. The size of the text required for that assumption to be met is enormous. Even entire books don't actually generate the letter frequencies in English; for example, my choice sample text, Dewey's *Democracy and Education*, has a different order of letter frequencies than the list given by wikipedia, even for the top letters. 

However, as an exercise I learned so much and considering it took me several hours over a month or two to do, I'm really just happy that I'm not getting any more error messages. I learned HTML and CSS when I was in my early teens, and have used R for stats classes, but this is the first time I felt like I was actually doing computer programming. I'm really just happy the damn thing returns a result without any error messages. It does what I want it to do, even if what I want to do is generate garbage. 


So plug in your ciphertext and enjoy some giggles as it returns even more gibberishy gibberish to you :)



    freq.sort<-function(x){
      # this function takes text encrypted in a simple substitution cipher
      # and calculates the frequencies of the letters in that ciphertext. 
      # It returns the ciphertext with the characters replaced by the letter
      # having that frequency in standard English, where e is the most frequent
      # letter, followed by t and so on until z. Over a large enough body of 
      # ciphertext, this statistical analysis should approximate a decryption
      # for any simple substitution cipher. 
      eng.low<-paste(letters, collapse="""") # the standard English alphabet
      r<-tolower(x) #converts ciphertext to lower case
      s<-gsub(pattern=""\\W"", replace="""", r) # removes punctuation
      t<-gsub(pattern=""\\d"", replace="""", s) # removes numerals
      letter.frequencies<-substring(t, 1:nchar(t),1:nchar(t))
      # creates a substring of letter frequencies
      tab<-sort(table(letter.frequencies), decreasing = TRUE)
      # a table of letter frequencies in decreasing order
      tabstring<-attributes(tab) # culls information about that table.
      # previous line and following lines are an ad hoc solution because
      # I couldn't figure out how to make a string of the column names. 
      tbstring2<-paste(tabstring[2]) #pulls only the info we want
      tbstring3<-gsub(pattern=""\\W"", replace="""", tbstring2)
      tbstring4<-gsub(pattern=""\\d"", replace="""", tbstring3)
      # these serve to clean up the noise generated by R
      tbstring5<-unlist(strsplit(tbstring4, split='ciesc', fixed=TRUE))[2]
      # removes everything but the column names from the prior table
      while(nchar(tbstring5) < 26){ 
        tbstring5<-paste(tbstring5,""_"")
      } #counts the number of characters in that string:
      # as long as the string of char frequencies generated is less than 
      # the number of letters in the English alphabet, this will add
      # underscores as blank characters at the end of that string.
      cipher<-chartr(eng.low,tbstring5,x) # the actual decription. 
      return(cat(cipher)) #returns decrypted text without quotes. 
    }

    freq.sort(txt)","I made my first real function, and I'd like to share it for giggles and feedback.",6fjclz,top
"Hello, so trying to learn more about R and usinr Latex in Rstudio. It is set up to go so now I was just wanting to fiddle around. 

https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html

I want to use the Chickweight. Different chicks are given a different diet and their weight is measured over time. However, since each chick has multiple observations, I was wondering how I can use this. 

My question, how can I group each chick and its multiple observation to get a sensible plot going which will show the difference between the chicks and their respective diets. Giving each diet a differnet color and then seeing which one yields a better result sounds like a good idea, but how would I do this? Or should I just ignore the ""chick"" variable and see how weight changes over time when I compare only each diet to one and another?","Learning R studio, Knitr and just basic functions. Have a question about a dataset and how I could use it to make a table and plot",68l9yh,top
Does anyone have any thoughts on using Atom as an R IDE?,Thoughts on Atom as R IDE?,68bbwr,top
"Hello, I've downloaded a version of R and I'm trying to teach myself how to get better at it with some YouTube videos, however I must not have the most recent version because the Youtube Channel ""Data Camp"" is showing a different screen.  Where do you recommend I go? ",Where Can I Download R?,64l2yc,top
"Hi,

I'd like to implement a semi-supervised learning strategy called [self-training](https://www.cs.utah.edu/~piyush/teaching/8-11-slides.pdf). Is there a better package for this than [DMwR](https://artax.karlin.mff.cuni.cz/r-help/library/DMwR/html/SelfTrain.html) ?

A nice feature would be to have something compatible with caret.

Thanks !",Best R package for self-learning (semi-supervised learning) ?,60tmpz,top
"I'm having trouble using Excels Solver and setting up the question. But I'd like to be able to answer questions like this one day with R. Does anyone have any homework examples? Is this doable with R?


>For a telephone survey, a marketing research group needs to contact at least 600 wives, 480 husbands, 400 single adult males, and 440 single adult females.  It costs $4 to make a daytime call and (because of higher labor costs) $10 to make an evening call.  The table below lists the results that can be expected.  For example, 30% of all daytime calls are answered by a wife, …  Because of a limited staff, at most half of the calls can be evening calls.  Determine how to minimize the cost of completing the survey.

>[Link to Table](http://imgur.com/BNyxTVA)

",Could I answer my homework optimization problems like this with R? What packages are required?,5t1fox,top
"Do you know the moment when you become to feel comfortable with a programming language but at the same time, you feel like you could learn more ? This is me with R right now.
Does anyone know a good website/app to have everyday tips/to learn useful functions ?
Thanks !",Learning some R everyday,5ss5md,top
"I found myself unsatisfied enough with the builtin combn() function that I've decided to build an alternative.

Specifically, when one calls combn() with substantial values, the L2 cache will overflow, and the results will need to be stored in main memory, then read back into the L2 cache to be applied to whichever data structure one is analysing.

When one calls combn() with slightly more substantial values, the operation is rejected due to insufficient memory to store the result.

So I found myself thinking, is it possible to generate arbitrary combinations without generating the rest of the table?

It is, and the primary limit on generating combinations in such a manner is the number of values that can be referenced with integer precision. Given 64-bit R doesn't have 64-bit integers, this limits the indexable combinations by the 53 binary digits of precision available to the 'numeric' type.

It strikes me that I've stumbled across a solution to a pretty general problem.

Does anyone want to beta test? Project is at https://github.com/mm0hgw/combnGen and approaching CRAN readiness.

devtools::install_github(repo=""mm0hgw/combnGen"",subdir=""combnGen"")",Combinations,5mmoi6,top
"Hi everybody, I'm going to be writing a function to download MSCI index data from their website instead of doing it manually. Is it generally considered bad form to a) do this at all, b) post the code for others to use?

R is my first programming language, so I'm not sure what the norms are for this kind of thing. Is everything considered basically fair game as long as the data is publicly available and you're not sending huge amounts of requests to the website at a time?",Question: Is it ethical to web scrape?,5m8v5c,top
"How would I make a record of what a user did while using a Shiny App?

So I made an app for fun and experience ( http://williamapp.shinyapps.io/HSK3_Mini_Test). At it's core the app is a foreign language test with audio, writing, and typing questions. One feature I'd really like is to be able to record people's answers. It'd be a really interesting dataset, I could go through and see if there are certain words or grammar structures that tend to be more difficult. Unfortunately, I'm not really sure how to do it.
  
My best psuedocode solution would be something like:  
-Import list of 1000 unique identifiers. Select one.  
-IF user has input all answers AND no csv file named ""Unique_Identifier"" exists  
-THEN print all input$answers to csv file title ""Unique_Identifier+Sys.Date()""   
-Delete ""Unique_Identifier"" from list of unique identifiers.  
  
BUT   
1 I'm hoping there's a more elegant and complete solution  
2 It's hosted on the RStudio shinyapp.io thing, which is great, except I don't really understand where any csv file I would save would go. It's just Somewhere On The Interwebs and I don't know how to download things from there.",How to capture user data is a Shiny App,5ifez7,top
"How do I log in to https://data.niwa.co.nz/#/home with R or python to download a large quantity of data? The user interface of this website only allow users to download one year of data for one parameter at one site. I need 19 years of data for 5 parameters from 9 sites , this means i have to download 855 files individually. What a pain! I tried to use R RCurl to access and save files but the website declined access because i am not logged in. 
",Log in to website using R?,5auo8o,top
"I have programmed with  R for over 1 year now. I am constantly using Rbind to do everything. Mostly a loop to rbind to a empty table. It is slow, and I feel like there is a easy way to do this, but I am not aware of it. ",Why am I constantly using Rbind?,5a6vdn,top
"I need R for a couple graphs, and was wondering if there is any type of overlay that will allow me to do the following things using drop down menus and the like, and output the code I would need to do it in vanilla R:

- change line colors
- change the type of dots
- change labels and titles
- change the number of columns in a histogram
- etc.

I'm hoping to use this to make graphs quicker, but also to allow me to understand what changes in the code are necessary to obtain the type of graphs I want

**edit**

Thank you all for your suggestions. I'll be sure to check them out and see what works best for my purposes",New to R - Is there a program or IDE that is user-friendly for beginners to make graphs?,589udq,top
"I am taking a Political Science/Statistics class. The data manipulation is done with Excel only. I have been wanting to learn R for a while, so I figured that I'd try to complete all the assignments with R on the side to learn. I am very new to the language, and only have some experience with one of the Coursera courses on the language.

For this assignment, we took electoral data at a county level in a state from the 2012 Presidential elections. I used this source: http://www.politico.com/2012-election/results/president/california/

I am having trouble understanding web scraping. The data isn't consistently presented on the page in the sense that a county lists the winner first, whether that is Obama or Romney. I don't know how to pull their data separately consistently. 

Thanks in advance.",How To Best Scrape Data From a Non-Uniformly Organized Source?,55p01n,top
"I'm pretty new to R. I'm doing scheduled (cron) jobs in Linux, but need to develop a simple GUI to share with my Windows coworkers. I've seen RGui and RStudio, but is there a simpler or lighter weight R environment for Windows? Something that does not pop up the default window, but just run my script & pop up those windows? I don't want to scare people with a log or a script window...

I latched onto gWidgets because it looked pretty straightforward and visually appealing, but is there a better GUI tool kit than gWidgets? I'm coming from a JSL / JMP background.",What's the lightest weight R environment to support gWidgets or similar in Windows?,50aqdc,top
"Quick tutorial  about some basic functions in R. 

http://www.storybench.org/getting-started-r-rstudio-notebooks/",R fundamentals.,4yme0t,top
"I'm going through the code in [the JSS split-combine-apply paper](https://www.jstatsoft.org/article/view/v040i01), and I'm having trouble just replicating the plyr code on the third page, specifically the call to aaply(). [Apparently this is a known issue that Hadley acknowledged](https://groups.google.com/forum/#!topic/manipulatr/kg2wDU96mGM), at least since 2014. 

Is there a fix to plyr that can make this work? And is this just a bug with aaply or the entire package? 

Thanks!",Help with plyr code in Hadley's split-combine-apply paper,4xkdjf,top
"Hi!

I am having *Hash Sum mismatch* errors when trying to install the latest R release on Ubuntu 14.04

I've added the relevant mirrors to my list of sources and followed the steps stated in the official [README](https://cran.r-project.org/bin/linux/ubuntu/README) for Ubuntu installations.

When I run

    sudo apt-get update

I get the following error

    W: Failed to fetch https://cran.r-project.org/bin/linux/ubuntu/trusty/Packages  Hash Sum mismatch

    E: Some index files failed to download. They have been ignored, or old ones used instead.

I have tried using other mirrors and other [known solutions](http://askubuntu.com/questions/41605/trouble-downloading-packages-list-due-to-a-hash-sum-mismatch-error) for Hash Sum mismatches in Ubuntu. None of them worked.

I am re-installing R because my server ran into some trouble and I have to rebuild it today. I have no issue with R installation on Ubuntu 14.04 3 days ago.

Is this issue caused by the latest update to R? I went to https://cran.r-project.org/bin/linux/ubuntu/trusty/ and noticed 10 items updated today at 04:05, including the file Packages

I would like to know if:

* This issue is a temporary issue caused by the latest updates to the cran mirrors? If yes, how long before it is resolved?

* Is there a work-around? I would like to set everything up by today if possible.

Thank you very much!",Unable to install latest R Ubuntu 14.04,4jfg53,top
"So I'm not very good in R, but I need specifically use it to figure the derivative equation to a set of equations I have.

I have input file that looks like this:
    
    y=4x/(1-x)
    y=6x/(14-x)
    y=3x/(5-x)
    etc..
    

I figure math like this is (or rather should be) second nature to a math oriented language like R, but searching for a means to do it is unintuitive. Can you guys help me out?

*background: I'm using redhat linux, and am using Rscript on command line (bash) to do my coding and compiling.*","I have a set of equations written down, and I need to know how to do calculus on them in R. I can't seem to find the precise methods though; can you guys help?",4ihsvf,top
Is there an R IRC channel that people use? If not should we set one up for the sub?,IRC channel for r?,4hx5f7,top
"A friend is having a very bizarre problem that I can't figure out: any attempt at making a scatterplot with the plot() function returns the error:


    plot() error in unique.default(x, nmax = nmax) 


For instance, she gets the error when running the following code (even though it works perfectly fine for me):

    a <- c(1, 2)
    b <- c(2, 3)
    plot(a ~ b)

Any ideas what could be going on? ",Bizarre problem: can't create any scatterplot with plot(),4exs9q,top
"Hello,
Does anyone know a good R elo package that I could use for MLB and the NFL seasons? I would like to update this each day/week throughout the season with the previous weeks scores, and then use it to try to predict upcoming games. I saw a package called PlayerRatings but it looks like it is setup for Australian Soccer. I am a bit of an R novice. ",R Elo Package for MLB and NFL?,4d4vbb,top
"I have almost no experience with R. I've done the first few exercises in Swirl, but that's it. My goal is to be able to write programs that can search through a dataset and generate ""heatmaps""... ie something like this: http://3.bp.blogspot.com/-yPY_35lsFuM/Uh9Y7WU7fDI/AAAAAAAACAo/mX9m8T0VSUc/s400/POVERTY.gif

Would Swirl give me the knowledge to do this? If not, could any of you recommend any resources for me to do after I get through Swirl?

Thanks everyone. I appreciate it.",What are the best resources to get to my goal?,4c7bq0,top
"Hi, first time posting here. 

So at my work, I adopted some R code that I need to make more robust and add some additional features. One thing that I want to add off the bat is automatic dependency downloading. 

So basically, I created a folder inside my git repo that is going to contain the R packages. I want the script to check which packages are missing and download them before continuing with the main functionality of the script. 

What is the best way of going about this? Is there some good 3rd party package that can do this for me? 

From some brief research, I know that the required command can tell me if the package is installed or not. Is there a command within R that can then download the package or is that just not supported within the R script itself?","New to R, adopted some R code at work and need some advice on R package management",4bicb3,top
"Hi there, I'm pretty tech savvy, not too strong on the math side, but good with traditional languages (spanish, hebrew, arabic, english). To finish a coursera Marketing Analytics course I need to learn ""r."" I've never learnt a programming language before, but have worked around programmers enough to get a vague idea. I like and enjoy logic as well. Are there any other newbies here I can connect with? Any lessons from going from 0 - r you can impart? Is there a better language I can learn before diving into this? I'm using it on a mac. Thanks :)

UPDATE: (sorry for the delay)
I studied my ass off for a couple weeks using Coursera, and attempted the test on my mobile while bussing to work. 

Question one... didn't have any idea (I understood the words/concepts, but not question as a whole. Same with question 2... 3... 4... despite the fact that I could define and understand the concepts within the multiple choice answers. I was dejected. This was my first foray into programming and I was stumped. 

I took a break from it and went back to focus on different hobbies (art etc.) and ended up switching jobs (not related). 

While visiting my previous job, one of the developers asked me about my ""R"" experience and I gave him the lowdown. Through some programming sorcery he was able to pull up the very test that I attempted ""R"", but gave up on and... I was able to get every question (this was about a month after I began). 

It turned out that the Coursera app had a bug and would ""crop"" the questions, or not display the whole questions within the view area on the Android app, hence my confusion as questions were along the lines of. ""In R strings"" [multiple choice answers]"" 

In anycase, I'm an idiot for not reporting it at the time (I had switched from Android back to iPhone as it was a work phone) so I couldn't replicate it, but I will tweet the instructor this summary.

After learning more about ""R"" it seemed like it was a bit advanced for me, but I did enjoy the learning process. I joined it as a knee-jerk response for needed it as a pre-req for another marketing course. 

Now I am learning JavaScript, and have been since early July, on Codeacademy and am progressing at a decent pace. I am hoping to grasp a framework by the end of the year. Thanks for the initial encouragement, really appreciated it!","Any tips for someone learning ""R"" as his first programming language?",451uym,top
"Just a thought based on that link...

[http://www.datasciencecentral.com](http://www.datasciencecentral.com/profiles/blogs/how-to-make-any-plot-with-ggplot2)

>Ggplot2 is the most elegant and aesthetically pleasing graphics framework available in R. It has a nicely planned structure to it. This tutorial focusses on exposing this underlying structure you can use to make any ggplot. But, the way you make plots in ggplot2 is very different from base graphics making the learning curve steep. So leave what you know about base graphics behind and follow along. You are just 5 steps away from cracking the ggplot puzzle.",Should ggplot2 replace the basic R plotting package?,40suwk,top
"I added a page to my site to show two new images from my upcoming issue.  One shows a text and sentiment analysis in R and the other shows the sound/sonar analysis of a small room using R and a single microphone.  Both were very fun to produce and completely reproducible from the code in the paper.  Take a look at the images and subscribe to get the full papers.  The e-magazine is free and comes out bi-monthly.
http://www.codeitmagazine.com/image",R analysis images,3wy2y5,top
"hi guys,
we are just about going to start off building an R project for our company (and serve it as an API .. e.g. Rserve). The rest of our stack is in java, so we were wondering if Renjin.. or any other jvm based R stack has matured enough to be used.

I have read that it doesnt play well with RStudio... which could be OK if we are prototyping on Rstudio and deploying in Renjin. any gotchas we need to take care of , etc. ?

We will be working with a Postgresql based database through R, so that is a particular concern.",Anybody using Renjin (jvm based R) in production ?,3up259,top
"Are there any really good (and free) resources to begin learning R? I have a book and subscribed to a very small channel on YouTube, but getting started and actually beginning to learn and pick up on the skill is a bit difficult.

Thank you!",How to get started on R,3kah6k,top
"Revolution Analytics recently released a fork of R that builds in multithreading. From what I've ready, this can give up to 26x performance for large matrix operations, the stuff we do in r.  It's based on 3.1.1. 

Can anyone think of a reason not to use it? Is there a significant danger of ending up in a situation like Python where over time, two significant versions became standard with different sets of libraries? ",Any reason not to use Revolution R Open?,2k3jca,top
"I have no programming experience whatsoever, and the most R experience I have is where the professors basically give you the code to input so you can interpret and analyze the data. However, this year, I'm really starting to get deeper into my Stats classes, and I'm taking a ""Statistical Computing"" course in the Fall which many people in the department consider to be one of the hardest required courses.

Because of this, I really want to prepare myself ahead of time and get any learning in ahead of time. Are there any good tools/ sites that I can read up on?
",Any good learning tools to self-teach myself R?,2csveb,top
"Hey all,

I was wondering if anyone has experience with R and D3.js for data visualization.  I'm looking for good resources to learn.  

 I'm starting a data visualization blog on alternative energy with a friend.

Thanks!",R and D3.js for interactive infographics,1t5k43,top
"[Hadley ](https://adv-r.hadley.nz/R6.html#controlling-access) And other sources have used this notation but I can’t tell why. I think it has something to do with trying to access the object and not the field but I’m guessing. 

Could anyone explain why the dot is necessary?",R6 and use of dot in private$.age,98e0a2,top
"I'd like to know whether Microsoft R Open will give significant performance improvement as compared to the standard CRAN R. The platform is Windows 7 (64 bit), my computer is an average desktop. I'm mostly interested in machine learning tasks such as random forests, boosting classification, SVMs etc. My datasets are of medium size (3-5 Mb).",Microsoft R Open,983ae5,top
"Hello Team!

The question at the end is very open ended so please bear with me.

Lets say I have the below data frame which represents my quarterly forecast and how it changed over time:

    library(lubridate)
    
    forecast <- data.frame(Date = c(010118, 010118, 020118, 020118, 030118, 030118, 010118, 010118, 020118, 020118, 030118, 030118),
                           Concept = c(""Toyota"", ""Toyota"", ""Toyota"", ""Toyota"", ""Toyota"", ""Toyota"", ""Ford"", ""Ford"", ""Ford"", ""Ford"", ""Ford"", ""Ford""),
                           Opportunity = c(""Tacoma"", ""Supra"", ""Tacoma"", ""Supra"", ""Tacoma"", ""Supra"", ""F150"", ""Focus"", ""F150"", ""Focus"", ""F150"", ""Focus""), 
                           Month1 = c(10, 10, 15, 15, 20, 20, 30, 30, 40, 40, 50, 50), 
                           Month2 = c(15, 15, 20, 20, 25, 25, 35, 35, 45, 45, 55, 55),
                           Month3 = c(10, 10, 15, 15, 20, 20, 30, 30, 40, 40, 50, 50))
    
    forecast$Date <- mdy(forecast$Date)
    forecast

The date column represents the day that the forecast for the quarter was received. Given that my real world data has hundreds of opportunities and \~30 customers, how would you track the change in forecast over time given that the concept and opportunities, for the most part, will remain the same as we step through iterations of the forecast?

For example: the forecast for the Month1 forecast of the Toyota Supra changed 3 different times. Starting on 1/1/2018 it was 10, then increased 5 units to 15 on 2/1/2018, then increased 5 units to 20 on 3/1/2018.

Is there any simple and effective way to go about this?",Track changes to forecast over time,96iglm,top
"Hi Everyone,

I'm a 2nd year grad using R for some research. I'm definitely a noob. I need to extract data from an API. The httr package is working well to pull the requests as a JSON but I can't figure out how to turn that into workable data. My code is as follows:

    # This package is required for Accessing APIS (HTTP or HTTPS URLS from Web)
    library(httr)
    #This package exposes some additional functions to convert json/text to data frame
    library(rlist)
    #This package exposes some additional functions to convert json/text to data frame
    library(jsonlite)
    #This library is used to manipulate data
    library(dplyr)
    
    #http request
    resp <- GET(""https://projects.propublica.org/nonprofits/api/v2/organizations/10549867.json"")
    http_status(resp)
    http_type(resp)
    
    # Shows raw data which is not structured and readable
    jsonRespText<-content(resp,as=""text"") 
    
    # Structurised data in form of R vectors and lists
    jsonRespParsed<-content(resp,as=""parsed"") 
    
    # Access data element of whole list and ignore other
    modJson<-jsonRespParsed$filings_with_data vectors
    
    #Using dplyr to format list to data frame
    modJson %>%
      bind_rows %>%
      select(filings_with_data$tax_prd_yr,
    filings_with_data$formtype,
    filings_with_data$totrevenue, 
    filings_with_data$totfuncexpns, 
    filings_with_data$totassetsend, 
    filings_with_data$subseccd, 
    filings_with_data$ein)
    
    

I get the error:

>""Error in bind\_rows\_(x, .id) : Argument 4 is a list, must contain atomic vectors""

I've tried other solutions from Stack Overflow all day but nothing has worked. I have tried removing the index to look as follows but still no bueno:

    #Using dplyr to format list to data frame
    modJson %>%
      bind_rows %>%
      select(tax_prd_yr,formtype,totrevenue)

My modJson object is a list containing 4 elements (lists). Each element is a list of 47 values (each for a different year of data). I need to extract only some of those values into a data frame as listed in the last batch of code. Am I indexing it incorrectly or is this the wrong approach all together? The modJson object is below:

[modJson object](https://i.redd.it/ms3r1prs9ze11.png)

Any tips?  

Thanks! And I'm sorry if this is in the wrong format, I'm happy to change it to something more general if needed.",Need help transforming response JSON data to data frame.,95sib4,top
"Example  
df2 <- subset(df1\[conditions,\])   VS    df2 <- df1\[conditions,\])  


Is it simply that the subset function offers more options and either is fine? Or is there something else to this I should maybe know. ",subset() vs [],95qrje,top
"Can not handle categorical predictors with more than 53 categories.

The structure of the data frame looks as posted in the image.

// rfm <- randomForest(UserType\~.,dt4.train)

Looking for some suggestions on how to proceed . My target variable is UserType

https://i.redd.it/5vt0u7yvfqd11.png",Error: Random Forest modeling . Can not handle categorical predictors with more than 53 categories.,942g90,top
"basically I have a large dataset of this form: 



        users <- c(""John"",""Paul"", ""Luke"", ""Mary"", ""John"", ""Mary"", 
                    ""Luke"", ""Paul"")
        start_times <- c(""2018-07-14 04:55:57"", ""2018-07-14 
                             04:47:31"",
                             ""2018-07-15 03:02:22"", ""2018-07-15 
                              03:58:21"",
                             ""2018-07-16 04:56:41"", ""2018-07-16 
                              03:59:28"",
                              ""2018-07-16 03:13:21"", ""2018-07-16 
                              04:58:14"")

         end_times <- c(""2018-07-14 14:02:31"", ""2018-07-14 
                           15:03:17"",
                           ""2018-07-15 12:01:14"", ""2018-07-15 
                            12:59:45"",
                            ""2018-07-16 14:02:14"", ""2018-07-16 
                             13:01:14"",
                             ""2018-07-16 11:25:41"", ""2018-07-16 
                             13:22:17"")

    df <- data.frame(users,start_times,end_times)


and I need to figure out how much time was spent in each 30 minute interval by day. I'm not sure how to do it without looping over everything which isn't really feasible with the actual data set. any clever tricks you guys know that could help me out? 
                ","given start and stop times, figure out time spent in each 30 minute interval",925pjn,top
"Still pretty new to R, wondering if someone could help me solve this problem.  I have a data frame with NFL stats, where each season's individual stat has it's own column.

|Full Name|Position|Passing Attempts (2016)|Passing Attempts (2017)|Passing Touchdowns (2016)|Passing Touchdowns (2017)|Carries (2016)|Carries (2017)|Rushing Touchdowns (2016)|Rushing Touchdowns (2017)|
|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|
|A.J. McCarron|QB||14||0||0||0|
|Aaron Rodgers|QB|610|238|40|16|67|24|4|0|

I'd like the resulting data frame to look like this:

|Full Name|Position|SEASON|Passing Attempts|Passing Touchdowns|Carries|Rushing Touchdowns|
|:-|:-|:-|:-|:-|:-|:-|
|A.J. McCarron|QB|2016|||||
|A.J. McCarron|QB|2017|14|0|0|0|
|Aaron Rodgers|QB|2016|610|40|0||
|Aaron Rodgers|QB|2017|238|16|24|4|

Thanks in advance for your help!!",Change Data Frame with Columns for Each Year to Data Frame grouped by Year,91m5gj,top
"Title pretty much says it all. Difficult to spot a dark cursor on a dark background (which I prefer). I assume there's  a way to change the color of the cursor, but I can't find anything in the usual menu settings in RStudio. Any insights?   


Thanks.",Changing color of cursor in RStudio?,8ysfu7,top
"I run into the issue where when plotting data data points on a DV versus time graph, the data points at time 0 get layered under the y-axis. Is there a way to ensure that the data points appear on top?

As for why I want it this way, I'm trying to automate certain graphing parts of my job, and my PI prefers a particular graphing/statistical software (GUI-based, which does not lend itself well to automation). However, this is also how most other graphing software I've seen do it anyways (GraphPad, SigmaPlot, and even Excel). I've replicated the aesthetics of the plots from his software fairly well, with the exception of this last issue. 

thanks!",GGplot2: layering data points on top of y-axis rather than underneath,8ycnav,top
I have some trouble installing packages from git hub (gganimate) and I think it's because R tools is not compatible with the newest version of R. Does anyone know how long time it usually takes for a new version of Rtools to get out?,R tools for version 3.5.1,8xp70n,top
"I've got an R script that I wrote locally that looks like below. When I run it locally, it works totally fine.     

    library(rJava)
    library(RJDBC)
    library (RPostgreSQL)
    
    URL <- 'https://s3.amazonaws.com/athena-downloads/drivers/AthenaJDBC41-1.1.0.jar'
    fil <- basename(URL)
    if (!file.exists(fil)) download.file(URL, fil)
    drv <- JDBC(driverClass=""com.amazonaws.athena.jdbc.AthenaDriver"", fil, identifier.quote=""'"")
    con <- jdbcConnection <- dbConnect(drv, 'jdbc:awsathena://athena.us-east-1.amazonaws.com:443/',                                  
                                       s3_staging_dir=""s3://aws-athena-query-results-XXXXX-us-east-1"",
                                       user= ""XXXXXX"",
                                       password= ""XXXXXX"")

The problem arises when I copy it over to `nano` on the server setup through my work. 

[So it looks like this.](https://i.stack.imgur.com/JLA12.png)

The reason I only posted those lines is that the last line is where the problem comes up.

When I run it, this error comes up:

`Error in .jfindClass(as.character(driverClass)[1]) : class not found
Calls: JDBC -> is.jnull -> .jfindClass`

Does anyone have a solution to this?",Works locally for me on R but not on my server,8ujern,top
"I am a long distance PhD Student and I am learning R by myself.

 I have done a biodiversity survey collecting insects in trial plots with different treatments (x4), each treatment was replicated 4 times (total:16 plots). 

I have collected my samples on the same plots,  5 times in one year. I have called this variable ""Event""

I have identified and counted all the different insects and put the data in the excel sheet. Each column represents a taxonomic group of insects. for example ""Araneae""

  
In the excel sheet, there is:

\- 1 column for Event ('I','II','III','IV','V')

\- 1 column for Treatment('Bd','Org','Con','Bt')

\- 1 column for replicates ('r1','r2','r3','r4')

\-The other columns are the counted taxonomic group of insects.

\-""TP17Grouped"" is the name of my file

I have done one way anova for one group ""Araneae"" 

\> View(TP17Grouped)

\> aov.17tp.Araneae=aov(Araneae\~Treatment,data = TP17Grouped)

\> summary(aov.17tp.Araneae)I have then done a tukey test   

\> comparison.tp17.5.Araneae<-TukeyHSD(aov.17tp.Araneae) 

\> plot(comparison.tp17.5.Araneae,las=1) 

  
 I would like in my formula to : 

1. Include ""replicates"" as random factors
2. Include ""Event"" in the model as the repeated measure factor

Can any one help me please?

Thank you",Using R in Natural science,8shx3t,top
"I'll preface this by saying that I am only recently dabbling in command window prompts (and, correspondingly, issuing them in R), and am generally unfamiliar with this subject, so I may not be able to answer certain questions about context or background.

I work in a company with a computer network (all using Windows 10) which can access certain shared drives, and I am developing some code that can create and update a selection of files on a daily basis.  I'd like this to be fully automatic, and R cannot write to files that are open in write-access in other programs or on other machines.  Instead of try-catching write attempts, I'd rather just set all access to read-only for every other person who can access the files, except for me (or whatever ""user"" owns the R program writing everything).

I've been experimenting with permissions on some burner .csv files with Sys.chmod(), like below:

> Sys.chmod(""file_path.csv"", mode = ""0777"", use_umask = FALSE)

My understanding from [the file system permissions](https://en.wikipedia.org/wiki/File_system_permissions#Numeric_notation) Wikipedia page is that this means everyone should have read, write, and execute permission.  If I want to make everyone have read-only, including myself (as the owner of the file), then I can write:

> Sys.chmod(""file_path.csv"", mode = ""0555"", use_umask = FALSE)

Then when I try to open  the .csv file in Excel, it opens a read-only version by default.  My coworker, on a different computer than mine but on the same network, also opens a read-only when he tries to open it.

I can confirm that I am the ""owner"" of the file by using the **dir** command with shell():

> shell('dir /q ""directory location""', intern=TRUE)

where the output for each item in that directory location is a string with a ""column"" with something like **NA\\\\richard_sympson**.  The NA, I suppose, refers to ""North America"", our region.

However, when I specify Sys.chmod() to allow read, write, and execute for only the owner, but read-only for everyone else:

> Sys.chmod(""file_path.csv"", mode = ""0755"", use_umask = FALSE)

my coworker, when he opens the file, opens a write-access version.  When he views the file properties, the ""Read Only"" box is not ticked.

I am not sure what's going on here.  For my specific purposes, I can get around this problem *in effect* by setting the permissions twice: once before writing, to allow write access, or 0777 / 0755; and once again immediately after writing, to set everything to read-only, or 0555.  However, I'd still like to try to avoid that gap, and have only myself able to write.

I've asked our IT guy if he's familiar with command window file permission changes, and he says he is not.  So, I'm wondering if anyone else has some familiarity.",Sys.chmod() does not seem to make a distinction between owner and others in Windows 10. Thoughts?,8qbbwp,top
"Hey all, I think I've run into a bug that is preventing me from running my scripts on my work server. I was running v3.3.2 for a long time and recently upgraded to v3.5.0. I had no issues with v3.3.2.

The issue is that when I use Rscript.exe to run an R script, it doesn't handle space characters correctly. It instead just cuts off the name of the file when it encounters a space in the path name. Here's a command line example:

Input:
> Rscript ""\\\\Companyname\Location\Department\Resources\Data Validation\Scripts\myScript.r""

Output:
>Fatal error: cannot open file '\\\\Companyname\Location\Department\Resources\Data': No such file or directory

This stackoverflow [post](https://stackoverflow.com/questions/48544345/rscript-file-path-with-space) seems to confirm it's a bug (see the additional comments), but maybe there's workaround, idk. Stuck!",Bug in v3.5.0 (can you confirm?),8m36mf,top
So I was told that I need to get R and RStudio and I did. I don't have much experience with them. Isn't it the same thing just that RStudio has more features?,Having both R and RStudio,8ki5qn,top
"Hello all!

I'm a relative newcomer to R, and I suppose in general to programming overall (< 1 year). I've got a project I'm working on to learn the language, and as part of my everyday routine, I find that there are about 5 different ""starting up"" functions that I run when beginning work. Is there any way to create a simple, custom function, say ""startup()"", that will execute a number of other functions sequentially? 

Thanks in advance for shaving off a few seconds of my daily routine :)",Startup Function,8k9v7y,top
"Hi everyone,

I'm trying to do a sentiment analysis on text messages in R, but I can't seem to properly get them from XML to a dataframe object. Googling is not going so hot for me, I think it's because the data are not formatted as is typical for an XML file (data are coded as XML attributes). (Files are from my android phone, I used the app [SMS Backup & Restore](https://play.google.com/store/apps/details?id=com.riteshsahu.SMSBackupRestore&hl=en))  
Here's an example of how the data are formatted:

    <?xml version='1.0' encoding='UTF-8' standalone='yes' ?>
      <sms protocol=""0"" address=""1234567890"" date=""1521766063682"" type=""1"" subject=""null"" body=""Lorem Ipsum"" toa=""null"" sc_toa=""null"" service_center=""null"" read=""1"" status=""-1"" locked=""0"" date_sent=""1521766056000"" readable_date=""Mar 22, 2018 8:47:43 PM"" contact_name=""Jane Doe"" />
      <sms protocol=""0"" address=""1234567890"" date=""1521771828209"" type=""2"" subject=""null"" body=""Ipsum Lorem"" toa=""null"" sc_toa=""null"" service_center=""null"" read=""1"" status=""-1"" locked=""0"" date_sent=""0"" readable_date=""Mar 22, 2018 10:23:48 PM"" contact_name=""Jane Doe"" />

Since it's unclear, `type` seems to signify if a text is sent by her `type=""1""` or me `type=""2""`  
I'm trying to get a dataframe with 3 values: the timestamp `date`, the sender `type`, and the body of text itself `body` so that I can do sentiment analysis. I imagine someone has done this before, does anyone have any tips to get texts into a workable format?

# Problem Solved!!

Adjusting a bit from [this stackoverflow thread](https://stackoverflow.com/questions/32896861/from-xml-attributes-to-data-frame-in-r) I managed to figure it out.

    library(dplyr)
    library(rvest)
    rows <- read_xml('text_messages.xml') %>% xml_nodes('sms')
    df <- data.frame(
      ID = rows %>% xml_attr(""type""),
      date = rows %>% xml_attr(""date""),
      body = rows %>% xml_attr(""body"")
    )",Extracting Oddly Formatted XML into a DataFrame in R?,8iy2ea,top
"Hi all,

I have a problem on how to implement a graph with edges and vertices based on my available data. The dataset is very simple although very large, around 200 000~1 000 000 rows. The data sets looks like the following:

source|target|value                        
:--|:--|:--                                  
50|100|20     

source -> target may appear several times. I would want to create a graph where the edges are thicker if it appears several times in the data.

Any idea how to start? As I'm struggling with the sheer amount of data it is quite hard to visualize, therefore, I would like edges to be thicker if source->target appears multiple times.

Sincerely,
Nowarez",[HELP] Using igraph with very large data set,8h8vb9,top
"I am learning how to run regression modeling in R, and I am confused as to whats happening in this piece of code:

model <- lm(IV ~ dv1 + dv2)
colors <- ifelse(dv1==1, ""black"", ""gray"")
plot(dv2, IV, xlab=""dv1"", ylab=""IV"", col=colors, pch=20)
curve(cbind(1,1,x) %*% coef(model), add=TRUE, col=""black"")
curve(cbind(1,0,x) %*% coef(model), add=TRUE, col=""gray"")


What im particular confused about is the curve(cbind()) part, as I am completely clueless as to what is happening here.

Thanks!",Can someone help me understand what is happening with this code?,8h11ja,top
"There is one example in ?rlang::UQ

```
args <- list(1:10, na.rm = TRUE); quo(mean( UQS(args) ))
```

&nbsp;

Why ```mean( UQS(args) )``` doesn't work? How can I execute this without ```eval_tidy(quo(mean(UQS(args))))```?",Non-standard evaluations example,8gaw6t,top
"Right now I have a data frame that I subset using about 6 conditions and its slowing down my whole model since I have to continuously do it based on new information so I was wondering if there is a better way to do it.  This is a shortened fake version but right now I have something like

data[which(data$first==aaa & data$second==bbb),]

I was wondering if I can do anything to improve this by changing class or really anything.  The most common thing I see is to change to a data table which I have tried but I havent found anything that is faster than what Im using.  ",What is the fastest way to subset,8ex6y7,top
"I'm stuck here, I cant seem to get my styling to work. I specifically would like to add conditional formatting to the first four columns of each chart.

Here is what I've got working without the formatting

    library(shiny)
    library(DT)


    ui <- fluidPage(
      sidebarPanel(
        sliderInput(""n"", ""Number of DTs"", value=1, min=1, max=maxTables)
      ),
      mainPanel(
        uiOutput(""dt"")
      )
    )
    
    server <- function(input, output, session) {
      
      output$dt <- renderUI({
        lapply(as.list(seq_len(input$n)), function(i) {
          id <- paste0(""dt"", i)
          DT::dataTableOutput(id)
        })
      })
      
        observe({
          species <- sort(unique(iris$Species))
        lapply(as.list(seq_len(input$n)), function(i) {
          id <- paste0(""dt"", i)
          output[[id]] <- DT::renderDataTable(iris[iris$Species == species[i],],
                                              extensions = 'Buttons',
                                              options = list(paging = FALSE, searching = FALSE,
                                                         columnDefs = list(list(width = '210px', targets = ""_all"")),
                                                             info = FALSE, dom = 'Bfrtip',
                                                             buttons = c('copy', 'csv', 'excel', 'pdf', 'print')),
                                              rownames = FALSE)
        })
    })
    }
   shinyApp(ui, server)",Adding styling to a dynamic number of datatables in a shiny app.,8dnj3t,top
"the way i know it <- was inherited from the s language, whereas = is just the way you know it as a programmist. now, when you define a map (or a named vector; call it what you will), the <- operator doesn't bind a value to an object:

>vectorMap <- c(purple=""Tinky Winky"",red<-""Po"", yellow=""laa laa"")

>vectorMap

returns

>purple (,) (,) yellow

>""Tinky Winky"" (,) ""Po"" (,) ""laa laa""

It is basically the same as if you used ""Po"" for red<-""Po"". Does anyone know of the rationale behind this?",in which cases is <- not the same as an =?,8bxi7r,top
"So, I've been looking at this R language thing, did some tutorials, and am really enjoying it. However, I do not work in a field (at all actually, about to start college this summer) that requires the use of this software. How could I use this to my own advantage, or better said, what are the uses that statistical software offers to the average joe?",What uses does R have for the average joe?,85e3rz,top
"Hi all! I've just gotten started learning R with Swirl, and I love the interactive courses so far, they've been incredibly helpful. I'm trying to intertwine more statistics into my major (HCI), and thought R would be a great addition when doing research, analysis, and data visualization.

I've been looking for reference books that are good for beginners, but everything I've found thus far has mixed reviews, and I'm honestly not sure what exactly to look for in a R reference book. It seems like the best I've found is [this](https://www.amazon.com/gp/product/1593273843/ref=ox_sc_act_title_5?smid=ATVPDKIKX0DER&psc=1), but I'd like to know if there's any better resources that I could utilize before making a purchase. 

Thank you!",R books for beginners?,848n9k,top
"Are there anyone experienced with scraping SEC 10-K and specifically downloading the exhibit 21 in R?

What I basically want to do is the following:

**1)** Download all 10-K available on SEC between for a specific list of company names (or tickers or sic number etc.)

**2)** Search every 10-K filing for Exhibit 21

**3)** Search every Exhibit 21 for a list of country names and create a merged dataset like the following where all the subsidiaries of a company are listed with the country location of each subsidiary per firm:

[Dataset example][1]


  [1]: https://i.stack.imgur.com/9BuLr.png



Here is one example of the 10-K exhibit 21 filing that I need to parse:

https://www.sec.gov/Archives/edgar/data/320193/000032019317000070/a10-kexhibit2112017.htm


So I basically need to parse/scrape this for a list of companies.


 
","How to scrape web, SEC Edgar 10-K , exhibit 21?",82rwsq,top
"I know there are three types of build-in classes in R. S3, S4 and reference classes. But I'm still somewhat struggling. It may be because I'm trying to hammer an R nail with a hammer used for more traditional OOP languages, but I realized that I could use an example.

This is a very simple python code that showcases basic classes abilities:

    class Rectangle:
    	def __init__(self, a, b):
    		self.a = a
    		self.b = b
    	def Area(self):
    		return(self.a * self.b)
    
    class Square(Rectangle):
    	def __init__(self, a):
    		self.a = a
    		self.b = a
    
    myRectangle = Rectangle(2, 4)
    mySquare = Square(3)
    
    print(myRectangle.Area())
    print(mySquare.Area())

How would you port this code to R? Using all three class types?

Thanks in advance.

---

EDIT: Based on comments, this is what I came with (though keep in mind guipier's comment about LSP):

    rm(list=ls())
    
    Rectangle <- function(a, b) {
        structure(list(a = a, b = b), class = ""Rectangle"")
    }
    
    Square <- function(a) {
        structure(Rectangle(a, a), class = c(""Square"", ""Rectangle""))
    }
    
    area <- function(x) {
        UseMethod(""area"")
    }
    area.Rectangle <- function(x) {
        x$a * x$b
    }
    
    myRectangle <- Rectangle(2, 4)
    mySquare <- Square(3)
    
    area(myRectangle)
    area(mySquare)
    ",I'm still struggling with classes in R,7wo6ls,top
"Hello,

I've just started working with decision trees using R. I could not understand one concept with regard to trees. If I have 2 or more input variables which are highly correlated, how does R deal with them while growing trees?
Also, what do trees do if I have a variable in which all the values are the same?

Any help with these queries is appreciated.

Thank you",Understanding correlation in R,7o5ss4,top
"In response to [this SO question](https://stackoverflow.com/a/47759816/1003565) I wrote a function and put it into a [gist](https://gist.github.com/Dasonk/2b62e333251404d517100c3262ea19fd) that will create a callback to alert you when some summary (dim, nrow, length, etc...) changes for a specified object.

If you're heavily modifying objects and want to get notifications about what new dimensions are so you can have a spot check this might be useful for you.",Made some code to help monitor changes in objects and wanted to share,7j5mlm,top
"I'm trying to estimate 4 parameters with the generalized method of moment estimation in R, using the package `gmm`. My distribution is a tempered version of the Positive Linnik.

This is what I wrote in R:


    g2 <- function(theta,x) {
    
        tau <- seq(1, 100, 10)
      x <- matrix(c(x), ncol=1)
      x_comp <- x%*%matrix(tau,nrow=1)
      emp_lap <- exp(-x_comp) 
      the_lap <- Lpar(theta,tau) 
      gt <- t(t(emp_lap) - the_lap)
      return(gt)}
    
    t0 <- c(lam = 50, del = 10, the = 0.3, gam = -0.6)
    
    print(res <- gmm(g2,it0,t0)) #it0 is my dataset


Where


    Lpar = function(theta,tau){
      
      lam <- theta[1]
      del <- theta[2]
      the <- theta[3]
      gam <- theta[4]
      
        the_lap <-  (1 - lam * del * ((the + tau) ^ gam - the^gam))^(-1 / del)
        return(c(the_lap))
       }

is the Laplace transform of my random variable. My ""empirical laplace"" is emp_lap.

If I run the code I obtain this error:

    Error in AA %*% t(X) : requires numeric/complex matrix/vector arguments
    In addition: Warning message:
    In ar.ols(x, aic = aic, order.max = order.max, na.action = na.action,  :
      model order:  1 singularities in the computation of the projection matrix results are only valid up to model order 0


Anyone knows where am I wrong??

Thanks in advance.",Use of gmm with Laplace transform in R,7f0fzx,top
"Hi everyone - I have recently started a class at my local university where we are learning how to create models in R. I am using this class to determine if I like this area enough to continue to pursue it. This week's homework assignment is super difficult for me. I was wondering if anyone here could help me get started with the second problem or provide a place that could help me? If the entire solution is available that would be much appreciated. Thanks.

I also understand that their are several ways to go about the second problem, but I have no idea how to start.

If it matters, I am taking this class for a grade, so I understand not wanting to cheat, but I don't care what my grade is in the class, I am here to learn. Any help is appreciated.

Questions: https://imgur.com/gallery/DuR03 

Data for Question 2: https://imgur.com/a/A5GNv",Help Setting Up a Predictive Model,7b2g3d,top
"Hi all. I have the following problem. let me type the code I'm working on and explain what I'm trying to do below:

> x1=8000

> x2=8000

> x3=7000

> x4=11000

> p=0.5

> Ux <- function(x,r){

  > U <- (x^(1-r))/(1-r)

  > return(U)

> }**

> solve((p*Ux(x1,r))+(p*Ux(x2,r))=(p*Ux(x3,r))+(p*Ux(x4,r)),r) **I dont think ""solve"" is the right formula, but I don't know which is**


I'm trying to calculate the coefficient of relative risk aversion (CRRA). My goal is to find an ""r"" such that p*U1+p*U2 = p*U3+p*U4, where  U= (x^(1-r))/(1-r)


I don't know if that makes any sense... thanks in advance for any help!
",I need help figuring out how to use the equivalent of solver/goalseek (from excel in R),78g5vo,top
"Hi all, 

I am a recent data science graduate interested in expanding my skillset, and an online course in NLP using R is exactly the type of course I am interested in taking currently. Unfortunately, my initial search online for a course like this has come up empty. If anybody has a good source in this regard and could share, that would be great. 

Thanks in advance!",seeking an into to Natural Language Processing with R course,6uli8q,top
"Hey guys, 

I'm new to learning R and was hoping to ease my transition with a list of excel function and how to replicate those functions within R.

I've googled a bit but only have found solutions to running R code within excel...which is obviously not what I want at all. 

If anyone has anything that could help me out I would appreciate it!",R code to Excel functions equivalent list/chart?,6rnp71,top
"Hey guys, trying to scrape some Amazon reviews to perform a sentiment analysis. I'm able to pull the fields I need but the output is all in one column where I need Title and Review as separate columns, any thoughts?


    library(stringr)
    library(XML)
    library(rvest)
    
    url <- ""https://www.amazon.com/Rainforest-Variety-Antioxidant-Infused-Beverages/product-reviews/B0088MXS6U/ref=cm_cr_arp_d_show_all?ie=UTF8&showViewpoints=1&reviewerType=all_reviews&pageNumber=""
    
    N_pages <- 15
    Table1 <- NULL
    for (j in 1: N_pages){
      website <- read_html(paste0(url, j)) 
      
      Title <- website %>% html_nodes("".a-color-base"") %>% html_text()
      Review <- website %>% html_nodes("".review-text"") %>% html_text()
      Stars <- website %>% html_nodes(""#cm_cr-review_list .review-rating"") %>%
        html_text() %>%
        str_extract(""\\d"") %>%
        as.numeric()
      
      Table1 <- rbind(Table1,Title,Review)
    }

",Amazon Reviews Scraping Issue,6o9t7j,top
"Hey I'm not sure if this post goes in this subreddit, but Idk where else it would go. I'm an Econ major and this fall I'm doing Econometrics where we will be learning R. Now since R is more powerful than stuff like Excel, do I ever need to learn how to use Excel? Like in a job if I'm using simple data could I just always use R since that's what I would be most familiar with?",Do I need to learn Excel if I'm going to learn R?,6mexs2,top
"What I mean is, is how can I create a list of vectors in a matrix such that each row has every way of arranging 1 and 0 for a vector of length n.

For example for n=6 a few of the vectors in the matrix would be: [1,1,1,1,0,0] , [1,1,0,1,1,0] , [0,0,0,1,0,1] and so on combined in a matrix such that every possible variation is covered. 

Any help would be appreciated!",How can you create a matrix with every combination of 1s and 0s?,6l1mwl,top
Rookie question which books or texts would anyone recommend for implementation of betting strategies in R?,R for betting strategies,6gry64,top
"Working through some tutorials and came across the lecture on Apply. For sapply the example below was used:

    v <- c(1:5)

    addrand <- function(x){
      ran <- sample(1:100,1)
      return(x+ran)
    }
    
    sapply(v,addrand)

My question is why is
 
    sappy(v,addrand)

used in place of

    addrand(v)

I don't see the difference in the output. Or is this something that will become clear with more complex use cases later on?",Not sure I understand the use of sapply.,6eofly,top
"Hi, I'm looking for a way to work with timeseries (forecast, timekit or prophet) using sparklyr. I found very good docs about this packages, but not working together. And when I try to use them. e.g. timekit, I got errors like this:

    > FB2_tbl <- copy_to(sc, FB_tbl) #sc as spark connection
    
    > idx <- tk_index(FB2_tbl)
    
    Warning message:
    In tk_index.default(FB2_tbl) :
      `tk_index` is not designed to work with objects of class tbl_spark.

Is there a workaround to this? Any idea I'll be very thankful. ",Sparklyr and timeseries,6djytp,top
"I am pretty new to R Lang and I have been trying to learn by creating Cryptography functions and tools, because that is what I am familiar with. However, I cant seem to find a good way to create large prime numbers larger than ~2^53. Is there a library that I am overlooking, or is R not really made for handling cryptography? ",Cryptography in R?,6btq1g,top
"I have the following R data.table

    library(data.table)
    
    dt <- data.table(start_position = c(12345, 12378, 72399, 72677, 72780, ...), 
                     end_position = c(12350, 12399, 72401, 72701, 72799, ...), 
                     group = c(""grp1"", ""grp1"", ""grp2"", ""grp2"", ""grp2"", ...))


I would like to calculate the difference between the first row in a position, and the following row for each group. So, for `grp1`, calculate the absolute value between 12345 and 12378. Then for `grp2`, you calculate the absolute value between 72399 and 72677, then 72677 and 727800. This should be done by group.

My idea would be to do this: 

    dt = dt[, distance := (dt$start_position[-1] - dt$start_position[-length(dt$start_position)]), by=group ]

The problem with this is that I'm getting errors, whereby 12378 is paired with 72399. There is also a problem of dimensions here. Given N samples, there are N-1 ""pairs"" of absolute values. 

Question: Why is this approach giving me the incorrect answer? Also, how do I properly give a distance for each sample? (My reason for doing this: Given the distance between rows, I would like to investigate distances of certain values (e.g. less than X) by subsetting on the data.table.)


",How does one calculate the distance between row1 and row2 by group in an R data.table?,60x7hd,top
"Hi everybody,

I'm R beginner and I want to learn it so I can do statistical analyses. Specifically, I am biologist, and I need to do for example principal component analysis, principal coordinates, ANOVA, ANCOVA etc. on my morphological data (mostly).

So, I found a lot of literature and lot of guides on-line. But, it's simply too much of that and I cannot discriminate whats important and where to start.
Today I installed Rstudio and package ""swirl"". That seems like a good starting point (from my point of view). But I want to know what do you think? Is swirl good start? Whats the next step? I have several books on this topic such as ""Modern Applied Statistics With S"", ""Introductory statistics with R"", ""Mixed Effects Models and Extensions in Ecology with R"", ""The Art of R Programming"". Books are very helpful, but the best way for me to learn are this practical courses like ""whirl"".

I would really want to read your advises and thoughts on this topic.

Thank you!",R beginner,604vj9,top
I'm a financial analyst and currently started learning R. I'm just curious what ways people who work in finance or with financial data are using R to make an impact for their business.,What are some really powerful ways of using R with financial data?,5vsnou,top
"Hi there! I am currently very interested in data mining and I wanted to learn to do some testing on a csv data file using an R program as opposed to using WEKA or another data mining program. I was wondering if I could get some advice or help in getting started with R and how to properly run something like Naïve Bayes in R. 

Thank you",Naïve Bayes and Programming in R,5g1bsl,top
"Example: the user selects mid town manhattan and MTA Stations
so the maps shows the MTA stations only in midtown.

He could also choose Brooklynn and MTA stations, so accordingly the website should update.


","Running R on a website/Server? I want to build an interactive website with a map, that would return data on the map depending on the options selected by the user?",5asmlh,top
"So you've written a script for colleagues which you think will save them time. But they don't use R themselves and aren't hugely motivated to do lots of learning/installing. What's the quickest, most pain-free approach to set them up for using your script?

My particular case: I have a script which takes an excel spreadsheet with column data as input. Output is another excel file with original data plus some new calculated columns. Some of my colleagues are non-programmers so seeing and running the source code could scare them off.",Sharing scripts with non-useRs,5a584k,top
"I could just, use some kind of neural network to predict?                  
 
I am new to R and Machine learning, so sorry if this question comes as very uninformed.","Kaggle.com, all the top positions in the competition are held by people who have used Neural Networks, so is using things like KNN, Naive Bayes is useless in this case of Kaggle competition?",58unjs,top
"Using RPython, I have within a single Python script `filename.py` the R code used to upload Python functions, etc. 


    import python_modules

    # intensive python code
  
    # python functions 
    def python_function(): 
        return # blah blah

    # the R code begins

    library(rPython)
    python.load(""file.py"")  # run/load all the python code
    
    # translate python functions into R
    R_function <- function(param){
        py_func <- python.exec(python_function()
        python.call(""python_function"", param)
    }


So, I have within one file Python code, and the Rpython functions to call this python code. My goal is to create an R library (for internal use) such that I simply run within R

    library(amazing_Rpython_code)

and I can treat this as every other R library. 

How do I package this? It's unclear to me how to create the ""package"" layer that access the R code with accesses the python code. 

Any recommendations? Where am I confused above? 

",How to create an R Package from a Python script with RPython?,56nabl,top
"Hey guys. 

I'm in a ""principles of experimentation"" class where we have recently been thrown into the world of ""R"", learning how to analyze data. 

I'm doing an assignment now where I'm just really stuck at this point: 

""Generate 500 random samples of size n = 45 from a Uniform(0,1) distribution in R.  Hint:   Store values into a matrix  U = matrix(nrow=500,ncol=45) then use a for loop to generate values""

I've created the matrix and all of the data points in ""U"" say ""N/A"", which makes sense because I haven't told R to generate random numbers. I understand that the ""for loop"" command is used for this, but I have googled for an hour now and just don't know how to use this command with the matrix. Can anyone help me please?        
","Thrown into this language without ever taking a course.. EVER. Can I get some help on a ""for loop"" command?",55olb7,top
"Hello!

I work in the field of network/computer security and I have been wondering what skills I can start build to be a little more unique and accomplish interesting things. I think I might like statistics to some extent. I was wondering if anyone out there is already combing security and R, and if so what sort of things they find it useful for. Would this be a good pursuit? R seems interesting, but I don't necessarily want to spend the time only to never find a use for it. 

Thanks!",Information Security + R,548uji,top
"Hi,

Real beginner here, Im not too sure to understand why i had to change the structure of the two following lines when all I wanted to change was the logical symbol:

data[""Value1"">376 & ""Temp"">27 & !is.na(data[,2]),2]
data[data$""Month""==2,][,""Temp""]

sorry if the code is atrocious. In the end it worked but I would llike to understand and I was unable to find the answer online.

thanks !","When subsetting a data frame with a logical expression, why is the $ symbol necessary for an equality and not > or < ?",516gy5,top
"Hi,

I have a couple of questions related to R since I am fairly new to it and I want to learn more.

I am looking at this data set about student enrollment program in university. 

So the data looks something like this:
**id**: student_id
**city_id**: city student live in
**application_timestamp**: when student applied for the school (YYYY-MM-DD) format
**background_check_date**: when school performed background check on student after application (YYY-MM-DD) format
**offer_made_date**: when school made the offer to student
**first_school_date**: when student accepts offer and starts attending the classes
**major**: major of student
**university**: university of student
**intake_year**: year of student intake

1) What fraction of students who applied attended school? (Basically I want to know out of xx number of students who applied how many get accepted and started attending school) How can I visualize it?

2) How can I build a predictive model to check whether a student who applied for will accept the offer and start school? 

Thank you. Please let me know if you need any clarifications.
",How do I do Analysis and Data Modeling in R,513my4,top
"Any recommendations? Should I use Rcpp?

",Examples of turning C++ code into an R package?,4zpt0e,top
"In R (for data.table or generally all vectors), is there a quick regex based row selection operator (for example, %like%)? 

Typing in grepl() kinda makes the code ugly----any better solutions/packages I should look into?","In R, is there a quick regex based row selection operator (for example, %like%)?",4zdf9h,top
"So, i know python and SAS. we have a new project at work that im dying to be a part of and i said i knwo R to do so.... 

I will need to know how to do regressions and the apriori alrogrithym. 

What books will take me from 0 to those skills the fastest?  I know the stat concepts behind them, so its purely learnign the langauge.

im a pure book learner.",Need to get up and running in R super quick. Help!,4yvh8e,top
"If I'm doing automated trading with R, do I need to use ECC ram in my workstation? ",R hardware help requested,4sf5s4,top
"    pretesta <- read.csv(""math122_pretest_a_cleaned.csv"", header=T)
    pretestb <- read.csv(""math122_pretest_b_cleaned.csv"", header=T)
    pretestc11 <- read.csv(""math122_pretest_c11_cleaned.csv"", header=T)
    pretestc22 <- read.csv(""math122_pretest_c22_cleaned.csv"", header=T)
    pretestd <- read.csv(""math122_pretest_d_cleaned.csv"", header=T)
    preteste <- read.csv(""math122_pretest_e_cleaned.csv"", header=T)
    pretestf <- read.csv(""math122_pretest_f_cleaned.csv"", header=T)
    pretestg <- read.csv(""math122_pretest_g_cleaned.csv"", header=T)
    pretesti <- read.csv(""math122_pretest_i_cleaned.csv"", header=T)
    pretestk <- read.csv(""math122_pretest_k_cleaned.csv"", header=T)
    
    pretesta <- tbl_df(pretesta)
    prestestb <- tbl_df(pretestb)
    pretestc11 <- tbl_df(pretestc11)
    pretestc22 <- tbl_df(pretestc22)
    pretestd <- tbl_df(pretestd)
    preteste <- tbl_df(preteste)
    pretestf <- tbl_df(pretestf)
    pretestg <- tbl_df(pretestg)
    pretesti <- tbl_df(pretesti)
    pretestk <- tbl_df(pretestk)
    
    pretest <- bind_rows(pretesta,pretestb)
    pretest <- bind_rows(pretest,pretestc11)
    pretest <- bind_rows(pretest,pretestc22)
    pretest <- bind_rows(pretest,pretestd)
    pretest <- bind_rows(pretest,preteste)
    pretest <- bind_rows(pretest,pretestf)
    pretest <- bind_rows(pretest,pretestg)
    pretest <- bind_rows(pretest,pretesti)
    pretest <- bind_rows(pretest,pretestk)

I'm using the dplyr library btw. My background is in CS but I never use R in any capacity before and this was my first major project for my master degree in stat. I feel like I can chain this via %>% somehow or use lapply or something because the redundancy is annoying.

Thank you",Can you guys help me make this code better?,4nzy0q,top
"I'm at a point where I think I will get a lot out of playing with other peoples' code. Any topic, any level of difficulty. I wouldn't mind trying to get my head around some code that drops down to C or something, for instance. That's just one example, any intermediate/advanced code will be interesting to me to try and learn from.

Also I would appreciate any examples of what you think is good or bad project layout. For instance, I am working on something where I recently put all my functions into a project_functions.R and at the top of my project.R I source(""project_functions.R""), though I'm not sure how recommended this is, or if I should be doing it some other way, or if I should jump into making packages for myself or what. 

There are a bajillion projects written in R, so rather than just pick blindly, I thought I'd ask for any suggestions here! :) Thanks",Beginner/intermediate looking for projects on github to explore and understand,4n6vvq,top
"I'm new to R, having learned statistics alongside SPSS/STATA. 

I'm still wrapping my head around doing things the R way and not trying to force R to do things as I would in other programs. Because of this, is it best that I gain a strong understanding of R using the base packages before moving on to these newer packages? Despite everyone racing how great it is, I fear that if I jump right into Hadleyverse will limit my fundamental understanding of how R works (and also my ability to read other people's code). 

Thoughts?

PS 
I searched and found a few *related* threads, but none that really answered my question. ",Hold off learning dplyr/hadleyverse?,4n0ija,top
"I need to add additional input box next to checkboxes (for the purpose of adding weight to each element). I tried doing it by adding one more column with input boxes but the result is horrible.

    ui.R
    library(shiny)
    library(shinydashboard)


    header <- dashboardHeader(title = ""Szkoly"", titleWidth = 150)
    sidebar <- dashboardSidebar(width = 150,
                            sidebarMenu(
                              fluidRow(column(4,
                                              checkboxGroupInput(""wybierz_lata"", ""Lata"",
                                                                 c(""2002"" = 2002,
                                                                   ""2003"" = 2003,
                                                                   ""2004"" = 2004
                                                                  ))),
                                       column(8,
                                              textInput(""waga_2002"", '', 100),
                                              textInput(""waga_2003"", '', 100),
                                              textInput(""waga_2002"", '', 100)
                                       )
                              ))
    )

    body <- dashboardBody()

    shinyUI(
      dashboardPage(
        header,
        sidebar,
        body
      ))",[Shiny] Adding additional text input next to checkbox,4lmldz,top
"I've been using R exclusively for the past 3 years for all my data/analytic/visualization needs but there is one task that continues to slow me down.  

Nested cross tabs.  

SPSS and Excel can do it painlessly but I have yet to find anything in R that makes it as simple.

dplyr and tidyr are standards.  Am I missing an easy approach? Or is there another package that would ease the burden?",Tips for Nested Cross Tabs in R,4kpynn,top
"Hi everyone,

I'm trying to automate a process of taking a word doc, and throwing some <br> tags on the front of each line, then saving as a .html document.

Basically I'm doing a double for loop where I read all of my files in and for each file, for each line, I insert a <br>.

Everything works great except for reading the .docx, I am using read_docx() from the qdap package, and it's missing lists, or at least the numbers that precede lists.  

Here's an example:

Word Doc:

This is text

But this is announcing a list:

   1. Item one
   2. Item two

-------------------------
My code output:

This is text

But this is announcing a list:

Item one

Item two


I know interfacing with word is a bitch, but is there a simple way to get my output to look like this:

This is text

But this is announcing a list:

1 . Item one

2 . Item two


Thanks for the help!",Reading text out of .docx,4j86rp,top
"I'm sure this is a very simple question, I just started teaching myself R. How would I exclude data corresponding to certain values of an omitted variable from a regression?

For example: 

reg=lm(y~x+z, data=d)

Say that I have another variable, ""year"". Can I exclude all data found for year==2008 without making a new object? 
",How to Run Regressions on Subset of Data?,4ibs2r,top
"All,
I am in need of some help. Here is my basic ggplot2 code: 
http://imgur.com/vrCm61A

I keep getting a funky error: Error: value for ‘cyl’ not found. When I look at my data set... it is there. And the code uses it fine earlier.  I am trying to complete this tutorial: http://www.r-bloggers.com/using-the-ggplot2-library-in-r/


Secondly, I am getting an: Error: unexpected symbol in:
""ggplot(mtcars, aes(mpg, disp)) + geom_point(aes(color = cyl)
ggplot . I must have something that shouldn't be there? Weird part is, I am literally cutting/pasting from the tutorial.

Thank you for any insight. 
",Funky Error,4e2szo,top
"As title suggests, I am working with an Access (soon to be moved to MSSQL) DB that has spaces in the headers.  I am trying to append data to a table using RODBC sqlSave and the space in the ""Last Update"" column is being deleted somehow in sqlSave which prevents the SELECT INTO query.  AFAIK spaces in headers is not best practice but I still want to see if there is a simple workaround since changing column names is not in the cards right now.  Here is sqlSave log with Verbose enabled.  Any help would be appreciate, thanks!

sqlSave(Conn, dat = CurrTbl, tablename = SheetNames[i], append = TRUE, test = FALSE, rownames = FALSE, varTypes = varTypes, verbose = TRUE, fast = FALSE, safer = TRUE)

Query: INSERT INTO ""Z-Score Table"" ( ""Factor"", ""Mean"", ""SD"", ""LastUpdate"" ) VALUES ( 'Rate', 0.1729443, 0.02982243, 'Updated 3/31/16' )

sqlwrite returned 
HYS22 -1507 [Microsoft][ODBC Microsoft Access Driver] The INSERT INTO statement contains the following unknown field name: 'LastUpdate'. Make sure you have typed the name correctly, and try the operation again.
[RODBC] ERROR: Could not SQLExecDirect 'INSERT INTO ""Z-Score Table"" ( ""Factor"", ""Mean"", ""SD"", ""LastUpdate"" ) VALUES ( 'Rate', 0.1729443, 0.02982243, 'Updated 3/31/16' )'

Query: DROP TABLE ""Z-Score Table""",sqlSave preserve spaces in column headers possible?,4d1g3f,top
So I came across this super useful resource today [reddit!](https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/colorPaletteCheatsheet.pdf) but it has no instructions on how to add it to a graph.  I'm currently making a simple scatter plot using ggplot of shoe size and height by gender and have no idea how to add the colors to my graph.  Any suggestions?!?!  ,How to use colorspace package?,4atcv3,top
"I tried if(!(is.null(x)) & nchar(x) != 0), but obviously realised it won't work as many other won't work, because when x=NULL then nchar fails and if x="""" then is.null() fails. Any ideas guys? Any function comes to mind that would be good to evaluate both ? 

Preference would be something using base package","How to check if value is not empty ("""") and not NULL at the same if statement?",49qink,top
"I'm brand new to this and trying to remove some NA's from a dataframe. most people show how to totally delete the rows that have NA in them, but I just want the NA's gone. I guess you can say I want to replace them with blanks. Any ideas?",Removing NA's,46921u,top
"Hello, I've been working a lot with the Shiny package from RStudio and there are great galleries of all the applications people have made with Shiny. I was wondering if anyone has seen some examples of R Markdown documents that people have made. 

I've been looking around and there doesn't seem to be a gallery of people showing off R Markdown reports.

Any help would be appreciated.",R Markdown Examples,3wq91f,top
"I just started a degree in Statistics and keep hearing about R.

I have no coding knowledge whatsoever and after downloading the program feel a bit intimidated with all the coding required for R.

Should I start with learning basic coding first, before starting with R or will I be fine if I keep at it? and/or is there another program that would be a good stepping stone towards R?",Finding a Starting Point,3u8csd,top
"Hi everybody, i have to learn R in order to write my degree thesis about ARCH and GARCH models. The thing is that i've never used R before and on internet there are plenty of guides about almost all the things R can do. 

To cut it short, as of now i don't need to know everything (i will in the future but i have to finish the thesis asap in order to continue my studies) therefore i don't want to spend much time into basics but the reasonable time to achieve a level of knowledge to cover the topic i have been assigned.

In detail what i should be doing:

* import time series;
* estimate an ARMA, ARCH, GARCH model;
* significance tests and all the analysis required.

I'm sorry for my poor statistics english but i've never studied it in english!",Where to learn R?,3bs4xa,top
"I've just started learning the R language using online tutorials like datacamp.com and Codeschool. Does anyone have any ideas of examples of types of projects I can attempt which could help me?

Thanks in advance. ",Project for a beginner,3b6o30,top
"Hello!
I've been tampering with plotting in some points on a local map.
I'm pretty new and the only thing I've found so far is how to make scatterplots dynamic in size or color

http://imgur.com/HhbfuKX

In some areas, as you can see, the density of the units i bigger than some other areas. I can zoom in, by simple ""zoom=8"" to ""zoom=12"", but that would mean I have a lot of ""manual"" stuff to do. 

Then I came to think of, if it is possible to make it like a normal google maps where it is possible to navigate with the mouse: zooming, moving back and forth?

This is what I do to make my map:
 
    #Load pakker
    require(ggmap)
    require(ggplot2)
    require(sp)

    #Åben data og lav plot
    EsbjergData <- read.csv(""C:/kort/561cat.csv"", dec="","", header=TRUE)
    coordsEsb <- cbind(Longitude = as.numeric(as.character(EsbjergData$Longitude)), Latitude = as.numeric(as.character(EsbjergData$Latitude)))
    cats.pts <- SpatialPointsDataFrame(coords, EsbjergData[, -(1:2)], proj4string = CRS(""+init=epsg:4326""))
    plot(cat.pts, pch = ""."", col = ""green"")
   
    #Script
    map <- qmap('Esbjerg', zoom = 8, maptype = 'hybrid')
    map + geom_point(data = EsbjergData, aes(x = EsbjergData$Longitude, y = EsbjergData$Latitude), color=""green"", size=3, alpha=0.5)","""Dynamic"" / interactive map made in R",395ly1,top
"Hopefully this is an appropriate place to ask this question. I'm working on a school project to profile where R is being used the most in research and industry. Almost every example I've been able to find is directly connected to the medical community, mostly in bioinformatics. 

I've found alot of packages that serve other communities, but very little discussion within those communities about their use of R or its analysis. My original hope was to do a comparison of specialty libraries and the domains that use them, but it's looking more and more like a one horse race.

Can anyone suggest non-medical hubs of R usage, or are the bio researchers really that far out ahead of the pack? Thanks for your help!",Looking for areas of research/business other than medicine that are using R regularly.,37darr,top
"Hi all! 
I'm new to R, and really want to learn how to get the most out of the language.
I have practically no experience, and am wondering if any of you happen to have any good websites or resources for beginners? 
I would like to cover the basics of data frames, matrices, loops and some of the plot functionalities of R.
Ideally I'd love to gain the ability to use R to visualise spatial data through packages like ggplot2, but I know I need to master the basics first! 

Any advice or suggestions would be greatly appreciated! 
Thanks guys! ",New to R: Looking for some great beginner guides please!,36fazi,top
"Hey R programmers!

I just posted in the Julia subreddit and wanted to post here too since I'm mainly a R programmer. I'm building a subreddit to submit challenges and would love some input from the data analysis side of things. If you guys have any suggestions please let me know. The idea of the subreddit is to put restrictions on challenges that are more fun in nature and less academic. I think using these restrictions helps you learn things you aren't usually using. Anyways, if you guys want to help out or just want to see a few challenges a day in your feed subscribe. Here is an example from a few days ago. 

http://www.reddit.com/r/HardyCoding/comments/2sxzmo/beginner4e11q_wr1dany/",R Programming Challenges,2t8k93,top
How is Coursera for learning the basics of R? I'm going to start the class today.,How is Coursera?,2ig35p,top
"I'd really like a modern debugger that allows stepping in and out (of functions), movement into all the stack frames with the ability to execute with respect to whatever stack frame I'm in, conditional breakpoints (hopefully based on all the variables across all calling stack frames).

Currently, I'm trying R Studio which, as far as I can tell, is missing some of these features in particular moving/evaling in calling stack frames.  I don't think they have conditional breakpoints either.","So, what's the best debug/IDE environment for R?",1tetq6,top
"First off, it looks like this subreddit is pretty much dead, but is anyone here to answer my questions about R?",R newbie looking for some help,1685vo,top
"Hi folks, 

I'm working on a CV in RMarkdown and I would like my sections to reflect the following format (attached picture).   


My code is as follows:

    # Education
    \noindent\makebox[\linewidth]{\rule{16.5cm}{0.4pt}}

This adds a line break between the word ""Education"" and the horizontal line.   


How can I eliminate the line break?

https://i.redd.it/319yya90ghi11.png",Eliminate the space (line break?) above horizontal line?,9aid2g,top
"Hi all, am new to R and I've been working on RMarkdown though I struggle to understand the difference between this and a notebook or script. Some enlightenment here would be helpful.

Additionally, I'm unsure why the 'Preview' button only shows up sometimes and other times, it's replaced by the Knit button. They produce the same(?) results but could anyone help explain why this 'Preview' button isn't there some times?

Edit: As for the preview button thing -> it only appear when your output is a notebook!",Knit vs Preview,99kb86,top
"if ur interested in the data here is the post 

/r/CryptoCurrency/comments/988lxb/i_have_5_years_of_coinmarketcapcom_crypto_price/

I mainly so far want to look for peeks and bottoms as they have occured throughout the time series. 

I'm familiar with stats, just did stats 101 at uni, and brushed up again years ago when i built a simple trading bot for stocks. 

So a tutorial that focuses on c# would be great, there are a few around but if there is a really good one you guys could share, id appreciate it

thanks","I have 5 years of historical crypto price data i want to do some analysis on, new to R, using c#. can someone provide me a good tutorial to get started?",988ws6,top
"Lately, I've been practicing with Python and creating GUI's and freezing them so non-programmers can use them. Now I want to create one that can analyze grades from students and classes. I've been trying to learn matplot, but it seems so much more difficult than using R and ggplot. I'm much more proficient with R when it comes to graphing. So instead of trying to learn matplot, I'd rather learn how to create GUI's and how to package scripts with R.

Does anyone have any recommendations on what libraries I should look into for these accomplish this? With R, I'm currently only familiar with R Studio, mainly using ggplot and tidyverse. ",Looking to create a GUI with R and packaging it,97tt6o,top
"In matlab you can do array(3,end) to get the third row, final column. What is the r command for this? Google hasn't turned up anything useful",How to index for last value in array?,961yhi,top
"across the web I can read that I should use data.table and fread to load my data.

But when I run a benchmark, then I get the following results

    Unit: milliseconds
    expr       min        lq      mean    median        uq        max neval
    test1  1.229782  1.280000  1.382249  1.366277  1.460483   1.580176    10
    test3  1.294726  1.355139  1.765871  1.391576  1.542041   4.770357    10
    test2 23.115503 23.345451 42.307979 25.492186 57.772522 125.941734    10


where the code can be seen below.

    loadpath <- readRDS(""paths.rds"")

    microbenchmark(
      test1 = read.csv(paste0(loadpath,""data.csv""),header=TRUE,sep="";"", stringsAsFactors = FALSE,colClasses = ""character""),
      test2 = data.table::fread(paste0(loadpath,""data.csv""), sep="";""),
      test3 = read.csv(paste0(loadpath,""data.csv"")),
      times = 10
    ) %>%
      print(order = ""min"") 

I understand that `fread()` should be faster than `read.csv()` because it tries to first read rows into memory as character and then tries to convert them into integer and factor as data types. On the other hand, `fread()` simply reads everything as character.

If this is true, shouldn't `test2` be faster than `test3` ? 

Can someone explain me, why I do not archieve a speed-up or atleast the same speed with `test2` as `test1` ? :)",read.cvs faster than data.table::fread,95vjd8,top
"I am  trying to  make a  montecarlo simulation on T-test  student, as described in this  article:

[https://www.r-bloggers.com/introducing-the-montecarlo-package/](https://www.r-bloggers.com/introducing-the-montecarlo-package/)

As  you can see,  the summary  out put  is  this:

    # generate table: MakeTable(output=MC_result, rows=""n"", cols=c(""loc"",""scale""), digits=2, include_meta=FALSE)
    
    ## \begin{table}[h] ## \centering ## \resizebox{ 1 \textwidth}{!}{% ## \begin{tabular}{ rrrrrrrrrrrrrrr } ## \hline\hline\\\\ ## scale && \multicolumn{ 6 }
    {c}{ 1 } & & \multicolumn{ 6 }{c}{ 2 } \\ ## n/loc & & 0 & 0.2 & 0.
    4 & 0.6 & 0.8 & 1 & & 0 & 0.2 & 0.4 & 0.6 & 0.8 & 1 \\ ## & & & & & 
    & & & & & & & & & \\ ## 50 & & 0.05 & 0.30 & 0.83 & 0.98 & 1.00 & 1.00
     & & 0.05 & 0.10 & 0.28 & 0.55 & 0.79 & 0.94 \\ ## 100 & & 0.05 & 0.51
     & 0.98 & 1.00 & 1.00 & 1.00 & & 0.07 & 0.16 & 0.53 & 0.84 & 0.98 & 1.00
     \\ ## 250 & & 0.05 & 0.89 & 1.00 & 1.00 & 1.00 & 1.00 & & 0.05 & 0.35
     & 0.90 & 1.00 & 1.00 & 1.00 \\ ## 500 & & 0.05 & 1.00 & 1.00 & 1.00 
    & 1.00 & 1.00 & & 0.06 & 0.58 & 1.00 & 1.00 & 1.00 & 1.00 \\ ## \\ ## 
    \\ ## \hline\hline ## \end{tabular}% ## } 
    ## \caption{ decision } ## 
    
    \end{table}

Well, I don't  know  what it means. It's  like  an alien language.   How  can I  red this? Any help please?  Why  the output is so complicated?  How  can I  show it in a readable  way?  Any istogram?",Montecarlo simulation in R,94ghuj,top
"I have a list, that is a string. In this string, the characters are separated by either a "";"" or "","". So I have to use a ""strsplit"". With this, in this example, I end up with 3 list, where 2 of those lists have 3 elements and the last only will have 2 elements in the list.    

    mylist = c(""ac*, be, cd*; daa, efae*, fge*; gefa*, h"")
    Liste <- strsplit(strsplit(mylist , "";"")[[1]], "","")

The reason for, using ""strsplit"" like this, is that when I have a "";"" in my string and "","" as a logical OR, then it acts like a logical AND, that means I have to use one element from each list, later in my code. 

So the output of Liste will be

    [[1]]
    [1] ""ac*""  "" be"" "" cd*""

    [[2]]
    [1] "" daa"" "" efae*"" "" fge*""

    [[3]]
    [1] "" gefa*"" "" h""

What I am trying to avoid, is the use of the double for-loop, and maybe make the code faster, if it is possible.

so now I am using a nested for-loop, to look at each element in mylist.

    for (c in 1:length(Liste)){
      for (d in 1:length(Liste[[c]])){
        # Extracting last character, matching if it is a wildcard
        # Liste[[c]][d] Prints all elements from the list
        # I need the double for-loop for this check
        if (stri_sub(Liste[[c]][d],-1,-1) == '*')
            DO SOMETHING
      }
    }

What else can be done here?",Trying to avoid nested for-loop,947tv7,top
I have 14 days and I need to learn R for medical research. I do not know the exact type of research that I will do but I need to be an average user of R in 14 days. I know how to program in general and have basic knowledge of medical statistics. Which book do you recommend?,Recommend the book to learn R in 14 days for medical research to a person that already knows programming and basic statistics.,91v33z,top
"Hi all,


I have a data frame of NBA basketball data in data frame nba


I'm experimenting with beginner things such as




    nba[team==""Brooklyn Nets"",] #return all row of data for brooklyn nets players
    nba[team==""Brooklyn Nets"",c(""name"",""salary"")] #return all brookyln nets players for column ""name"" and ""salary""



I was also experimenting with the ORDER function and it works great on its own



    nba[order(salary,decreasing=TRUE),c(""name"",""salary"")] #return the ""name"" and ""salary"" for the ENTIRE LEAGUE with highest salary on top



This is fine, but I would like to:


1 - Order the ""Brooklyn Nets"" (1 team) by highest salary (""Who has the top salary in the Brooklyn Nets?"")


2 - Find the top salary for each team 




Appreciate any help, Thanks",Beginner Question: Filtering and Ordering in a Data Frame,8zx2w0,top
"I'm an undergrad in a human genetics lab which likes to use computational biology as well as wetlab for research. During the upcoming year I will be analyzing a lot of bacterial DNA sequences that have been previously extracted from mouse stool. I want to figure out how to construct a bacterial profiles and know what other cool things I could do with R using this data (and maybe other languages/software, if you know any). 

I have previously taken an introductory statistics course which used R, and that is basically my only experience using it.  I have no previous serious coding experience. Of course I would like to have a thorough understanding of the R language, although I am in need of guidance to what (possibly shorter) path to take in this as I would like to be ready in about 2 months when the academic year starts.

Currently I am following through a Udemy course called ""Master Data Science in R"" but it just seems that it is too broad for my needs (and it bored me pretty easily, maybe books/YT videos are better?). Right now I'm pushing through the initial sections, and thinking ""When am I gonna get to the stuff?"". I was recommended to follow ""Advanced R"" by Hadley Wickham. I'm going to give it a shot, but the word  \~advanced\~ sorta feels scary for a newbie like me. 

What do you think? I have never taught myself a programming language, so all help/advice is appreciated!!! :)",New to R. Advice on Analyzing Microbiome Data?,8z3z6h,top
" Hi everybody, I'm a newbie with R. I would like to know how to increase the digits displayed with the summary function after creating a multiple linear regression with lm function. Is there a way to show more digits for all the coefficient or, otherwise, single out specific coefficients to see more digits  for each of them? Thanks ",Increasing the number of digits displayed,8vac9u,top
"I have a dataset that looks like this, where the variable 'NewEvent' counts the number of days between events occurring for each person in the dataset (if NewEvent=0, then event has occurred). 

Day = c(1:8,1:8)

Person = c(1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2)

NewEvent = c(NA,NA,0,1,2,3,0,1,NA,0,1,2,3,0,1,0)

dat <- data.frame(Person,Day,NewEvent);dat

https://i.redd.it/4rsoqo174z511.png

I am trying to restructure the dataset so that it takes the maximum value BETWEEN events occurring for each person, and copies or fills that value. I want it to look like this:

https://i.redd.it/q6el2fcc4z511.png

Any help would be greatly appreciated!",Data restructuring help: How to identify maximum number of days between 'events' and copy that value,8tito9,top
"Hi everyone! I am currently learning R in one of my classes and need to display two histograms in the same window and overlay lines of fit over the both of them. I managed to get the graphs in the same window, but can not figure out how to get the lines to overlay correctly. If anyone has an idea how to help it would be greatly appreciated! Thanks!

Edit: Adding my code so other can see

par(mfrow=c(2,1))

hist(NewMaleHeight, xlab = ""Height"", ylab = ""Frequency"", density = 25,

main = ""Histogram of Male Height with Normal Distribution"", freq = FALSE)

rug(NewMaleHeight, col = ""red"")

curve(dnorm(x, mean = 70.51, sd = 3.080943), col = ""red"", lwd = 2, add = ""TRUE"")

hist(NewFemaleHeight, xlab = ""Height"", ylab = ""Frequency"", density = 25,

main = ""Histogram of Female Height with Normal Distribution"", freq = FALSE)

rug(NewFemaleHeight, col = ""red"")

curve(dnorm(x, mean = 64.76, sd = 3.363986), col = ""red"", lwd = 2, add = ""TRUE"")

Edit 2: Solved!",How to add lines of fit to multiple histograms in the same window?,8q2vpj,top
"I'm trying to merge two dataframes by ID but keep getting 0 observations. I created test dataframes and used merge(d1, d2), and the only observations in the output were ones that had the same ""ID"" variable in both frames (See below). The other rows were not included. How do I merge two files by one variable so that it includes all rows, including those that are not present in both datasets?

Ex: 
D1
ID: 1 2 3 4
Var: a b c d

D2
ID: 3 4 5 6
Bar: e r t y

Merge (D1, D2, by=""ID"")

Merged output was
ID: 3 4
Var: c d
Bar: e r",Trouble merging dataframes,8om7xr,top
"Hello all,

I’m pretty new to R and programming so please forgive me if my questions/knowledge are lacking.

I’m trying to convert text within PDFs of quarterly financial statements into data-frames for manipulation and analysis. 

I’ve tried read_pdf() but it dumps the results as one single string which makes the data cleaning up process a nightmare and very unstructured. 

I’m exploring tabulizer’s extract_tables() function. It’s slightly better as a rough data frame format is provided in the output but a lot of the data values are still recognised as row names. 

I’m hoping someone here would’ve attempted something similar and can give me some pointers.

Any help / input would be greatly appreciated!

Thanks all! ",Reading financial statements (PDF) for data analysis,8ogebe,top
How do I go about making it use the 64bit version when I call it? Thank you!,Trying to use python and keras in R but it says I have 32bit version installed and not the 64 bit version.,8maj79,top
"R has a few ways of making presentation slides - slidy, ioslides, slidify etc.

I have made a presentation using slidify that contains image carousels. Works great on my laptop. But I can't publish it on RPubs, nor can I publish even the simplest slidify example to RPubs. 

So I need an alternative; I went for ioslides. Also, having found the 'slickR' package, I can use that to generate a working carousel in RStudio. However, when I generate the ioslides presentation slides with a slickR carousel, the carousel in the slides is unresponsive/unclickable, as if it was just an ordinary image.

Does anyone know either

- How to make that carousel work in ioslides?
- What else I could use to generate a presentation with an image carousel?",Which of the options for an R presentation will allow me to include an image carousel?,8l47gd,top
"I want to add two convergent lines, one upper and one lower, for the existing plot in R.
Is there a way to do so in R?
I fail in googling the answer.

Thank you!

Image here : https://imgur.com/a/Si6clb4

Code :


    set.seed(123)
    plot( x = 1:100,
          y = rnorm(100)/1:100,
          type = ""l""
    )",Adding a upper and lower boundary curve to enclose existing plot,8kzfzr,top
"I'm running through R For Data Science and can't seem to get through the chapter ""Pipes with magrittr""

The book assumes that little\_bunny\(\) is built into the library, but it doesn't seem to be the case for me.

When I type in:

foo\_foo \<\- little\_bunny\(\)

I get an error message:

Error in little\_bunny\(\) : could not find function ""little\_bunny""

I've insured the magrittr library is installed correctly as well as trying to install tidyverse then running the code. Anyone know the issue? Or what the output of little\_bunny\(\) looks like so I can just write it myself?

Thank you in advance.",Little_bunny(),8jlwyr,top
"I have a set of data about stays, and if those encounters meet these conditions: (same person_id) && (same location_id) && (that person's enc_start_date is within 30 days of their previous enc_end_date) I want to show that as one row with person_id, location_id, first_start_date, last_end_date, sum_of_days_for_each_enc.

 Many times a person has only one encounter (so no summing of days would be necessary), sometimes a person could have multiple stays that should all be added together as one.

I tried doing this as a for loop, but the it doesn't seem to be summing correctly (or at all).



Here's basically the code I have that doesn't seem to work:
    
    VISIT.test <- data.frame(""PERSON_ID"" = character(),
                            ""LOCATION_ID"" = character(),
                            ""ENC_FROM_DT"" = character(),
                            ""ENC_THRU_DT"" = character(),
                            ""ENC_PMT_AMT"" = numeric(),
                            ""ENC_LOS"" = integer(),
                            ""ENC_FROM_YEAR_MONTH"" = character(),
                            stringsAsFactors = FALSE)
        encIndx = 1
        VISIT.test[nrow(VISIT.test)+1, ] <- c(test$PERSON_ID[1], test$LOCATION_ID[1], test$ENC_FROM_DT[1], test$ENC_THRU_DT[1], test$ENC_PMT_AMT[1], test$ENC_LOS[1], test$ENC_FROM_YEAR_MONTH[1])
        for (ii in 2:nrow(test)) {
          # if same person as previous, same location as previous, and encounter starts within 30 days of previous, add this LOS to previous LOS
          if ( (test$PERSON_ID[ii]==test$PERSON_ID[ii-1]) 
                  && (test$LOCATION_ID[ii]==test$LOCATION_ID[ii-1]) 
                  && (as.Date(test$ENC_FROM_DT[ii]) - as.Date(test$ENC_THRU_DT[ii-1]) <= 30 )) 
              {
                # update encounter through date
                VISIT.test$ENC_THRU_DT[encIndx] = test$ENC_THRU_DT[ii];
                # recalculate length of stay
                VISIT.test$ENC_LOS[encIndx]     = as.numeric(VISIT.test$ENC_LOS[encIndx]) + as.numeric(VISIT.test$ENC_LOS[ii])
                # add this payment amount to previous payment amount
                VISIT.test$ENC_PMT_AMT[encIndx] = as.numeric(test$ENC_PMT_AMT[encIndx]) + as.numeric(test$ENC_PMT_AMT[ii])
              }
          else {
            encIndx = encIndx + 1;
            VISIT.test[nrow(VISIT.test)+1, ] <- c(test$PERSON_ID[ii],test$LOCATION_ID[ii],test$ENC_FROM_DT[ii],test$ENC_THRU_DT[ii],test$ENC_PMT_AMT[ii],test$ENC_LOS[ii],test$ENC_FROM_YEAR_MONTH[ii])
          }
        }
    

Any help would be greatly appreciated.",Conditionally summing rows,8ir08j,top
"This is a problem that's highly specific to the company I work for. I'm not a data scientist, but I'm the best we've got, so I'm trying to tackle this problem. I've tried to make the problem as general and reproducible as possible.

I'm trying to summarize user behavior by getting the amount of time a user spends on each step of a process. I've got a dataframe (df.log) with columns user.id (integer), item.id (integer), log.event (factor), and timestamp (POSIX time). Cells in log.event can have the following values, with their respective meanings:

1 - user takes item  
2 - user releases item without submitting work  
3 - item expires before user submits work on item, say after 24 hours  
4 - user submits work on item  

For some reason, our database associates user IDs with log events 1 and 4, but not 2 and 3. However, only one user can ""hold"" an item at a time (i.e., after user takes action 1 on item X, another user cannot take that action until action 2 or 3 is taken on that item). After an item has undergone action 4, it is no longer visible to users.

I also have a list of all unique users whose user IDs are present in df.log$user.id. I would like to construct a dataframe (user.summary) with the following columns:

user.id (unique - each user should only have one row in user.summary
take.count (number of times the user has done log code 1)
release.count (number of times the user has done log code 2)
expire.count (number of times user has allowed an item to expire before submitting, i.e. log code 3)
submit.count (number of times user has done log code 4)
avg.working.time (average difference between when a user takes an item (log code 1) and when they submit it (4)
avg.preview.time (average difference between when a user takes an item (1) and releases it (2)

This has proven tricky because rows with log codes 2 and 3 do not contain a user ID. BUT: because no two users can be ""holding"" an item at the same time, it is safe to infer the user ID from that log event by taking the user ID from a row with the following conditions:

log.code == 1  
item.id == item.id of the current row with log event 2 or 3  
timestamp == max(timestamp) less than the timestamp of current row with log event 2 or 3 (I have no idea how to do this)  

So I have conceptually identified what I need to do, but I have failed to figure out how to write the code to do it. The best solution I can think of is creating a data frame containing all log events for each user, sorting by timestamp, and inferring the user.id for each row missing one using the above logic. This is where I get stuck:



foreach(i=which(df.log$user.id==NA)) %dopar% {  
  current.item <- df.log$item.id[i]  
  df.log$user.id[i] <- df.log$user.id[df.log$item.id == current.item &  df.log$timestamp ==  max(df.log$timestamp[df.log$item.id == current.item]) & df.log$timestamp < df.log$timestamp[i]  
}  

Obviously this code does not return the row for which timestamp is the greatest value less than the timestamp of the current row. I'm not sure how to do that, and I would appreciate any tips you can offer.

Additionally, I'd appreciate any tips on getting the average difference in time between rows with the same item.id and user.id but two different log.codes.

I'm happy to clarify if any of this doesn't make sense. Thanks for your time!",Organizing log timestamps in a data frame where certain events lack a user ID,8g64kv,top
" Hi,

I have a recurrent problem and I saw that I was not the only one in various forum. However, I do not find the solution to this problem... 

I installed Rcmdr but, when I load it this is the error message that I have: 

Loading required package: RcmdrMisc

Loading required package: car

Error: package or namespace load failed for ‘car’ in loadNamespace\(j \<\- i\[\[1L\]\], c\(lib.loc, .libPaths\(\)\), versionCheck = vI\[\[j\]\]\):

there is no package called ‘data.table’

Error: package ‘car’ could not be loaded

Obviously I downloaded RcmdrMisc and car but still the same error message... 

Does anyone has a possible solution for this problem ? 

Thank you very much 

JB ",Rcmdr - impossible to load,8fsk79,top
"EDIT :  
thanks guys! I totally appreciate your help. Unfortunately , it still didn't work. 
I tried all your options but somehow I still either get error messages or the function will only pick the comments from the first list element instead of all the 398 list elements. 

per request hereby the link to my list / dataframes: https://imgur.com/a/ptruY0y
(do you guys mean this when you mean a reproducible dataframe, I wasn't hundred percent sure, also next time will definitely include something visual!) 

Hi for my thesis i am planning to create an analysis on Facebook posts by big Facebook pages and their interaction

I am a novice user  and learning on the go however I can’t seem so find the solution to my problem. Hopefully you guys can point me in the right direction. 

So in short using rfacebook I collected all comments of their Facebook post. However the end result is a list  of 398 objects. And each one of them is a list that contains to data frames. I want to acces the second data frame every time and merge all those data frames in to one big data frame or list. 
And then afterwards I can do data cleaning etc because I want to analyse all the sentiments between posts and comments and likes etc etc 

Anyway every time I try to do a for loop or while loop to go through every initial list to get to the comment framework, in the end I do get the comment however only from the first list. 
 
I am not sure right now what I am doing wrong 

Code rn is : 

For (i in 1:length(list) {
If (I < length (list) { 
Bind_rows(list[[i]][[“comments”]], list[[i+1]][[“comments”]])-> newcommentlist
}
}


",How to bind multiple dataframes that are nested within a list in a list ?,8focj2,top
"Hello,
I'm doing a ML course where I'm using R to plot graphs. The plots used to come out fine. But suddenly R studio started to go crazy on me, the top part of the plots are cut. For example, if the title of the graph is Age vs Salary, I'm only seeing half of it! Not vertically cut, but horizontally! Some weird lines show up for no reason, axis labels are not where they should be anymore, the axes themselves decide to move to the left or more to the bottom, making the plot look like it's been put in a blender and thrown back. What's going on, I didn't change the code one bit and I am checking with the code the lecturer is using and there's nothing wrong. Please help. What should I do. I restarted R studio, my laptop and also told my Mom I love her very much. 

https://imgur.com/a/n1V97fi",Problem with Plots. Plots in R are derping.,8fikw4,top
"This is a continuation of my last post - So I thought I had the solution when applying my function to a list and its components...

test_data

    structure(list(mengzi = structure(list(chapter = c(""liang-hui-
    wang-i"", 
    ""liang-hui-wang-ii"", ""gong-sun-chou-i"")), .Names = ""chapter"", 
    row.names = c(NA, 
    -3L), class = c(""tbl_df"", ""tbl"", ""data.frame"")), liji = structure(list(
    chapter = c(""qu-li-i"", ""qu-li-ii"", ""tan-gong-i"")), .Names = 
    ""chapter"", row.names = c(NA, 
    -3L), class = c(""tbl_df"", ""tbl"", ""data.frame""))), .Names = 
    c(""mengzi"", 
    ""liji""))

a simple function pasting the list name and the embedded values.

    my_function <- function(book, chapter) {
    paste(""www.fakewebsite.com/"", book, ""/"", chapter, sep = """")
    }

Now look what happens when I map my paste function to the list.

    map2(book_list, names(book_list), ~  my_function(..2, ..1))

result - the base url was pasted once, ie, not vectorized, whereas all list values were pasted onto it!  
   
    structure(list(mengzi = ""www.fakewebsite.com/mengzi/c(\""liang-
    hui-wang-i\"", \""liang-hui-wang-ii\"", \""gong-sun-chou-i\"", 
    \""gong-sun-chou-ii\"", \""teng-wen-gong-i\"", \""teng-wen-gong-
    ii\"", \""li-lou-i\"", \""li-lou-ii\"", \""wan-zhang-i\"", \""wan-zhang-ii\"", 
    \""gaozi-i\"", \""gaozi-ii\"", \""jin-xin-i\"", \""jin-xin-ii\"")"", 
    liji = ""www.fakewebsite.com/liji/c(\""qu-li-i\"", \""qu-li-ii\"", \""tan-
    gong-i\"", \""tan-gong-ii\"", \""wang-zhi\"", \""yue-ling\"", \""zengzi-
    wen\"", \""wen-wang-shi-zi\"", \""li-yun\"", \""li-qi\"", \""jiao-te-
    sheng\"", \""nei-ze\"", \""yu-zao\"", \""ming-tang-wei\"", \""sang-fu-
    xiao-ji\"", \""da-zhuan\"", \""shao-yi\"", \""xue-ji\"", \""yue-ji\"", \""za-ji-
    i\"", \""za-ji-ii\"", \""sang-da-ji\"", \""ji-fa\"", \""ji-yi\"", \""ji-tong\"", 
    \""jing-jie\"", \""ai-gong-wen\"", \""zhongni-yan-ju\"", \""kongzi-xian-
    ju\"", \""fang-ji\"", \""zhong-yong\"", \""biao-ji\"", \""zi-yi\"", \""ben-
    sang\"", \""wen-sang\"", \""fu-wen\"", \""jian-zhuan\"", \""san-nian-
    wen\"", \""shen-yi\"", \""tou-hu\"", \n\""ru-xing\"", \""da-xue\"", 
    \""guan-yi\"", \""hun-yi\"", \""xiang-yin-jiu-yi\"", \""she-yi\"", \""yan-
    yi\"", \""pin-yi\"", \""sang-fu-si-zhi\"")""), .Names = c(""mengzi"", 
    ""liji""))

For the record, I can always rely on transforming my data to a data frame format that plays nicely - and the simple function works cleanly.  IE,

    df_format <- map2_df(test_data, names(test_data), 
    ~mutate(.x, book = .y))

    map2(df_format$chapter, df_format$book, ~my_function(..2, 
    ..1))

results 

    list(""www.fakewebsite.com/mengzi/liang-hui-wang-i"", ""www.fakewebsite.com/mengzi/liang-hui-wang-ii"", 
    ""www.fakewebsite.com/mengzi/gong-sun-chou-i"", ""www.fakewebsite.com/liji/qu-li-i"", 
    ""www.fakewebsite.com/liji/qu-li-ii"", ""www.fakewebsite.com/liji/tan-gong-i"")


So, while I can accomplish what I need right now,  I'm wondering WHY I can't get it to work with purrr... Why can't I vectorize the paste function with the book arg, for each chapter embedded under it?


##Begging for an answer, lol!
",Purrr - paste function not vectorizing when using Map(),8ej4qh,top
"Hey guys, I'm trying to figure out how to pass a function to a list but using different arguments for each component-  Purrr seems to be the right tool. 

I've got 5 data frames in a list. Each data frame is a book,  and the values are its chapters.  The function has 2 arguments, one being the book name, the other argument being the chapters.  The function feeds this information to an API address to download the specified chapters from the specified book.  It calls something like ""website.com/book/chapter"".  Now you can see what I mean - if I call the same book over and over, then the API call will be all wrong.

 I can do it for one chapter since the arg names are the same.  I can do it for one book (since I can still specify the same ""book"" arg) Problem is, I want to do it for multiple books, but can't figure out how to pass different book name arguments to the list of books. The book names are the names of each list component. And the API call goes all wrong as a result.

    library(tidyverse)
    library(httr)
    library(jsonlite)

##My basic API call function - (Not very robust... lol)
    ctext_api <- function(path) {
    url <- modify_url(""https://api.ctext.org/"", path = path)
    resp <- GET(url)
    if (http_type(resp) != ""application/json"") {
    stop(""API did not return json"", call. = FALSE)
    }
    parsed <- jsonlite::fromJSON(content(resp, ""text""), simplifyVector = FALSE, flatten = TRUE)
    parsed
    }

API call for grabbing a chapter in a text:

    get_text <- function(book, chapter) {

    path <-  paste(""/gettext?urn="", ""ctp:"", book, ""/"", chapter, sep = """")
 
    raw_data <- ctext_api(path)

     ##R-bind the ugly raw data for parsing
    bound_data <- do.call(rbind, raw_data)

    ##Make it into a pretty data frame
    setNames(data.frame(matrix(unlist(bound_data), ncol = 2, byrow = TRUE)), c(""Word"", ""Chapter""))
    }


Here is a short list of books and chapters for example, I need to call the function on this list,  ideally by designating each individual name for the ""book"" argument, but for the proper element. 


    book_list <- structure(list(analects = c(""xue-er"", ""wei-zheng"", ""ba-yi"", ""li-ren"", 
    ""gong-ye-chang"", ""yong-ye""), mengzi = c(""liang-hui-wang-i"", ""liang-hui-wang-ii"", 
    ""gong-sun-chou-i"", ""gong-sun-chou-ii"", ""teng-wen-gong-i"", ""teng-wen-gong-ii""
    ), liji = c(""qu-li-i"", ""qu-li-ii"", ""tan-gong-i"", ""tan-gong-ii"", 
    ""wang-zhi"", ""yue-ling""), mozi = c(""befriending-the -learned"", 
    ""self-cultivation"", ""on-dyeing"", ""on-the-necessity-of-standards"", 
    ""seven-causes-of-anxiety"", ""indulgence-in-excess""), hanfeizi = c(""chu-jian-qin"", 
    ""cun-han"", ""nan-yan"", ""ai-chen"", ""zhu-dao"", ""you-du"")), .Names = c(""analects"", 
    ""mengzi"", ""liji"", ""mozi"", ""hanfeizi""))
  
Simple test - test it on one single chapter, in a single book. Chapter 1 of Analects, ""xue-er"". This is the most basic call, the arguments simply get pasted into the API function, so no need to apply it to the list. 

    Analects_Chapter_1 <- get_text(""analects"", ""xue-er"") 

And it works well, output is:

    structure(list(Word = structure(c(5L, 15L, 6L, 12L, 9L, 7L, 1L, 
    3L, 13L, 10L, 8L, 16L, 14L, 4L, 11L, 2L), .Label = c(""子夏曰：「賢賢易色，事父母能竭其力，事君能致其身，與朋友交言而           
    有信。雖曰未學，吾必謂之學矣。」"", 
    ""子曰：「不患人之不己知，患不知人也。」"", 
    ""子曰：「君子不重則不威，學則不固。主忠信，無友不如己者，過則勿憚改。」"", 
    ""子曰：「君子食無求飽，居無求安，敏於事而慎於言，就有道而正焉，可謂好學也已。」"", 
    ""子曰：「學而時習之，不亦說乎？有朋自遠方來，不亦樂乎？人不知而不慍，不亦君子乎？」"", 
    ""子曰：「巧言令色，鮮矣仁！」"", ""子曰：「弟子入則孝，出則弟，謹而信，汎愛眾，而親仁。行有餘力，則以學文。」"", 
    ""子曰：「父在，觀其志；父沒，觀其行；三年無改於父之道，可謂孝矣。」"", 
    ""子曰：「道千乘之國：敬事而信，節用而愛人，使民以時。」"", 
    ""子禽問於子貢曰：「夫子至於是邦也，必聞其政，求之與？抑與之與？」子貢曰：「夫子溫、良、恭、儉、讓以得之。夫子之求之   
    也，其諸異乎人之求之與？」"", 
    ""子貢曰：「貧而無諂，富而無驕，何如？」子曰：「可也。未若貧而樂，富而好禮者也。」子貢曰：「《詩》云：『如切如磋，如  
    琢如磨。』其斯之謂與？」子曰：「賜也，始可與言詩已矣！告諸往而知來者。」"", 
    ""曾子曰：「吾日三省吾身：為人謀而不忠乎？與朋友交而不信乎？傳不習乎？」"", 
    ""曾子曰：「慎終追遠，民德歸厚矣。」"", ""有子曰：「信近於義，言可復也；恭近於禮，遠恥辱也；因不失其親，亦可宗也。」"", 
    ""有子曰：「其為人也孝弟，而好犯上者，鮮矣；不好犯上，而好作亂者，未之有也。君子務本，本立而道生。孝弟也者，其為仁之   
    本與！」"", 
    ""有子曰：「禮之用，和為貴。先王之道斯為美，小大由之。有所不行，知和而和，不以禮節之，亦不可行也。」""
    ), class = ""factor""), Chapter = structure(c(1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = ""學而"", class = ""factor"")), .Names = c(""Word"", 
    ""Chapter""), row.names = c(NA, -16L), class = ""data.frame"")

Test 2 - Try it on an entire work.  The book of ""mozi"". Since I need this vectorized over many chapters (which I don't have memorized) I use map from Purr to apply it to my list.  The results come out in a list due to the map function, so the results itself need to be parsed. But otherwise this works well too. I can't show output due to API running out of credits for today :( 

    mozi <- map(book_list$mozi, function(chapter) get_text(book=""mozi"", chapter = chapter))

     do.call(rbind, mozi)



So yeah, now I am trying to pass this get_text(book, chapter) to my entire list, but I have no clue how to pass a different (""book"") arg to each different data component of my list.
    
IE, I need to pass ""analects"", ""chapter"" to the analects, ""mengzi"", ""chapter"" to book_list$mengzi, ""liji"", ""chapter"" to book_list$liji     etc. 

I try:

       Books <- map(book_list, function(chapter) get_text(chapter = chapter, book = names(book_list)))

 (above doesn't work) I thought I could simply use the ""names"" function to access the book names and they'd be passed to the function as it is called on different list elements, but nope.  

Help? 
  


 
[Current Status: Not Purring](https://image.ibb.co/cEbCnS/1180183937.jpg)",Help - Applying Function to list with Purrr,8duqpv,top
" Hi there,

I am trying to iterate through a fairly large dataset of English words. First things first, I want to eliminate all derivative words (e.g. keep ""pet"" but removed ""pets"". In the code you will see some examples of the conditions I am going to use, but there are many more I need to add. (the 'to_delete' array to which I am appending values that match my conditions—I am going to use it to eliminate derivatives from the 'words' dataset afterwards, but I want to be able to just look at an array of potential derivatives first and evaluate from there.)

Buuuuuut, my problem: is iterating with a for loop the best strategy? I did a test run and the code will literally take days to run as is. Hahaha. 

I thought of using something similar to:
df[!(df$... ==...)] but I could not figure out a way to make this work for checking to see if word *n* in my dataset was duplicated as a derivate (adj, adverb, etc) somewhere else in the dataset. 

Any tips would be greatly appreciated. Thank you. 

    for (i in 1:NROW(words)) {
            print(i)  ## to see how code is progressing
            for (j in 1:NROW(words)) {
                if (words[j] == paste(words[i], ""s"", sep="""") ||
                    words[j] == paste(words[i], ""ed"", sep="""") ||
                    words[j] == paste(words[i], ""d"", sep="""") ||
                    words[j] == paste(words[i], ""ly"", sep="""") ||
                    words[j] == paste(words[i], ""ing"", sep="""")) {
                    to_delete = append(to_delete, words[j])
                }
            }
        }    

------
EDIT: Thanks to everyone who contributed their thoughts and suggestions. Ultimately, /u/guepier and /u/antiheaderalist provided the crucial tip and I found the tidytext package to be extremely useful.  ","Iterating through large dataset for linguistics project, using nested for loops—am I a fool?",8bpa5l,top
"Hi all,

I am working on a project that uses the tuneR package to parse and analyze midi files of videogame music. I've been impressed with some aspects of the tuneR package. I've been underwhelmed by other aspects.

One thing that bugs me about tuneR is that I can't use it to write midi files. It looks like the function lilyinput was going to do that, but the developers never got around to finishing it. 

So I'm taking the lilyinput function and sprucing it up so that I can write lilypond files. Then I use lilypond to generate a score and a midi file. 

Here's the github project: [lilyinput](https://github.com/areeves87/lilyinput). Pretty bare bones right now. Would love to collaborate and maybe get some feedback. ",Writing midi files with R: lilyinput2,87nout,top
"**Edit:** Thanks for the input guys. I wrote a heatmap function after all: [example output](https://github.com/SchmidtPaul/useful/blob/master/img4.png?raw=true)

Hey there! Mediocre R stats guy here.

So I don't often work with matrices, but when I do, they are too large to be displayed in the console or viewer and I often want to quickly check things like 

* What are its dimensions?
* Is it diagonal?
* How many differnt values are on the diagonal?
* Are there mostly zeros or small values on the off diagonal?
* Are there exceptions to an overall pattern?

So what do you guys do to quickly investigate/check your matrices. I thought that looking at the matrix as a heatmap would be quite nice. Yet, before I throw myself into writing a function I wanted to make sure that I am not missing an important point here.

Bonus: table(df$col1, df$col2) output also creates such ""matrices"" that I would like view as heatmaps for a quick overview.

Cheers! 

","Guys, how do you quickly examine your large matrices?",862q94,top
"I was only good with excel on a very basic level and vlookup/pivot tables. Was very impressed with a temporary colleague (sent from HQ) who saw how I was struggling with some simple work and made a file which im not sure from macro or Visual Basics.

I did not have chance to ask him more about those skills but I would really like to improve on my skillset with data manipulating and things along that line. 

Should I bother with learning Visual Basics/VBA, or should I go straight into R or Python and then apply them in Excel?",What's next for me?,85tmfm,top
"I have an R Shiny app hosted on an aws server, and yesterday I realized that the app wasn't getting up to date data due to the data querying happening in global.R, which is only run when the app starts.

However, today it looks as though the app has rerun global.R and the data is now up to date, however, the AWS server was apparently not restarted.

What could have caused this? Can the Shiny app restart itself independently of the server? How can I check this?

Also, if I cloned the directory holding the original shiny app and ran the clone, would running global.R for the clone update global.R for the original?

The one thing I'm not able to do is update the data in the original data source to see whether the app updates to reflect the changes.",How would an R Shiny app hosted on a AWS server rerun global.R without a server restart? Is it possible?,81ens4,top
"I am trying to create my own implementation of K-means. The theory isn't confusing. It's just my lack of knowledge with R.

I have a matrix of data and I am confused about instantiating new variables. I have a matrix of my initial random centroids.

Now I am not quite sure how to create an empty cluster to start filling based on the distances. Do I create an empty matrix for each cluster and put them in a list of size k? Then add a point to that matrix using rbind? Just not sure of what to store things in. Any insight will really help! Sorry if this is the wrong subreddit for this.",Problems with R. Trying to implement K-means.,7zt533,top
"Done with the basics...  Just finished reading and practicing  stuff at http://tryr.codeschool.com 

I would like to learn more and reach at least intermediate level.

Can somebody guide me, what's next? I need to be be good at this within a month.",Beginner's Guide,7vtptn,top
"I have a problem with the following code. I'm scanning through a data frame and when I've hit the row I'm interested in, I can successfully print it out. However, when I try to print out just one element/column entry of this row, it gives me nonsense. 

## Code:

    # Scan through current data frame of terms and their frequencies:
      for(i in 1:nrow(DF)){
        # Determine the start of the current term in the data frame:
        current_prefix <- substr(DF[i, 1], 1, prefix_length)
    
        # If the start of the current term in the data frame matches the prefix:
        if(current_prefix == prefix_to_match){
          current_term <- as.character(DF[i, 1])
          current_freq <- as.numeric(DF[i, 2])
          vec_matched_terms <- c(vec_matched_terms, current_term) 
          vec_matched_freqs <- c(vec_matched_freqs, current_freq) 
      
          if(current_term == ""no surprise""){
            print(DF[i, ])
            print(DF[i, 1])
            print(DF[i, 2])
          }
        }
      }
  
      print(""!!!???"")
      print(vec_matched_terms)
      print(vec_matched_freqs)



## Output of this code:


          terms_vec freqs_vec    percentages_col cumulative_percentages_col
    151 no surprise        13 0.0619047619047619                       29.9
    [1] no surprise
     20259 Levels: n a n â<U+0080><U+009C>this n aftra n austin n awh n ballas ... nzt saving
    [1] 13
    67 Levels: 0 1 10 100 106 11 114 12 124 13 132 134 135 14 15 16 ... 
    [1] ""no surprise""
    [1] 10
    [1] ""!!!???""
    [1] ""no surprise"" ""no such""     ""no sense""   
    [1] 10  6 66

The quantity I'm interested in is the frequency, which is the second column of my data frame. When I print out the whole row, this is the 13 seen underneath 'freqs_vec'. This part works correctly, print(DF[i, ]) prints out the row as it looks in the data frame.

However, immediately after I do print(DF[i, ]), I do print(DF[i, 1]) and  I do print(DF[i, 2]). It gives me the correct phrase (""no surprise"") and number (13) back when, but is accompanied by all these levels. This I don't know how to stop or what consequences it might have, but using as.character() and as.numeric() hasn't got rid of this info about levels being somehow attached to the actual quantities I care about. That's the first problem, and I'm guessing it's related to the main problem.

The main problem is that I'm supposed to have assigned the values of DF[i, 1] and DF[i, 2] to current_term and current_freq, but when I print these out, I find that current_freq holds different numbers to what I'd expect -
this number has changed from 13 to 10 by being assigned to current_freq. 

What is going on here?",Whole row of data frame can be printed correctly but trying to print only one entry in that row gives me nonsense?,7sxf2q,top
"I'm trying to follow along with this [exercise file](http://www.bio.ic.ac.uk/research/crawley/statistics/exercises/R1Plots.pdf). Everything seems to work fine except for the part on Logarithmic axes. I can never get R to convert it into log form. It just plots it out regularly, even if I copy straight from the exercise file. Is there something wrong with this material, my data, etc? Any help would be appreciated.

Here is the data from the plotdata.txt that I have. It was a download file.

x|y
:--|:--
1|11
2|12
3|9
4|7
5|5
6|8
7|4
8|4
9|5
10|3",Learning R. Having problems with Logarithmic axes,7s1cw3,top
"Hi,

I don't know R very well and I have a one-time assignment I need help with. I have a [spreadsheet of voting results in the 2016 Democratic primaries](https://docs.google.com/spreadsheets/d/1WXo8o3dOV7LC0zOjYggrzc7IkgbdXKBNZD1CcH11efI/edit?usp=sharing). I need to make a bar graph displaying Sanders's average performance by type of election (primary or caucus). 

This is what I have:

> > Primary2016$SandersPercent = (Primary2016$Sanders / (Primary2016$Sanders + Primary2016$Clinton)) * 100

> > library(ggplot2)

> > Primaries = Primary2016[which(Primary2016$Type == ""Primary""),]

> > Caucuses = Primary2016[which(Primary2016$Type == ""Caucus""),]

And then I'm not really sure what to do. I've been playing with:

> > ggplot() + geom_col(Primaries, aes(y=SandersPercent, x=Type)) + geom_col(Caucuses, aes(y=SandersPercent, x=Type))

But it hasn't been working...I've been getting an incorrect result or the following errors:

> > Error: stat_count() must not be used with a y aesthetic.

> > Error: ggplot2 doesn't know how to deal with data of class uneval

Thanks for your help!",Help with quick bar graph in R,7otgug,top
The estimator for generalized least squares is given by [this equation](https://wikimedia.org/api/rest_v1/media/math/render/svg/cc6def71cb9c0a746e21a3ae20b593f2aa6da1a7). What function and how should I use if I know the Ω variance matrix (as well as X and y)? Where in `lm` or `glm` should I input this?,Estimating GLS with known variance-covariance matrix,7cfsqb,top
"

Following [this
post](https://www.reddit.com/r/Rlanguage/comments/7c4vbb/ggplot_alter_the_x_axis_density/?st=j9vbr3ou&sh=cefed0bb)
I thought that I should make something with a reproducible example.

* Here's the code for this example : http://vpaste.net/lS5Ft
* Here's the original graph plotted using base r : https://i.imgur.com/ljP0vA6.png
* Here's the  graph plotted using ggplot2 : https://i.imgur.com/hRUa9uL.png
* This is the graph plotted using the code that I've provided : https://i.imgur.com/7ztIjl2.png

# Problem

The x axis *ticks* are too densely packed in, something which the base r plot
seems to handle automatically but ggplot doesn't.

I'm not sure how best to handle / control this.

## Using `scale_x_discrete`

Using this I'm able to do *something* with the axis, but it doesn't seem to be
behaving as I would expect.

For example - for the following : 

    ## Create a plot of the data for total number aboard each year
    p <- ggplot(aboardYears, aes(yearLevels, aboardYearTotal))
    breakV <- seq(1910,1990,by=20)
    p + geom_point(aes(size = aboardYearTotal))+  scale_x_discrete(breaks=breakV)

I would expect to have the x ticks as 

    tick 1 : 1910
    tick 2 : 1930
    tick 3 : 1950
    tick 4 : 1970
    tick 5 : 1990
 
But this isn't the case, instead I get this output : https://i.imgur.com/GYCk4Ky.png

This is the code that generated that output : http://vpaste.net/kFqpm


# So...

I'm not sure how to go about sorting this. I've tried to use the `limits`
parameter of `scale_x_discrete`, but that didn't really work how I would have
liked either.

I'm not sure how to get this to behave in a manner similar to the default behaviour.


Thanks
",Adjusting the tick values in ggplot sensibly,7c8f1v,top
"I'm once again looking at some legacy R code, trying to read the user's mind. It looks like they are using Python style, whereby they define an empty R vector, and then use a for loop to append the results to a vector.

    library(data.table)
    dtable = read.table(""path/filename.txt"",header=TRUE,sep=""\t"",check.names=FALSE)

After defining this data.table, here is what was 
Here is what is being done:

    empty_vector <- c()
    
    for(i in 1:nrow(dtable))
    {
    empty_vector <- append(empty_vector,strsplit(dtable[i,6],"":"")[[1]][2])
    }

This is a rather large `data.table`, with +500K rows. 

(1) We shouldn't be using a for loop. There is a data.table way to do this. 

(2) So, defining an empty vector and appending results to this vector is not R. What is the ""R approach"" to this?

EDIT: I think the programmer was thinking of something like this in Python:

    empty_list = []    ## equivalent to R vector

    for i in range(10):
        empty_list.append(i)

    print(empty_list)   ## now [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

How would someone do something like this, given this is R and we are iterating over rows of a data.table?

",Appending data.table rows into an empty vector---doing the right data.table thing,7amukz,top
"Hello,


I am trying to get the maximum likelihood estimation of a function to be later used as a variable in my model. The function has four unknown parameters and two known variables. If we let the unknowns be u1, u2, u3, and u4, and the two variables x1 and x2, it goes like this:

Qit(u1, u2, u3, u4) = [(u3)(x1it*u1)^(1-u4)  +  (1-u3)(x2it*u2)^(1-u4)] ^ (1/(1-u4))



the data for x1 and x2 is time varying (about 100 observations). I am essentially trying to estimate u1, u2, u3, and u4 in order to be able to use the entire function as a variable in my main RE model. How do I go about doing that in R? I am fairly familiar with the software but Ive never done MLE.



Thanks for taking the time to read!",MLE in R,77fjwd,top
"Hi, my dataframe (df) looks like:

    MONTH   YEAR   COUNTY1   COUNTY2   COUNTY3
    Jan      2004    100      200        300
    Feb      2004    100      200        300
    Mar      2004    100      200        300
    April    2004    100      200        300

I would like to plot a line graph, with each line representing the individual county variable, while the x axis is based off of both the month and year columns. Any help would be greatly appreciated.",Beginner Question: How to plot multiple lines on a graph,76shyz,top
"I love Rstudio, Especially the new release. But I was wondering what other developer environments people here use. I've come across emacs + ESS, Visual Studio, and more lightweight editors like Atom/VS Code with a bunch of extensions added in. What setup do you all use?",Alternatives to Rstudio for an R development IDE,75ne6z,top
"Hi All

I'm a python programmer and recently I wanted to install R (with biocLite and all dependencies) on a server that doesn't have internet access... I did a google search but couldn't find a good tutorial.... 

So looking for some starting prints and recommendations from you all...

Thank you very much.",Install R locally (without access to the internet),6y82og,top
"I have a simple dataset with 'earn', 'transport' and 'country' and tried to estimate simple fixed effects using 'lm': transport ~ earn + country (I'm not attempting random or mixed effects here).

The problem is when I want to plot the result using ggplot2. I can plot one geom_smooth for all datapoints:

    gg.all <- ggplot(data=data, aes(x=earn, y=transport)) +
    	geom_point(aes(colour=country)) +
    	geom_smooth(method=""lm"", se=F)
[fig. 1][1]


or I can plot geom_smooth for each country independently:

    gg.indep <- ggplot(data=data, aes(x=earn, y=transport, colour=country)) +
    	geom_point() +
    	geom_smooth(method=""lm"", se=F)
[fig. 2][2]

My problem is that I'm unable to plot each line with it's own fixed effect (intercept), but with shared slope for all countries.

How should I approach this problem? Thanks

  [1]: https://i.stack.imgur.com/amXJH.png
  [2]: https://i.stack.imgur.com/nDvAM.png",Plotting fixed effects with ggplot2,6xqa4r,top
"Hi all, i'm looking to learn R and get into data analytics. Thing is my highest level of math was Trig IIRC, and Statistics(which I don't really remember all too well). I didn't care much when I was in school as I thought I would never have to use high level math IRL.

Anyways to the point- What would be the best/most efficient way of learning high level math, at least enough to understand R? Should I take a couple courses in city college? Or should I just get a book and learn on my own? Or maybe just learn on the go? Like when I run into a term say 'matrices', I can just look that up and learn that way?

Any guidance would be greatly appreciated

Thanks",Ways to catch up in advanced math?,6vefgt,top
"I've been searching around trying to find a way to create an interactive image of a 96-well plate (like [this](http://www.cellsignet.com/media/plates/96.jpg)) where the user could select wells by clicking them and then the wells would become shaded (like [this](http://labstats.net/figs/96well_rand.png)). I have yet to find any solutions or any packages that will allow me to do this.

Is there a way to customize a checkboxgroup from gwidgets to accomplish this?

Any help is appreciated
","Creating a custom ""checkbox group"" resembling a 96-well plate where the user can interactively select wells by clicking (for GUI)",6trc3s,top
"Hello everyone,

Normally I would agree that a for loop should be avoided and someone from the apply family should be used, but I think I've run into a situation where a for loop will be required.  (Perhaps someone can show me I'm wrong.)

I have a rather ugly spreadsheet coming to me from a vendor's conference room scheduling product.  My ultimate goal is to join this data with a spreadsheet that shows the utilization of the A/V equipment in each conference room.  For now, I'm just trying to get the scheduling data cleaned up so I can join with A/V data.

Here is a sample of what the scheduling data looks like:

x1 | x2 | x3 | x4
---------|----------|----------|----------
Room Name | ConfRmA | 
Subject |  | Start Time | Hours
Dept A |  | 7/10/2017 7:30 | 2:30
Dept B |  | 7/10/2017 12:30 | 1:30
Room Name | ConfRmB
Subject |  |Start Time | Hours
Dept B |  | 7/11/2017 8:00 | 1:00
Dept C |  | 7/11/2017 9:30 | 3:30

My end goal would be a dataframe that looks like this:

Room | Subject | Start Time | Duration
---------|----------|----------|----------
ConfRmA | Dept A | 7/10/2017 7:30 | 2:30
ConfRmA | Dept B | 7/10/2017 12:30 | 1:30
ConfRmB | Dept B | 7/11/2017 8:00 | 1:00
ConfRmB | Dept C | 7/11/2017 9:30 | 3:30

The reason I suspect I need the for loop is so I can conditionally evaluate the original data frame to see if x2 is null or not.  If it's not null, then I need to create a column with the value of x2 for each row where x2 is null until I run into another row where x2 is not null.

Hopefully this all makes sense.  Can someone get me going in the right direction, please?  Here's the code to create my example dataframe:

    x1 <- c('Room Name','Subject','Dept A','Dept B','Room Name','Subject','Dept B','Dept D')
    x2 <- c('ConfRmA','','','','ConfRmB','','','')
    x3 <- c('','Start Time','7/10/2017 7:30','7/10/2017 12:30','','Start Time','7/11/2017 8:00','7/11/2017 9:30')
    x4 <- c('','Hours','2:30','1:30','','Hours','1:00','3:30')
    df <- data.frame(x1,x2,x3,x4)",Struggling with for loop on dataframe,6stixj,top
I am trying to learn how to use the NVidia Tesla GPU on my work computers to perform our statistical models. I am having trouble with grasping the concept and my coding language is somewhat basic. Does anyone have any advice or help?,[Help] R coding to use GPU,6o1v23,top
How can I write excel files with R without using Java? ,Writing excel files without Java,6ndm3i,top
"I'm having trouble making sense of data discrepancies in some outputs I am getting, so am hoping some of you can help enlighten me.   
   
To quickly summarize, I am trying to remove the top .5% and bottom .5% of expense values for each ID in a data frame. I am using the dplyr library and the following code to do so:
    
    DB1_ID_1 = DB1 %>% group_by(ID) %>%    
        filter(Total_Expend <= quantile(Total_Expend,.995) & Total_Expend >= quantile(Total_Expend,.005))

   
When I run this code 421 data rows are excluded (5.3% of the entire data frame). To check which values were removed, I inverted the greater-than and less-than signs in the above code, assuming it would output those 421 data rows that were excluded. However, instead it filtered ALL but 2 rows from the data. My first question is, does anyone know why this would happen?
   
   
To test this myself, I amended the code below to just filter the bottom percentile and invert that less-than sign to output the filtered values.    

    DB1_ID_1 = DB1 %>% group_by(ID) %>%
        filter(Total_Expend >= quantile(Total_Expend,.005))

    DB1_ID_1 = DB1 %>% group_by(ID) %>%
        filter(Total_Expend <= quantile(Total_Expend,.005))   
   
The results of these were 42 values removed and over 3000 values removed, respectively. This confused me even more, which is why I am making my first post here in hopes of gaining some clarity.   
   
Thanks in advance!

",Using quantile() for data exclusion,6my9ed,top
"I have the following ggplot2 violinplot 

    library(ggplot2)                                                                                                                                                                                                                                                                                                      
    bp <- ggplot(data=PlantGrowth, aes(x=group, y=weight, fill=group)) + 
                 geom_violin() +
                 geom_dotplot(binaxis='y', stackdir='center', dotsize=0.5, binwidth = 0.01)                      


                                                                                                                                 
http://imgur.com/a/cXQTt

It's unclear to me based on previous examples how to put labels in the legend (as seen with `vplot()`. I would like to put an integer just to the right of each label in the legend

    ctrl 10
    trt1 10
    trt2 10

I've manually calculated these simply with

    > table(PlantGrowth$group) 

What is the standard way to automatically do this? I've tried the function

    give.sample.size <- function(x) {                                                                                                                                                                                                                                                                                                
        return(c(y = mean(x), label = length(x)))                                                                                                                                                                                                                                                                         
    }                                                                                                                                                                                                                                                                                                                 


    bp <- ggplot(data=PlantGrowth, aes(x=group, y=weight, fill=group)) +
       geom_violin() + 
       geom_dotplot(binaxis='y', stackdir='center', dotsize=0.5, binwidth = 0.01) + 
       stat_summary(fun.data = give.sample.size, geom = ""text"")

But this wouldn't affect the legend. ","Problems adding ""sample sizes"" to ggplot violinplot legend",6mwrx1,top
"Hey Reddit! I'm trying to learn how to classify objects with machine learning. I have to use R to create a fuzzy random forest, but I've never actually gotten the chance to implement ML algorithms. Therefore, I have no idea how to actually create and fuzzy random forest in R. Can someone send me an example piece of code in R that will show me what I need to do? Thanks!!!",Help with Fuzzy Random Forests,6mgr0u,top
"I am taking a course Edx, Microsoft: DAT209x Programming with R for Data Science, and struggling with understanding the concepts.  Additionally the instructor has a very thick accent that I have a hard time understanding.  The link to the course is below: 
https://courses.edx.org/courses/course-v1:Microsoft+DAT209x+2T2017/info

I am asking for a tutor to work with me through the course, helping me understand the concepts and guiding me through the test/labs.  I'm not asking for you to do the work for me, just to work through the question and challenges with me, and guide me when I have issues.  

Of course there will be compensation for the tutoring.   ",Tutoring request for Programming with R for Data Science course,6l8ddf,top
"Is some library on Shiny the best way to do it, or should I use something from Python/JS?",What is the best way to show information on an interactive map?,6kkc3n,top
"This is probably a weird question, but if I have a machine that I want to run a C++ program on, and have an R script, that I want to embed in my C++ application, could I run it by including RInside in my C++ script without installing R on my machine? Or is that not how it works?","If I use <RInside.H> in a C++ program, will I need to install R onto my machine, or does this package come with an R interpreter?",6k5q3j,top
"I have a dataset (.csv) containing a Storename, a date (monthly data, recorded to the 1st of each month) from June 2007 to May 2017 and the demand(sales) for that period.

My task is to forecast demand in general/for each store by using time-series in R.

I have no idea how to go about this.
My general plan was to:

- visualize the demand for a couple of Stores to see what kind of time-series i can use (ARIMA, Holt-Winter etc.) What ggplot do I use for that, how do I do it?
- Then use that to build a model that i`ll use on each store (there are 350+), how can I automate that? I can´t subset and repeat the process that often!

Any kind of input is appreciated. I am a total newbee to R :(",Forecasting demand from a dataset: How do I go about this?,6hlriz,top
"In RStudio, I have a data set of 3 columns (Allocation Group, Date, and Hours) and 17,354 rows.  I want to get a sum of total hours for each date, and group those hours into one of 8 allocation groups.  Then I want to create a line graph where x = date, y = total hours, grouped by allocation group. So my line graph will contain 8 different lines. Finally, i want to smooth out the lines by creating a running average of the lines.

Data currently looks something like this:

Allocation Group / Date / Hours

A / 2017-02-06 / 8

B / 2017-02-06 / 2

A / 2017-02-06 / 1

A / 2017-02-07 / 5

B / 2017-02-07 / 3


What do i need to do to summarize the daily totals by allocation group, then graph that data?

any help would be appreciated. I can provide more detail if needed. Thanks!",Rookie Question: How do I sum up the values in a data set by date AND grouping?,6fo2m6,top
"I have a dataset structured something like this:

ID     | Day | Score

123   | 1     |5

123   | 2     |4

234   | 1     |30

234   | 3     |34

234   | 2     |25

345   | 1     |12

And I want it to look like this:

ID  | Day 1| Day 2 | Day 3

123|   5     |   4     | 

234|   30   |   25   | 34

345|   12


Is there a good way to do this?  I'm pretty new to programming loops and such in R and I assume that's the way to do this, I'm just not sure how to structure it.

Thanks!",Looping to fill a matrix,6e86kx,top
"I'm talking about the ""build"", ""codecov"", and ""CRAN"" buttons in the readme file for some packages on GitHub. Maybe there are others too.

[Example.](https://github.com/hafen/trelliscopejs)

I can't tell if they are a 'thing' (e.g. a package creates these buttons for you) or a convention (e.g. the build button is manually pointed to a travis URL for example).

Are they common? Do you find them useful (as either package authors or users)?",What are these and how do I get them?,6cy1hd,top
"I have a colleague who is a wizard with `data.table`. The tricks she knows just amaze me, and I always feel slightly lost with respect to what she's doing. 

Where could I learn more about how to ""improve"" my data.table skills?",What are the best resources for learning `data.table` tricks? (Besides the documentation),67ptoy,top
"I need to generate Dashboards and reports, but can this only be done in R Studio?

","Can ""R Markdown"" be used in R (programming language) to generate Dashboards/Reports?",62rx7h,top
"Here is an [example image](http://imgur.com/a/WFhnG).  I already have a column containing the means of each row.  Now, I want to replace the NAs in each row with their corresponding means.  Also, the Means column has a few NA's as well.

I'm new at R, so simpler solutions are definitely preferable.  I've checked other sites, but they all provide solutions for situations where the NA's are only in one column, or where the means aren't already provided which doesn't match this situation.",How can I replace the NA values in all rows by their row's mean found in another column?,5zgqdk,top
"I'm performing sentiment analysis in R and need to perform sanitization to remove all useless characters, quotes, stop words, links and especially EMOJIS! 

Could anyone suggest the library and/or regular expressions for this purpose!

I've already done the following : 
    tweets = tolower(tweets)
    tweets_cl <- gsub('\\p{So}|\\p{Cn}', '', tweets, perl = TRUE)
    tweets_cl = gsub(""(RT|via)((?:\\b\\W*@\\w+)+)"","""",tweets_cl)
    tweets_cl = gsub(""http[^[:blank:]]+"", """", tweets_cl)
    tweets_cl = gsub(""@\\w+"", """", tweets_cl)
    tweets_cl = gsub(""[ \t]{2,}"", """", tweets_cl)
    tweets_cl = gsub(""^\\s+|\\s+$"", """", tweets_cl)
    tweets_cl = gsub(""[[:punct:]]"", "" "", tweets_cl)
    tweets_cl = gsub(""[^[:alnum:]]"", "" "", tweets_cl)
    tweets_cl <- gsub('\\d+', '', tweets_cl)
    
    #map_chr converts to Vector
    tweetaftermap <- map_chr(tweets_cl, function(x) x $text)",Sanitizing Twitter data for text analysis,5ysitv,top
"My company uses an ancient and extremely aggravating software to label exhibits and place watermarks like ""draft,""  ""confidential,"" ...etc
Is there any way to import PDFs, label watermarks and headers on each page, then export to PDF again?",How to import PDF and add page numbers/exhibit numbers?,5slqru,top
I’m in the research phase of developing an application that will need to run regression analysis. Wondering if I could use R to power this or if I’d have to write the whole regression model into the application myself.,Can r power a commercial SaaS application?,5s3z89,top
"I have plotted a scatter graph (with the help from folks here at /r/Rlanguage) using Twitter data gathered from their API. 

Basically I have just plotted the frequency of tweets from a user over the past few months, to see if they have a specific time of day they tweet, or any other interesting trends). I'm using this project to get better at visualising my data in R, as I'm used to just exporting it to excel and making a graph in there, since it's so quick and easy to do. 

I've made a plot in R and in Excel. IMO the excel one is much nicer to look at. Is there a way to improve on my existing R plot, so as to make it look similar to my excel one (doesn't have to be the exact same, but along the same lines, or even better). Here are the two graphs: 

* [Graph using R](http://i.imgur.com/vZW2RHB.png)
* [Graph using Excel](http://i.imgur.com/8UfVHgb.png)

Also for the life of me, I can't seem to get the y-axis in my R plot to be between 00:00 and 00:00 like it is in the Excel plot. I tried using the *limit* argument, but that still hasn't worked. Can anyone help me solve this? It's the thing that is pissing me off the most! 

EDIT: Here is the code I'm using for plotting  the R graph. 
My dataset structure looks like this:

    created             | TweetDate  | TweetTime
    2017-01-31 11:27:02 | 2017-01-31 | 11:27:02
    2017-01-31 11:21:52 | 2017-01-31 | 11:21:52
    2017-01-31 00:45:50 | 2017-01-31 | 00:45:50
 
All three features are in POSIXct format.

The code:

    #LIMITS TO TRY AND SCALE THE Y-AXIS TO START AT 00:00 AND END AT 00:00
    #DOES NOT WORK ATM
    lims <- as.POSIXct(strptime(c(""2017-02-03 00:00"",""2017-02-03 23:59""), 
                            format = ""%Y-%m-%d %H:%M:%S"")) 

    #PLOT USING gglot2
    library(ggplot2)
    library(scales)
    ggplot(refinedDF, aes(x=TweetDate, y=TweetTime)) + 
    geom_point(aes(colour = I(""blue""))) + 
    scale_y_datetime(limits = lims, breaks = date_breaks(""3 hour""), minor_breaks=date_breaks(""30 min""), labels=date_format(""%H:%M"")) + 
    scale_x_datetime(breaks = date_breaks(""2 month"")) +
    theme(axis.text.x=element_text(angle=360)) +
    theme(plot.title = element_text(family = ""Trebuchet MS"", color=""#000000"", face=""bold"", size=18, hjust=0.5)) +
    theme(axis.title = element_text(family = ""Trebuchet MS"", color=""#302e2e"", face=""bold"", size=12)) + 
    ggtitle(""Tweet Fquency Over Time"") +
    labs(x=""Tweet Date"",y=""Tweet Time"")",How can I improve on this visualization I've created with ggplot2?,5rwjo0,top
"Hey Everyone, 
I'm new to R and I'm trying to do a lot of bioinformatics work. I'm downloading packages through biocLite from Bioconductor and I'm receiving the error message The downloaded source packages end with the message

""installation path not writeable, unable to update packages: mgcv, survival""

So, I went to that folder and manually installed them through  Tools > Install Packages. However, I see that they're still listed in my packages list before I manually install them. 
What does this  mean?
Thanks
Sam",Downloading packages: Path not writeable: magcv. survival.,5nqqec,top
"this is how i have it written: tapply(X=fish$fish_weight,INDEX=fish$sex,FUN=mean) 
Could somebody point me in the right direction please.",Question:I keep getting an error saying arguments must have the same length when applying the tapply function.,5mdfmo,top
"Hello everybody,
my brother-in-law is a computer science student at UC Merced and he began, with some friends, a super nice project in which they post beginner-level coding challenges at a github page and encourage people to solve those challenges in different languages. It's really cool because you can not only work on a different coding challenge every couple days but also compare your work to the work of others.

I have been doing this for less than a week and I have already learned:

1) How to write R script in order to make it executable both from a Unix terminal and from the interactive Rstudio screen;

2) How to use GIT and github (in fact, the brother-in-law wrote a super nice and useful introduction to git and github in the homepage)

3) How to use vim;

4) and others.

 There's no one doing R, just myself, and it would be super rad if more people were solving the challenges, because we would be able to compare solutions and whatnots. Here's the link:

https://github.com/YearOfProgramming/2017Challenges","New project, good for beginners: collaborative periodic coding challenges",5m4fdv,top
"I am new to R and I have a question on whether such a thing is possible. 

If I have a set of R scripts, let's call them A, B, and C. Then what is the best way to create a dashboard for loading A, B and C from a UI instead of accessing them through the folders manually? With two scripts one could create conditionals and use action buttons, correct? What about if I have a large set of scripts? 

Would I have to pre plan and put them into one large script or is it possible to create a dashboard for the many scripts now?",Creating a Shiny dashboard for accessing scripts,5lgwwd,top
"Hi there,

I've a simple data structure question for you.

So there are a few data types you can work with in R:

* Vector
* Array
* Lists
* Factor
* Matrix
* Data Frame

Say for instance you were running a study where you interviewed N subjects and asked each subject, 12 questions. All of this data is recorded and then imported into R. You now have each question represented as a data frame. 

    question_01 <- data.frame()
    question_02 <- data.frame()
    .
    .
    .
    question_12 <- data.frame()

Here's the catch. Each question data frame has the **same columns** but **different rows**. Merging them as one wont be as straight forward.

    subject01 <- data.frame(question_01,question_02,...question_12)

Will throw an exception with respect to a mismatch of rows

So the workarounds I see is fill each question data frame with the same rows with NA or NULL values.

Put each question data frame into some table or list? **I don't want to lose any information the data frames have already.**

What other options do I have?

____
https://www.tutorialspoint.com/r/r_data_types.htm
http://www.statmethods.net/input/datatypes.html
",R Data Structures: Is it possible to combine several data frames under one data frame?,5j27fw,top
"I have this [this](https://shreymudgal.shinyapps.io/betterlivingnyc/), when the three circle creating variables are chosen(School Quality, Recreational Facilities and daycare), they clutter the map.

What I want is that in whatever combination they are chosen, the only overlapping areas should be shown rest circle markers ignore.
       
 One very very very hectic way is to find the distance between all the points in all the combinations possible > 60, and create a corresponding csv and then display that on the map according to the chosen variables. ",Anyway to detect overlapping Circle Markers in Rshiny Leaflet,5g0nlp,top
"Hello boys and girls,

i am writing a script that locates .bat files and checks if there is a specific text in the file. If the text is there, nothing happens, but if the text is not there the script adds the needed text to the contents of the file.
The only problem i have encountered is reading the .bat files (or batch files) into the environment so the algorithm can check them.
Is there a way i can read them as a single string vector? Or to read .bat files at all?",Reading .bat (batch files) with R and RStudio,5etc6r,top
"Hey everyone!

I decided to use R for a project at work as I'm trying to learn it. What better way to learn than to do?

So I have two datasets, both in the data.frame format. One set has my IVs - there is an observation for each employee that includes various data including their department, and the IVs are things like number of calls made per day, training time, etc. 

Here's the tricky part (for me). The second dataset has my DV (sales), but it is more or less a summary matrix that includes total sales per department. 

In the first dataset, department is listed in a column. In the second dataset, department is the column headers. 

Any help on running a regression model with this data? I'm sure I'm overthinking it...",New to R and the community - multiple regression help would be appreciated!,5dcsia,top
"Hi there!

I have a dataset of n=100 and I wanted to test the correlation of 4 performance metrics. I use the spearman correlation since the data is not normally distributed.

Following my code:

Code: 

> cor.test(IRR,PME,method = ""spearman"",exact = TRUE)

	Spearman's rank correlation rho

data:  IRR and PME
S = 27357, p-value < 2.2e-16
alternative hypothesis: true rho is not equal to 0
sample estimates:
      rho 
0.8948348

I wanted to ask you guys about the p-value. The details are described as following: ""For Spearman's test, p-values are computed using algorithm AS 89 for n < 1290 and exact = TRUE, otherwise via the asymptotic t approximation. Note that these are ‘exact’ for n < 10, and use an Edgeworth series approximation for larger sample sizes (the cutoff has been changed from the original paper)"".

My n is bigger than 10. So an Edgeworth series approximation for a t-test will be used. Is this ok or should I change something? ",Spearman's Correlation and p-Value,573zvb,top
"Hi there, 
I'm a student at a university making progress on my thesis analysis and am running into an error within my loop. My codes is as follows:


    library (dplR)

    itrdb <- read.csv (""itrdb.csv"")
    itrdb.rwl <- (itrdb [,7])

    for (i in 1:length(itrdb)) {
    list.rwl <- as.character (itrdb.rwl [1] [i])
    rwl.files <- read.rwl (list.rwl)
    {

where `list.rwl` is a list containing URLs of files I am trying to read in off a FTP server. However, not every file is formatted correctly so my loop will constantly fail. I want to bypass the bad files, but still collect the 'bad' URLs in a seperate object so that I can retrieve them on my own at a later date. I know I need to use `tryCatch()` to solve this problem, but even after spending hours reading stackoverflow I am essentailly clueless. 

If anyone could help me out I would really appreciate it. ",Help using tryCatch to bypass errors in a loop,54sxkl,top
"I'm in the process of writing some R scripts that automate the data processing and reporting at my company. With our current system, one of the final products is an image that contains a graph, a few charts and a picture all together. I have no problem writing the code to automatically pull in the data and generate the individual figures, but I can't figure out how (or even if) I can then pull all of this stuff together into a single figure.

Has anyone here attempted to do something like this before?","Stitching together graphs, pictures and tables",53o5k2,top
"Hi everyone

Is this possible? Any examples would be be appreciated. 

So far, I am only able to output shiny into separate browser",Example of a shiny interactive visualization within a Jupyter/IPython notebook?,4yy6r0,top
"Hey everyone,

I am trying to figure out what ip address is used whenever I send off an RCurl function (""getURL""). I first ran across this question after signing up for one of the popular VPN services that routes your traffic through an alternate IP address and wanted to test if RCurl was picking up the new public IP address. What I found was that my public IP address was different every time I used ""getURL"". Does anyone know why this is the case and why a RCurl function wouldn't use my VPN service's public IP address?


Here is the code snippet I am talking about.


    library(RCurl)
    library(XML)

    url <- 'http://www.whatsmyip.org/'
        
    site <- getURL(url)
    site_data <- htmlParse(site)
    
    # different ip address on every single request?
    xpathSApply(site_data, '//*[@id=""ip""]', xmlValue)  


I looked through the RCurl documentation, but wasn't able to find much regarding this topic. That documentation mainly led me to how the curl package written in C was mapped to libcurl and then RCurl. 


My hope is that I can find an answer without having to dig too much further into anything C related (only know the basics of C).


Any help or other resources to check would be greatly appreciated!


edit: spelling / grammar

**Edit: so it appeared to be that website I was using. If I use [this one](http://ipinfo.io/ip) instead, then it seems to work better. It even picks up on my VPN ip address when I use RCurl.**
",What IP Address does RCurl use (default options)?,4yxdir,top
"This semester I am working as a TA for a Stats Professor in my college. The class primarily uses R to teach statistics. He has created an entire textbook using RMarkdown and would like to have some tutorial videos made to coincide with the textbook. The class is mostly made up of psychology, political science and math education majors. I took this class and saw that a lot of people had trouble just getting used to R which ended up getting us behind in the semester due to troubleshooting problems and such. 

My Professor has pretty much given me carte blanche on how to develop the videos. I was wondering, how would you guys prefer to have tutorial videos made?

I was thinking making short 15-30 second videos that demonstrate a single function or library. I myself hate youtube tutorials that take **FOREVER** to get to the point and I end up fast forwarding through most of it. 

I'd rather make quick, upbeat, maybe even slightly comedic tutorial videos that somebody could watch quickly or replay maybe once or twice to get the gist of the function. 

Since this class isn't focused on programming in R but utilizing prebuilt libraries to answer statistical questions I don't think I'd have to delve very deeply into the fundamentals of programming.

Here is my short list of videos I think would be helpful. Let me know if you think there are any videos I should add or that you guys would enjoy watching. 

    Install R, Rstudio, LaTeX Windows

    Install R, Studio, MacTex OS X 

    Install R, Studio, MacTex, Homebrew OS X (using homebrew method)

    Installing packages

    Important Statistical Packages

    Functions: ANOVA, GLM, Chi-Squared, etc...

    Functions: cbind, subset, merge, apply, dplyr etc...

    Plotting: ggplot2(basics), mPlot, qqPlot, etc...

    LaTex Tips

    RMarkdown tips and styling

    Things like how to read in csv or data from URL or database

That's my running idea. Obviously some of them might be a little longer than 30 seconds but the general idea is to make short, fun to watch, and informative videos on just some simple basics in R without having to go on and on about why somebody should use R. 

Any thoughts on what I should add or take away? I understand you don't have access to the course material but what would you guys like to see in some basic R tutorials?",Developing R Tutorial Videos for Stats Professor this Semester. Any ideas?,4yrmtq,top
"Hi all. I have a data frame that I want to add new values that I generate from for loop.

I have 5 rows of data frame and I would like to add new data into new column at each row and aggregate all of the values I generate from my for loop code and looking for a code that allows me to do so. Thank you!",How do I add new data in R?,4w7las,top
"So I'm melting a matrix:

    > mymatrix
         [,1] [,2] [,3] [,4] [,5]
    [1,]    1    4    7   10   13
    [2,]    2    5    8   11   14
    [3,]    3    6    9   12   15
    
    > melt(mymatrix)
       Var1 Var2 value
    1     1    1     1
    2     2    1     2
    3     3    1     3
    4     1    2     4
    5     2    2     5
    6     3    2     6
    7     1    3     7
    8     2    3     8
    9     3    3     9
    10    1    4    10
    11    2    4    11
    12    3    4    12
    13    1    5    13
    14    2    5    14
    15    3    5    15

Is there a way I can ""customize"" Var1 and Var2 (without doing it manually) in the melt to get, for example:

           Var1  Var2 value
    1     0.005    10     1
    2     0.010    10     2
    3     0.015    10     3
    4     0.005    20     4
    5     0.010    20     5
    6     0.015    20     6
    7     0.005    30     7
    8     0.010    30     8
    9     0.015    30     9
    10    0.005    40    10
    11    0.010    40    11
    12    0.015    40    12
    13    0.005    50    13
    14    0.010    50    14
    15    0.015    50    15

I've tried changing the row/colnames to c(0.005, 0.01, 0.015) and c(10,20,30,40,50) with no success. Should I be using a data frame rather than a matrix?
",Quick question: melting a matrix,4v0woi,top
Anyone know how to graph d3.horizon-like plots in R?,D3 Horizon-like plots in R,4twaxa,top
"Hello!

Well, I'm a student and I'm finishing my Master Thesis. My thesis consists in developing a R Package to help a user with optimization problems ou Metaheuristics. For example, a user will use my package to perform some optimization problems in a easier way than using per example tabuSearch ou Genalg. 

To perform the usage of tabuSearch, it's necessary to convert numbers to binary, because this package/method only works with binary. 

Actually I can perform an optimization where the user inserts integer values, then I have a function to convert to binary those values. My problem now, it's that I want to create the possibility to the user put some real values, like, 2.32, 20.4, 10, 30.2, and convert them to binary. It is possible to convert those values to binary to the package perform the otimization and then when the optimization is done, convert them to real values again?

I really need you help in this.

Thank's a lot. ;)",Binary convertions,4ts1l2,top
"I normally code in Python, Scala, C, etc. 

I am utterly baffled by how R's `factor` data structure is to be applied, or how this concept translates into other programming languages. 

What is the motivation of this? Why is it useful? 

What is an ""R factor"" in (let's say) Python?

Thanks for any help!","How does R's ""factor"" data structure translate into other programming languages? Why is it useful?",4qscz0,top
"Attempting to install muxViz (muxviz.net) and I followed all the steps, except R I installed through anaconda (conda install -c r r) but when I try to start it within R, I get the following errors:
> source('muxVizGUI.R')

>Loading required package: devtools

>--- Please select a CRAN mirror for use in this session ---

>Error in download.file(url, destfile = f, quiet = TRUE) : 

>  unsupported URL scheme

>In addition: Warning message:

>In library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :

>  there is no package called ‘devtools’

>Error: .onLoad failed in loadNamespace() for 'tcltk', details:

>  call: fun(libname, pkgname)

>  error: Can't find a usable init.tcl in the following directories: 

>    /opt/anaconda1anaconda2anaconda3/lib/tcl8.5 ./lib/tcl8.5 ./lib/tcl8.5 ./library ./library ./tcl8.5.18/library ./tcl8.5.18/library

>

>

>

>This probably means that Tcl wasn't installed properly.

Any ideas?","Installing muxViz: ""This probably means that Tcl wasn't installed properly.""",4p1jya,top
I've seen tutorials online but what is the exact purpose of them? ,What is the purpose of Shiny apps?,4mdyte,top
"Hello,

I am trying to convert a file to csv using R, and I have a column called ""ArticleCode"" that is a article reference, but it has a bunch of leading zeros, and when I try to save it as csv2, they are truncated.

For example:


FirstName | LastName | ID | City | Country
---------|--------|--|----|-------
John | Dow | 000358 | Milan | Italy
Mike | Snow | 126 | NewYork | USA 


becomes: 


FirstName | LastName | ID | City | Country
---------|--------|--|----|-------
John | Dow |358 | Milan | Italy
Mike | Snow | 126 | NewYork | USA



currently my code is:

     df1 = read.xlsx2(Path, header = T)
    
     df1$ID <- as.character(df1$ID)
    
    write.csv2(df1, file = PATH , quote =c(3), row.names = FALSE)
    

And I want John Dow's ID to continue 000358 . 
How can I solve this problem?
I have tried to convert to factor, but the problem seems to be in the write process, because in RStudio the df1$id appear as string and with the leading zeros.. 
Thank you!",How to avoid truncation of leadings zeros when saving as csv?,4iekrj,top
"I have created a GBM from my training set and applied it on a few testing sets but I'd like to visualize the decision tree in an actual tree/graph form. Is this possible?

I've look at the output from pretty.gbm.tree but i'm not sure how to manually create it.
",How to get decision tree visualization?,4hehpe,top
"Did a multiple linear regression with stats from MLB baseball teams with runs scored as response variable and OBP and SLG as my predictors. How can I explain each diagnostic plot in relation to my model.
Here are the plots http://imgur.com/a/sF55N",How to interpret these regression diagnostic plots?,4ge5ke,top
"I'm not sure if this is the right sub to post this here but can someone point me in the right direction in translating this piece of code into Python? http://users.utu.fi/attenka/trent.R

>###############################
###############################
## FUNCTION TRANSFER ENTROPY ##
###############################
###############################

# 070527 (ver. 081126), Atte Tenkanen
# s, time shift
trent<-function(Y,X,s=1){

    #---------------------------------#
    # Transition probability vectors: #
    #---------------------------------#

    L4=L1=length(X)-s # Lengths of vector Xn+1.
    L3=L2=length(X) # Lengths of vector Xn (and Yn).

    #-------------------#
    # 1. p(Xn+s,Xn,Yn): #
    #-------------------#

    TPvector1=rep(0,L1) # Init.

    for(i in 1:L1)
    {
            TPvector1[i]=paste(c(X[i+s],""i"",X[i],""i"",Y[i]),collapse="""") # ""addresses""
    }

    TPvector1T=table(TPvector1)/length(TPvector1) # Table of probabilities.

    #-----------#
    # 2. p(Xn): #
    #-----------#

    TPvector2=X
    TPvector2T=table(X)/sum(table(X))

    #--------------#
    # 3. p(Xn,Yn): #
    #--------------#

    TPvector3=rep(0,L3)

    for(i in 1:L3)
    {
            TPvector3[i]=paste(c(X[i],""i"",Y[i]),collapse="""") # addresses
    }

    TPvector3T=table(TPvector3)/length(TPvector2)

    #----------------#
    # 4. p(Xn+s,Xn): #
    #----------------#

    TPvector4=rep(0,L4)

    for(i in 1:L4)
    {
            TPvector4[i]=paste(c(X[i+s],""i"",X[i]),collapse="""") # addresses
    }

    TPvector4T=table(TPvector4)/length(TPvector4)

    #--------------------------#
    # Transfer entropy T(Y->X) #
    #--------------------------#

    SUMvector=rep(0,length(TPvector1T))
    for(n in 1:length(TPvector1T))
    {
        SUMvector[n]=TPvector1T[n]*log10((TPvector1T[n]*TPvector2T[(unlist(strsplit(names(TPvector1T)[n],""i"")))[2]])/(TPvector3T[paste((unlist(strsplit(names(TPvector1T)[n],""i"")))[2],""i"",(unlist(strsplit(names(TPvector1T)[n],""i"")))[3],sep="""",collapse="""")]*TPvector4T[paste((unlist(strsplit(names(TPvector1T)[n],""i"")))[1],""i"",(unlist(strsplit(names(TPvector1T)[n],""i"")))[2],sep="""",collapse="""")]))
    }
    return(sum(SUMvector))
    } # End of the trent-function.
I've tried learning R but the intricacies of the language are a bit confusing for me. I would prefer having it in Python so that I can easily integrate it with other pieces of code I've already written. ",Need Help Translating Code to Python,4gaud8,top
"Me and my team have been working on a shiny web app, and one of the things we're trying to do is linking to another app on our local machine. We're using a single file with a UI and a Server function. 

    library(shiny)
    ui <- fluidPage(
 
     absolutePanel(top = ""30%"", left = ""40%"",
      wellPanel(
       actionButton(""doThis"", label = ""Submit"", style = ""color: #fff; 
        background-color: #337ab7; border-color:#2e6da4"")
      )
     )
    )
    server <- function(input, output)
    {
     observe({
      if(input$doThis==0) return()
    
      isolate({
       runApp(""C:/Users/myUser/Documents/GUI_Code/main"")
      })
     })
    }
    shinyApp(ui, server = server)


We're just trying to run another app after clicking the action button, but we keep getting this error.

    Warning: Unhandled error in observer: Key / already in use
    observe({
     if (input$doThis == 0) 
         return()
     isolate({
         runApp(""C:/Users/myUser/Documents/GUI_Code/main"")
     })
    })

Any idea what we're doing wrong? Thanks!
",Help opening Shiny app from a Shiny app.,4fqblk,top
"Hi there. I have a client looking at macs and Windows PCs with 4,6,8,12 cores, some with dual graphics cards too. What are the major benefits when using R with multi core, or is there an upper limit where you'd see dimishging returns in terms of output. ",Multi core support,4fb6p6,top
I believe I can pass some arguments to the script. But does R provide an interface for the script to return something back? Can a script return something to the variable of a parent script?,Is it possible to have a whole script included as a function?,4ds0kb,top
"Hey y'all, 

I'm doing research this term where I want to compare the local popularity of different activities through their use in hashtags across the U.S. I have seen [Spencer Greenhalgh's Series](http://www.spencergreenhalgh.com/2015/12/02/plotting-twitter-users-locations-in-r-part-2-geotags-vs-web-scraping-vs-api/) on using R to collect this information, using geotags if enabled, and otherwise pulling users location from their profile. My problem is that the R code he provided for doing this pulls this data as it comes in rather than searching archives. 

How does this process differ for searching archives, can you suggest any packages? 

Is this something to do in R or is this a project for another language where I should import my data into R later? 

Anyone have questions or suggestions? 
*Edit: formatting",How to go about collecting location data of archived tweets,4d93nj,top
"Hello! I have two dataframes that consist of five string variables. I want to match rows in one dataframe with their closest counterparts in the other dataframe using fuzzy matching. I'm familiar with adist, amatch, and the concept of fuzzy matching in general, but as far as I understand all of the impementations i've learned abotu can only match an individual string with its closest counterpart in a vector, as opposed to matching a whole vector of strings with its closest counterpart in a dataframe.

Is there a function or automatic way to handle this, or should I work on a manual implementation?",Fuzzy string matching with dataframes,4d2mbp,top
"Hello Reddit Rlanguage,
I built a model in regards to 'insurance charges' and basic stats (age, what region someone lives in, number of kids in house and BMI). I am trying to see if the insurance charges go up if someone has these qualities. My model looks good but I am not sure 'what' these numbers mean. For example, under 'smoker yes', does that mean that if someone is a smoker, they will pay 13402 more than someone that isn't a smoker or 13402 more than the median of -1251.6? My second question is how can my median be -1251.6 when everyone has charges in my data set. Here is a screen shot: http://imgur.com/rbkevGe

Thank you!",What does it mean?,4bomqs,top
I've been search all over to see if there's any packages with template formats like in ggthemes but haven't found any--am I missing something? ,Are there any other packages like ggthemes?,48tmn6,top
"GOAL: Create a line graph showing the total number of home runs by all players in baseball from 1980s-2015.  

DATA: I have an excel spreadsheet of the amount of home runs each player hit in the 1980, 1981...2013,2014 baseball seasons.  The year and home runs hit are 2 separate columns.  How do I average together the total # of home runs in 1980, then average the total # of home runs in 1981... and so forth so I can plot the graph?",How to take an average of a range of values with a column?,48brtq,top
"I have both in my laptop however I don't know specifically the difference. If I open RStudio, I can see in the console that there is Microsoft R Open 3.2.3. I'm quite confused. Haha. Thanks for the good soul would take time to explain. :D",ELI5: What is the difference between RStudio and MRO?,424dl0,top
"I'm taking a beginner course in machine learning using R on Udemy. So far the course has been great, but there's one thing I didn't understand when following along with an example.

We're on data frames, and trying to generate a bar chart using some sample data. This is the data frame I have:


         orange apple banana strawberry
    2001   5323 20605  34891       2008
    2002   5511 20001  32891       1978
    2003   5079 19567  36777       2078
    2004   5280 20004  31476       2267
    2005   5777 22678  36617       2198
    2006   6435 21564  39789       2780

We go on and plot a bar chart from this on fruit sales for all years. When doing this for individual sales we used

    barplot(data.m[1,], main=""2001 sales"")

But when we do it for all years he uses 

    barplot(t(data.m), legend = TRUE,  main=""Fruits"")  

Why is there a need for the ""t"" in the second example? What does it do? The instructor on the course never states what it does.

EDIT: I think I found the solution on [this site](http://www.statmethods.net/management/reshape.html). It looks like t transposes the data? Can someone confirm this for me?","What does ""t"" do in this data frame example?",3zf3vq,top
"Apparently I have enough knowledge to make me dangerous. I have enough that baby tutorials are not sufficient, but I don't understand 90% of the questions on the front page of this subreddit. 

Any suggestions for more ""practice"" oriented tutorials? I feel the need to do and not just copy. Plus I'm interested mostly in taking some fairly simple data files (a time stamp and then various events, maybe 500-1000) associated with the time stamp. Extracting the relevant data and graphing it in a somewhat complicated way (as a raster plot where the Y axis are different data files and the X axis is time.) ",R for dummies reference?,3xakno,top
"I am pulling data from a python app and plotting it on a map using R. I was forced to use a loop to extract the data I need and was hoping someone could show me how to do it in a more R friendly way. I believe the reshape function is what I need but I can't seem to get it right. 

Basically the data is returning in this format:

    x[1:2]
                                   col1               col2
    city                     Pittsburgh               Erie
    date                    08 Dec 2015        09 Dec 2015 
    state                            PA                 PA
    key                8de242c388570729   623ca16d7bb9e9e9

And I would like to have it like this:

            City   State         Date               Key
    1 Pittsburgh      PA  08 Dec 2015    8de242c3870729
    2       Erie      PA  09 Dec 2015    623ca16d79e9e9

The loop I am using now:

    cities = c()
    dates = c()
    states = c()
    keys = c()
    ittr = 0
    for (i in jobs){
      cities[ittr] = i[1]
      dates[ittr] = i[2]
      states[ittr] = i[3]
      keys[ittr] = i[4]
      ittr = ittr + 1
    }

    jobs = data.frame(key=keys, date=dates,
           city=cities, state=states)",R reshape data/optimization help,3wk3x1,top
I have lots of data. I want to access this data in a shiny application. Should I use .rds files? Or construct a sqlite database. I'm estimating a weekly addition of 25gb (.rds dataframes) so it will grow to be massive. Most of the time I don't need to access it all at once so currently I selectively grab the .rds files I need but I have a feeling loading several hundred .rds files might be inefficient. What are my options?,Shiny friendly database,3wdhgs,top
"In my free e-Magazine, I am writing articles to introduce users to R.  In the first issue, I included a ""Getting Started"" article.  In the upcoming issue, I have one on using data frame, one on plots, and one more advanced on text analysis.  I would like some more tip based articles from seasoned users.  Would anyone be interested in submitting anything?  It would be greatly appreciated.",White papers,3w803t,top
"Hi,
I am very new to R and am trying to format my dates.
dates are given as dd.mm.yy
I have a data frame h with h$date and h$birth given in the above format. I need to store them as dates with yyyy
what I tried:
    

     year2to4<-function(t,year=1968){
        y.last2=year(t) %% 100 ## return the last two digit of year by       find the remainder
        cut=year%%100
        year(t)<-ifelse(y.last2>cut,1900+y.last2,2000+y.last2)
        return(t)
     }
     h$date <- year2to4(as.Date(h$date))
     h$birth <- year2to4(as.Date(h$birth))

And I still have years as 2060 in my data...Why?
Thank you very much!","2K problem, 68-69",3vo10p,top
"So we were assigned a microarray dataset from the NCBI GEO website and we are having trouble completing some basic statistical analysis. I'm not gonna lie, we are newbs and we need serious help.  We have performed PCA, but we really need help with hierarchical clustering. Could anyone point us in the right direction with code, or examples of the code.  

The data set is 134 samples with 48,701 entries, so nothing simple.  Please help!!!! We will love you forever.",Help with microarray dataset in stats project,3v24mc,top
"I'm very new to R. I'm trying to replicate the results of a previous project as research for my own. I have the .csv files of the training data and the test data. My problem is I can't seem to find a good tutorial on how to actually implement Naive Bayes. 

I've seen a few examples like [this](http://www.inside-r.org/packages/cran/e1071/docs/naivebayes) and [this](https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Classification/Na%C3%AFve_Bayes#Installing_and_Running_the_Na.C3.AFve_Bayes_Classifier) but they don't do a great job of really explaining the code to me.

For example, my class node will be the variable ""Status"", which will have 28 other variables which influence it. I need to train the model with my training data, so when I can introduce the test data it will determine whether the ""Status"" is a Win or Lose.

Right now I can input the training data, and view it's str() and summary(). I just can't find any good tutorials on implementing the training and prediction part, at least not the way I need it to. 

Can anyone recommend a good tutorial on this?",A good example of implementing Naive Bayes?,3r98ra,top
I am conducting a research study on R programming Acceptance. The results from this survey will help better understand the future use of 'R’. This survey should take 4-5 minutes to complete. Be assure your responses will be strictly confidential. Thanks for agreeing to take part in this study. http://goo.gl/forms/X2aiBTzxHw,Research about R acceptance,3qsqse,top
"I have a string that I'm searching through trying to find a pattern expressed via regular expression. I don't want to extract the pattern, just how many times it appears. The documentation for regexp, grep and the like don't seem to show that it is possible but it seems like it should be. Thanks. ",Trying to figure out how to find the number of times a regular expression appears in a string,3nv73x,top
"I'm looking for a good stable way to have a R server. There are [rApache](http://rapache.net/downloads.html) which has not been updated for a [long long time](https://raw.githubusercontent.com/jeffreyhorner/rapache/master/ChangeLog) and there is Shiny which is dominating the marker as far as I know.
Is there any good R web-server or R hosting out there other than Shiny to be update and maintained?

**EDIT:** I'm not looking for interactive usage of R on a server. I'm well aware of Rstudio Server but that it in interactive mode. I'm looking for:

* run R as cron job
* a way to generate HTML by R
* work with databases

basically think of it more like a PHP Apache server but in R language",R web server,3mmhhh,top
"Hi everyone,

I'm working on an analysis of my facebook messages... well.. trying to do so.  I'm having trouble parsing the html into a data.frame.  I've never really worked with html before, and although I basically get how it works, and can visually interpret the data, I'm still struggling to convert it.


The structure of the data is as follows:

    <html>
      <div class=""thread"">
        ""names of people in thread separated by commas""
        <div class=""message"">
          <div class=""message_header"">
            <span class=""user"">""Message Sender Name""</span>
            <span class=""meta"">Thursday, August 18, 2011 at 
              11:53pm PDT</span>
          </div>
        </div>
          <p>""1st Message Here""</p>
        <div class=""message"">
          <!--message info-->
    </div>
        <p>""2nd Message Here""</p>
    <!--more messages to follow-->
      </div>
      <div class=""thread"">
        <!--2nd thread here-->
      </div>
    </html>




And I'd like to just build the dataset to fit something like:


Thread Participants|Message Sender|TimeStamp|MessageContent
:--|:--|:--|:--
name1, name2|name1|...|...
name1, name2|name2|...|...

I understand that the XML library will probably do the trick, but I've been struggling with this for 2 days now, and I'm ready for some help.


FWIW there's a [python tutorial](https://www.teamleada.com/tutorials/facebook-message-analysis) for exactly this (where I got the schema), that I followed, but I'm trying to do this in a way where the next time I do html stuff, I'll know the tools a little better, and I'm just so much more comfortable in R.


And I've read the following docs from R people, without really getting very far.  Again, although I've never worked with html, I understand it in theory.  I understand the tree structure, I understand how xpath queries operate in lay man's terms.  I just can't put 2 and 2 together here.

http://www.inside-r.org/packages/cran/XML/docs/htmlTreeParse

http://www.inside-r.org/packages/cran/XML/docs/matchNamespaces

http://www.r-bloggers.com/migrating-table-oriented-web-scraping-code-to-rvest-wxpath-css-selector-examples/

http://www.omegahat.org/RSXML/Tour.pdf

http://www.omegahat.org/RSXML/shortIntro.pdf

Thanks for your help, everyone!

",Help parsing an html document,3lolnj,top
"Hi,

I've been developing visualisations at work utilising R+Shiny which are hosted on a AWS instance.

Till now I had been reliant on flat files, with a script in the background updating the data in those flat files.

I have been advised to move to utilising Databases to manage anticipated growth in data in the future.

I have concerns about performance. I am more of a data analyst, and not a programmer, so I'm unaware of the pros & cons of such an approach.

Can somebody share their experience/view point around this? Also, what DBs would be a good choice for my use case. Are things like Google BigQuery or Amazon RedShift something I should consider. Or start with something like MySQL?

Thanks for any advice.


  ",R Shiny: Flat files vs. Database?,3a9sb5,top
"Hello, I am just starting to learn and use R and wanted to do some analysis with my data. I am trying to normalize volumes of different brain regions using the intracranial volume(eTIV). In this example, my region of interest is R_CA4_DG. The formula I am using to normalize is:
 Adj = Raw - B(ICV-ICV.m)

Adj would be adjusted/normalized volume

Raw is raw volume (R_CA4_DG)

B is the slope of the linear regression line

ICV is intracranial volume (eTIV)

ICV.m is the eTIV mean of all subjects


My first step was to load csv file and attach, then I did lm() function to get the slope, which I pulled from the summary().

x <- lm(R_CA4_DG ~ eTIV)

xsum <- summary(reg)

xsum$coefficients[2]

Adj <- R_CA4_DG[1] - (xsum$coefficients[2])*(eTIV[1]-mean(eTIV[1:8])) 

Would someone mind telling me how to apply that formula to every subject under R_CA4_DG, without doing: R_CA4_DG[1] , R_CA4_DG[2], R_CA4_DG[3] ,... R_CA4_DG[8] ? 

Any great outside sources for learning this (looping??) would be appreciated as well.",very beginner R question,39ujn8,top
"I'm pretty comfortable with shiny and knitr independently. I keep hearing they work well together also, like embedded documents or downloadable reports, I guess? Does anyone have experience with this or know of any example products or resources?",Shiny + knitr,37yqcu,top
"I am using R version 3.1.2 with rstudio-server 0.98.113 on debian build 3.2.0-4-amd64 #1 SMP Debian 3.2.68-1+deb7u1 x86_64 GNU/Linux.

I often use the %dopar% operator in from the foreach package to run code in parallel. However, the only other use on the box seemingly installed a few items and suddenly %dopar% will use far more than the number of cores I am specifying and seems to load balance between all of them. The issue with this is that it doesn't actually seem to perform non-trivial tasks at all anymore.

This is an example of testing code I've been using for testing the %dopar% loop.

    library(iterators)
    library(foreach)
    library(doParallel)
    library(Parallel)
    nCores <- 4

    cl <- makeCluster(nCores)
    registerDoParallel(cl)
    trials = 100000

     x <- iris[which(iris[,5] != ""setosa""),c(1,5)]
     t2 <- system.time({
     r2 <- foreach(icount(trials), .combine=cbind) %dopar% {
     ind <- sample(100,100,replace= TRUE)
     results1 <- glm(x[ind,2]~x[ind,1],family=binomial(logit))
     coefficients(results1)
    }
    })[3]

    stopCluster(cl)
Another interesting behavior is that I can now stop R code that should be running on the slave workers where as previously I had to use a kill command to handle the workers.

I have checked the system logs and can't seem to find what's been changed so it's unclear to me exactly how to proceed. It is almost reminiscent of a change in the BLAS library but this behavior persists after recompiling R to not use the shared BLAS lib.

here is the output from lsof -p 23618 | grep 'blas\|lapack'

    R       39781 user  mem    REG               8,17  3576576     1055038 /usr/local/lib/R/lib/libRlapack.so
    R       39781 user  mem    REG               8,17   655336  1572936 /usr/lib/libblas/libblas.so.3.0
 
Output from R CMD ldd /usr/local/lib/R/bin/exec/R

    linux-vdso.so.1 (0x00007ffca59fd000)
    libR.so => /usr/local/lib/R/lib/libR.so (0x00007f15fdc30000)
    libgomp.so.1 => /usr/lib/x86_64-linux-gnu/libgomp.so.1   (0x00007f15fd9f7000)
    libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f15fd7da000)
    libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f15fd431000)
    libblas.so.3 => /usr/lib/libblas.so.3 (0x00007f15fd190000)
    libgfortran.so.3 => /usr/lib/x86_64-linux-gnu/libgfortran.so.3 (0x00007f15fce72000)
    libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f15fcb71000) 
    libquadmath.so.0 => /usr/lib/x86_64-linux-gnu/libquadmath.so.0 (0x00007f15fc933000)
    libreadline.so.6 => /lib/x86_64-linux-gnu/libreadline.so.6 (0x00007f15fc6e9000)
    liblzma.so.5 => /lib/x86_64-linux-gnu/liblzma.so.5 (0x00007f15fc4c6000)
    librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f15fc2bd000)
    libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f15fc0b9000)
    libicuuc.so.48 => /usr/lib/x86_64-linux-gnu/libicuuc.so.48 (0x00007f15fbd4a000)
    libicui18n.so.48 => /usr/lib/x86_64-linux-gnu/libicui18n.so.48 (0x00007f15fb97e000)
    /lib64/ld-linux-x86-64.so.2 (0x00007f15fe1cf000)
    libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f15fb768000)
    libtinfo.so.5 => /lib/x86_64-linux-gnu/libtinfo.so.5 (0x00007f15fb53d000) 
    libicudata.so.48 => /usr/lib/x86_64-linux-gnu/libicudata.so.48 (0x00007f15fa1cd000)
   libstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f15f9ec2000)

Is it possible to rebuild R without any shared library's? I am open to any suggestions at this point.

Thanks for your help guys!",Foreach %dopar% operator incorrectly load balancing,35ngzc,top
"Has anyone tried loading your exported Google search history into R? I'm as far a reading the files in with ""fromJSON()"". But the results are pretty ugly lists of lists of lists.

I'm working towards getting that data into a dataframe. I'll update this thread as I go. But was wondering if anyone else has attempted it.",Loading your Google search history into R,34btaz,top
"Hi everyone,

This Friday I have the opportunity to give a one hour presentation on R for financial analysis.  I assume that I am working with a group that has no real programming background.

I'm assuming that the community here has a lot more experience with teaching this than I do.  What topics would you cover/how would you budget your time?

The emphasis is on data handling and back testing so right now I have this broken up into:


1.  Introduction to the language 
2.  Logical values.
3.  Working with dataframe and xts objects.
4. Using loops, if statements, vectorization.

5.  How to pick up data from Quandl, quantmod.

Any other idea for topics to cover?

Thanks!",Teaching 1 Hour Intro to R,2wzp61,top
"I want to create a vector with 100 entries of ""Yes"" and 200 entries of ""no."" How do I do this without typing it in all manually?","How do I create a string of ""Yes""?",2svnxb,top
"There is software developed in MS access that uses excel as a platform for the user to input data as needed. Originally, linear optimization and sensitivity analysis were being performed via this method as well, but it is of course limited. R is not allowed to be installed on the end users computers either. Is there 1) a way to have access run R as the backend for analysis with inputs and outputs from excel via MS access, and 2) can this be server based so that R is only installed on the one server that the end users connect to?

thanks /Rlanguage",Question: server deployable R and communication with MS access,2rvi7n,top
"I have found a few fellow students, staff, and faculty at my university who use R and are interested in starting a user group.  Was curious if anyone else has any experience doing something like that?  
What did you do at meetings?  
How often did you meet? ","Starting an R user group at my university, any suggestions?",28mphj,top
"Hi,

I've been using Python as a data scientist for a while now, with the typical tools of the trade: numpy, pandas, scikit-learn, statsmodels, etc.

Now I'm going to start working in a new place which uses R instead of Python, and I'm looking for some pointers to quickly ramp up my R skills.

From what I read so far, R mostly looks like Python with dollar signs in place of dots (plus a few other surprising little differences). I would like to dig deeper and get highly proficient with the language - any help would be appreciated! 

**EDIT:** I am already familiar with some R basics, and I am very comfortable with vector operators (as a longtime MATLAB and numpy user). I am looking for books/online resources that will help me get the best practices, advanced topics, etc.",Getting into R from Python,25qrsz,top
"Hi Rlanguage!

I'm using R to interface with a number of other platforms to gather data.  To do so, I have to specify my user credentials for those platforms in my R script.  

What I want to do is find a way to protect my credentials so that they aren't specified as plaintext in my R code.  I need to do this in a way that still allows me to pass them to another platform to login successfully.

I'm not super well versed on infosec, but how can I use existing R packages to do this in a way where another R user can't just use that same package to do the process in reverse and obtain my plaintext password?",Protecting user credentials in R scripts,25i1b9,top
"Can anyone learn R programming without knowing
math and statistics at all?

I would like to learn R for trading financial products.",Can anyone learn R programming without...,21j0pr,top
"I am working on learning R. I have a hope of one day working on data science. I am looking for projects that will be good practice. I usually start with a tic tac toe program when learning a new language, but I don't think it will help me learn a language like R very well.  ",Learning to R,216218,top
"I'm creating dataframes for each student using our online course website. We have 375 students. 

I have a data mining and wrangling script that starts with a GET request to a website. That request is for a single user because the API only allows certain data to be collected individually. By the end of the script, the student gets a dataframe object that is named after their username.   

But I can't imagine doing this for each and every user!

Do any of you fine people know some fundamental strategies on how to automate the creation of each script?",Automate data wrangling... specifically the assigning of objects.,9bwiby,top
"I'm using dbplyr to push work into the database, rather than having my computer churn on it here.  But I am trying to get a weekdays calculation.  I know that certain things are dbplyr aware (i.e. they will be converted to a sql statement) and others are not.  I am guessing that ""weekdays"" is not a dbplyr aware command.  I was trying to add a ""%>% mutate(WEEK_DAY = weekdays(TIME_KEY))"" to a command, and it doesn't translate right.  Does anyone on this sub have familiarity with dbplyr to that level that they could help me send this over?  If not, I can collect the data and do the weekdays local, but it is 6+ gigs of data once collected.",probing for DBPLYR familiarity,9bbdax,top
"Hello R Programmer, Newbies here i want to learn about R but my background is Networking. I dont know much about coding and algorithm. Today i started with installation of R and R studio and run some basic program about adding, variables and vectors. A friend of mine said the future is Data science and AI.

Please advise me how to move forward? Any resources? What kind of projects will done in R?
",Want to learn about R,9az4t5,top
"Here is a reproducible example
library(ggplot2)
library(scales)
a <- rnorm(1000,0,1)
colnames(a) <- c(“test”)
ggplot(a,aes(test)) + geom_histogram(aes(y=(..count..)/sum(..count..))) + scale_y_continuous(labels=scales::percent) +
stat_function(fun=“dnorm”)

As you will see the distribution hits 40% instead of 4
My real numbers are around the same as rnorm. I do use the number’s mean and sd as args in stat function(the values are close to mean 0 as 1) and the distribution is way off

For other values were the mean and sd were higher (eg mean 4 sd 5) the distribution looked more normal",How to plot normal of histrogram with y as percentage,9au2m0,top
"I have a dataframe that look something like this,

    df 
    month year ID   location pin  amount
    1     12   xx1  1        1    123
    2     12   xx1  1        1    456
    3     12   xx1  1        1    789
    1     12   xx2  1        2    10123
    ...    

The data goes on for monthly amount from 2012to 2018for 5 locations and 6 pins and some 500 IDs. plotting amount against dates shows a variation of amounts across different months but similar, steady increase throughout the year. So, I am trying to get a linear regression model training sample representative enough to get a good R^2 value for one pin in a one location, so using month and year as variable. So I added a date column into df; and basically what I am looking into is this:

    training <- df[df$date >= ""2012-01-01"" & df$date <=""2017-12-01"", ]
    lm.fit <- lm(amount ~ month.sequence, data = subset(training, location == 1 & pin== 1))


but R^2 is not beyond 0.35. Any idea what is a good practice into choosing a sample size for linear regression model training dataset?
",Representative testing data for linear regression,9atxs6,top
"I am trying the predict revenue of a firm. I ran a regression on a few variables giving me :

    Returns = 239216.9 + 10705*X1 + 23.3183* X2 - .7468334*X3

Variable X3 is a one period lagged return variable. I would like to simulate two quarters out and was wondering how one would do that in R. Any help would be appreciated. Essentially I want to take the returns generated from the first simulation and then run one more...

​",Two stage simulation,999rkr,top
"Hello, sorry not  familiar to R could  you   explain me somenthing and  help me  a littlebit, please?

I  was reading  this  article  which  talks  about  Amazon stocks price   modelling using AR (autoregressive  model)

There are  some terms  I don't  understand.

This  is  the article:

[https://www.quantstart.com/articles/Autoregressive-Moving-Average-ARMA-p-q-Models-for-Time-Series-Analysis-Part-1](https://www.quantstart.com/articles/Autoregressive-Moving-Average-ARMA-p-q-Models-for-Time-Series-Analysis-Part-1)

## Simulations and Correlograms

## AR(1)

Let's begin with an AR(1) process. This is similar to a random walk, except that *α*1

does not have to equal unity. Our model is going to have *α*1=0.6

. The R code for creating this simulation is given as follows:

\> set.seed(1) > x <- w <- rnorm(100) > for (t in 2:100) x\[t\] <- 0.6\*x\[t-1\] + w\[t\] ''''

Why  did  he set  the  *α*1 = 0.6?  Based  on what?

And  what is  this coefficient?  What  does it  rapresent?  (In simple words)

**question 1:**

He goes on with the simulation:

Notice that our *for loop* is carried out from 2 to 100, not 1 to 100, as

    x[t-1]

when *t*=0 is not indexable. Similarly for higher order AR(p) processes, *t* must range from *p*

to 100 in this loop.

We can plot the realisation of this model and its associated correlogram using the layoutfunction:

\> layout(1:2) > plot(x, type=""l"") > acf(x)

The  loop ''for''   from 2  to 100..... what  is  that?  Is it  the  number of  simulations?

**Question number 2:**

(He plots the  ACF graph)

We can plot the realisation of this model and its associated correlogram using the layoutfunction:

\> layout(1:2) > plot(x, type=""l"") > acf(x)

[https://s3.amazonaws.com/quantstart/media/images/qs-tsa-armapq-ar1-plus-six-x-correlogram.png](https://s3.amazonaws.com/quantstart/media/images/qs-tsa-armapq-ar1-plus-six-x-correlogram.png)

**Realisation of AR(1) Model, with** ***α*****1=0.6**

**and Associated Correlogram**

Let's now try fitting an AR(p) process to the simulated data we've  just generated, to see if we can recover the underlying parameters. You  may recall that we carried out a similar procedure in the article on [white noise and random walks](https://www.quantstart.com/articles/White-Noise-and-Random-Walks-in-Time-Series-Analysis).

**My  question is  WHAT IS  THIS  ACF  graph?  How  to read  it?  What  does it mean  with  LAG?  What is  LAG?**

I see only  some lines....  but  what  are they?

As it turns out R provides a useful command arto fit autoregressive models. We can use this method to firstly tell us the best order *p*

of the model (as determined by the AIC above) and provide us with parameter estimates for the *αi*

, which we can then use to form confidence intervals.

For completeness, let's recreate the *x*

series:

\> set.seed(1) > x <- w <- rnorm(100) > for (t in 2:100) x\[t\] <- 0.6\*x\[t-1\] + w\[t\]

**Question number  3:**

why  do we  need  to  find out the  ''*αi*'' parameter if  we already knew it  is  0,6?",Autoregressive in R,96yxis,top
"Hello, 
I've written a script in R and using ggplot2 I've generated a series of graphs that my employer would like to put on our website.  

I'm repetitively new to this, so I'd like to get some information on what is required to make this happen before I contact our IT department.  I'm aware that I could just use R Markdown and generate an HTML document, but I'd like to take it a step further and add controls so that the users can modify the visualizations as they see fit.

In addition, once this is set up, would I be able to just refresh the dataset (a single file), in order to get new data or is there something else that I'd need to do?

Thanks for any tips! ",Posting Visualizations on the Web? What's required?,94mz3q,top
"Hi,

I'm working with a dataframe that does not include complete observations, that is to say 1700ish observations with 250ish variables and everything observation is missing at least one variable. 

I'm following the following procedure:

Define the lm() model

stepAIC()

But I am having trouble with lm() since na.omit or na.exclude will both empty out the dataframe. 

Please advise on ways to treat lm() with so much missing data, and wehater that will negatively impact the stepAIC() portion. 

Thanks! Here is a joke in return:

My social life. 


Zinnnng",lm() model in stepwise regression with no complete observations,94i8o4,top
"Hi everyone! I'm new to R and Arch Linux.

I recently started using Rmarkdown for notes. I have noticed that when I type any Korean .Rmd -> (any other formate) It will just use (???) instead of Korean. I've tried including different latex packages but still get the same result. I am using vim for editing the .Rmd files. I'm not sure if that might be the root cause. I am using this script to run it in vim

autocmd FileType rmd map <f5> :!echo<space>""require(rmarkdown);<space>render('<c-v%')""<space>\\|<sapce>R<space>--save<enter>

Due to my lack of knowledge in Linux and R, I was hoping someone could point me in the right direction",[Noob] Adding Korean in rmarkdown results in (???),93ixev,top
"As pictured, ID 01012 has two FORM 2s with a year that matches that of FORM 7 and a year that matches that of FORMs 8 and 18.

What I am trying to do is return the most recent FORMs so that I have the latest ID's information to go with the other FORMs.  I have tried filter, unique, and distinct without much luck. Any help would be awesome!

I tried: df <- df\[!duplicated(df\[c(1,3)\]),\]

but it doesn't return  the max value of the DTYvisit col. (ie returns forms 7,8,18, and the most recent form 2)

P.S.  I tried this coding and it worked --> but it dropped my form 7, which I need to keep;

df <- df %>%

group\_by(CASEID) %>%

top\_n(1, abs(DTYvisit))

https://i.redd.it/ic2bdmx9z3c11.png",Subsetting a dataframe with most recent date based on values in other columns,91slha,top
"I have a runjags script that generates predicted burrow density for every cell on an island. I’m looking to obtain multiple draws (around 100) from an mcmc object for every cell. My dissertation supervisor thinks I should be able to do this using the coda package but I’ve only been able to extract the mean value for each cell rather than multiple realisations.

Code used to run the model and extract the summary stats:

S2VS1\_best\_fit\_result <- run.jags(model=S2VS1\_best\_fit\_model, burnin=100000, sample=1000, n.chains=3, modules=""glm"", thin = 100)

S2\_result <- as.mcmc(S2VS1\_best\_fit\_result, vars = ""S2"")

S2\_result\_list <- as.mcmc.list(S2VS1\_best\_fit\_result, vars = ""S2"")

S1\_summary <- summary(S2\_result\_list)

S1\_stats <- S2\_summary$statistics

I've posted the full model on [Stackoverflow if that's any use](https://stackoverflow.com/questions/51459110/run-jags-extract-multiple-realisations-from-mcmc-object). 

Can anyone tell me how to get multiple independent values for each cell?  


Thanks in advance for any response.",Runjags - extract multiple realisations from mcmc object,90s05i,top
"I am not even a bit good in using R and i have to use it for my Bachelor-Degree. 

I just need to build a simple Graph or better 32 but i cant even get the first one to work. 

The following is what i got so far and im allways getting a ""Error: Discrete value supplied to continuous scale""

I even tried to set every collum as a foctor and even that did nothing. 

I spend 12 hours on this so far and i am stuck.

What am i missing?  


library(dplyr)

library(ggplot2)

library(gridExtra)

data1.1 <- read.table(""Fishing1\_1.txt"")

data1.2 <- read.table(""Fishing1\_2.txt"")

data1.3 <- read.table(""Fishing1\_3.txt"")

data1.4 <- read.table(""Fishing1\_4.txt"")

data2.1 <- read.table(""Fishing2\_1.txt"")

data2.2 <- read.table(""Fishing2\_2.txt"")

data2.3 <- read.table(""Fishing2\_3.txt"")

data2.4 <- read.table(""Fishing2\_4.txt"")

data3.1 <- read.table(""Fishing3\_1.txt"")

data3.2 <- read.table(""Fishing3\_2.txt"")

data3.3 <- read.table(""Fishing3\_3.txt"")

data3.4 <- read.table(""Fishing3\_4.txt"")

data4.1 <- read.table(""Fishing4\_1.txt"")

data4.2 <- read.table(""Fishing4\_2.txt"")

data4.3 <- read.table(""Fishing4\_3.txt"")

data4.4 <- read.table(""Fishing4\_4.txt"")

c <- c(""VP"", ""Trial"", ""Target Position"" , ""Guess Position"" , ""Difference"", ""Score"")

colnames(data1.1) <- c

colnames(data1.2) <- c

colnames(data1.3) <- c

colnames(data1.4) <- c

colnames(data2.1) <- c

colnames(data2.2) <- c

colnames(data2.3) <- c

colnames(data2.4) <- c

colnames(data3.1) <- c

colnames(data3.2) <- c

colnames(data3.3) <- c

colnames(data3.4) <- c

colnames(data4.1) <- c

colnames(data4.2) <- c

colnames(data4.3) <- c

colnames(data4.4) <- c

DataVP1<- rbind (data1.1, data1.2, data1.3, data1.4)

DataVP2<- rbind (data2.1, data2.2, data2.3, data2.4)

DataVP3<- rbind (data3.1, data3.2, data3.3, data3.4)

DataVP4<- rbind (data4.1, data4.2, data4.3, data4.4)

\#Transfer Pixel to a -0.5 to 0.5 scale

DataVP1$""Target Position"" <- DataVP1$""Target Position""/2560-.5

DataVP2$""Target Position"" <- DataVP2$""Target Position""/2560-.5

DataVP3$""Target Position"" <- DataVP3$""Target Position""/2560-.5

DataVP4$""Target Position"" <- DataVP4$""Target Position""/2560-.5

DataVP1$""Guess Position"" <- DataVP1$""Guess Position""/2560-.5

DataVP2$""Guess Position"" <- DataVP2$""Guess Position""/2560-.5

DataVP3$""Guess Position"" <- DataVP3$""Guess Position""/2560-.5

DataVP4$""Guess Position"" <- DataVP4$""Guess Position""/2560-.5

DataVP1$""Difference"" <- DataVP1$""Guess Position"" - DataVP1$""Target Position""

DataVP2$""Difference"" <- DataVP2$""Guess Position"" - DataVP2$""Target Position""

DataVP3$""Difference"" <- DataVP3$""Guess Position"" - DataVP3$""Target Position""

DataVP4$""Difference"" <- DataVP4$""Guess Position"" - DataVP4$""Target Position""

idx1 <- which (DataVP1$Trial<200)

idx2 <- which (DataVP2$Trial<200)

idx3 <- which (DataVP3$Trial<200)

idx4 <- which (DataVP4$Trial<200)

DataVP1 <- DataVP1\[-idx1,\]

DataVP2 <- DataVP2\[-idx2,\]

DataVP3 <- DataVP3\[-idx3,\]

DataVP4 <- DataVP4\[-idx4,\]

DataVP1$VP <- factor(DataVP1$VP)

DataVP1$Trial <- factor(DataVP1$Trial)

DataVP1$Score <- factor(DataVP1$Score)

gg <- ggplot(data=DataVP1\[1:400,\] , aes (x=""Target Position"",y= ""Guess Position"")) +

  geom\_point(colour = ""gray91"", shape=1, size=1, alpha=.4, stroke=.2) +

  geom\_smooth(method = lm, se= FALSE, colour = ""firebrick"" )+

  scale\_x\_continuous(""Target"", breaks=c(-0.5, 0, 0.5), expand = c(-.5,.5)) + 

  scale\_y\_continuous(""Guess"", breaks=c(-0.5, 0, 0.5), expand = c(-.5,.5))+

  coord\_fixed(ratio=1, xlim=c(-0.5,0.5), ylim=c(-0.5,0.5)) + 

  ggtitle(""A"") +

  theme\_bw() +

  theme(plot.title = element\_text(size = 25, face = ""bold""), axis.title = element\_text(size=20), axis.text = element\_text(size=15))

print(gg)

The Dataframe(DataVP1) looks basically like this : 

215

1

215

\-0.18023203125

\-0.158203125

0.02202890625

0

216

1

216

\-0.02453125

\-0.031250000

\-0.00671875

0

217

1

217

0.0277109375

0.039062500

0.0113515625

0

218

1

218

0.22152734375

0.239453125

0.0179257812500001

0

219

1

219

\-0.0158828125

\-0.020312500

\-0.0044296875

0

220

1

220

0.21695703125

0.197656250

\-0.01930078125

0",New to R and R-Studio and i am absolutly frustrated,90por2,top
I’m pretty new to scraping but I have successfully used rvest before although it’s not working for this.  So I was wondering if there is some trick or another package to use for scraping dynamic websites? ,How to scrape dynamic website?,8xh7x1,top
"I am often using knitr to create PDF files (R-markdown) and will use print() statements throughout my chunks. Problem is, these statements will sometimes run-off the page in the final PDF.

How can I control this? 

Thank you!",Knitr/PDF: Keeping printed text on page,8w2846,top
"Hi,

How can I approximate the Y axis line from the first value on X axis? 
[Here's a example of how the chart is now[1]](https://imgur.com/HPHJJwO) and[ how I would like it to be.[2]](https://imgur.com/dDXqMoj) 





Script for reproduce the chart: 
    
    library (ggplot2)
    
    QTD <- c(""11"",""10"",""9"",""13"",""15"",""12"",""10"")
    DATE <- c(""2018-01-01"",""2018-01-02"",""2018-01-03"",""2018-01-04"",""2018-01-05"",""2018-01-06"",""2018-01-07"")
    
    dataset <- data.frame(DATE,QTD)
    
    p<- ggplot(dataset, aes(x = DATE, y = QTD, group = 1)) + geom_line()
    
    p
 
Thanks!",Approximate Y and X axis on ggplot2,8vxfg5,top
"I have a bunch of geom_smooth() plots that are overlaid but am struggling to create a legend which labels each plot. Any ideas?


Code looks something like this:
ggplot(data=x) + geom_smooth(...) + geom_smooth(...) + ...",Showing legend with overlaid plots?,8uwmys,top
"So I have been  trying to map GTFS info in the leaflet package for R studio for a project. I have been trying many days to come up with a solution but am at a brick wall. I have code to make a map of each individual route ID but because there are almost 200 individual route ids, this is not that useful. I also have code to map things by route\_type which is what I want but that map routes are not correct and many of them are straight lines :/ I have attached my code in a word doc and some pictures. The GTFS data download link is also attached, I am using the Januard 2015 version. I have a feeling it is something with the way I am merging them or ordering them but I am really at a loss.   


    #BY ROUTE
    
    library(tidyverse)
    library(leaflet)
    
    shapes <- read.csv('kansas/shapes.txt')
    
    shapes_simplified <- shapes %>%
    
      mutate(shape_pt_lat = round(shape_pt_lat, 3),
    
             shape_pt_lon = round(shape_pt_lon, 3)) %>%
             distinct(shape_id, shape_pt_lat, shape_pt_lon)
    
    my_map <- leaflet(data = shapes_simplified) %>%
    
      addProviderTiles(""Esri.WorldTopoMap"")
    
    groups <- levels(shapes_simplified$shape_id)
    
    groupcolors <- colorFactor(palette = 'viridis', domain = groups)
    
    for(grp in groups) {
      my_map <- my_map %>%
      addPolylines(data = filter(shapes_simplified, shape_id == grp),
                   lng = ~shape_pt_lon,
                   lat = ~shape_pt_lat,
                   group = grp,
                   color = groupcolors(grp),
                   weight = 2)
    }
    

https://i.redd.it/vbn2g66cif611.png

    my_map
    
    #BY ROUTE TYPE BUT ROUTES ARE STRAIGHT LINES IN SOME CASES
shapes_simple <- shapes %>%
    
      mutate(shape_pt_lat = round(shape_pt_lat, 3),
    
             shape_pt_lon = round(shape_pt_lon, 3)) %>%
              distinct(shape_id, shape_pt_lat, shape_pt_lon, shape_pt_sequence)
    
    routes_simple <- routes %>%
      mutate(route_id, route_type, route_short_name) %>%
      distinct(route_id, route_type, route_short_name)
    
    trips_simple <- trips %>%
      mutate(trip_id, shape_id, route_id) %>%
      distinct(route_id, trip_id, shape_id, route_type, shape_pt_lat, shape_pt_lon, shape_pt_sequence)
    
    t_s_simple<- full_join(trips_simple, routes_simple, by = NULL) %>%
      mutate(trip_id, shape_id, route_id, route_type, route_short_name) %>%
      distinct(route_id, shape_id, route_type, shape_pt_lat, shape_pt_lon, shape_pt_sequence)
    
    M_MAP <- full_join(t_s_simple, shapes_simple, by = NULL) %>%
    
      distinct(route_id, shape_id, route_type, shape_pt_lat, shape_pt_lon)
    
    M_MAP[,3] <- lapply(M_MAP[,3,drop=FALSE], factor)
    
    M_MAP <- filter(M_MAP, shape_pt_lat != ""NA"")
    
    my_map <- leaflet(M_MAP) %>%
      addProviderTiles(""Esri.WorldTopoMap"")
    groups <- levels(M_MAP$route_type)
    groupcolors <- colorFactor(palette = 'viridis', domain = groups)
    
    for(grp in groups) {
      my_map <- my_map %>%
      addPolylines(data = filter(M_MAP, route_type == grp),
                   lng = ~shape_pt_lon,
                   lat = ~shape_pt_lat,
                   group = grp,
                   color = groupcolors(grp),
                   weight = 2)
    }  
    my_map %>% addLegend(""bottomright"", pal = groupcolors, values = ~groups, title = ""Legend"", opacity = 1) -> my_map
    

https://i.redd.it/b82gv9d7if611.jpg

    my_map
    
    ",Need Help with this code-GTFS Leaflet Visualization,8u4q9a,top
"When using the plot function, I want to choose the axis sizes myself. How do I do that?","plotting, choosing the x and y axis",8tv63p,top
"I have a vector of varying numbers of A, B, C, D, which I need to rearrange randomly. Is there a way to fix the values of D in place? Eg if I have ABCD I could have ABCD, ACBD, CBAD, CABD, BCAD, BACD?

The actual vectors have a length of around 100 so it isn't feasible to list all combinations like I did above or use sample and remove when they aren't in the right place.",Rearranging a vector but keeping certain values in place,8tq7j9,top
"I have pretty big dataset of 7027 observables and 65 variables with many NAs, and i want to scale the columns.

First i took minimal values and maximal values:

maxs <- apply(year, 2, max,na.rm=TRUE)

mins  <- apply(year, 2, min,na.rm=TRUE)

then i tried to scale them:

scaled <- as.data.frame(scale(year, center = mins, scale = maxs - mins))

and i got following error:  Error in scale.default(year, center = mins, scale = maxs - mins) :

length of 'center' must equal the number of columns of 'x'

but when i check : length(mins)==ncol(year)

\[1\] TRUE

Feel free to ask questions. I tried everything that came to my mind ;\_;

UPDATE ; i cleaned dataset from NAs and the problem still persist",problem with scaling values,8t0a5t,top
"Hi I’m looking to plot multiple lines onto a single plot and can’t figure out how to. I have a working code to do it by hand but considering there are like 40 specimens I’d rather not have to type out each specimen name by hand. I am looking to plot all of these specimens with the y being variable 3 and the x being variable 1, on one graph. They all have varying lengths of x.Is there a way to do this using a for loop or any other type of looping thing? I also know that some of the later specimens in this data set have a longer x value than the first one, and I’m not sure how that will change it.

The data that I want to use is formatted into a list similar to this: 
List Name

-Specimen 1

--Variable 1

--Variable 2

--Variable 3

-Specimen 2

--Variable 1

--Variable 2

--Variable 3

-Specimen 3 etc…

The working by hand code is this:
-plot(ListName$`Specimen1`$Variable1, ListName$`Specimen1`$Variable3, type = ""l"", main = ""ListName  Variable 3"", xlab= ""Year"", ylab= ""Variable 3"", col=""light green"")

-lines(ListName$`Specimen2`$Variable1, ListName$`Specimen2`$Variable3, type = ""l"", col=""light green"")

-lines(ListName $` Specimen3`$ Variable1, ListName $` Specimen3`$ Variable3, type = ""l"", col=""light green"")

Thank you in advance to anyone who looks at this!
",Plotting Multiple Lines on a Single Plot,8sea0u,top
"Hello /r/Rlanguage,

I'm new to R and I'm trying to replace all the values = 0 with a small number (e.g. .000001) to perform a log function. However, I'm struggling to find the correct code I need to do so.

I was hoping someone might see this and know the answer. I feel like it is a simple answer, but I can't seem to figure it out. 

Thank you in advance!",How can I replace all zeros with a small number?,8rvawz,top
"
I am trying to create a generalised linear model with random effect. I have a small dataset, with longitudinal data of 4 subjects during different years. The data I obtain from them is a frequency data, and for one of the subjects all of the data points are 0. So when checking the normality and the residual plots the distribution is not normal. [Residuals plot](https://i.stack.imgur.com/BifAH.png)

I tried transforming the data in different ways but the plot remains to look the same.

Is there any model or transformation I can use for this type of data, where one of the subjects shows no variability?

m=lme(Freq ~ Time, random=~ 1|Subject,  data=my_data, method='ML')

Thank you",Zero-inflated generalised linear model?,8qqgxs,top
"The idea is simple but I can't figure out how to implement it. I have a datatable with measurement values and I need to calculate a rolling average on the measurement values but since some measurement values are NA I need to keep track of how many actual measurements were used to calculate each rolling average, I want to store this information in another column inside the original datatable but I can't figure out how to do this.

>library(tidyverse)
>library(zoo)

>df <- tibble(
>  run_number = 1:100,
>  MEASUREMENT = c(runif(24, min = -1, max = 1), NA, runif(24, min = -1, max = 1),
>                  NA, runif(24, min = -1, max = 1), NA, runif(25, min = -1, max = 1))
>)

>df <- mutate(df, RUNAVG = rollapply(df$MEASUREMENT, width=8, FUN=mean, fill = >NA, align = ""right"" ))
> df$AVGSAMPLECOUNT=NA

>df <- mutate(df, AVGSAMPLECOUNT = rollapply(df$MEASUREMENT, width=8, FUN=length(!is.na()), fill = NA, align=""right""))
        

here is what I wrote so far but I am unable to pass FUN=length(!is.na()) to rollapply() is there anyway to pass composite functions to rollapply?",need to apply a rolling average to a table and track the number of NA's in the rolling avergae,8pr5gi,top
"I have a roster with start dates and end dates for team assignments.These are used to track team changes over time. I'm trying to take that and turn it into a file which will gives a list of everyone's team on a specific day. For instance if I have: 

                team.assignment <- as.data.frame(matrix(nrow = 5, ncol = 4))
                names(team.assignment) <- c(""name"", ""supervisor"", ""start.date"",""end.date"")
                team.assignment$name <- c(""John"", ""Mark"", ""John"", ""Mark"", ""Luke""                               
                team.assignment$supervisor <- c(""Matt"", ""Matt"", ""Steve"", ""Kyle"", ""Sarah"")              
                team.assignment$start.date <- c(""2016-05-02"", ""2018-02-02"", ""2017-02-12"", ""2018-04-05"", ""2018-03-14"")
                team.assignment$end.date <- c(""2017-02-01"", ""2018-04-04"", ""2018-05-30"",""2018-05-30"",""2018-05-30"" )

I want to return a dataframe with every date for every person and who they were assigned to on that day. Obviously the actual list of people is way larger so I think looping through everyone would be too slow. 

I tried this: 

                all.dates <- function(x,y){
                    z <- seq.Date(x,y,1)
                    return(z)}
                team.assignment$dates <- mapply(all.dates, as.Date(team.assignment$start.date),as.Date(team.assignement$end.date))


             
and was thinking some kind of melt but it did't work correctly with the list. Any ideas?  ",creating list of assignments for all dates between two dates,8nbpf3,top
"Hello. How would i transpose this SQL query to R ?

SELECT books.publisher, SUM(sales.sales), COUNT(books) AS ""Nr. 2015 published books""

FROM books

INNER JOIN sales ON books.ISBN=sales.ISBN

WHERE books.year = 2015

GROUP BY books.publisher

ORDER BY COUNT(books) ASC, SUM(sales.sales) DESC

LIMIT 10;

This is what I got so far,

books %>%

inner_join(sales) %>%

sum(sales) %>%

filter(year == '2015') %>%

group_by(publisher) %>%

count() %>%

top_n(10, publisher) %>%

arrange(desc(sum(sales)))

but I get the following error
Joining, by = ""isbn""
Error in FUN(X[[i]], ...) :
only defined on a data frame with all numeric variables

Stackoverflow doesn't really help me, as everything there looks like spaghetti to me.
",Problem with transposing SQL to R,8mpxoh,top
"I have a matrix of integers which can be positive and negative, and each row of the matrix is treated as a dataset. I am trying to analyze streaks of positive and negative numbers in each row of the matrix, for example to get the probability of a streak of length n appearing. I was able to do this using ""rle"" and some manipulation, however I also want to analyze the size of streaks in addition to their length, and I am unsure how to approach this.

For example, let's say I have the following matrix:

         [,1] [,2] [,3] [,4] [,5] [,6]  [,7]  [,8] [,9] [,10] [,11] [,12] [,13]
    [1,]  252  455 1364   68 2125 2400 -1514   252 2775  2064   575   242  2376
    [2,] -390 2847  976 -726 2099  233   270 -1346 1584 -1961   496  1516  2233

In row 1, the streak lengths are +6, -1, +6. In row 2, they are -1, +2, -1, +3, -1, +1, +3. I'm able to collect this data easily with rle, but I am also interested in the sums of each streak. So for row 1, I want (252+455+1364+68+2125+2400), -1514, and (252+2775+2064+575+242+2376).

It would also be nice to have all of this information in one big object I can query. Any help is appreciated.","Trying to do analysis on streaks, not sure how to approach it",8ljdqp,top
"I'm familiar with R and the tidyverse suite of packages but my experience up to now have been exclusively with files such as CSV,
Txt, etc. 

I need to analyse netCDF files obtained the European Centre for Medium-Range Weather Forecasts

What are the best packages for dealing with netCDF files? ",Beginner working with netCDF files in R,8ifpgc,top
"Are there any users that have done loops and package loading on HPC that I could correspond with about some trouble I'm having? I'm new to HPC and parallels package, and I'm having trouble getting the job to take advantage of all the cores correctly.",Help with using a package/loop on HPC R/,8gghgp,top
"Hey everyone,

I have a large dataset with 1,400 rows and 92 columns. Of those 92 columns, I'm only really interested in 4 - 5 of them.  Is there a way that I can define something like ""MyVars = (LargeDataSet, ""What I Care About"") to filter it down?

I was thinking this would allow me to more easily find correlation/significance without wading through a bunch of unnecessary stuff.

Please let me know if you need more information.  I'm rather new to R if you can't tell",Pulling out just the variables I want from a larger dataset?,8fcnom,top
"I am new to R and trying to run a [detrended fluctuation analysis](https://www.rdocumentation.org/packages/nonlinearTseries/versions/0.2.3/topics/dfa) using the [nonlinear time series package](https://www.rdocumentation.org/packages/nonlinearTseries/versions/0.2.3). 

I am able to execute the dfa() function as outlined in the [first line of the usage example](https://www.rdocumentation.org/packages/nonlinearTseries/versions/0.2.3/topics/dfa). This produces a plot of fluctuation function (Y) vs window size (X) - however, it does not give a trendline.

To get a meaningful result, I need to plot a trendline and get it's slope. Does anyone know the easiest way to accomplish this? Should I be trying to plot the output of the dfa() function and then running my own linear regression? Or is there an easier way to do it using the ""estimate""() parameter?",Help with running a detrended fluctuation analysis,8dl0te,top
"I work for a small non-profit and have picked up R to solve many of our data and reporting requirements. We have a database managed by our parent organization which we use to collect our service data. I've been download excel reports from the database and doing relatively simple data manipulation and cleaning before exporting .csv files for use in reports created in Tableau. 

Everything is running great and going smoothly, however, I'll be leaving the organization in August and no one else on staff is prepared to learn R to manage the scripts and run the workflows. I'm trying to create a solution that will allow our less computer savvy staff to generate the required .csv files so they can use them with Tableau.

In my head, I'm imagining a simple website that will allow users to upload the required .xlsx files, run the R program, and then allow users to download the .csv files generated. 

I have a few questions though. 

First, does that seems like a possible solution that is somewhat stable? 

Second, I currently know a bit of Python and am in the process of learning Django, so I'm hoping that the web server portion of this can be somewhat easily done with that language/framework. If so, are there any recommendations on how to get started with that? Specifically using R scripts in conjunction with Python/Django.

Third, are there any obvious things I'm missing that will cause this solution to be more difficult for myself or my team once I leave? I'm hoping to train an intern or my hopeful replacement on how to manage the code once it is hosted somewhere, but I'm not sure how difficult it will be to access and manipulate the files once they are hosted. 

Any ideas are greatly appreciated! ",Running R Script from a Webpage,8cyje5,top
"Putting this out there first, by no means am I competent or even vaguely adequate at R. However, I have been studying it progressively for the past 2 months and would like to know if there are any kind of competency tests I can try out to see if I am getting better with R or not. I study social sciences but I've pretty much exhausted re-analysing my data using R and I'm sure theres a ton out there to learn in order to advance my data analysis skills.


Does anyone know of any way to test my progress in R? Or, even better, does anyone know of any certifications to prove competency in R that I can study for? By no means am I good enough now, but it would give me something to work towards as well making my portfolio to get into uni look better. Thanks so much for reading!",Are there any R language competency tests?,8ce7vk,top
"I've been struggling for over a day with R, I still haven't gotten a grasp on how to accomplish my goal. ggplot bar graphs and data frames keep throwing me off.

Here is the example which I'm trying to emulate, but using my data.:

https://www.r-graph-gallery.com/288-animated-barplot-transition/

Hopefully one of you will be willing to help.

My dataset is a CSV file that looks something like this:
    
    Year,LabelOne,LabelTwo,LabelThree
    
    87-88,15160,3190,1590
    
    88-89,16530,3260,1650
    
    89-90,17050,3340,1650

I'm using 

    df <- read.table(""~/Downloads/data.csv"", header = T, sep = "","") 

But that's where I get stuck, I'm trying to make an animated bar graph, but I can't even make a static one. The idea is that each row in the dataset is one frame in the final GIF. (Lables as labels, and the values are the heights of each corresponding bar and column 1 being used as the title for each bar graph.)

For ex. Frame one should have 3 bar graphs side by side, with ""LabelOne"" having a height of 15160, ""LabelTwo"" having a height of 3190, etc. And a title of ""87-88"".",Need help extrapolating a R-Gallery example onto a simple dataset.,8bchkg,top
"How does one go about getting certification in R?
I'm asking to be able to put it on my resume for future career endeavors. If anyone has any verifiable sources that will give certification for R after taking some courses I would greatly appreciate it. I'm going to be researching it myself but wanted some perspective on anyone who has received certification either online or through another class setting.

Thanks.",Certification in R,8b9w8l,top
"I'm sure this is easy but I'm an R beginner.

I have a data set that has two variables one is continuous (# of species) and the other is categorical (pH level in low, med, and high).

I want to run shapiro wilks test on the species data for each category (i.e. shapiro wilks on species in low, med and high categories). How do I do that?",Quick easy question on performing tests on categories of data,8b2nnk,top
"Hello everyone,

I am still relatively new to R and would your support.


I want to analyze the following:


Y - Cortisol


X - Time (Within: 8 measurement points)

   - Light condition (Mixed: 2 within for some subjects, and 3 within for other subjects)

  
I realize that calculating a standard between ANOVA does not take into account the repeated measure nature of the light conditions.


I came up with this:

model1 <- lme(cortisol ~ light * time, random = ~ light | subject, data=df)

When I anova() it, I get plausible results, however they are ""worse"" than the between ANOVA I ran originally. Is this possible? I thought accounting for the within-variance could only improve the results. What am I missing?

Thank you for any help =)",Mixed Model Question,8ayvh8,top
"Hi, I had a super simple issue that made me want to get advice on how to handle something similar in the future. I had just imported a large new data set and wasn't sure what all the factors inside a column were called, but when I tried to look it up, I had no idea what I was looking for.  In that situation, it was as easy as getting more familiar with the names of objects. Once I knew I was looking for the unique factors inside a column it was easy to find, but in the future, things will be much more complex I'm sure.

My question is, how do I ask a proper question when I don't know what I'm actually looking for?",Question about how to ask questions,8aiswp,top
"Could someone please suggest simple way to convert data matrix into beautiful table in MS Word.
I'm kinda beginner but this is like biggest problem I have encountered 😔
Especially, I cannot get point of 'print'. Using xtable package doesn't let You save to docx but, f, I can't even save it to HTML the way it should look like 😕

(Sorry for such a idiot q, I'm just desperate)",Data Matrix to scientific table in MS Word,88sjgh,top
"I tried this and it's working:

df <- within(df, Name[Name == 'John Smith' & State == 'WI'] <- 'John Smith1')

However, is there a way to do it for multiple columns like I have ID numbers. and I want to add job title sales for example based on these id numbers, like whole column, how can I do it in r? Is there a way to update the column job based on id numbers? if I have 50 id numbers and I want to insert sales into job for all 50 rows. Moreover, is there a way to query columns, so let's say if column job contains sales, update industry to marketing for example. Any ideas or suggestions? is there a library that can do this? like pandas in python?","How to insert values into a column based on another columns value, conditional insert/ update.",87ur1l,top
"Hi all,

I've been trying to figure this out for a while - I have a dataframe that has GPS location data stored for about a hundred different animals(with over 400,000 entries), it looks something like this:
   

    > head(the.animals[,1:11])
    name bear_ID location_n        x       y   loc_date loc_time loc_year loc_month loc_day fix_type
    1: G001   21202        161 494000 5820000 2000-05-24 11:01:00     2000         5      24        2
    2: G001   21202        590 512000 5830000 2000-09-01 19:01:00     2000         9       1        3
    3: G001   21202        621 498000 5830000 2000-09-13 07:01:00     2000         9      13        2
    4: G001   21202         66 493000 5830000 1999-05-11 13:02:00     1999         5      11        3
    5: G001   21202         31 489000 5800000 2000-04-26 11:01:00     2000         4      26        3
    6: G001   21202         63 49000 5830000 1999-05-10 21:01:00     1999         5      10        3

... I want to subset those data with another dataframe that looks like this: 

    > head(target.animals)
    name sex                  years
    1 G008   2                   2006
    2 G040   1                   2006
    3 G074   3             2009, 2010
    4 G110   2                   2008
    5 G111   1 2008, 2012, 2013, 2014
    6 G115   2                   2011

So at the end of my operation, I will have a new dataframe that includes all rows from the first dataframe (the.animals) that belong to the appropriate animal across the years specified in the second dataframe.

I welcome any thoughts

Thanks!",Selecting rows of a dataframe efficiently,87ny5u,top
"Hello, 

I have just stated using R, I have been trying a couple things. 

I would like to make a plot like said in the title, with the contour XYZ and vector XYAM like this [one](https://imgur.com/a/4aYes) from Origin. I don't find Origin practical for this type of graph even though the result is pretty nice. I find it a pain to deal with, so this is the main reason I am heading toward using R.

I have my data and all done on R, I plotted [this](https://imgur.com/a/SQJ1H) using quiver. I don't get why some vectors are completely off. 

I can't use the filled.contour and contour because of the error with ""x and y should be increasing..."". I looked at heatmaps as an alternative at the moment. 

If you have any idea, tips, insights on this issue it would be fantastic.

Cheers,
",Plotting a contour XYZ and vector XYAM,8733km,top
"Hi,

I was assigned to write a program that simulates the game connect 4, where the user plays against my program.

I'm an intermediate programmer, so writing the code itself wasn't hard. So for a bit more of a challenge, I thought, maybe I could write a code, that learns to play connect 4, as you play more and more games. Basically using machine learning. But I dont know how hard that would be using R, if possible at all.

I was just wondering if you guys think that would be possible, and if possible, how should I get started with it?

I know there are probably better languages to do that, but I'm restrained to R here.

Thanks!

EDIT: I've never used machine learning before, so I don't know how feasible this all would be, or if it would be beyond my coding skills to begin with. Any advice is welcome",[Question] Machine learning connect 4 game,85n4ur,top
"https://www.reddit.com/r/dataisbeautiful/comments/7ol3gy/gaussian_distribution_oc/

I know R isn't the ideal software to do so, but I was wondering if it'd be possible to achieve that result using R",[Question] Is there anyway to do this in R,85gy40,top
"I'm attempting to create a heatmap of a dataframe using [ComplexHeatmap](http://bioconductor.org/packages/release/bioc/vignettes/ComplexHeatmap/inst/doc/s1.introduction.html). However, I've run into a problem where the values of the heatmap run from -1 to 1, and many are extremely close to each other, such as 0.98 and 0.99. As a result, the colors of the heatmap are useless when attempting to differentiate smaller values. 

[The heatmap can be seen here](https://i.imgur.com/dxaAMqv.png).

In the above heatmap -1 is red, 0 is white and 1 is blue.

Is it possible to better differentiate these close values in ComplexHeatmap?",Is there a way to better differentiate close values (i.e. 0.98 and 0.99) in a visualized heatmap?,855icw,top
"current code is


 ggplot(female_data, aes(x = Age, y = EPG)) + 
  geom_boxplot(fill = ""cornflowerblue"", colour = ""black"") +
  facet_wrap(~Year, nrow=1) +
  theme_bw() +  
  ggtitle(""Female comparison between age and EPG"") +
  ylab('Eggs per gram')

but no legend is coming",How do i add a legend to a boxplot in ggplot2,84omt4,top
"I am working on a project for a non-programmer. It's based off of a smallish data set but I don't want to do it in excel(ugly graphics, not customize-able, etc). What is the best way for me to share my R code, graphics, and some analysis with them? R markdown requires having R installed, correct? Is there something else similar, or is it best to pop this all in an intermediate document format like word/ markdownfile saved as a pdf? ","Best way to communicate R code,analysis, and data with someone who doesn't have R",832drb,top
"If I read in data for say computers, with each row listing out amount of ram, type of cpu, and amount of storage (say: 16, intel, 1) how could I find rows that contain both ""intel"" and 16 gb of ram? I know that table(pc$cpu) will give me the number of intel cpus but how do I apply both conditions?",how to find data that fills two conditions,82a6um,top
"So i started the book ""Building recommendation engines"" from packt and in the 2nd chapter, they build a movie recommendation thing.

  This is the CSV they provide: https://pastebin.com/FXv8gjvQ and this code: https://pastebin.com/errexiyj. 

This all works fine https://imgur.com/Pc2Aowc , but i thought it would be fun to add a friend to the data, so i did that so the CSV file looks like this: https://pastebin.com/TYa7T2N2.   
I changed this line:  
> sim_users = cor(movie_ratings[,1:6], use=""complete.obs"") 

to  
> sim_users = cor(movie_ratings[,1:7], use=""complete.obs"")

Now i keep getting the error ""In cor(movie_ratings[, 1:7], use = ""complete.obs"") :  the standard deviation is zero"".

I really can't figure out why this happens and i hope one of you can show me how to solve this.","New to R, can't understand standard deviation is zero error.",80m5o7,top
"I'm learning ggplot2, using resources like this:

http://zevross.com/blog/2014/08/04/beautiful-plotting-in-r-a-ggplot2-cheatsheet-3/

and a few others.

The trouble I'm having is putting it all together - all my preferences for the tick marks, legend, colours, etc.  The examples usually show one change at a time, not several.

I can't seem to make more than one work at a time.

For example, this works:

>create line graph of TotalTrav data

Totalplot <- ggplot(TotalTrav, aes(x=Year, y=Travelers, group=1)) +geom_line() + scale_y_continuous(labels = comma ) 

>print graph with preferred gridlines

Totalplot + theme(panel.grid.major = element_line(color = ""black"", size = 0.25), panel.grid.minor = element_line(color = ""gray"", size = 0.05))


But not this:

Totalplot <- ggplot(TotalTrav, aes(x=Year, y=Travelers, group=1)) +geom_line() + scale_y_continuous(labels = comma ) + theme(panel.grid.major = element_line(color = ""black"", size = 0.25), panel.grid.minor = element_line(color = ""gray"", size = 0.05))

I get this message:

Error in inherits(x, ""theme"") : argument ""e2"" is missing, with no default

I can't figure out what I'm doing wrong.

All help appreciated :)",ggplot2 and syntax issues (very nooby),7z9h42,top
"I've been writing some of my own R functions for a statistics course of mine, such as for calculating common distributions.

When I invoke ls(), however, there's little organization. The functions are all just ""there"".

Is there any way to group certain functions by category under ls()?",Is it possible to group custom R functions into categories/packages/groups?,7vyghr,top
Please take compare and contrast this language it's supporting packages like shiny and tidyverse with those the two softwares mentioned. ,What can I do in R that I can't do in Tableau/Power BI? What can I do in Tableau/Power BI that I can't do in R?,7vd5yj,top
"I'm creating an R package. All dependencies are installed. The source code is (as far as I can tell) correctly annotated for roxygen2. 

Within the package root, the following commands are successful:

Documenting the package works:

`> devtools::document()` 

Building the package works:

`> devtools::build()` 

Installing the package fails:

`> devtools::install()` 

    ** R
    ** data
    ** preparing package for lazy loading
    ** help
    *** installing help indices
    ** building package indices
    Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec,  : 
      line 1 did not have 18 elements
    ERROR: installing package indices failed

I'm at a loss at to why. Are there any troubleshooting tips for this? 

",Creating R package: ERROR: installing package indices failed,7um1e1,top
"Here's my code and I suspect it's slow as hell:

    # terms_vec1 = a vector containing lots of words
    # terms_vec2 = another vector containing lots of words
    matched_terms_vec <- vector()
    for(current_term in 1:length(terms_vec2)){
      term_value <- terms_vec2[current_term]
      
      if(term_value %in% terms_vec1 == TRUE){
        matched_terms_vec <- c(matched_terms_vec, term_value)
      }
    }

Can I use any of the '-apply()' functions to do this quicker? ",What would be an alternative to a for-loop here?,7tjz4g,top
I've been using TuneR which is great for reading in midi files. But not so much for writing midi files. Nor is it great for visualizing track information. Looking for something that resembles a very stripped down version of a digital audio workstation.,Any good R packages for interacting with midi files?,7t99g8,top
"Im new in the world of coding, but i have some experence on c++. But in R i don[t know where i can find a awnser for this project. I like to create a tournament with 8 teams, like A,B,C...H. The tournament is like a Quarter-finals of the World cup( The teams will be divide in two separate sides, with four teams each (live A, B, G,H) and (C,D E,F). Then we have 2 matchs, for exemple (A x G) and (B x H). The winner of mach 1 plays against the winner of mach 2. ). I wanna give each team some probability of ""winning"" the match, and i like to repeat the process like 100 times. Someone knows where i can find a material to learn how to make thism or at lest the name of this progran?",Help on a project,7ss9a8,top
"So I was trying to create an R shiny app which, upon uploading two files (a raster and a shapefile) it would execute a source script and output a couple of results. To be more specific, for example, I want to do the following

    ras=brick(readline())
    poli=readOGR(readline())
    poli@proj4string=CRS(""+init=epsg:2100"")
    plot(ras)
    plot(poli, add=T)

And as until this point I've written this with Shiny

UI:
    library(shiny)
    library(raster)

    shinyUI(pageWithSidebar(
  
      headerPanel(""Header1""),
  
      sidebarPanel(
        fileInput('layer', 'Choose Layer', multiple=FALSE, accept='tif'),
        fileInput('shp','Choose shp', multiple=T, accept='.shp'))
      ),
  
      mainPanel(
       plotOutput(""mapPlot""), 
       plotOutput(""shapefile"")
     )
    )

Server:
library(shiny)
library(raster)
library(maptools)

    shinyServer(function(input, input2, output, output2){
  
      output$mapPlot <- renderPlot({
    
        inFile <- input$layer
    
        if (is.null(inFile))
          return(NULL)
    
        data <- brick(inFile)
    
        plot(data)
        })
    
        output$shapefile 
        renderPlot({
      
          inFile2 <-input$shp
          if (is.null(inFile2))
            return(NULL)
          data2 <- readOGR(inFile2)
          plot(data2)
      })
  
  
    })

and I get the following line:

**Error : unused argument (mainPanel(plotOutput(""mapPlot""), plotOutput(""shapefile"")))**


Is there something that I do wrong?

**UPDATE** So, I dubbuged my code and I am quite sure that now I have a problem using the wrong inputs, but fear not, I will solve that as well.

Here is the code:

UI

    library(shiny)
    library(raster)
    library(rgdal)
    shinyUI(fluidPage(pageWithSidebar(
     headerPanel(""Header1""),
     sidebarPanel(
        fileInput('layer', 'Choose Layer', multiple=FALSE, accept='asc'),
        fileInput('shp','Choose shp', multiple=T, accept='.shp')),
     mainPanel(
        plotOutput(""mapPlot""),
        plotOutput(""shapefile"")
      )
    )))


Server

    library(shiny)
    library(raster)
    library(rgdal)
    options(shiny.maxRequestSize = 30*1024^2)
    shinyServer(function(input,output,session){

      inFile<-input$layer
      if (is.null(inFile)){
        return(NULL)}
      data <- brick(inFile)
  
      inFile2 <-input$shp
      if (is.null(inFile2)){
        return(NULL)}
      data2 <- readOGR(inFile2)
  
      output$mapPlot<-renderPlot({
        plot(data)})
    
       output$shapefile<-renderPlot({plot(data2)})
  
  
    })",Working with R Shiny for the first time,7ryroq,top
"Hello everyone!
My goal is to create a random football fantasy league schedule, given 8 teams. Every 7 matches the calendar is repeated, for a total of 35 games. 
Our fantasy league is based in 4 direct matches between two teams each round , and depending on the points made you can score 0,1,2,3 or more goals. Who scores the most goals in that round between the two wins; each win is worth 3 points, each draw 1 point, each defeat 0 points.

As you can see, the randomness is given by the fact that with different schedules you can win, draw or lose certain games (depending on the opponent encountered on that day).

I already have data on goals scored by all teams, divided into ordered vectors, so my aim is to create a calendar in which the teams are randomly matched, and given the goals made in every round see the new ranking. I am interested both in the single simulation, that in the average ranking after a lot of simulations.
At first I thought that the best team turned out to be simply the one that scored the most total goals, but then I noticed teams that score many goals on some days (the average goals scored are 2, there are those who do 6 in a single game) and many few in the others.



How can I simply manage to do this with R?

P.S. I know that this question is not really useful, it is just a silly curiosity!",Football fantasy league schedule in R,7qe2jf,top
"Some of my R code is infuriating me - I'm attempting to select words out of a large column of words and store them in a vector, but they are somehow becoming numbers by the time I'm finished looping and print out the vector's contents. 

Here's the relevant bit of code:

    # Function definition
    find_terms_for_current_prefix <- function(DF, prefix_to_match){
    vec_matched_terms <- vector()
    vec_matched_freqs <- vector()
    prefix_length <- nchar(prefix_to_match)
  
   
    # Scan through current data frame of terms and their frequencies:

    for(i in 1:nrow(DF)){
    # Determine the start of the current term in the data frame:
    current_prefix <- substr(DF[i, 1], 1, prefix_length)
    
    # If the start of the current term in the data frame matches the prefix:
    if(current_prefix == prefix_to_match){
      vec_matched_terms <- c(vec_matched_terms, DF[i, 1]) 
      vec_matched_freqs <- c(vec_matched_freqs, DF[i, 2]) 

      print(paste(""^^^ PREFIX MATCHED TO A TERM!!!!!: "", DF[i, 1]))
    }
    }

    print(""inside find_terms_for_current_prefix: head(vec_matched_terms):"")
    print(head(vec_matched_terms))
    
    df_prefix <- data.frame()
    df_prefix <- cbind(vec_matched_terms, vec_matched_freqs)

    df_prefix  
    }


The important part is inside the if-statement:

    print(paste(""^^^ PREFIX MATCHED TO A TERM!!!!!: "", DF[i, 1]))

That line of code prints out the word I'd expect to see - right after it has supposedly been added to vec_matched_terms. However, immediately after that for-loop, when I do

        print(head(vec_matched_terms))

I find that vec_matched_terms contains numbers rather than the expected words. Numbers that do not exist anywhere in the column of words.

What's even more maddening is that this doesn't happen if I pass a different data frame (one that the current one is a subset of) to this function.

What is going on here? ",Words inexplicably becoming numbers and causing problems?,7oe7cc,top
"I'm a SAS user trying to use R.

In SAS, a PROC SUMMARY will calculate the subtotal for every combination of classification variables, (including the grand total). The NWAY option can also limit the size of combinations. For example, I can output all combinations of 3 variables among 14 total variables, and sum something. Is there a similar function in R ?

Thanks.",Equivalent to SAS Proc Summary (i.e. subtotals for all combinations) ?,7madmo,top
"I am a R self-learner and have grasped the basic syntaxes of R.
I learn via visiting various online R tutorial website and youtube channel. The teachings are excellent but not so complete in coverage. 

I want to gain a more in-depth learning on R.

Is there any more advanced R websites or ebook ( preferably a free one ) you can recommend? 

Thanks!

",Request for good R self-learning resources,7ln44w,top
"I want to get to an advanced level of skill in R. Right now I'd say I'm intermediate. I also want to add some cool projects that would look impressive on my resume.

However, I can't find or think of any project to do, even though I am aware of numerous databases on the internet. Any ideas on how I can even begin thinking about something like this? Any other words of advice?

Thanks",How can I figure out an R project to do?,7li3ls,top
I'm coming back to R after years of working in SAS where memory management isn't as much of an issue. Is there a preferred method like processing data in chunks or is there a package that handles bigger than memory data well? ,What's the current best practice for dealing with data too big to fit in memory?,7l71r7,top
"I've created a t-SNE plot of the top 10,000 subreddits from reddit data extracted for January of this year. [The plot can be seen here](https://i.imgur.com/ssKtRbj.png).

t-SNE was performed using the tsne() function from the package ""tsne"", and I plotted the returned result with the base function plot(). This plot is good because you can see that there are distinct clusters of subreddits found in the data. However, as I have it now, that's really all one can take away from this graph, there is no way to see what sorts of subreddits comprise each cluster.

My first idea was to color code each point according to some predefined labeling system which would be independent from each cluster. However, I'm not sure how to implement this, so I'm not actively pursuing this idea.

My second idea, which I feel is much more doable, is to present the data in an interactive way. I think it would be cool to be able to hover a point to see a description of the subreddit's name and maybe some other cool characteristics like the number of comments in that subreddit. However, I don't have any experience working with such a package.

Does a package exist which allows interactive plotting? Would this be a good way to visualize my data?",Interactive plotting for t-SNE?,7hsj7a,top
"I have some C code in my R package which I place into `/src`. It compiles correctly and works. 

Following the tutorial on creating R packages http://r-pkgs.had.co.nz/src.html#src

and how to execute C functions via `.Call()`.

The shared object `sharedobj.so` is created upon compilation of the C code. It is located here: 

    /my/path/to/package/src/build/haredobj.so

So, I would like to test the function in R using `.Call()`. Within R, I run  the following


    > dyn.load(""/my/path/to/package/src/build/haredobj.so"")

which outputs the error: 

    Error in dyn.load(""/my/path/to/package/src/build/haredobj.so"") : 
      unable to load shared object '/my/path/to/package/src/build/haredobj.so':
      /my/path/to/package/src/build/haredobj.so: cannot dynamically load executable

So that doesn't work. I then try `library.dynam()`:

    > library.dynam(""haredobj.so"", package=""AwesomePackage"", lib.loc = ""/my/path/to/package/src/build/"")
    Error in find.package(package, lib.loc, verbose = verbose) : 
      there is no package called ‘AwesomePackage’

That's odd, because I can load `library(AwesomePackage)` and execute commands. 

What am I doing wrong?

",dyn.load() and library.dynam() error for compiled C in R package: cannot dynamically load executable,7g9s6u,top
"I'm undertaking some R tutorials and learning Booleans and Loops (if, else, for) but it's so difficult to just try and comprehend the right coding to do a problem like:

""find the mean of the democratic vote count of the years 2004 and 2008 in each county of Georgia from the pres dataset.""

I'm driving myself insane trying to do this, I'm even trying to dissect it on pen and paper, but it's making things to much harder to try and understand what set of code will unlock the answers.

Perhaps I am thinking about coding wrong? Perhaps I am dissecting the question incorrectly?
Perhaps I dont fully understand when I use for, if, parenthesis and brackets?

Is there a chance I can learn this well, or am I doomed to be completely overwhelmed by it all? ",Why is learning to code so difficult?,7f5axk,top
"I am trying to standardize data into 8 characters like this 42XX0001. My data is a mix of 42XX01, 42XX855, and 42XX4444. I need to insert 0's  after the 42XX to get a total length of 8 characters. Sample data below.

    spatdat<-data.frame(""ID""=c(""42XX234"", ""42XX01"", ""42XX1"", ""42XX34"", ""42XX0234"", ""42XX1222"",""42XX45""), ""Value""=runif(7, min=0, max=100))",Standardizing data: Inserting characters into a character string.,7domvm,top
"Hi, I am creating a small Rshiny app that reads in a csv file, does some simple processing of the data in the file then returns the results as a csv file with the same name as the user submitted file. But I cannot figure out how the downloadHandler function works. Can someone tell me what am I doing wrong in this code

    library(shiny)
    
    doprocessing <- function(wb){
      #some code here to modify wb
      return(wb)
    }
    
    ui <- fluidPage(
      fileInput(inputId =""file"", label = ""Input a file"", multiple=F,
                buttonLabel=""Browse"", placeholder = ""No file selected""),
      actionButton(inputId = ""submit"", label = ""submit""),
      downloadButton(outputId = ""outfile"", label = "" retrieve file"")
    )
    
    server <- function(input, output, session)
    {
      worksheet <- reactiveValues()
      observeEvent(input$submit,
                   {
                     worksheet$wb <- read.csv(input$file$datapath, stringsAsFactors = F)
                     worksheet$newwb <- isolate(doprocessing(worksheet$wb))
                   })
    
      output$outfile <- downloadHandler(filename = function() {input$file$name},
                      content = function(file){write.csv(file, input$file$datapath)},
                     contentType = input$file$type)
      }
    
    shinyApp(ui = ui, server = server)                                                                        ",(Rshiny) downloadButton/downloadHandler help,7dg608,top
I have 2 separate and different size dataframes that I want to combine so that I can write them on the same excel worksheet. Is there a quick and easy way to do this without coercing the dataframes to be the same size and merging that way?,merging 2 different sized data frames for presentation,7dcgu1,top
"I'm currently creating an R package, and my scripts require before any analysis is done that 3-4 text files be loaded. Normally, I would run the scripts with the following:

    library(data.table)
    session_data = read.table(""/path/name/to/filename.txt"")

and then refer to `session_data` throughout the analysis. 

However, in order to release this as an R package, I believe that these files must be downloaded at the time on the package installation. 

(1) Normally, how are text files distributed in R packages? Are these gzipped? Where are they placed? 

According to http://r-pkgs.had.co.nz/data.html, all .text files should be `inst/extdata` I guess. However, it's not clear to me how to ""link"" to this data within the R package. Also, users would be able to access these text files, which I'm not sure is really necessary or desired. 

How have other packages dealt with this? (Is there a size limit?)

(2) In this case, should the function loading the text file be executed about loading the R library, `library(package_name)`? Is there more appropriate option? 

",How to release an R package with several text files?,7ag8au,top
"

I have some data, and I wanted to make a post with some code that someone else
would be able to run... But I've no idea how to go about that. Obviously sending
the whole dataset around is quite clumsy.


I have a dataset that has around 5500 rows in it, so I wanted to extract say 5
elements in order to ask a question about them.

I've tried to use this post :

https://stackoverflow.com/a/5963610/3130747


# So

Here is the `head` of the vector that I'm currently interested in

    > head(acd$Date)
    [1] 9/17/1908  7/12/1912  8/6/1913   9/9/1913   10/17/1913 3/5/1915
    5100 Levels: 10/10/1933 10/10/1938 10/10/1944 10/10/1946 10/10/1955 ... 9/9/2005
    >

I want to get the first 5 elements so that I can put them in a script, and ask
some questions.


Using the instruction from that stack post :

    a = dput(droplevels(head(acd$Date,5)))


Then I have `a`

    > a = dput(droplevels(head(acd$Date,5)))
    structure(c(4L, 2L, 3L, 5L, 1L), .Label = c(""10/17/1913"", ""7/12/1912"",
    ""8/6/1913"", ""9/17/1908"", ""9/9/1913""), class = ""factor"")
    > a
    [1] 9/17/1908  7/12/1912  8/6/1913   9/9/1913   10/17/1913
    Levels: 10/17/1913 7/12/1912 8/6/1913 9/17/1908 9/9/1913

So these elements should be identical to those of the original vector shouldn't
they?

Yet when I test for equality I have the following

    > a[1] == acd$Date[1]
    Error in Ops.factor(a[1], acd$Date[1]) :
      level sets of factors are different

Some type checking :

    > typeof(acd$Date)
    [1] ""integer""
    > typeof(acd$Date[1])
    [1] ""integer""
    > typeof(a)
    [1] ""integer""
    > typeof(a[1])
    [1] ""integer""



*******************************************************************************

If anyone could help with this I'd be really grateful, as I can't even ask a
meaningful question at the moment.

Thanks


### Note

I originally made [this post](https://i.imgur.com/9EwAP7r.png) and deleted it (
there hadn't been any response) as I thought that I could be more specific.

",Please can someone help me to actually make a post with reproducible code?,799pw0,top
"My objective is to include country info in a csv that has only coordinates of over 1,200 entries. Can I achieve this through R? Thank you in advance",Is there a way I can include Country info in a database file through R?,78yr4o,top
"Hey there, hopefully this is the right place to post. I'm trying to install R on Linux but have been unable to. Every time I attempt *sudo apt-get install r-base-dev* I get the following:
    
    Reading package lists... Done
    Building dependency tree       
    Reading state information... Done
    Some packages could not be installed. This may mean that you have
    requested an impossible situation or if you are using the unstable
    distribution that some required packages have not yet been created
    or been moved out of Incoming.
    The following information may help to resolve the situation:
    
    The following packages have unmet dependencies:
     r-base : Depends: r-base-core (>= 3.4.2-1xenial1) but 3.2.3-4 is to be installed
              Depends: r-recommended (= 3.4.2-1xenial1) but it is not going to be installed
              Recommends: r-base-html but it is not going to be installed
    E: Unable to correct problems, you have held broken packages.

I've gone through a couple installation tutorials but they all seem to be the same. Here's the path I've taken to install:

    $ sudo sh -c 'echo ""deb http://cran.rstudio.com/bin/linux/ubuntu xenial/"" >> /etc/apt/sources.list'
    $ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E084DAB9
    $ sudo apt-get update
    $ sudo apt-get install r-base-dev

To preemptively answer some questions:

* Yes, I am running xenial

* Yes, the xenial repository has been added to /etc/apt/sources.line

* This error happens when I try to install r-base and r-base-dev, but *not* r-base-core. That seems to have installed correctly (*r-base-core is already the newest version (3.2.3-4*)

* I've tried multiple mirrors from the R site 

* When I attempt *sudo apt-get install r-recommended*, I get the same error but with the following line added `Depends: r-cran-boot (>=1.2.19) but it is not going to be installed`
    
* When I try *sudo apt-get install r-cran-boot*, I get the same error with only the r-base-core line

* I have also tried `sudo add-apt-repository ppa:marutter/rrutter` per a couple forum posts I saw, but to no avail

Thanks for your help.","Unable to install R on linux: ""Depends: r-base-core (>= 3.4.2-1xenial1) but 3.2.3-4 is to be installed""",78x78p,top
"Hello,
I am trying to estimate 4 unknown parameters in R with the Maximum Likelihood Estimator.

My probability density function is actually:

    h <- exp(- the * x) * (x^(gam / del - 1) / (lam * del)^(1 / del)) * 
    mlf(-(1 - lam * del * the^gam) * x^gam / (lam * del), gam, gam / del, 1 / del)
where mlf is the Mittag Leffler function (you need MittagLeffleR package)


So i wrote this code in R (yvec is the vector of observations):

    x=yvec

    LL <- function(the,gam,del,lam){
  
    h <- exp(- the * x) * (x^(gam / del - 1) / (lam * del)^(1 / del)) * 
    mlf(-(1 - lam * del * the^gam) * x^gam / (lam * del), gam, gam / del, 1 / del)
    #
    -sum(log(h))}

    library(stats4)
    mle(LL, start=list(the=2,gam=0.1,del=1,lam=2))

But what i got is:

    ""Error in optim(start, f, method = method, hessian = TRUE, ...) : 
    initial value in 'vmmin' is not finite""


Maybe is because i have not fully understood wich are the values of the parameters that i have to put into mle()

Where am i wrong?

Thanks a lot for the reading",optimization with R,77lxp7,top
"Sorry if this is a stupid question. I tried googling it but couldn't find an answer.

I need to calculate the population standard deviation of my population. I believe sd() calculates sample standard deviation. Is there a formula to directly calculate population in standard deviation? I was just planning on working backwards from sample sd, but I figured there was a straight way on R. ",Calculating Population Standard Deviation?,75hzpt,top
"Just curious if anyone has come across a good resource for more robust, aesthetic, shiny apps?",Best Guide For Advanced Shiny Development?,75aprf,top
"head of my df looks like this:
 
     MONTH AIRLINE ARRIVAL_DELAY
         1      NK            25
         1      NK            43
         1      HA            15
         1      B6            20
         1      B6            85
         1      B6            89

I previously used the table function to create a new df that was a frequency counted for all ARRIVAL_DELAY's.
Now I want to do the same thing but grouped by each airline. Sorry, I'm kind of an R noob, trying to practice my DF manipulation and DPLYR skills.",Having trouble figuring out how to count the frequency of a numeric string grouped by a factor of another string in my df,732a5g,top
"Today, data scientists are generally divided among two languages  —  **R** and **Python**.

**What is the best way to integrate both languages in one data science project? What are the best practices?**

Beside git and shell scripting additional tools are developed to facilitate the development of predictive model in a multi-language environments. For fast data exchange between R and Python let’s use binary data file format **Feather**. Another language agnostic tool **DVC** can make the research reproducible  —  let’s use DVC to orchestrate R and Python code instead of a regular shell scripts: **[Best practices of orchestrating Python and R code in ML projects](https://blog.dataversioncontrol.com/best-practices-of-orchestrating-python-and-r-code-in-ml-projects-f28f3a879484)**
",Best practices of orchestrating Python and R code in ML projects,72nh2n,top
"Completely new to R programming and Shiny, I've created some very basic reactive tables and wanted to try graphs. However, the examples I found pull data from some other source. I wanted to allow the user to input their own X and Y coordinates onto a scatter plot. Would the syntax be similar to a reactive table?",Help with User Inputted Graphs,71vxun,top
"I'm trying to create an HTML file using rmarkdown, but the HTML is not displaying the results I'm expecting.

I AM NOT USING THE IDE.

I have installed the following successfully:

    install.packages(""rmarkdown"")

    library(""rmarkdown"")

    install.packages(""knitr"")

    library(""knitr"")

I have also installed Pandoc.
Was getting this error: ""Error: pandoc version 1.12.3 or higher is required and was not found (see the help page rmarkdown::pandoc_available).""

1) installed Pandoc
2) found the folder Pandoc was installed in
3) used command
    Sys.setenv(RSTUDIO_PANDOC=""c:/Users/user_me/AppData/Local/Pandoc"")

I'm using 
    rmarkdown::render(""c:/Users/me_user/Desktop/RScripts/RMD Files/my_rmd_document.txt"")

to render the HTML.

I'm using a copy of this RMarkdown document as ""my_rmd_document.txt"".

http://rmarkdown.rstudio.com/demos/1-example.Rmd

from this page

http://rmarkdown.rstudio.com/lesson-2.html

The only changes I've made are to replace the lines referencing the image command with

    plot(0,1)

and

    image(volcano)

and added the following section:


```{r}
dim(iris)
```

Here are the issues:

This

{r include = FALSE} library(viridis)

is displayed in the web browser.

The code for the plot, image, and dim commands displays and looks like code, but doesn't display results.  The code doesn't seem to run.  I don't get the plot, the image, or the results from the dim command.

If anyone has any ideas I would really appreciate it.

Thank you
",RMarkdown,70wt4g,top
"As the title, I can't find a library to create curses interface in R. Does something of this kind exists?

",Is there a ncurses interface for R?,6z7jmg,top
"Background: I'm an R rookie doing some GIS-related work which requires reducing the number of locations on my map based on latitude/longitude clustering. Normally I'd just use a simple rounding technique to cluster sites in a square lattice, but this leads to maps looking very ""blocky"" so instead I'm trying to use R's [hexbin](https://cran.r-project.org/web/packages/hexbin/hexbin.pdf) class to create a hexagonal lattice.

I run the following code to create a hexbin S4 (?) object:
    hbin <- hexbin (SiteData1$X, SiteData1$Y, xbins = 100)

I can then plot this using:
    plot(hbin)

...and can get cell coordinates using:
    cells<-hcell2xy(hbin)

However what I really need is to determine cell membership, i.e. which original locations now belong to each cell. I'm quite new to R and struggling to get that info out of the hexbin S4 object!

Any help is much appreciated :)",Hexbin for location clustering,6us9yx,top
"I have a vector of about 1.3 million strings.  Each string is 9 letters long, each letter corresponds to one of the 20 amino acids.

I want to change each amino acid letter into a corresponding number so that I can then do math using each amino acid (I have stuff that evaluates the peptides for their specificity to certain kinases).

So I have a bunch of peptides as letters, so my vector of ""Lettered Peptides"" might look like this

""A"" ""A"" ""A"" ""A"" ""Y"" ""A"" ""A"" ""A"" ""A""  
""A"" ""A"" ""A"" ""A"" ""Y"" ""A"" ""A"" ""A"" ""C""

And so on and so forth. 
And I want to change that so that each amino acid is replaced with a number, so all those As would be replaced with something like 1.8, the Ys would be 500, the Cs would be 1.2 etc etc.

For now my solution has been something like this:  
NumeratedPeptides<-sapply(LetteredPeptides, function(y) gsub(""A"",A,y,perl = TRUE))

That replaces all the ""A"" amino acids with the value that I have assigned to the amino acid A.  I then have another 19 sapply(gsub) lines to replace the 19 other amino acids with the value I have assigned to them.  

I use sapply and gsub with perl=TRUE because during a google search, I saw a Stack Overflow thread implying that gsub with perl=TRUE is the fastest way of doing this kind of thing (thread here:https://stackoverflow.com/questions/29273928/faster-approach-than-gsub-in-r)  

My problem is that currently it takes about 40 minutes to replace the letters with numbers in all 1.3 million of my peptides.  And that's BEFORE I've done any math to the peptides, all I'm doing is replacing letters with numbers.  That's a very long time and I might have to do this with 20^9 different peptide sequences (each of the 9 positions in the peptide can have one of 20 different amino acids), so I'm looking at how I can speed this up.

So is there a faster way than the way I'm doing it now?

I'm still new to R so if I've made some rookie mistakes please tell me.",Is there anything faster than gsub with perl=TRUE for replacing letters with corresponding numbers?,6u4dan,top
"I am trying to sort txt files into two batches depending on if their name contains ""YES"" or not. How could this be made possible?",Sorting files by name,6s66r3,top
"Hi I was working with some binary data that I need manipulated 

They are yes/no and I want to change them to 1/0 there's 100+ columns I need to change 

Is there a way to change them based on column index instead of column name as that's the only method I've found so far 

Thanks in advance ",Noob question,6rtnxa,top
"Hi,

I have a data set of about 6,700 data points over time (~10 hours).
I was wondering if I could get someone to make a video for me, showing me how to import the csv (my data is in excel now), create a time vs unit plot, and animate that plot with code in R. I'm not really wanting the animation to display a scatter plot graph but rather just a blip/circle that grows/shrinks as the time progresses through the data.

Just contact me first if you're interested. i'll give you $ for your time/video but we will have to chat first to get on the same page.

thanks..   contact me: p.russom16 @ g _m a i l",R csv animation video for $,6rq1dp,top
"Whenever I start R or Rstudio, I get this error: 

    Error: 1:6: unexpected '/'
    1: http:/
             ^    

It hasn't negatively affected anything so far as I can tell. But I can't figure out why I'm getting it. Anyone have any ideas? ",Unexpected symbol error on startup?,6qcso7,top
"The [vignette](https://cran.r-project.org/web/packages/rlang/vignettes/tidy-evaluation.html) is like, kinda helpful, but I think I need someone to really dumb it down, lol.",Can someone please ELI5 tidyeval and how I can start using it in my own functions?,6pshi4,top
"I wanted to know if there is a way to execute R code inside a shell script, because I am using GRASS commands in the same shell script. If there is a way, can you help me how? ",R shell script,6p8a8q,top
"Hello,

I am trying to scrape the information from the Illinois Report Card with R: https://www.illinoisreportcard.com/ListSchools.aspx

Would love some help. I tried the rvest package but am not sure if that's where to start.

Thanks!",[Help] Scraping an .aspx site with R,6o3bea,top
"I have been looking into Prophet and tried scouring a few other sites to try to find the best possible way to do what I need, but I'm a bit stuck right now.

I need to create a revenue forecast model, but would like to designate what the input variables/levers that will affect it are. 

What I (think) I would like to go is have multiple items roll up - so in our sales funnel we have the various stages and I want a projection from that stage through the end of the funnel, and when it moves to the next stage it now becomes a part of that forecast (if that makes sense).

Can anyone point me in the right direction for a way to input saying: 

- here are the key dates of our funnel
- here are the key customer profile datapoints
- here is the final revenue number.

Thanks in advance.",Help Forecasting Multistage Funnel,6ntlwn,top
"I have the following R data.table

    library(data.table)
    DT <- fread('unique_point biased    data_points   team   groupID                                                                                                           
     up1          FALSE     3             1      xy28352                                                                                                                 
     up1          TRUE      4             22     xy28352                                                                                                                 
     up2          FALSE     1             4      xy28352                                                                                                                  
     up2          TRUE      0             3      xy28352                                                                                                                  
     up3          FALSE     12            5      xy28352                                                                                                                 
     up3          TRUE      35            7      xy28352')

Printed is as follows:

    DT
        unique_point biased    data_points   team   groupID                                                                                                           
     1: up1          FALSE     3             1      xy28352                                                                                                                 
     2: up1          TRUE      4             22     xy28352                                                                                                                 
     3: up2          FALSE     1             4      xy28352                                                                                                                  
     4: up2          TRUE      0             3      xy28352                                                                                                                  
     5: up3          FALSE     12            5      xy28352                                                                                                                 
     6: up3          TRUE      35            7      xy28352 
     ....  

At the moment, each `unique_point` has two rows, with a `biased` value `TRUE` and `FALSE`. I would like to expand `DT` such that there are 6 rows for each `unique_point` in the following format:


        unique_point biased    type    data_points   team   groupID                                                                                                           
     1: up1          FALSE     A       3             1      xy28352                                                                                                                 
     2: up1          TRUE      A       4             22     xy28352                                                                                                                 
     3: up1          FALSE     B       0             1      xy28352                                                                                                                  
     4: up1          TRUE      B       0             22     xy28352                                                                                                                  
     5: up1          FALSE     C       0             1      xy28352                                                                                                                 
     6: up1          TRUE      C       0             22     xy28352 
     7: up2          FALSE     A       1             4      xy28352
     ...

That is, for each unique point, there would be a FALSE/TRUE with A, B, and C. 

I began with the following code:

    > DT2 <- DT[, .SD[CJ(type=c(""A"", ""B"", ""C""), biased = biased, unique = TRUE), 
                    on = .(biased, type)], by = .(unique_point)][]     

I get the following error

                                                                                                                                                                                                                            
    Error in `[.data.table`(.SD, CJ(variants = c(""SNP"", ""INS"", ""DEL""), fused = fused,  :                                                                                                                                                                                                                                                                                   
       Column(s) [variants] not found in x   

 

So, I used the following hack to create a new column in `DT` named `type`, with at least these three unique values:


    DT$type[2] = ""A""
    DT$type[4] = ""B""
    DT$type[6] = ""C""

The above code then works...kind of. It looks like the dimensions are all wrong though. 

What is the correct way to expand `DT` via the `type` categories `A`, `B`, `C` ?",Expand an R data.table by rows via column not in that data.table?,6npfig,top
"After seeing the stats about how much faster `library(odbc)` is than `library(RODBC)`, I set out to connect to my workplace's MS SQL Server using FreeTDS. Of course, I'm open to using other drivers or whatever, as long as it works.

If you were able to set up FreeTDS + DBI + odbc, please for the love of god help me.

Every time I try ""ODBC Driver 13 for SQL Server"" it crashes RStudio. ",Has anyone been able to set up a FreeTDS ODBC connection using the DBI/`odbc` combo?,6nhofq,top
I could get the PC scores and loading using logisticPCA from the logisticPCA package(https://cran.r-project.org/web/packages/logisticPCA/logisticPCA.pdf). But I can't find a way to extract either the eigenvalues or explained variation captured by each PC. ,How to get the amount of variance explained by each of the principle components of logistic PCA ?,6n95uo,top
"Hi, 
Might be a stupid question, but I am trying out the forecasting. I have read a lot about testing the accuracy of model using training and testing sets. Let's say I have data set of 30 months 01/15 - 06/17

My question is: After seeing that the model fitted on training set (e.g. 24 months 2015-2016) performs well against the test set (6 months 2017) should I refit the well performing model like

    refit <- tbats(complete_data, model = fit)

Or just use the old model?
All the tutorials just told it is important to test the model but no real example what to do after that ",Forecasting with same model,6n91n6,top
"Hello

Here is my very beginner level R code:

	x<-read.table(text=""date,value
	2017-01-01,4
	2017-01-02,1
	2017-01-03,1
	2017-01-07,5
	2017-01-13,22
	2017-01-22,33
	2017-02-10,41
	2017-02-11,31
	2017-02-12,2
	2017-03-13,3"", sep="","", header=TRUE)
	plot(x)

This produces http://i.imgur.com/gXHd6IB.png

How can I make it understand the dates and render them on the x-axis relative to the value of the date? i.e dates `2017-01-01` and `2017-01-02`should be very close to each other but there should be a gap between `2017-02-12` and `2017-03-13`.

thanks",how to position dates in the correct place on x axis,6n7utl,top
"Hello.

Im stuck at this project where I need to process images using R, specifically the RYGCBM channels (Red, Yellows, Greens, Cyans, Blues and Magentas).
I produce the effect I need in the images by using Image->Adjustments->Black & White in Photoshop CC but I can't find any package who let me do the same in R.

The purpose of using R is automation of the process.",Editing images in R like photoshop? (RYGCBM),6n5ufl,top
"I'm brand new to dplyr and I'm having issues querying my SQL database using the package.

I have three tables: report, flight, and condition.  report connects to flight through the column flight_id and flight connects to condition through the column condition_id.  What I'm attempting to do is get a count of all rows once these three tables are joined where the values in the column conditions_precipitation of the condition table is equal to ""Fog"", ""Fog, Rain"", ""Fog, Rain, Snow"", or ""Fog, Snow"".

I've attempted the following code to get the count, but it isn't working correctly, and I think that there is a small problem somewhere that I am overlooking:

    tbl(mydb, ""report"") %>%
      inner_join(tbl(mydb, ""flight"", by = ""flight_id"")) %>%
      inner_join(tbl(mydb, ""condition"", by = ""condition_id"")) %>%
      filter(""conditions_precipitation"" %in% c(""Fog"", ""Fog, Rain"", ""Fog, Rain, Snow"", ""Fog, Snow"")) %>%
      summarize(n())

This outputs:

    # Source:   lazy query [?? x 1]
    # Database: sqlite 3.19.3
    #   [/path/to/database]
      `n()`
      <int>
    1     0

I know that this isn't correct, so I'm wondering where my problem is.",Issues querying SQL database with dplyr?,6n4eas,top
"I have a column that calculates how many days since a case has been released OR reassigned. What would be the best way to make a column that checks if there is a reassignment date and calculate the days since? 


So far I have this since a for loop takes too long: 

The code works, but I feel like it's too verbose. Eventually, I also will create columns based on many conditionals.
    
        
        #### Creates the column      
        rdn_dat$Days.Since <- """"
              
        ##  Released is a date 
        ##  Reassinged is a date 
        ##  Closed is a TRUE or FALSE
        
        rdn_dat$Days.Since[is.na(rdn_dat$Closed) & !is.na(rdn_dat$Released) & !is.na(rdn_dat$Transport.Reassinged)] <- as.numeric(difftime(today(), rdn_dat$Reassigned[is.na(rdn_dat$Closed) & !is.na(rdn_dat$Released) & !is.na(rdn_dat$Reassigned)], units = ""days""))
              
        rdn_dat$Days.Since[is.na(rdn_dat$Closed) & !is.na(rdn_dat$Released) & is.na(rdn_dat$Reassigned)] <- as.numeric(difftime(today(), rdn_dat$Released[is.na(rdn_dat$Closed) & !is.na(rdn_dat$Released) & is.na(rdn_dat$Reassinged)], units = ""days""))
              
        rdn_dat$Days.Since[!is.na(rdn_dat$Closed)] <- NA  #Since we don't pay attention to closed cases

        rdn_dat$Days.Since <- as.numeric(rdn_dat$Days.Since.Release) #converts ""x days"" to a numeric for calculation 
      ","Is there a better way to calculate column, on conditionals?",6kwpqv,top
"The title pretty much says it all. I mostly use Python, and I'd created an interactive Jupyter notebook to try and give some other people the ability to manipulate and explore a dataset. The problem is that I'm unable to share this notebook with the people I need to with either setting up a JupyterHub server (which IT doesn't want to do), or host the information publicly, which isn't an option. Furthermore, interactivity with Jupyter is...not robust.

So, I'd like to see if I can get the same thing up and going in a ShinyApp, because I think I can deploy the shinyapp on an internal webserver to allow people to access it there.

Which brings me to my question/problem: I have a functional knowledge of python, but I know very little R. Are there any resources that would help me convert python code (as contained in a notebook) to R code for use in Shiny? It's not a particularly complex bit of code, but if I can do anything to cut down the time for me to learn enough R/Shiny to get this app up and running, it would be huge!

ANy help or suggestions would be greatly appreciated!

Thank you for your time.",Help converting an IPython notebook into a Shiny app?,6k9zyw,top
I'm tired of having to re-import everything into my global environment and resetting the working directory each time.,How do you save a project in R Studio where it saves everything in your global environment and working directory location?,6imml5,top
"I'm having a doozy of a time with the concept of scraping information from across multiple pages and combining it into a single data frame.  I can easily get the first page piped in, the data from other pages ends up being repetitions of the first page,  not the data from the other pages! There is something wrong with my loop, or the way I grow my data frame.  Please help me out A-Teamers, I desperately need to learn to code loops to get me out of the paper bag. 


library(tidyverse)
library(stringr)
library(rvest)

page number is in the middle of the website: 

https://find-mba.com/schools/usa?page=1&keyword=&rank=false&accredition=true&cities=&specs=14&sort=popularity&numberperpage=8


## Create empty vectors for rank, university, and university links
    ranks <- vector() 
    universities <- vector()
    links <- vector()
    
    ## Create Website Vector with Vectorized page # in middle
    first_half_url <- 'https://find-mba.com/schools/usa?page='
    second_half_url <- '&keyword=&rank=false&accredition=true&cities=&specs=14&sort=popularity&numberperpage=8'
 
## Get first iteration of data
for(i in 1:1) {
url <- paste(first_half_url, as.character(i), second_half_url, collapse = """")
   website <- read_html(url)
  ## Get Data into vectors
   ranks <- html_nodes(website, '.school-list-counter') %>% html_text() %>% as.numeric()
  universities <- html_nodes(website, '.school-list-title') %>% html_text()
  links <- html_nodes(website, '.school-list-title a') %>%  html_attr(""href"")
 ##cbind the first iteration to combine with later iterations
 mydata <- cbind(ranks, universities, links)

  ##Loop through all other pages of data, cbind to first iteration
  
 for(i in 2:59) { 
  url <- paste(first_half_url, as.character(i), second_half_url, collapse = """")
  website <- read_html(url)
  ranks <- html_nodes(website, '.school-list-counter') %>% html_text() %>% as.numeric()
  universities <- html_nodes(website, '.school-list-title') %>% html_text()
  links <- html_nodes(website, '.school-list-title a') %>%  html_attr(""href"")
  
##cbind these iterations with first iteration
  df <- cbind(ranks, universities, links) %>% rbind(mydata)
  print(df)
}
}",Help with scraping multiple pages into a data frame,6icy6t,top
"Hello! I'm a total newbie to R. I've downloaded R and RStudio. The download of R gave a shortcut that opens the program. The download of R only gave a folder under Program Files. I know that these two programs are interconnected and that I need RStudio to properly source a script, however I can't seem to  open RStudio.  Can anyone help?",Difficulty opening RStudio,6hn2oj,top
Hello I am having issues sending parameter to a SQL query using RODBC. Whenever I issue a SQL query using the RODBC library's function SQLquery() I have to hard code in the statements that I want to send.  I would like to instead pass variables to the SQLquery function but I don't understand how this is done. I have tried googling this question before and a found a few examples but was never able to get this to work. I am hoping someone here can help me.,Sending parameters to a SQLquery statement,6h7ubn,top
"Does anyone have experience setting up a Docker image to run a standalone Chrome browser? I'm trying to write a script that will go to a web page. Log in. Run a search and export the results. 

Most of the material on RSelenium online is outdated because they moved over to using Docker. I attempted going through the [vignette](https://cran.r-project.org/web/packages/RSelenium/vignettes/RSelenium-docker.html)... but I couldn't get it to work. Thanks a ton! 


EDIT: Got it to work. For some reason changing 

    remDr <- remoteDriver(remoteServerAddr = ""192.168.99.100"",
                          port = 4445L)

to 

    remDr <- remoteDriver(remoteServerAddr = ""192.168.99.100"",
                          port = 4445)

worked ... All I did was take out the L, even though the vignette uses it. ",RSelenium and Docker,6f7v9g,top
"I've got a bunch of height/weight data and dates of birth in an excel doc, and I need to find the corresponding ht/wt percentiles based off the WHO/CDC growth charts.

Does anyone have experience with how to go about doing this? I was mucking about with the WHO's ""AnthroPlus"" R Macro, but it only produced Z-scores, and even then, the output wasn't making sense. 

I'm very new to R, however I am familiar with automating tasks using vba in excel. 

Would appreciate any help, thanks! ",[help] Automate Growth Chart Percentiles,6dz7be,top
"Hey, this is a difficult problem for my lab and I was wondering if anyone had suggestions

I have a 2x228 list of data, the second column of each data entry is a list of between 50 and 600 characters.  I want to be able to do the following to each entry:  

Turn each string into something like a vector so that each character in the string can be iterated over  

The problem is that I can't find a way to do that.  I can do it one by one to every string, for instance:

string1<-list[1,2]  

string1<-as.character(string1)  

string1<-strsplit(string1,"""")  

string1=unlist(string1)  

Which allows me to do something like  

string1[]==""Y""  

To find every instance of Y in the datapoint.  The problem is that this method doesn't let me do this to all 2x228 points at once.  

One thing I considered is if I could put {string1:string228) in a for loop then I could create and unlist each string in a loop and then iterate over them each in another loop, but R doesn't seem to do that.  

It doesn't seem that I can then put each string into a dataframe to iterate over since each string is a variable number of character long.  

If either of these things can be done (either iterate over string1:string228 or create a dataframe of unequal lengths) then I could do this, or if someone has any other suggestions I could try those.  

Thank you for your time if you read this",Turn list of strings into something I can iterate over,6dpz41,top
"To start, I'm a noob at R. This is only my third week working with the language. I initially began by learning some exploratory data analysis skills and graphing (ty ggplot2). Now, I'm learning some fundamentals of the language. So, any help or advice is appreciated! I'm not a computer scientist or statistician. I'm a PhD student who works with pharmaceuticals. My background is in python, excel, physics, math, and bio.




d is the name of the data frame I'm working with, and volume is the name of the column I'd like to work with. Because some objects in the dataset I'm working with are 2D, I get some volumes of zero. I'd like to replace them with NA for clarity and translatability (and just to practice).

Code:


    #remove0 is the function I'm attempting to create.
    remove0 <- function(dataframe, target){
    #first I create a vector copy of the column I'm going to replace
      tprime <- dataframe$target
     #then I loop through the vector and replace any values of 0.0 with NA 
      for(i in length(tprime)) {
        if(tprime[i] == 0.0) {
          tprime[i] <- NA
        }
      }
     #finally, I return the initial data frame with the modified target column
      dataFrame$target <- tprime
    }
    
    #then, I run the function on the data I'm working with
    remove0(d, volume)

Problem is, every time I run the code I get the error message:

    Unknown or uninitialised column: 'target'.Error in if (tprime[i] == 0) { : argument is of length zero


I've done some research on the error, and I can't seem to find why my code is producing the error. I suspect it has to do with my if syntax. Thank you in advance!
","Hey guys, I'm getting an error while looping through a column of a data frame. I'm trying to replace all zero values with NA",6di91p,top
"Hi all,

I found the following example and copied the first chunk of code in order to play with it:
http://www.sthda.com/english/wiki/create-and-format-word-documents-using-r-software-and-reporters-package#add-texts-title-and-paragraphs-of-texts

However, when I run the code, this is what I see:

Error in UseMethod(""addParagraph"") : 

  no applicable method for 'addParagraph' applied to an object of class ""docx""



What am I doing wrong?  Doing ""library(ReporteRs)"" loads the library just fine.  What am I missing?



Also, how do make code blocks?",Trying to generate a *.docx file.,6b5jc1,top
"I have an version of R installed on OS X. Whenever I try to install a package as follows:

    install.packages(""new_package"")

it stays frozen with 

    --- Please select a CRAN mirror for use in this session ---
 
and doesn't show the repo options. (In this case, I have to cancel the installation.) Naturally, I can install packages by explicitly specifying the CRAN repo via

    install.packages('awesome_package', repos='http://cran.us.r-project.org')

but I'm still confused why this ""sticks"" when installing in the ""traditional way"". Any advice?",Why does my version of R not allow me to choose a CRAN mirror when installing packages?,6b1xrh,top
"I ran across this discussion on Andrew Gelman's blog:

http://andrewgelman.com/2017/04/26/hate-r-volume-38942/

What is the reason for this? Any other computer programming language I can think of allow block comments, and 


    if(FALSE){
        comments here
        comments here
    }



really *is* a hack. 

What are the historical reasons behind this?",What is the reason why base R doesn't allow block comments?,69ncwg,top
"Hey, does anyone know of a good tutorial on using RScript for making command line R tools?  I have a larger software system that I'd like to use to push data into an RScript, collect the output, and display the result as part of a larger webpage.  I can't do this with interactive R and it looks like most R users run their scripts from R Studio instead of headless... help?!",Running R from the command line?,6759i1,top
"I just started learning R. I have background knowledge in Excel VBA, basic SQL and a bit of Python.

Currently reading Bradley Boehmke's book called *Data Wrangling with R*. Currently at chapter 4 and i am being bombarded with functions (as.double, sample(), runif(), etc). I am progressing slowly because i don't want to just scan through some functions and forget them.

Any tips about learning R? Should i try to list down/memorize all these functions or just proceed through the book? Because honestly, if i just read and read, i may understand but i might forget the specific syntax.

I've learned other languages by watching them in youtube so reading a book is new to me. And i've learned those languages through application/activities/examples. The book (as of now) only provides piece by piece info about the functions. 

Thanks all!",Info overload with R. Help a newbie out.,66o66c,top
 I want help in understanding how to do image processing and recognition using machine learning or deep learning using mxnet or any other package?,Image processing and recognition using R,66j50f,top
"So this is some sample data I have:

    signal1   signal2   signal3   
    1         0         1        
    1         1         1  
    1         0         1  
    1         0         1  
    1         0         1  
    1         0         1  
    1         0         0 

And I want to add a fourth column, such that whenever `signal1==signal2==signal3` are both 1, the new column repeats 1s until signal3 changes from 1 to 0.

So from the above example, I want to generate something like:

    signal1   signal2   signal3   signal_generate
    1         0         1         0
    1         1         1         1
    1         0         1         1
    1         0         1         1
    1         0         1         1
    1         0         1         1
    1         0         0         0

I'm thinking this would be achieved by an `ifelse` statement, but I'm having a lot of difficulty over this seemingly simple task. I'm thinking of doing something along the lines of:

`signal_generate <- ifelse(data[,1]==data[,2]&data[,3]>0, rep(data[,3]==1), 0)`

But I can't figure out how to get `signal3` to repeat the correct number of times.

Edit: Thank you everyone! I'm going to slowly look through comments and try to understand code :)",How to replicate values after a conditional statement is met?,651d09,top
I am trying match on two different data elements: color and make.  I would like me to substitute in make to reflect make-color.  Is it possible to match across 2 columns of data in R?,Gsub,64wdmr,top
"I want to learn C++, but my sole reason for doing so is to use it through Rcpp. With this goal in mind, what features of C++ should I skip spending time on? What features of C++ are especially helpful (I know STL is on this list)?",What parts of C++ are not available under Rcpp?,649pnh,top
"I have a dataframe that looks something like this:


var1 | var2
---|---
 a | NA
a | NA
b | NA
a | NA
b | NA
b | NA
a | NA

and for each value of var1 I want to return a value for var2 (eg. a = cat, b = dog), so that it looks like this: 

var1 | var2
---|---
 a | cat
a | cat
b | dog
a | cat
b | dog
b | dog
a | cat

I've been pulling my hair out on this all day and hoping someone can help me out. 
Thanks in advance. 




 
",Basic data manipulation problem,6443yh,top
"I've got an idea for a project to see if sentiment analysis can be useful to model crypto-currencies. The Poloniex trollbox is a very active chatroom with instant reactions to market prices - https://www.poloniex.com/trollbox, anyone know if it would be possible to scrape this text data in R?

This might be easier in another language... but I'm a bit of a noob programmer so I'd like to stay in R since I feel most comfortable there. Thanks for any help",Possible to scrape text from a chatroom in R?,639zi5,top
"I have two dataframes that I'm trying to join and I've having trouble doing it. It's dataframes from two different 'moving' companies. Sometimes two different companies will move the same VIN at different times. 

I need to calculate the lifetime cost of transporting each VIN. How do I join entries from df2 (which has multiple duplicates for moves) to df1 which has only unique VINS? 

Any suggestions? 

Edit: Dummy dataframe that represents my issue. One df has duplicates and extraneous vins because the company handles different types of moves. I want to join this so that the first mover get priority but I want to add all cases of moves. So YS3DF78K527013330 in this example, I want it to show both the 2017-01-15 move and the 2017-02-14 move. If there's no way for me to have both dates, I would rather have the latest date of all matching VINs. 



    vin_mover_one <- c('YS3DF78K527013330','5FNRL38679B039269', '1FTRW08L13KB17454', 'JH4DB8580RS000024','1C4BJWFGXDL531773', 'JH4KA7660RC001542')
    dates_mover_one <- as.Date(c('3-1-2017', '3-1-2017', '3-2-2017', '3-3-2017', '3-3-2017', '3-6-2017'))
    
    vin_mover_two <- c('YS3DF78K527013330', 'YS3DF78K527013330', '1FTRW08L13KB17454', 'WDBAB23A6DB369209', '1B7GL22Z31S190315')
    dates_mover_two <- as.Date(c('2017-01-15','2017-02-14', '2017-03-15', '2017-02-02','2017-03-20'))
    
    mover_one_df <- data.frame(vin_mover_one, dates_mover_one)
    mover_two_df <- data.frame(vin_mover_two, dates_mover_two)
    
",Best way to join dataframes with multiple entries?,60xzgn,top
I'm trying to set the meta data in an XLSX file.,How does one add character data to an existing ZIP file?,5z5ech,top
"hi reddit. Today is my first day with R. im struggling to use [this function](http://www.wiu.edu/users/ft100/CircularBonferroniR.pdf).


I've got a bunch of azimuth values. im supposed to introduce them to the ""t"" field but i dont know how to format them.


im introducing the values as follows


    297, 27, 325, 64, 60, 66, 305

since those are vectors, their magnitude:direction is as follows


       4884.76:297
       15675.49:27
       7009.72:325
       6342.73:64


could anyone help me please
thanks",how to enter data for this function?,5yx1hm,top
"I have two dataframes in R:

    Died.At <- c(22,40,72,41, ...)
    Writer.At <- c(16, 18, 36, 36)
    Name <- c(""John Doe"", ""Edgar Poe"", ""Walt Whitman"", ""Jane Austen"", ...)
    Gender <- c(""MALE"", ""MALE"", ""MALE"", ""FEMALE"", ...)
    Date.Of.Death <- c(""2015-05-10"", ""1849-10-07"", ""1892-03-26"",""1817-07-18"", ...)
    Pet <- c(""cat"", ""dog"", ""cat"", ""cat"")
    df1 = data.frame(Died.At, Writer.At, Name, Gender, Pet)
    print(df1)
      Died.At Writer.At     Name          Gender    Pet
    1      22        16     John Doe      MALE      cat
    2      40        18     Edgar Poe     MALE      dog
    3      72        36     Walt Whitman  MALE      cat
    4      41        36     Jane Austen   FEMALE    cat
    .....

In `df1` not each row for `Name` is unique (i.e. there are several rows with the same author.)

The second dataframe `df2`, there is also a column `Name` with both authors from `df1` (e.g. Jane Austen) and completely new authors. This dataframe is also far larger. 


    print(length(unique(df1$Name)))
    ## output 1168
    print(length(unique(df2$Name)))
    ## output 5572


I would like to subset `df2` such that the only names are the names from `df1`. 

My idea was to do this: 

    subset_df2 = df2[df2$Name == unique(df1$Name)]

However, I would expect there to be 1168 unique author names here:


    print(length(unique(subset_df2$Name)))
    ## output 880

That's less than I was expecting. Where is my error? 

",How to subset one R dataframe with the values of another R dataframe?,5xlik2,top
"I want to create 50 bar plots in a 10x5 matrix.  My data consist of water quality data from 13 sites.  Each site has its own row, there are 50 columns each representing different times.  For many sites, the value does not change.

Using the data below, the first plot would have a value of 926 for site A-1, a value of 1485 for site A-7, etc.  For the second plot, site A-1 would have a value of 926, site A-7 would have a value of 5395, etc.  I want to show all the sites on each plot, I'm just mentioning A-1 and A-7 to illustrate how the plots should look.

===============
Site	1	2	3	4	5  (continues to 50)

A-1	926	926	926	926	926...

A-2	1376	1376	1376	1376	1376...

A-3	2936	2936	2936	2936	2936  ...

A-4	876	876	876	876	876  ...

A-5	1964	1964	1964	1964	1964  ...

A-6	1498	1498	1498	1498	1498  ...

A-7	1485	5395	2227	1148	871  ...

M-1 2390 2390 2390 2390 2390  ...

M-2 1941 1655 1477 871	656  ...

M-3 5145 1963 850	2441	3803  ...

M-4 3996 3506 1390 1457 2265  ...

M-5 696 696 696 696 696  ...

M-65024	5024	5024	5024	5024  ...

==============

Here is what I’ve done so far:

    library(ggplot2)
    library(gridExtra)
    tds <- read.csv(""wq_coefficients.csv"")
    for (i in 1:50) {
    date = paste0(""X"",i)
    Gi <- ggplot(data=tds, aes_string(x=""Well"", y=date)) + geom_bar(stat=""identity"")
    }
    grid.arrange(G1,G2,G3,G4,G5,G6,G7,G8,G9,G10,
    G11,G12,G13,G14,G15,G16,G17,G18,G19,G20,
    G21,G22,G23,G24,G25,G26,G27,G28,G29,G30,
    G31,G32,G33,G34,G35,G36,G37,G38,G39,G40,
    G41,G42,G43,G44,G45,G46,G47,G48,G49,G50,ncol=10)
When I run it, I get:
>Error in arrangeGrob(...) : object 'G1' not found

If I define each plot (G1 … G50) individually (without a loop) it works fine.

Is there another way to do this that will produce the output I want?  It seems as though a list or function would be better than a loop, but I’m new to R and I haven’t been able to get either of those to work by building on examples I’ve seen on-line.

edit: formatting",Problem creating multiple plots using ggplot and a loop,5wk4hi,top
"Hi guys,

Was hoping if anyone has a solution to separate names and job titles.

I have a vector that looks like this:

John Smith senior associate

Michael Flynn associate

Jenny Park partner

Michael B. Douglas Senior associate

-----------------------------
I need the job titles to be in a separate column. 

I was thinking tidyr but struggling to program it right. However many of the job titles are quite similar/narrow - so its possible to code it in such a way that it recognises specific job titles rather than relying on a separator.
",Separating names and job title,5usqac,top
"Hi,

I'd like to download and install the LightGBM package offline. The package is stored on GitHub [here](https://github.com/Microsoft/LightGBM/tree/master/R-package).

As far as I know, [I need a zip of the package to install it offline](http://stackoverflow.com/questions/33179156/installing-a-package-offline-from-github). So far, I have not found such a file.

Anyone know where / how I can find it please ?",How to install LightGBM package offline,5udyd4,top
"I have followed the comments here, http://stackoverflow.com/questions/33796585/authentication-in-shiny-app-and-multiple-pages and I can login users. I just can't create a button that resets and brings the login page back.

Thanks","I can log users into my shiny app, how do i create a logout, reset button?",5tot55,top
"Hey guys, I'm trying to run this code in R that was created for me by someone, improved by someone else, and now slightly adjusted by me. After I run it, during the plot render, my iMac seems to nearly collapse trying to render it. It actually took over three hours for the plot to appear (I started it at 9pm, checked it at midnight, and went to bed - so it could have been a lot longer). Anyways, here is the code:
****
    #I stored the csv in this location
    setwd('/wherever you decide to place the file')
    require(ggplot2)
    
    
    league = read.csv('Test.csv')
    league$ShotsFacedPerMatch = with(league, SfpM)
    #the with() function allows you to reference column names without needing to write the data frame's name down multiple times
    league$ShotsFacedPerMatchConceded = with(league, SfpGC)
    league$AverageScore = (league$SfpM)/(league$SfpGC)
    
    density_kernel <- function(grid_points, data, variable.name, kernel_sd){
      cols = colnames(grid_points)
      distances = matrix(0, nrow=nrow(grid_points),ncol=nrow(data))
      dev_factors = apply(data[,cols],2,sd)
      rot_grid = as.matrix(t(grid_points))
      for (i in 1:nrow(data)){
        #use R's vector recycling to simplify process
        distances[,i] = sqrt(colSums((
          (rot_grid - as.numeric(data[i,cols]))/dev_factors
                                      )^2))
      }
    
      influences = dnorm(distances, sd=kernel_sd)
      denominators = rowSums(influences)
      #multiply each row by the vector of target variable and then sum the rows
      weighted_values = rowSums(sweep(influences, MARGIN=2, data[,variable.name], `*`))
      return(weighted_values/(pmax(1e-18,denominators)))
    }
    
    
    
    
    #this creates a grid that can be used to determine the background color, and it will approximate a contour line very well
    data_grid = expand.grid(ShotsFacedPerMatch=
                         seq(min(league$ShotsFacedPerMatch) - 0.5, 
                             max(league$ShotsFacedPerMatch) + 0.5,0.025),
                       ShotsFacedPerMatchConceded=
                         seq(min(league$ShotsFacedPerMatchConceded) - 0.1,
                             max(league$ShotsFacedPerMatchConceded) + 0.1,
                             0.0002))
    
    ddata_grid = data_grid[rowSums(data_grid <0)==0,]
    
    data_grid$AverageScore = density_kernel(data_grid, league, 'AverageScore',0.67)
    
    data_grid$AverageScoreRange = with(data_grid,
                                       cut(AverageScore,
                                           seq(-1.2,1.5,0.3)))
    
    ggplot() + 
      geom_tile(data=data_grid, aes(x=ShotsFacedPerMatch,
                                    y=ShotsFacedPerMatchConceded,
                                    fill=AverageScoreRange),
                       alpha=0.6) + #add this for visible gridlines in background
      geom_point(data=league,
                 aes(x=ShotsFacedPerMatch,
                     y=ShotsFacedPerMatchConceded)) + 
      geom_text(data=league,
               aes(x=ShotsFacedPerMatch,
                   y=ShotsFacedPerMatchConceded,
                   label=Team),
               nudge_y = 0.18, size=3,color='darkred') + #shifts the text label slightly above the points
      ggtitle('Premier League Defensive Efficiency') + 
      labs(subtitle=expression(paste(sigma,'=0.67'))) +
      theme(plot.title = element_text(hjust = 0.5))
****

[Here is the CSV for reference.](https://www.dropbox.com/s/mb4dn8ct6ais0gl/Test.csv?dl=0)

Now, I'm really new to R. As in, I've rendered about 3 plots. I feel comfortable around coding, but I haven't had enough time around this language. If anyone could explain to me if anything in the code is tripping up the program, or if perhaps it's just my computer (it's a mid-2011 iMac with 12gb of ram running an ATI Radeon HD 5750 - I know, I know... but the render was ridiculous).

Also, if any parts of my code are redundant, I'd love to hear about it (I'm assuming some of the lines below the read.csv are useless).

Thanks a lot!",New to R: Why is this code killing my comp during plot render?,5thnpt,top
"Hey all I am having a bit of trouble running this set of code where I am trying to take a Cholesky decomposition of a large sparse matrix. The problem I am having is two fold. Here is the code with the output in comments

    rm(list=ls())
    #devtools::install_github(""nmmarquez/ar.matrix"") # if you want to run code
    library(ar.matrix)
    library(Matrix)
    library(sparseMVN)
    
    graph <- US.graph
    ages <- 20
    years <- 5
    
    run_test <- function(){
        # create list of variances for correlation process
        sigmas <- list(A=1.4, T=.7, L=1.2)
        # create list of autocorrelation parameters for correlation process
        rhos <- list(A=.85, T=.99, L=.90)
        # define the structure of each aoutocorrelated process
        N <- list(L=graph, A=ages, T=years)
        # define the functions for spatial, temporal, and age process
        # create the three precision matrices
        funcs <- list(L=Q.lCAR, A=Q.AR1, T=Q.AR1)
        Qlist <- lapply(c(L=""L"", A=""A"", T=""T""), function(x)
            funcs[[x]](N[[x]], sigmas[[x]], rhos[[x]], sparse=TRUE))
        # take the Kroneckor prodect of the 3 precision matricies
        Qlat <- kronecker(kronecker(Qlist$L, Qlist$A), Qlist$T)
        # check the dims
        cat(""1. check the dim size \n"")
        print(dim(Qlat))
        # time the process of taking chol decomp of sparse matrix
        cat(""2. run time of chol decomp process"")
        print(system.time(Qchol <- Cholesky(Qlat)))
        # using the chol decomp generate random data with the covar specification of
        # Qlat^-1
        cat(""3. run time of generating random draws"")
        system.time(test <- rmvn.sparse(1, rep(0, nrow(Qlat)), Qchol , T))
    }
    
    # chol decomp takes a while but it runs
    run_test()
    # 1. check the dim size 
    # [1] 47500 47500
    # 2. run time of chol decomp process   user  system elapsed 
    # 34.376   0.152  34.531 
    # 3. run time of generating random draws   user  system elapsed 
    # 0.964   0.100   1.066 
    
    ages <- 40
    years <- 50
    
    # and here the chol fails cause problem is too large
    run_test()
    # 1. check the dim size 
    # [1] 950000 950000
    # 2. run time of chol decomp process
    # Error in Cholesky(as(A, ""symmetricMatrix""), perm = perm, LDL = LDL, : 
    #  Cholmod error 'problem too large' at file ../Core/cholmod_change_factor.c, 
    #  line 539
    #  Timing stopped at: 9.472 1.624 11.094 

I would like to know 2 things  
1. Is there a better method to take a Cholesky Decomp of a large sparse matrix in R  
2. How can I overcome this issue of the problem being to large  
For the second problem I'm willing to move outside of R but would love any and all suggestions.

Thanks",Trouble with large Cholesky Decomposition,5rrkzj,top
is there a way to compare if a POSIXct variable is equivalent to a specific day while ignoring the year. For example if I have a POSIXct variable and I want to see if it is set to midnight July 3 any year? How would I do this since POSIXct requires me to specify a year?,Compare a POSIXct variable to a specific day,5rktc8,top
"Hey Rlanguage, coming at you today with a problem which I'm assuming has a very, very simple answer. I simply cannot get the URL data found in the code underneath to run.

S = ""http://solarscience.msfc.nasa.gov/greenwch/spot_num.txt""

sun = read.table(S, header = T)

Every time I attempt to run it, I receive the error:
 
Error in file(file, ""rt"") : cannot open the connection

From reading on the internet, I believe this has to do with my working directory. Does anyone here have any better of an idea than I do? ",Help-Beginner,5q4nou,top
"Hi guys, I'm pretty new to programming in R, but I always look for new ways to learn it and further my knowledge. I recently found a book called [Mastering Software Development in R](https://leanpub.com/msdr) by Roger D. Peng, Sean Kross, and Brooke Anderson. The book itself is free, but for $20 you can also get the code files and datasets. Has anyone used these extra files and are they worth the extra $20?","Is the book ""Mastering Software Development in R"" along with extra files worth $20?",5p45e3,top
"I have a data.frame called ""opps"" for sales opportunities. On each row, I have a close_date, a money amount, and a column to denote what currency the transaction was done in (and a few other columns but those are the relevant ones).

3 million out of 10 million rows are not in US Dollars. I need to convert those into dollars based on the exchange rate of the close_date of each individual transaction. Can anyone tell me if what I've done here makes any sense? I've had it work for a few hundred lines, but it takes long enough to run the whole thing (I'm not an optimizer as you can tell from my for loops), so I figured I'd get some feedback before I can get feedback from the program itself.

EDIT: 24 hours later and it's still running. Does this seem reasonable for that last for loop looping through 3 million rows? All of the conversion rates are downloaded into the current environment, so it's not accessing anything external.

    # This makes a list of the different currencies in the dataset:
    currencies <- unique(opps$currency[opps$currency!=""USD""]) 
    currencies <- currencies[currencies!= """"]

    # this makes a smaller data frame with just the non-USD transactions
    oppsforeign <- opps %>%
      filter(currency != ""USD"",
             currency != """")

    # Don't attack me for the for loop. They just make more sense to me. This line just uses the quantmod package's
    # getFX function to pre-download the object that has the conversion rates for every day for every conversion to USD
    for (i in 1:length(currencies)){
      getFX(paste0(""USD/"",currencies[i]), from = ""2014-01-01"", to = ""2016-03-31"")
    }

    #Create empty vector to store the conversion rates
    convrate <- rep(0,length(oppsforeign$amount))


    # This is the big meaty loop. Every row, it accesses those getFX objects and pulls the right number out. That main 'coredata' line came from
    # a lot of trial and error, so it may not be a very clear line.

    for (i in 1:length(oppsforeign$amount)) {
  
      framez <- coredata(get(paste0(""USD"", oppsforeign$currency[i])))[as.numeric(opps$close_date[i]) - as.numeric(as.Date(""2014-01-01""))]
       if (length(framez) > 0) {
        convrate[i] <- framez
       } else {
         convrate[i] <- 1
      }
      rm(framez)
    }
    oppsforeign$rate <- convrate",Easy way to convert the currency of 3 million rows of transactions,5oeha7,top
"I have been trying to get this running: http://code.markedmondson.me/googleAnalyticsR/setup.html

**First error I get is: Error in httpuv::startServer(use$host, use$port, list(call = listen)) : 
  Failed to create server**


**Code looks like this now: (with sections of id/secret x'd out)**

    library(""googleAuthR"")
    library(""googleAnalyticsR"")

    options(googleAuthR.client_id = ""40586XXXXXX-4pa4a5pgn4ciehosvmm7jp41fapehjg6.apps.googleusercontent.com"")
    options(googleAuthR.client_secret = ""xEXXXXXXAF8w9tF9fGu2_w"")
    options(googleAuthR.scopes.selected = ""https://www.googleapis.com/auth/analytics"")

    # This should send you to your browser to authenticate your email.
    # Authenticate with an email that has access to the Google Analytics View you want to use.
    ga_auth()
    
    unsampled_data_fetch <- google_analytics_4(id, 
                                                 date_range = c(“2015-01-01”,”2015-06-21""), 
                                                 metrics = c(""users"",""sessions"",""bounceRate""), 
                                                 dimensions = c(""date"",""landingPagePath"",""source""),
                                                 anti_sample = TRUE)

    # get your accounts
    account_list <- google_analytics_account_list()

    # pick a profile with data to query
    ga_id <- account_list[23,'ga:6476469']

1. Where do I put my options?
2. What is the first number in ""account_list"" represent?
3. Does anyone have an example of a working bit of code from a GA pull?


",Help with GoogleAnalyticsR Auth,5o8216,top
"Hi all,

I have recently installed RStudio on my machine and I was wondering if there was any way to import .do files and, less importantly, .dta files. Or is there any type of file that is similar to the .do file in R? 

I have .do files that were completed in STATA and need to use them to analyze the data, but I don't really have the money atm to shell out $200 for the license. ","New to R, have a few questions.",5nyu3x,top
"Hi all,

I'm considering a pet project in R where I would be working with video.  I did some googling though and wasn't able to find any libraries that seem to deal editing videos though so I am coming here for recommendations.

The project involves trying to correct errors using previous frames.  The other alternative I can think of is treating the videos as a succession of pictures.  That said, I don't want to reinvent the wheel and if someone knows of a more sensible thing to do, I'd like to hear it.  It isn't lost on me that I may have to use C++ for this project.

Thanks,",Working with Video in R,5mktp5,top
"I'm looking to perform a logit and then obtain odds from that, but every time I use the GLM for my variables, I've had the following warnings messages:

*1: glm.fit: algorithm did not converge* **(maxit=1000 seemed to solve this first one)**  
*2: glm.fit: fitted probabilities numerically 0 or 1 occurred*

My code is basically as follows:

*summary(glm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8, family=binomial, weights=weightname, data=dataname))*

The predictors are recoded to factors that exclude non-answers, with some binary while others are multinomial, but all are categorical. When the logit is run, all estimates are nearly zero (i.e., e^-14 and e^-13). Everything is also very high in significance (<2e^-16 ).


I've searched for solutions to both these warnings and found it for the first one, but if anyone could explain at least the second warning, I would deeply appreciate it as time is also running out for me to submit my work.",GLM warnings (algorithm did not converge & fitted probabilities 0/1),5l206l,top
"My searching indicates this message comes up in a variety of situations, but so far I haven't figured out the solution to my particular problem.

I want to make a map in R of the administrative boundaries of Barbados.  I downloaded a shapefile from http://www.diva-gis.org/

I'm using the maptools package not rgdal (some unresolved issues with rdgal for Mac OS), and I'm following the examples [here](https://www.r-bloggers.com/shapefile-polygons-plotted-on-google-maps-using-ggmap-in-r-throw-some-throw-some-stats-on-that-mappart-2/) and [here](http://blogs.oregonstate.edu/geo599spatialstatistics/2014/05/06/working-shapefile-data-r/).

I get the error message in response to this:

Barbados <- Barbados+ geom_polygon(aes(x=long, y=lat, group=group), fill='grey', size=.2,color='green', data=Barbados, alpha=0)

Any ideas?","Error in as.vector(x, mode) : cannot coerce type 'environment' to vector of type 'any'",5ktl9l,top
"I'm trying to install `rmarkdown` package, but its dependency `evaluate` fails with an ERROR at something called lazy loading.

    install.packages(""rmarkdown"")
-
    ## Installing package into ‘/home/marek/.rkward/library’
    ## (as ‘lib’ is unspecified)
    ## also installing the dependencies ‘knitr’, ‘evaluate’
    ## 
    ## trying URL 'https://cran.wu.ac.at/src/contrib/knitr_1.15.1.tar.gz'
    ## Content type 'application/x-gzip' length 1027808 bytes (1003 KB)
    ## ==================================================
    ## downloaded 1003 KB
    ## 
    ## trying URL 'https://cran.wu.ac.at/src/contrib/evaluate_0.10.tar.gz'
    ## Content type 'application/x-gzip' length 21914 bytes (21 KB)
    ## ==================================================
    ## downloaded 21 KB
    ## 
    ## trying URL 'https://cran.wu.ac.at/src/contrib/rmarkdown_1.3.tar.gz'
    ## Content type 'application/x-gzip' length 2073859 bytes (2.0 MB)
    ## ==================================================
    ## downloaded 2.0 MB
    ## 
    ## * installing *source* package ‘evaluate’ ...
    ## ** package ‘evaluate’ successfully unpacked and MD5 sums checked
    ## ** R
    ## ** preparing package for lazy loading
    ## Error in dyn.load(file, DLLpath = DLLpath, ...) : 
    ##   unable to load shared object '/home/marek/.rkward/library/stringi/libs/stringi.so':
    ##   libicui18n.so.57: cannot open shared object file: No such file or directory
    ## ERROR: lazy loading failed for package ‘evaluate’
    ## * removing ‘/home/marek/.rkward/library/evaluate’
    ## ERROR: dependency ‘evaluate’ is not available for package ‘knitr’
    ## * removing ‘/home/marek/.rkward/library/knitr’
    ## ERROR: dependencies ‘knitr’, ‘evaluate’ are not available for package ‘rmarkdown’
    ## * removing ‘/home/marek/.rkward/library/rmarkdown’
    ## 
    ## The downloaded source packages are in
    ## 	‘/tmp/Rtmp0HQEG6/downloaded_packages’
    ## Warning messages:
    ## 1: In install.packages(""rmarkdown"") :
    ##   installation of package ‘evaluate’ had non-zero exit status
    ## 2: In install.packages(""rmarkdown"") :
    ##   installation of package ‘knitr’ had non-zero exit status
    ## 3: In install.packages(""rmarkdown"") :
    ##   installation of package ‘rmarkdown’ had non-zero exit status

I'm not really sure what lazy loading is nor why does it fail, but how do I properly install `rmarkdown` package?",ERROR in lazy loading of 'evaluate' package.,5kjfeg,top
I'm new to R programming and I'm a little confused. What is the difference between () and {} and when should I use it? I googled it but I don't understand the answers. ,Newb questions about curly brackets {},5kezp1,top
"Hello,

i am using the abod function from the abodOutlier package in R to detect multivariate outliers.

The result that the function gives is an angle-based outlier factor and if the factor is small the observation is an outlier. It ranges from 0 to 1.

My problem is as to how do i determine what value of this factor do i use as a cut off for my outlier detection. I would greatly appreciate all the help i can get.

Thank you! ",Angle-based outlier detection,5j6h8f,top
"hello all, I am very new to R and I am teaching myself, does anyone know of any good tutorials to learn R, especially some simple lm() models, as I am focusing on that at the moment.",Simple Linear Regression,5fpuuo,top
"I had a indexed for loop going through each row of a dataframe. The dataframe['column'] way of calling each row returned two errors - 

    Error in `[<-.data.frame`(`*tmp*`, i, value = 1) : 
    new columns would leave holes after existing columns 

and

    In addition: Warning message:
    In `[<-.data.frame`(`*tmp*`, ""colum_A"", value = list(colum_A = c(1,  :
    provided 2 variables to replace 1 variables

Meanwhile, dataframe$column method returned no error

I always thought the two were completely the same.",What is the difference between dataframe['column'] and dataframe$column?,5f6s4k,top
"I have created a program that simulates an evolutionary prisoner's dilemma scenario, and then draws squares onto the screen based on what type of player each square is. It works perfectly, except for the annoying fact that every step the graph fades to a lighter version of itself while calculating. How do I disable this behaviour?",How to stop R/Shiny fading out graphs while computation is happening?,5eoedh,top
"I'm a college student and a huge baseball fan, but my major has nothing to do with sports, sports is just a hobby and fantasy for me.

I was hoping to do some sort of predictive analysis model on some 2017 projections on a sports team(s) and my fellow colleagues told me to research on R a bit and learn it. I know R programming is a statistical data computing language and software, where you can develop data analysis and such. 

My question is how does it work in a bigger picture? Do you import data and build models and graphs from it? And for the data analysis part, does one have to analyze it from trends and such to get the projections? Or how are algorithms implemented to create such data analysis results? 

Hope you can answer and ELI5. 

Thanks",I'm new here and to the R language itself and I have some questions,5d14z6,top
"I have heard from the Dr. gugel (google) that one can create a retail calendar (no sundays or holidays) using lubridate. Does anyone know of examples or resources to do this? Very much appreciate it, I am a noob who is trying my best. ",Advice for creating a retail calendar in R using the lubridate package,5czszn,top
"Hello.

Is it possible to make a robust loess (rloess) in R?",Robust loess,5cvplh,top
Does one use Quantmod package?,How does one get information from Nasdaq on R,5bp3qn,top
"Hi, I'm relatively new to R and I'm interested in simulating sports events (World Series, English Premier League Season) and I have no idea where to start. I feel like the World Series would be easier to do since its two teams and a max of 7 games. Could someone point me in the right direction for learning how to do simulation in R and specifically in answering a question like this?

For example, if Team A has a 60 percent shot of winning a game and Team B has a 30 percent shot, how could I simulate that series many times. I presume I would use a Monte Carlo simulation.

I really have no idea how to get started and have looked around a lot online.

Thanks in advance! ",Help Learning to do Simulation (Monte Carlo or other),5bisib,top
"First of all, if this is not the appropriate subreddit, just let me know and I'll happily follow the rules. Now, I'm an economics student. I know my way around Excel, some Stata (still learning tho) and I've been told combining these two tools with R is just what I need to completely cover my data handling needs. 

I'm taking DataCamp's great course on R and decided to try out some of what I've learned. I downloaded R version 3.3.0 (2016-05-03) and after typing my first line and pressing enter to jump to the next, it ""ran"" (I'm not a programmer, I'm not sure if this is the correct term) that one line of code. And then I found out that R's enviroment is vastly different from DataCamp's.

Is this happening because I'm using R console, not DC's script.R?",I'm a newbie who needs help,5a4qr2,top
"So I have 2 data frames that have some columns in common. In one data frame (150 rows), there are columns X, Y, and Z, as well as column A. I ran a lm(A ~ X+Y+Z) in this data frame to get coefficients and called that Model. Now, I want to use those coefficients to make a prediction in a separate data frame. This data frame also has columns X, Y, and Z (and others) and has 3000 rows.

How do I pass the coefficients from my original model to my new data frame such that it recognizes the column names matching the coefficients and runs the model to give me a new column A for my 3000 rows?

I am trying to do predict.lm(Model, new data frame) but it is giving me an error since there are more rows than variables in my original model. 

Can anyone help? Thanks!",Using coefficients from lm to predict values in a separate data frame,586tqm,top
"i have a csv file consisting of 11 lakh rows,
i want to write a loop where it takes 1 lakh rows at a time perform some functions and then again continue taking next 1 lakh rows.",Read Large CSV(11 lakh rows) and create a loop for using only 1 lakh in a batch,57fi1b,top
"
up vote
0
down vote
favorite
I have a single script `filename.R` to distribute, which has a variable for an input file and a variable for an output file.

input <- ""/path/pathname/file1""
output <- ""/path/pathname/file1""
The script takes in an input, and saves an output. Without porting this single script into a Python package, what is the ""python standard"" for having users name the input file and the output file?

It is possible to create a function that takes in a pathname:
If users do not do this, I can then throw an error.

However, this is may not be the most responsible approach. A prompt seems like a bad ideas as well.","When distributing a single R script to run, how does one prompt users to set io pathn",5725es,top
"Im trying to download the R package ""CasualImpact""

to do so, here were the directions:

install.packages(""devtools"")
library(devtools)
devtools::install_github(""google/CausalImpact"")


**Issue** doesnt work as CasualImpact has other package dependences....

**Package Dependencies**:
There are 5 bsts, BoomSpikeLab, Boom, zoo, xts.

**zoo** package: This is the one that has me stuck

**installing zoo**:


      install.packages(""zoo"")
     Installing package into ‘C:/Users/nfoley1/Documents/R/win-library/3.3’
     (as ‘lib’ is unspecified)
     --- Please select a CRAN mirror for use in this session ---
     trying URL 'https://mirrors.nics.utk.edu/cran/bin/windows/contrib/3.3/zoo_1.7-13.zip'
     Content type 'application/zip' length 898657 bytes (877 KB)
    downloaded 877 KB

     package ‘zoo’ successfully unpacked and MD5 sums checked
     Warning: cannot remove prior installation of package ‘zoo’

      The downloaded binary packages are in
        C:\Users\nfoley1\AppData\Local\Temp\Rtmpoh9cAa\downloaded_packages
      > library(zoo)
      library(zoo) : there is no package called ‘zoo’

What gives? Why cant i install and have R find my package zoo",Cant download this R package...wasted a complete day of work.,56daco,top
Anyone have experience using the ODBC connectors here? how difficult is it,Can R pull from Oracle OBIEE?,55tvhs,top
"I am required to create a classfication tree for german credit data and extract data from it. Problem is, my code for the tree is not working. can someone assist me?

here is my code:
german_credit = read.table(""http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data"")
german_credit_sample = sample(nrow(german_credit), nrow(german_credit) * 0.8)
> german_credit_train = german_credit[german_credit_sample, ]
> german_credit_test = german_credit[-german_credit_sample, ]
install.packages(""rpart"")
library(rpart)
credit.rpart <- rpart(formula = Y ~ . - id, data =
+ german_credit_train, method = ""class"",
+     parms = list(loss = matrix(c(0, 10, 1, 0), nrow = 2)))
Error in eval(expr, envir, enclos) : object 'Y' not found
> ",Problem creating classification tree for my data,5346oa,top
I'm still a bit confused to be honest why and how one would use dcast(). Thank you for any help!,Could someone offer an example how and why to use `dcast()`?,52mndu,top
"I'm pretty new to R and bioinformatics. I'm currently doing cancer research that requires me to learn both. My issue is with the Significance Analysis of Microarrays, or SAM, which I'm using on microarray data to find differentially-expressed genes between healthy individuals and pancreatic cancer patients. Previous people in my lab ran a two-class unpaired SAM with a targeted false discovery rate of 5% on the same data. Their results demonstrate around 200 genes unregulated and 500 downregulated. However, when I ran a similar analysis with the code I have pasted below, I got a wildly different result (70 genes up, 1100 down.) How can the results be so different with the same data and analysis method? Is there some parameter that can cause such a wild fluctuation in the results? Additionally, is there another way to find differentially-expressed genes between two populations that is fairly reliable?

I'm aware this question may be a bit vague, and it is unfortunate that I can't share the data. Let me know if there's anything else I can clarify. 

Code obtained from this website (https://github.com/MikeJSeo/SAM): 

library(shiny)
library(shinyFiles)
runGitHub(""SAM"", ""MikeJSeo"")

Thanks guys. ",problem running significance analysis of microarrays (bioinformatics) - please help,50f7nq,top
"https://cran.r-project.org/

http://swirlstats.com/students.html

Are there any better online taught courses that aren't too much money that would provide me the background needed?","Is ""r-project.org"" enough to get certified?",4za8by,top
I'm looking for examples of polished r in online publications for examples of what the industry techniques and standards are. For example: fivethirtyeight.com,What online publications use r?,4ygxgt,top
"Hi, I'm currently reading (and doing) ""R for Data Science"" by Hadley Wickham and I'm stuck at the downloading package intro section.

I can't even google for the modelr package. It's not in cran either. Google keeps on pointing the the caret package which have a wonderful webpage.

Any help is much appreciated.

Thank you!!

Book links:

http://r4ds.had.co.nz/introduction.html",package ‘modelr’ is not available (for R version 3.2.4),4y9c34,top
"I would like to do Gibbs sampling with R, but I suspect there may be even more efficient solutions I am not aware of. 

What do you recommend? ",What are the best MCMC options for R?,4wtyqn,top
Does anyone know any good forecasting in R books that preferably use the 'forecast' library? I know R at a rookie/intermediate level. I need to forecast sales by month with seasonality. I see a lot of books on Amazon but they are fairly dated and some have low ratings. ,Forecasting in R Book Recommendations,4uiw3w,top
"


I've been trying to automatize part of my workflow with R. Periodically I have to use transformations in the datasets I am working with. 

I have already created a small function that uses optional arguments, so that one can transform all or part of the columns of the passed dataframe.

The function looks like this now:

    # Function:
    #   transformDivideThousand(dataframe, optional = vectorListOfVariables)
    #
    # Definition: This function applies a transformation, dividing variables by
    # 1000. If the vector is passed it applies the transformation to all variables
    # in the dataframe.
    #
    # Example: df <- transformDivideThousand (cases, c(""label1"",""label2""))
    #
    # Source: http://stackoverflow.com/a/36912017/4417072

    transformDivideThousand <- function(data_frame, listofvars){
        if (missing(listofvars)) {
            data_frame[, sapply(data_frame, is.numeric)] =
                data_frame[, sapply(data_frame, is.numeric)]/1000
        } else {
            for (i in names(data_frame)) {
                if (i %in% listofvars) {
                    data_frame[,i] = data_frame[,i]/1000
                }
            }
        }
        return(data_frame)
    }

Ok, now I face a problem where I have to apply a fairly complex transformation. This time it should:

1. reflect the scores stored at the variables (ie, find the largest value and subtract it from all the other values);
2. Sum one to the resulting score;
3. Square root the resulting score;
4. De-reflect the scores (now sum the same value it was subtracted with in the first step)

All this should happen maintaining the ability to run the function in all or in part of the columns of the given dataset.

I found a way of creating a subset of the dataframe with the largest values at [SO](https://stackoverflow.com/questions/24212739/how-to-find-the-highest- with the largest values at [SO](https://stackoverflow.com/questions/24212739/how-to-find-the-highest-value-of-a-column-in-a-data-frame-in-r) with a small function:

    colMax <- function(data) sapply(data, max, na.rm = TRUE)

But I am running in all sorts of problems while applying it in the transformDivideThousand.


## Question

I would appreciate pointers as to how to achieve this rather complex, multitask transformation in one function. I am not looking for code, only pointers and suggestions.

Thanks.",Help with a function to perform complex transformation in a dataset,4u0lme,top
"Just started in R, and my summer work (research assistant) gave me some data to play around with. I've made a file with the date, min, max and avg temperature for the date in excel. I want to  make a graph comparing the water temp values from years past. The x-axis will be 1-365, and the y will either be daily temperature min, max or average (I want to make three graphs at once). As well, I want each year to be separate in the graphs by year, probably by colour (ex: 15133, 14133, are the 133rd day of their respective years, and have the same x value, but will be different coloured for their yr 15&14). Any guidance/referral to tutorials to help me with is would be greatly appreciated.","Need some help, a little over my head",4tylc8,top
"First off, I should state that I'm using Auburngrad's branch of ggmap, where he adds API key functionality in geocode(): https://github.com/Auburngrads/ggmap

To be more specific: https://github.com/Auburngrads/ggmap/blob/master/R/geocode.R#L104

Here is the line I'm using

    mutgeo_leadsDF <- mutate_geocode(mut_leadsDF, Address, source = ""google"", key = ""API_KEY"", override_limit = TRUE)

where I replace API_KEY, with my API key, of course. It keeps throwing me the max limit exceeded error after successfully geocoding a hundred rows or so (my dataset is over 8000 rows). I've enabled billing on my geocoding API and everything looks good in the API console. 

Can someone please help me out!?",ggmap: I keep getting blocked by Google's API limit even though I've acquired a key and am passing it in,4ttjaz,top
"What is the best way/package to read large Microsoft Access files (.accdb) stored locally in r, and then manipulate/join/query the data?",Microsoft Access files in R,4ti3lw,top
"Hello all, 
I'm messing around with some of the new Spark functions with R (Sparklyr mostly) and wanted to mess around with some subreddit data. I was wondering if was possible to extract JSON / XML data for individual subreddits and how one might start doing such a thing. ",Reading API from R,4thk2c,top
I was reading [this](https://www.quantamagazine.org/20160712-hyperuniformity-found-in-birds-math-and-physics/) and wanted to check its properties. Any idea how to produce it using R? (or any other way)?,Does any one know how to produce hyperuniform distributions using R?,4su9gk,top
"Hello, I am trying to use the following two functions on a series of economic data:
 1)  Year over year percentage change 
 2)  Year over year difference change 

The second one is the one I'm having the most trouble on. Any help would be appreciated. I am a bit lost figuring out what package or steps to take for this task. 
",Question-trying to run a few functions on a economic series. Having some trouble finding my way around.,4o9sdp,top
"Hi all,

I'm trying to make a graph that looks like this:
http://imgur.com/zG4oEyO

A grid with colored squares, 12 per year in that example. It's rather common but I don't know the name of this kind of graphics so I have a hard time finding solutions. I looked into the qqplot book but I haven't found any ready made solution.
Anyone knows how these are called or what package can produce these in R?",Grid plotting with ggplot or others,4mazzd,top
"Hello all, 

I'm trying to write a for loop, but am having some issues. I have a series of factor variables, *question1*, *question2*, ... *question18*. I would like to simply make a copy of each variable. I could do 
    question1_copy <- data$question1
for each of the 18 variables, but I would like to do this in a loop. 

But I can't seem to figure out how to do it. For example, in STATA, I could say:

     forvalues i =1/18{
          gen question_copy`i' = question`i'
     }
Where what's in-between the tick/apostrophe thing appends the current value of i to the end of question. Is there an R equivalent of the ` ' command that appends a value to the end of a variable name?

Thank you
",Create new variables within for loop,4m357a,top
"Hi I have a dataset that is formatted like so:

CustomerID | DateID | Purchase Amount
:--|:--|:--
1|1|125.02
1|2|140.31
1|3|170.66
2|1|110.11
2|2|160.34
2|3|190.98
3|1|64.75
3|2|75.88
3|3|82.93

However, in my dataset there are thousands of customers and hundreds of days per customer.  I'm trying to create a regression for each customer and store the resulting coefficients in a dataset at a customer level.  

Every example I have found has been dealing with multiple independent variables, but never multiple regressions for many subsets of the data. 

If anyone could help I would greatly appreciate it!",Multiple regressions from one dataset?,4m13uw,top
"Hi there, I've been lurking forever but can't figure this out so I made an account. I am trying to create a RP tree using rpart. My data frame is 502 columns long and I basically need the formula to read:

rpart(COL2~[Here I need columns 3 through 502],method=""anova"",data=MyDataFrame)

I just can't figure out how rpart wants me to notate the right side of the formula argument without typing out COL3+COL4+...+COL501+COL502.

I have read through the documentation and haven't been able to find what I am looking for. Any help would be greatly appreciated!


",Need help with rpart package! Can anyone help?,4llfo9,top
"I have a vector:
v<- c(""A23C9320"",""A49B4820"",""X17R3920""...)
I need to substitute numbers for the alpha characters such that:
A = 11, B=12, C=13... and then convert each element of v to an integer. 
My first strategy has been to use strsplit(v,null) and try to match the alpha characters to a elements of data frame where:
df<-data.frame(alpha=LETTERS,val=seq(11,36),stringsAsFactors=F)
So far I've spent a lot of time trying to match with grep, which, and %in%, trying to match elements of v to with df[1,] and assign the value of df[2,]. There must be more efficient ways to accomplish this. ",Character String Manipulation/Substitution- I need to convert alpha element of char strings to numerals and then each string to an integer.,4lbpqc,top
"So I'm predicting some stuff (stock price up/down move), but I'm running into some kind of bug or error on my part here calculating the AUC.

    >library(pROC)
    > test_upmove
    [1] 1 0 0 0 0 0 0 0 0 0 0 0
    > predicted_classifier
    [1] 0 0 0 0 0 0 0 0 0 0 0 0
    > auc(test_upmove, predicted_classifier)
    Area under the curve: 0.5

test_upmove are the 'actual' upmoves from the data.

predicted_classifier are my own predictions according to my model.

To me it seems that it does a reasonable job. But when I calculate the AUC I get 0.50! That is (as far as I am aware) not better than random. 

I would love a second pair of eyes. ",Calculating AUC bug?,4kafth,top
"Hi reddit,
I am  tryging to estimate Beta for my CAPM model. Do you know how can i make an estimation of Beta using linear regression with GARCH effect ?  For example Apple with sp500 ?
We can make it simple by typing:
reg = lm(return.aapl~return.sp500)
But how can i use linear regression with GARCH effect ?",linear regression with garch,4kaevv,top
"Teaching myself R instead of using stata for an econometrics class. I tried googling this issue but couldn't find anything that helped.

This code:

log.reg2=loglin(price/1000 ~ livarea + beds + baths + lgelot + age + pool + liv.lot)

gives me this error message:

Error in loglin(price/1000 ~ livarea + beds + baths + lgelot + age + pool +  : 
  unused argument (data = stockton4)

I didn't encounter this error when I ran linear regressions with this same structure (with ""lm"" instead of ""loglin"").

What am I missing?","Log-linear Regression Troubleshooting -- ""unused argument""",4iyve6,top
"my csv file has the following columns:

> names(data)

> [1] ""Day""           ""Month""         ""Year""          ""PM10""         

and i need all the PM10 data from months 5-9. (for all years)
How do I extract the right data, ignoring months 10-4? 

I could go into the csv file and just delete all the wrong months but that seems like cheating!! haha!! 

Thank you Reddit.",extracting specific data from a csv file,4im2yl,top
"Hello All,
I keep getting this error:
Error in `[.data.frame`(tuneAcc, , params, drop = FALSE) : 
  undefined columns selected

Here is a screen shot of both my lines of code and my actual data set: 
 http://imgur.com/a/eYQAB

Does anyone know what I am doing wrong? All of the data is clean and scrubbed -- there are no 'null' or blank cells.",Error in `[.data.frame ??,4h2980,top
"Hi there,

I'm brand new to R. I found the systemfit package, which returns estimates of systems of equations. I've read the [man pages](https://cran.r-project.org/web/packages/systemfit/systemfit.pdf) for systemfit, but the examples did not help me because I cannot deduce the system of equations being inputted as I don't know the structural syntax of R. If the man pages wrote their examples in ""plain math"" first and code second, I'd understand it.


Just as an example, let's say I have this very simple system of equations:


    1*a + 0*b + 0*c + 0*d = 5
    0*a + 1*b + 0*c + 0*d = 10
    0*a + 0*b + 1*c + 1*d = 15


How would I construct the variable names, coefficient matrix, and value matrix in R, and then input this into systemfit()?


Thank you so much.",Syntax for SystemFit package (Estimating Systems of Simultaneous Equations),4frm1j,top
"Hi guys,

I have to find out how to solve this:
I have a data set which contains information about torrents with around 10 attributes and a few million rows. Some of them are numbers, some of them are text, for example file size is an integer type. But most of them are text. Text attributes which have low amount of distinct values and are short (1-3 words) might be considered as a factors, so there are no problems with that. In that case i would try apply logistical regression or decision tree models.
I have to create a model, which would classify records to ""Useful"" and ""Useless"". Useless records for example would be considered torrents with too low file size, file name would contain such words as porn, xxx and so on.
The problem is that i don't know how to use text variables in the model such like torrent page title or file name, which contain many words.

Are there any packages or methodologies which would help me to solve this?
Basically, all information would be useful, what packages would be useful, maybe there is a term, which would describe this problem, so this would help me to search for articles.

Thanks,
Justinas",Text mining with R,4et2jg,top
Just curious what laptops you all use when you handle big R data sets and data mining. I am using a zbook by HP but may be looking to upgrade. I have done some with Macs but would like to stay with Windows based. ,What laptops are you using?,4edzfz,top
"All,
I am trying to transpose a data frame called weekend_8 and then sort it largest to smallest. The dimensions are 50x8 and I want it 8x50, largest to smallest. I then want to view my data frame. Seems basic--

>>t(weekend_8)


>>View(weekend_8)

When I run this command, it obviously doesn't sort largest to smallest. What is the command for this? Secondly, when I look at the View, it isn't transposed. Why is it reverting back?",transpose a data.frame issue?,4dor7x,top
"Been a little stumped with how to proceed with this one.

I want to use ggplot2 to make something like [this](http://imgur.com/QXLanLr.jpg)

Thanks for reading.",How do I make a bar chart like this pic - with positive and negative values?,4dn04q,top
"Hello All,
I am trying to run a probability/odds model on 'acceptance' given a subjects variables. This is my data set: http://www.ats.ucla.edu/stat/data/binary.csv

I have everything built, but I think R maybe interpreting a class rank of '4' higher (or better) than a rank of '1'. Does anyone have any suggestions? The range of ranks is 1 through 4 so I was thinking of making a new column called 'rerank' and run the equation '5 minus rank' and then have my model exclude the 'rank' column. In other words, if your rank was 1, your new rank would be 4. I have a feeling there is a much better way of doing this. 

Lastly when I run my log odds, I am getting a -0.75. Not sure what that means when a log odd is negative. Ideas?

Thanks much for any advice and or help you can offer. ",Ranking suggestions,4c39od,top
"the r-project.org tls certificate appears to have expired today, 3/10/16. Is this a major vulnerability to the whole R ecosystem? Does anyone know who to reach out to at the foundation to get this fixed?",r-project.org TLS certificate expired today,49vjut,top
"I have 4 data frames I want to merge.

1 has 500K rows and shares an ID column with 2.

2 has 65K rows and shares one ID column with 1, another with 3, and another with 4.

3 has 2.5M rows.

4 has 500 rows.

Is it possible to merge these frames?  Is there anything I should watch out for or be sure to do?",noob question about merging data frames,49e09r,top
"I have some notion of what PCR is and I kinda know how it works. But the output from `pcr` function is a bit confusing for me. I don't know if PCR has some hypothesis testing on regression parameters, if is it is meaningful since the regression is done on principal components. I also had trouble finding something akin to R^2. Can anyone explain that output to me? Thanks

edit: here's sample `summary` and `str`: http://pastebin.com/3WyDhj9E",Interpreting results of `pcr` from `plsy` package. (Principal Component Regression),496zhm,top
"I don't know if this is a unique problem, but I'm having difficulties keeping track of solutions for that I have created from past analyses longer than 2 years old.  

Currently, I collate old scripts in a single folder and do a generic search across them through R or Bash. However, it is still rather time-consuming, especially when it is hard to recall specifically what to search for, or when the scripts were inconsistently commented (collated from co-workers, or functions from different packages). Building a personal repo is potentially possible, but it feels awfully painful to start everything from scratch, especially for analyses I rarely conduct, like artificial machine functions such as  ANN, GA/GP, Random Forest just to name a few.

So I'm just wondering if you have a better long-term storage solution for keeping R-scripts or script snippets. Hopefully there is something that allow more intuitive commenting and won't feel like starting over from scratch.",Long term storage and search of R-script and custom function,46i9u8,top
"Hello all,

I was wondering if anyone knew a good way to run R code over a grid of machines?

For example, needing to run R statistics over 80000 stocks -> it's obviously a lot faster if it can be run in parallel.

Anyone able to recommend some possibilities there?

Thanks.",Distributed Computing R,467mcv,top
"I want to create an S4 class to hold a set of data. I currently have the data held in a list of lists. Each sub-list has the same structure and looks something like this:

    [[1]]
    [[1]]$filepath
    [1] ""~/path/to/file""

    [[1]]$sample
    [1] ""Sample1""

    [[1]]$compound
    [1] ""Compound1""

    [[1]]$intensity
    [1] 42.61 43.11 43.61 44.11 44.61 45.11 45.61 46.11 46.61 47.11 47.61 48.11 48.60 49.10 49.60 50.10 50.60 51.10 51.60 52.10 52.60 53.10
    [23] 53.60 54.10 54.60
    
    [[1]]$rt
    [1]  64462  67255  65674  73225  73217  71455  77020  72577  74770  75669  72119  75187  72634  75526  75896  80630  82754  87253  95377
    [20]  94302 106255 104502 103138 104135 

This format could easily be made into an S4 class. But is it possible to create an S4 class that holds all of these objects. Is this bad practice? If so, how could I set up my S4 class to hold this data in a sensible way?

Thank you very much in advance to everyone who responds.",S4 classes: Question about the setting them up.,441i0k,top
"My data frame has 1000 rows and 3 columns (that are relevant to the situation.

I want to delete all the rows that have the same value in any of the three columns

Here is my code

    for (i in 1:nrow(dataname)) {
        if (a==b|a==c|b==c) {
            dataname = dataname[-i,]
        }
    }

I keep getting error for ""missing value where True/false needed"" on the if statement.",Problem with deleting a row in a loop,40f0pq,top
"Hi,

I am new to R, and need to figure out how to begin running ARIMA analysis in it. Any of yous guys know a good starting point? Also, anyone have any ready made script you can point me to?",ARIMA in R,3ypzk0,top
"So I have some tables such as 

> baz
, ,  = I1

           
               D    E    F    G    H    I    J
  Fair         4    9   35   53   52   34   23
  Good         8   23   19   19   14    9    4
  Ideal       13   18   42   16   38   17    2
  Premium     12   30   34   46   46   24   13
  Very Good    5   22   13   16   12    8    8

, ,  = IF

           
               D    E    F    G    H    I    J
  Fair         3    0    4    2    0    0    0
  Good         9    9   15   22    4    6    6
  Ideal       28   79  268  491  226   95   25
  Premium     10   27   31   87   40   23   12
  Very Good   23   43   67   79   29   19    8

In order to do stratification I need to make them into a matrix, not a problem. However, when I do this it makes the order wrong by row  matrix=4,8,13, when I need it to go matrix=4,9,35.

I tried transposing it and byrow=FALSe but neither works. 

Code is

foo<-table(d$1,d$2,d$3) and then I need to do something like 
t(foo)
bar<-matrix(foo)",Help making tables into correctly ordered Matrix,3vs472,top
"If I had the csv below, and needed to rename the highest ranking ""Blue"" team in each row how can I do this. Over 100,000 rows in the full data set. 

E.g if ""Blue Team B"" is 4th and ""Blue Team A"" is 6th, I want to rename ""Blue Team B"" as ""Blue Winner"" for example.

Position 1,Position 2,Position 3,Position 4,Position 5,Position 6
Blue Team B,Red Team 1,Green Team 1,Blue Team A,Red Team 2,Green Team 2
Red Team 2,Green Team 2,Green Team 1,Blue Team 1,Blue Team 2,Red Team 1
Green Team 1,Red Team 1,Green Team 2,Blue Team B,Red Team 2,Blue Team A
Green Team 1,Red Team 1,Green Team 2,Blue Team A,Red Team 2,Blue Team B
Blue Team B,Red Team 2,Blue Team A,Green Team 1,Red Team 1,Green Team 2","Find and Replace across multiple rows, ended up using excel :( but would still like to know how!",3uvqtu,top
"I'm using the UScensus2010blkgrp package, which contains SpatialPolygons for each census block group, and I need to match long-lat coordinates to their census block group. I've been trying to use the over() command from the sp package to find the block group:

    pt <- data.frame(Longitude = -81.699427, Latitude = 41.506181)
    coordinates(pt) <- ~ Longitude + Latitude
    over(pt,ohio.blkgrp10)

But this gives the error message:

    Error: identicalCRS(x, y) is not TRUE

Does this mean I've coded the coordinates wrong or am I not using the right function?

EDIT: Nevermind. I found an easier to use polygon file directly from the [Census Bureau](https://www.census.gov/geo/maps-data/data/cbf/cbf_blkgrp.html). All I had to do is:

    oh <- readShapePoly(""cb_2014_39_bg_500k.shp"")
    over(pt,oh)

and it gave me the info I needed.",Matching long-lat coordinates to census block group,3sxta1,top
"I'm trying to implement a NB classifier in R by recreating the results of data given to me. Right now I'm simply testing on the training data itself, to see what the accuracy is like.

There are 29 variables in the dataset, one of which is called ""Status"". It has two values, Win and Lose. I've split the training data into 2/3 training, 1/3 testing. I think I understand the error, in so much as ""Win"" and ""Lose"" aren't numeric values, but as I understand it, would they not be factors? I'll post my code below. I'm using the bnlearn examples from  http://www.bnlearn.com/documentation/man/naive.bayes.html as my bases for this. 

If anyone could offer advice on this, I'd really appreciate it.

    ##Read in training data
    trainingdata <- read.csv(""C:\\.....filepath.csv"", header=true"")
    
    ##split data into training and test sets
    training.set = trainingdata[1:1200, ]
    test.set = trainingdata[1201:1860, ]

    ##Train model
    bn = naive.bayes(training.set, ""Status"") **this is where I start getting the errors**
    fitted = bn.fit(bn, training.set)

    ##Predict
    pred = predict(fitted, test.set)
    table(pred, test.set[, ""Status""])","Trying to do a simple Naive Bayes classifier using package ""bnlearn"". Keep getting error ""variables must be either numeric, factors or ordered factors""",3sabrv,top
"Ok, so I'm a noob and this is pretty simple: we have Likert-scale survey data, where students choose either ""Strongly Disagree"", ""Disagree"", ""Agree"", or ""Strongly Agree"" to a series of statements. The results have each question as a column and each student's response as a row. I just want a table that says Question 1-Question 6 for the columns, Strongly Disagree-Strongly Agree for the rows (or vice versa, I suppose).

I could do this in Excel, but fuck that. I want to use what I've been learning in R.

And I was so close! I did this:

>survey <- read.csv(""survey.csv"")

>results_table <- data.frame()

>for (i in 1:6) {
>results_table <- rbind(results_table, table(survey[,i]))}

And this was working! I was so proud of myself! But *one* of the rows in my results table was off: I realized it was because responses to that question did not have any 'Disagree's, so the table from that variable only had three...variables, so the final numbers got wonky. 

Any suggestions on how to fix that problem, or easier ways of going about all this, would be much appreciated.

Thank you all!",Using R to analyze survey data,3rspig,top
"I am dealing with absolutely massive ff data frame so I am going to use an example of what I need to accomplish for simplicity’s sake. Let’s say that I have an ff data frame containing a column for a timestamp and a second column describing how many users where on a network during a specific time interval as shown below:
                                              
  timestamp user_quantity                
        1             3                       
        1             5                   
        1             4                   
        2             7                 
        2             8                  
        5             7                       
        7             8                          
       11             1                           
The timestamp column is already ordered so if it were a normal data frame it would be easy to just say:              
                                                      
Timestamp_partition <- split(data,data$timestamp)                 
                                         
Unfortunately I have to use an ffdf. How can I split the ffdf using ffdfdply (or some alternative method)? My current problem with ffdfdply is I just want to save the partitioned bits into ffdfs with a naming system I can understand (data_partition_1,data_partition_2,…). For example:                  
                                                                
> data_timestamp1                              
  timestamp user_quantity                               
        1             3                             
        1             5                               
        1             4                           
                                            
> data_timestamp2                             
  timestamp user_quantity                            
        2             7                               
        2             8                               
...etcetera                             
                                        
Can anyone please provide guidance? I am sure there is a simple solution I just don't understand at the moment. Thank you for your time.",How to use the ffdfdply function to partition and save each of the partitioned ffdfs,3r4muf,top
"I'm trying to find the most efficient way to calculate a % change from one period to the next in a long data set. Here is an example of the format:

    set.seed(1234)
    df <- data.frame(Date=c(2001:2010),CompanyA=rnorm(10,0,1),CompanyB=rnorm(10,1,2),CompanyC=rnorm(10,-1,2))
    longdf <- melt(df,id.vars=""Date"")


What I want is to add a 4th column which shows the % change in each company's score from one period to the next. 

I can create this column by using the following code:

    for (c in unique(longdf$variable)) {
      for (y in unique(longdf$Date)[-1]){
    longdf$change[longdf$variable==c & longdf$Date==y] <- (longdf[longdf$variable==c & longdf$Date==y,""value""]-longdf[longdf$variable==c & longdf$Date==y-1,""value""])/abs(longdf[longdf$variable==c & longdf$Date==y-1,""value""])
      }
    }
    longdf

The problem with the above code is it seems extremely inefficient. The data frame I'm working with is going to have millions of rows. Is there a more efficient way of creating a % change column for longform data?
",Assistance with a % change column in long form data,3piq14,top
"So I am an IT Technician at a college. I am trying to install Rcmdr on a Windows 10 Machine.  I have tried multiple times using   -   
install.packages(""Rcmdr"", dependencies=TRUE)  and I get nowhere. I keep getting an error that it can not load package ""car""  I have installed it and I get the same error. 

-Loading required package: RcmdrMisc
Loading required package: car
error in loadNamespace (i, c(lib.loc, .libpaths()), versionCheck = vI[[i]]) : there is no package called 'Rcpp'
error: package 'car' could not load 

We don't use this program and other professors do. We have no training in it. If anyone could hel it would be appreciated. 

**EDIT:** Go ahead and assume I did every normal trouble shooting step. I did. It saves time this way. I think I have an idea of what it might be though after trying to replicate on my personal Windows 10 machine. I am pretty sure somewhere along the install the path directories got mixed up so it's installing packages to one place but trying to pull them from an other. 

**EDIT 2: SOLUTION**  So I have no idea why but I managed to figure out what was happening. For some reason, unknown, when installing the packages through the string they would not go to the directed folder. The packages and dependencies however did download into a temp folder under appdata (R told me this the entire time)  So once I realized the packages weren't installing at all and just being downloaded I unzipped them and put them in the correct folder. 

**TL;DR Solution** For some reason it was forcing me to install manually. 
",HELP! Trying to install Rcmdr,3oi27e,top
"full disclosure, this is homework.    
    
I'm evaluating the performance of a few classification algorithms, with this function I wrote:    
   

    evaluate <- function(fit, test_set, correct) {
        #evaluares the performance of a fit
        pred <- predict(fit, test_set, type=""class"")
        cm <- confusionMatrix(pred, correct)

        cat('\n')
        print(cm)
    }
 
and this gives me some data that I am interested in:    

    Confusion Matrix and Statistics

            Reference
    Prediction   setosa versicolor virginica
    setosa         37          0         0
    versicolor      2         27         1
    virginica      11         23        49

    Overall Statistics
                                        
      Accuracy : 0.7533        
      95% CI : (0.6764, 0.82)
      No Information Rate : 0.3333        
      P-Value [Acc > NIR] : < 2.2e-16                                       
      Kappa : 0.63          
      Mcnemar's Test P-Value : 2.97e-07      

    Statistics by Class:

                         Class: setosa Class: versicolor Class: virginic
    Sensitivity                 0.7400            0.5400           0.9800
    Specificity                 1.0000            0.9700           0.6600
    Pos Pred Value              1.0000            0.9000           0.5904
    Neg Pred Value              0.8850            0.8083           0.9851
    Prevalence                  0.3333            0.3333           0.3333
    Detection Rate              0.2467            0.1800           0.3267
    Detection Prevalence        0.2467            0.2000           0.5533
    Balanced Accuracy           0.8700            0.7550           0.8200

Now I want to find the average Pos Pred Value and Specificity, but can't figure out how to access that data. I know the confusion matrix has an attribute called $byClass, but I don't know how to parse cm$byClass to make the specific rows available. And those weird PDF documents don't really help. How does this work?   
    
And seriously, why is all the documentation in PDFs? ",How do I access the attributes and values of my ConfusionMatrix?,3o8w5g,top
"New to reddit, R, and Imgur so I apologize for formatting/image issues. 

I am trying to create barplots of means with sem bars. I have been able to use the following code:  
    
    cdataDis1<-ddply(MyData, c(""Level.f""), summarise,  
                 N=length(Dis1),  
                 mean=mean(Dis1),  
                 sd=sd(Dis1),  
                 se=sd/sqrt(N))  
    ggplot(cdataDis1, aes(x=Level.f, y=mean, width=.9))+  
      geom_bar(position=position_dodge(),stat=""identity"",   
    colour=""black"", size=.3)+   
    geom_errorbar(aes(ymin=mean-se, ymax=mean+se),    
                width=.2, position=position_dodge(.9))+    
      xlab(""X Label"")+    
      ylab(""Rating"")+    
      ggtitle(""Title"")+    
      scale_y_discrete(breaks=0:10*1)+  
      expand_limits(y=c(0,10))+  
    theme_bw()  

to get this sort of barplot http://i.imgur.com/6ViMvnt.jpg

Now I need to be able to get that barplot for 4 different X variables; they are all ratings from 1-10. My variables are in a CSV file with Level (1-4) as a column and then each of these four variables as its own column. I understand how to use the ""fill"" option in the code above to create the levels, but my x axis is actually 4 different x variables. How can I adjust my data so that I can plot it to get something like this [Imgur](http://i.imgur.com/hK3OpdX.png)  ? I've seen examples with short lists put into matrices but I need to be able to pull hundreds of trials from a CSV file. 
Thank you!",Plotting multiple barplots on same plot,3mdcsj,top
I'm looking for a package that contains a Twitter dataset. Does anyone know of one?,R datasets: Twitter?,3m38w8,top
"I am trying to create a histogram from a dataset with two categories:

    Treatment | Rainfall
    Unseeded  | 1202.6
    Unseeded  | 830.1
    Seeded | 372.4
    Seeded | 345.5
    etc. etc.

I only want to create a histogram of the ""Unseeded"" values. 

Currently my code is just:

    #case0301 is the dataset
    #Rainfall is the numerical variable
    #Treatment is the ""Unseeded, Seeded"" category
    hist(case0301$Rainfall, freq=FALSE,br=75)

How do I go about creating a conditional statement to only plot the Rainfall values if Treatment = Unseeded?",Creating a histogram from dataset,3l7x8b,top
"Anyone have any pointers on importing SQL dump files into R?

I've looked at the files with [The V File Viewer](http://fileviewer.com/) and the first 45 lines look like the SQL statements to pull the tables.  On the data portion of the file, each line starts with INSERT INTO...VALUES.  Each line has a ton of records.  Each record is separated by parenthesis and the individual fields are separated by commas.  

Any help is much appreciated!   ",Reading SQL dump files into R,3ji1f0,top
"I am trying to install the Quandl API in R following: https://www.quandl.com/help/r

However, I get this error (first line is the code, the rest is the return):
> install_github('quandl/R-package')

>Downloading github repo quandl/R-package@master

>Installing Quandl

>""D:/Program Files/R/R-3.2.1/bin/x64/R"" --no-site-file --no-

>environ --no-save --no-restore CMD  \
  INSTALL  \
  >""C:/Users/Tommie/AppData/Local/Temp/RtmpqyX55V/devtoolsecc5db27bc9/quandl-quandl-r-8f17669""  \
  --library=""D:/Program Files/R/R-3.2.1/library"" --install-tests 

>'D:\Program' is not recognized as an internal or external command,

>operable program or batch file.

>Error: Command failed (1)

Help?",Help installing the Quandl API: error,3je7fn,top
"I have a text file that is organized oddly from a tool output. Basically there are sections of the file with parseable data separated by a name for each group. The name is in a line thats basically 

=========== groupname =============

data here


=========== group2name =============


Right now I have a functional parser that subsets the ""block"" per group and parses it with a for loop. 

    blah <- readLines(filename)
    block <- blah[SubLines[i]:SubLines[i+1]-1]  

where SubLines is a list of the ""groupnames"". Than I have a bunch of random regex subs to cleanup my oddly formatted data into a dataframe. 


The question I had was how can I do this without the if loop with like an lapply... only issue is I am kind of new and dont know how to do this properly. Basically I want to be able to feed in the text file, parse/cleanup by each groupname, than combine the output into 1 table. ",[Text parsing help] Parsing a file with several groups of usable data,3iruon,top
"I have three .R files which use 5 .RData data files to run the entire program. 

What is the preferred method R programmers use to run such files? 

Couldn't I just run these on my terminal? ",Easiest way to run a series of .R and .RData files without downloading external IDE like RStudio?,3iq6gp,top
"I've got a data set with sigmoidal character and I'm trying to fit it using nlsLM function which I've used in the past. Apparently I'm a tad rusty though. 

This is the error I'm getting:
Error in nlsModel(formula, mf, start, wts) : 
  singular gradient matrix at initial parameter estimates

And this is what is somehow causing it:
fit <- nlsLM(y ~ (((Fh-Fl)*(x^ a) +
                     Fl*(pka+x)^ a)/
                    ((pka+x)^ a)),
             start = list(a=1),
             control = nls.control(tol = 1E-5,
                                   minFactor = 1/1024, 
                                   warnOnly = TRUE))

I'd appreciate any feedback you may have. I'm kinda stuck on this til I(we) figure it out. 

Thanks!",Looking for some help with nonlinear least squares regression,3ihocz,top
"I was debugging some code and I found the following weirdness:

    > a
    [1] -0.007777519
    > b
    [1] 0.09980119
    > a ^ b
    [1] NaN
    > -0.007777519 ^ 0.09980119
    [1] -0.6158904
    > class(a)
    [1] ""numeric""
    > class(b)
    [1] ""numeric""

Why the hell does ""a ^ b"" result NaN? I can't figure it out",Why is this returning NaN?,3hxx3m,top
"I have a data frame with gender specific information and I need to calculate a t-test for each gender based on each variable.

So for example if I have a data frame of:

    sex age height weight 
    
    M    1     1         1
    M    2     2         2
    F    2    2          2
    F    2    2        2

Although there are better options out there, the problem I have to solves EXPLICITLY says to use apply to calculate the T-Test between M and F for age, height and weight.  

First I tried splitting the data by gender and feeding that into an apply function:
    
    apply(split(data[,], data$sex), 2, function(x) { #calculate t test somehow})

but that clearly doesn't work, mostly because the split(data) doesn't have any dimension.

Then I tried this:

    apply(subset(Data, Data$sex == ""F"", 2:4), 2, function(x) {
     res = t.test(x)
     return(res)
    }

Which works only on one subset of data and I need both.  I'm not sure how to do a columnwise t-test for both the females and males in the data set.  A similar example that's shown in the book uses a lm() function:

    r = apply(painters[,1:4], 2, function(x) {lm(x~ School, data=painters) 
   }

but this wouldn't work for the t.test, seemingly. 

EDIT: I figured it out, somewhat:

   apply(cholData[,2:12], 2, function(x){
      res = t.test(x ~ sex, data=cholData, na.rm=TRUE)
      return(list(F.mean=res$F.mean, M.mean=res$M.mean, t= res$statistic, df = res$parameter, p=res$p.value))
})",Use apply to calculate a columnwise t-Test,3hjm6x,top
"
Hi, I'm studying statistics and probability and I'm learning the R language at the same time. I'm having a hard time understanding how R can help solve probability problems. Here is an example problem I'd like to solve with R. This is not a assignment, it's just a problem I created to try and formulate an example of what I'd like to be able to accomplish.

------
Jack would like to know the probability of finding a new 2015 orange Mustang at one of the three Ford dealerships in his city. 

The Ford Mustang is one nine new vehicle models stocked by local dealerships. Orange is one six color options available by the vendor. For this excerise I don't care about the specifics of upgrades or subcategory (he doesn't care if it's a base model Mustang or a high end GT model).

The numbers we have:

Inventory by model 
------------------------
Dealer #1
Mustang   0.21
F150      0.12
F350      0.00
F450      0.00
Escale    0.13
Exploer   0.08
Edge      0.25
Flex      0.16
Fiesta    0.05

Dealer #2
Mustang   0.08
F150      0.25
F350      0.02
F450      0.02
Escale    0.13
Exploer   0.08
Edge      0.2
Flex      0.17
Fiesta    0.05

Dealer #3
Mustang   0.10
F150      0.20
F350      0.12
F450      0.00
Escale    0.13
Exploer   0.08
Edge      0.24
Flex      0.13
Fiesta    0.00

Dealers may have 2014 and 2015 new inventory.
Distribution by year
--------------------------------------------------

Dealer #1
2014      0.22 
2015      0.78

Dealer #2
2014      0.12
2015      0.88

Dealer #3
2014      0.15
2015      0.85

We do not have color distribution by dealership but from the vendor we have this infromation for 2014 and 2015

Color distribution by Mustangs sold in 2015
--------------------------------------------------
Red       0.17
Black     0.40
White     0.20
Yellow    0.15
Orange    0.06
Blue      0.02",Probability problems with R,3f1f6a,top
"Hey, all, 

I'm currently working on a project in healthcare and I need help opening a password-protected file in R. Due to patient data protection, we are looking for a solution to read password-protected Excel files in R. Does anyone know how one can read password-protected Excel files in R without leaving saved files on the computer after running the code? Thanks! ",How can I open a password-protected Excel file in R?,3dy5vl,top
"I am brand new to R and I am trying to create a graph that is basically a social network map. I have read a few things and have a very basic understanding of how it all works. Most of what is below is copy, paste and modify from tutorials.

I am very close. This is what I have so far:

    x <- read.csv(""matrix.csv"",header=TRUE,row.names=1,check.names=FALSE)

    network <- as.matrix(x)

    g <- graph.adjacency(network,mode=""undirected"",weighted=TRUE,diag=FALSE) 

    plot.igraph(g,vertex.label=V(g)$name,layout=layout.fruchterman.reingold, edge.color=""black"",edge.width=E(g)$weight)

The matrix.csv is a file like this (spaced for ease of reading)

    Name,  User1 , User2 , User3
    User1, 0     , 10    , 3
    User2, 10    , 0     , 5
    User3, 10    , 0     , 0

A weight of 10 represents an active friendship, 5 is requested, 3 is hidden and 1 is blocked.

Right now it works fine changing the line width depending on the weight, but what I would like to do is change the line color and style - green for active, green dashed for requested, black for hidden and red for blocked. I have control over the creation of the source data, so I can change the weights, or even the entire export format as needed.

One potential hurdle is that the data can have two weights for one connection. In the example above, User1 has hidden User3, but User3 has not hidden User1. I am not sure how to best deal with (or represent this), but I am happy to ignore it and make them both hidden in the source data if it causes problems.

Additionally, I would like to change the node size depending on how many active friends a user has. I haven't started looking into this yet, so any hints would be appreciated.

EDIT: I worked out how to change node size, but now the vertices (vertexes?) are too squashed together and some overlap or are even completely enveloped by larger vertices. All the while there is plenty of space around the edge for them to expand to.

Thanks!
",Changing line color based on weight in an adjacency plot.,3d5pjm,top
"I'm trying to use R to work with a trading API and I'm able to make GET request just fine, but when I try to make a POST request by sending a FIXML message I keep getting errors.

Here's the code:

    # Order Preview
    
    # Call the required packages
    library(ROAuth)
    library(RJSONIO)
    library(XML)
    
    # Set your application keys
    cKey <- 'xxxx'
    cSecret <- 'xxxx'
    oKey <- 'xxxx'
    oSecret <- 'xxxx'
    
    # Set the API endpoint
    tkURL <- ""https://api.tradeking.com/v1/accounts/xxxxxxxx/orders/preview.xml""
    
    # Create the OAuth connection - this is straight from the ROAuth documentation on CRAN 
    credentials <- OAuthFactory$new(consumerKey = cKey,
                                    consumerSecret = cSecret,
                                    oauthKey = oKey,
                                    oauthSecret = oSecret,
                                    needsVerifier = FALSE,
                                    signMethod='HMAC')
    
    # Update the connection so the handshake is TRUE
    credentials$handshakeComplete <- TRUE
    
    # Create FIXML
    doc <- newXMLDoc()
    root <- newXMLNode('FIXML', namespaceDefinitions = 'http://www.fixprotocol.org/FIXML-5-0-SP2',
                           newXMLNode('Order', attrs=c(TmInForce='0', Typ='1', Side='1', Acct='xxxxxxxx'),
                                   newXMLNode('Instrmt', attrs=c(SecTyp='CS', Sym='FAS')), 
                                   newXMLNode('OrdQty', attrs=c(Qty='1'))), doc=doc)
    newFIXML = saveXML(doc, encoding='UTF-8')
    newFIXML
    
    # Post order
    response <- credentials$OAuthRequest(tkURL, method = ""POST"", newFIXML)
    response


When I run this I get this error message back:

    ""<response id=\""-3491729f:14e4f104ddc:7f50\"">\n\t<type>Error</type>\n\t<name>ScriptFailure</name>\n\t<description></description>\n\t<path>/v1/accounts/xxxxxxxx/orders/preview.xml</path>\n</response>""
    attr(,""Content-Type"")
                                charset 
    ""application/xml""           ""UTF-8"" 
    
Any idea what I might be doing wrong?",Does anyone know how to implement a POST request using FIXML in R?,3bvt5x,top
"I am having difficulty installing the Rsymphony package on my Mac.

install.packages(""Rsymphony"")

Then I get this:

Package which is only available in source form, and may need
  compilation of C/C++/Fortran: ‘Rsymphony’
Do you want to attempt to install these from sources?
y/n:

After typing y, this happens:



installing the source package ‘Rsymphony’

trying URL 'http://mirror.las.iastate.edu/CRAN/src/contrib/Rsymphony_0.1-21.tar.gz'
Content type 'application/x-gzip' length 7429 bytes
==================================================
downloaded 7429 bytes

* installing *source* package ‘Rsymphony’ ...
** package ‘Rsymphony’ successfully unpacked and MD5 sums checked
Cannot find SYMPHONY libraries and headers.
See <https://projects.coin-or.org/SYMPHONY>.

The downloaded source packages are in
	‘/private/var/folders/n4/9mql2sh50p5gbq15rsd24vvr0000gn/T/Rtmp8ofsox/downloaded_packages’
Warning message:
In install.packages(""Rsymphony"") :
  installation of package ‘Rsymphony’ had non-zero exit status
ERROR: configuration failed for package ‘Rsymphony’
* removing ‘/Library/Frameworks/R.framework/Versions/3.2/Resources/library/Rsymphony’





I'm new to R. Any help would be much appreciated!",Problem installing packages?,3btktp,top
"I am trying to get a normal curve to be the same height as my histogram. By default, it does not appear as such; it seems to be very small.
[This picture shows what I mean pretty well.](https://imgur.com/d6aLXQK) I want the curve to be the same height as the histogram.

IT *does* have to be a frequency histogram though. I had a probability chart and it worked, but I need frequency.
",Fit Normal Curve to histo,36wnpj,top
"Hi!  Never posted here before, but I'm starting to use R for a bioinformatics project, and I was hoping for some help with color schemes.

I'm using ggplot2 to make some big stacked bar graphs, and ggplot2's normal color scheme blends together and makes it almost impossible to differentiate between colors (I've got about 30 different bars).  Is there a color scheme that will provide higher contrast?

Alternatively, is there a place on the web for building color palettes that are automatically designed for high contrast when layered on a graph?

Thank you in advance for any suggestions!",Useful color schemes for high-contrast ggplot graphs?,36o9h0,top
"Hi Everyone,

I have R revolution open with the option math library enhancements. 

However, when I run R and check the process list, it's still only using 18% of my cpu which indicates it's probably only using 1 core. 

Do I need to enable something to get the multicore feature to work?","R Revolution, Multicore?",354b9e,top
"I am currently doing a project for an R class at my college, and I am running the program maxent.  I got great results (I think), but I am having a little trouble comprehending and relating my ROC graphs and curves to my Analysis of variable contributions tables.  
How do the two correlate or don't correlate, with each other?",ROC curve help and comprehension.,33udmm,top
"I would like to create a database/dataframe of over 500 test questions. The goal is to eventually create a web app (maybe with shiny) that users can login to and select what questions they would like to practice based on the question category, difficulty, and other factors, but for now I just want to create a data.frame in R or maybe an MySQL database I am not sure what would be best. I was just hoping that I could get some direction from the r masters on this forum. Thanks",Question Bank then Web app,32rslm,top
"Hi All,

With stringr 1.0.0 coming out this month, I'm started to wonder how R stacks up against other languages for string manipulation / parsing...
Is there a defacto string manipulation language that isn't awk or sed? If so, how does R compare to that?",R for string parsing?,32m2yq,top
"I'm hoping there's an good resource for my dilemma. After years away from R and statistics, I'm going back and learning R and statistics again. I've discovered that my R skills are coming back moderately, but I'm not remembering any of the stats courses I had in college or the statistical work that I did on the job for a few years. (An intervening head injury seems to have helped wipe alot of it.) 

Can you suggest some decent online resources that will help me go back and relearn stats again (ideally within the context of R, although not necessarily)? Thanks!",Help with R-elearning R-elated stats,30zcmf,top
"Hi,

I am fairly new to R. Right now I work with SQL and I want to learn other stuff like R and Python (pandas esp). I would also like to do certification in R that would help me with my job prospects. Any idea what certification to choose for considering my background and any online courses that are more certification oriented?

Thanks in advance!",Certification question,2yg33f,top
"Is it possible to allow the user to select points on a Shiny plot to see their value, similar to the identify() function?

Thanks!",identify() with Shiny?,2wp3e9,top
"Due to a weird twist of fate I've become somewhat proficient with R, but am still lacking basic statistical skills. Can anyone recommend a good book on statistical testing, preferably with hands on examples for the most popular statistical tests? I'm especially interested in Monte-carlo simulations. It does not have to be R focused.",Looking for a beginners guide on statistical tests.,2s9akq,top
"Tagging on from the ""[how does R fit into your software stack at work""](http://www.reddit.com/r/Rlanguage/comments/2jgzo7/question_how_does_r_fit_into_your_software_stack/) question, how does your company support R?  My company has chosen to use Open Source R for a calculation engine for which I now have to find a company to support it.  Any ideas?",Support For R,2msmj1,top
"hi guys, i'm trying to generate a table like this one (
http://imgur.com/2BoDnsy ) with easily changed labels. I can't find a good solution via google. please help!

",how do i create almost-presentation ready tables that can export to excel?,2i5lgo,top
"I have been looking at several books on R. Most of them look pretty similar, and often they look like they progress from simple to complex pretty quickly. I am not very skilled at programming but would like to learn R for practical uses when doing research next year in grad school.

There is a book called [Python for Kids: A Playful Introduction to Programming](http://www.amazon.com/Python-Kids-Playful-Introduction-Programming/dp/1593274076/) for the Python language that looks very readable and easy to work with for the unskilled programmer, so, what would be the most comparable introduction to R in you guys' opinion?","What would be the best, most readable, introduction to R?",2bmdo2,top
"Hello! I am currently working on a very computation heavy spatial analysis project in R. However, R-studios only takes advantage of one of my cores.

Is there a simple way to allow me to use the computers full potential?

using R 3.0.3",Multicore in R-studios?,233kx3,top
"I've never used R, but I just spent an hour or so using http://tryr.codeschool.com/ out of curiosity. It all seems very well, but one thing nags at me. I am failing to understand why it is a special-purpose language all on its own, instead of just a great library available for such-and-such general-purpose language (like `#!/usr/bin/env python ... import R`). What advantages do you get from being a special-purpose language, apart from perhaps some syntactic niceties? Are there not also significant downsides, such as not having general-purpose libraries available in R?
",What makes R any better than a general-purpose language with a good statistics/reporting library?,1r7zgi,top
I use R for quantitative genetics/bioinformatics :) just saying hi,R user here,opjsl,top
"I have a dataset in which one column represents monthly Date:from 02/01/2004 to 09/01/2008, i have to create a dummy for the Dates in 2008. I tried to use:

\*\*dummy <- as.numeric(Date >= 01/01/2008)\*\*,

but R said me that: ""\*\*>= is not meaningful for factors\*\*"", hence i tried to transform the factor variable Date in a numeric one, but all my Dates disappeared, substituted with some random numbers.

I am a noob using R, hope somebody can help me.

Thanks to all",Dummy for time series in R,9ctvxd,top
"So, I've been using R for a few days now.

​

Here's my code:

​

salario<-c(25,35,40,45,55,65,85)

​

homens<-c(3145,2465,4675,11220,9180,8160,3655)

​

mulheres<-c(2664,2640,2196,2808,996,516,180)

​

tabela<-data.frame(Salario = salario, Homens = homens, Mulheres = mulheres)  (it's working so far)

​

barplot(mulheres,salario)

​

[The \\""salario\\"" variable isn't showing in X](https://i.redd.it/iebb9q9t05k11.png)

​

​

i'd like to have the x axis label of each bar to be \[25,35), \[35,40) etc (those ""salario"" values).

how can i do that?

thanks!

also, sorry for my bad english!!",Beginner question on graphs.,9crv29,top
"I have to make many individual API calls by replacing one set of numbers in the API URL. 

But the GET request only allows for a ""length of 1"". Any ideas?",GET function for many URLs.,9cm80h,top
"I was reading up on this function on the [Tidyverse reference](https://dplyr.tidyverse.org/reference/all_equal.html#examples) and the example the documentation gives for the behaviour of the `convert` parameter is unclear. Both examples evaluate to `TRUE` so it offers no insight into why the parameter is needed since it appears that the function converts similar classes even when the parameter is on its default of `FALSE`. 

&#x200B;

Does someone have an example of where setting `convert = TRUE` gives a different evaluation to the default?",What does the convert parameter of dplyr's all_equal() actually do?,9bx195,top
"I have some points plotted via geom_point, but I'm wondering if I have a two column list of line segments I need to add by point (e.g. column 1 is departure city and column 2 is arrival city), can I add that with native ggplot2 somehow or will I end up needing another library like ggnetwork?",geom_segment functionality in ggplot2?,9br4yr,top
"I  have two time  series,  they  respectivley describe    the  performances  of   a tennis  player, in  two separate  matches.

I want to merge the time series  togheter  and  get   a unique time  serie  which  describe the best the performance of the tennis player. 

Should  I run a regression fit  line, or  there  is another method to  merge  both time series  togheter?  Which are the methods  that I can use?

Thank you.",How to merge two time series?,9b1dud,top
"So, I have a data frame:

       state sex  diag death status T.categ age
    1   NSW   M 10905 11081      D      hs  35
    2   NSW   M 11029 11096      A      hs  53
    3   NSW   M  9551  9983      D      hs  42
    4   NSW   M  9577  9654      A    haem  44
    5   NSW   M 10015 10290      D      hs  39
    6   NSW   M  9971 10344      D      hs  36

Let's say I want to find what percentage of the men have status D. I did it manually by just storing the number of men with that status and the number of all men in another variable but wondered if there was a more natural way to do ir.",How to get the percentage of a subset of a data frame?,9ar2em,top
"I have XYZ coordinates for spatial objects and an edgelist for which objects 'connect' to each other. The coordinates are measured in meters, but the overall area is light years in size. (e.g. one object's XYZ coordinates are -88510792599980600, 42369443966878900, -44513525346479700).  

I've tried mapping them in ArcGIS and QGIS with little success for a few reasons: both had labeling issues; I couldn't figure out a good scale for symbology; they require a coordinate reference system that is Earth-based (my objects are measured in XYZ meter distance from a point in space, there is no projection to account for).  

My question is if I can 'map' these in R but calculate a scale for doing so where neither the dots representing each object nor the labels for each object overlap each other or the connections between them (from the edgelist of connections)?  

Size isn't a big issue but the final proportions for printing should end up being around 3ftx4ft with all the labels being legible at like an 8pt sans serif font.",Plotting/mapping space objects?,9a8ghh,top
"So, I use both R and Python at work.

&#x200B;

I notice anaconda allows you to install both rstudio and spyder.

&#x200B;

Is there any disadvantage in using anacando to run rstudio vs downloading rstudio by itself?",Anaconda R studioq,99zpgg,top
"First of all, if this is not allowed the please delete this post or let me know and I'll delete it.

I just recently finished my first R Shiny project and I'd love some advice on how I can make it better. This is my first major R project, having come from doing a few Python projects. I'd love any kind of advice on the code style/format, how I can improve the code to make it run smoother, making the app prettier, features I should add/remove, or really just anything I haven't thought of. My degree is in Biology so I may be lacking on the programming, design, and statistics side of things. But I want to get better.​

This project is a student grade analyzer specific to the school I will doing my apprentice teaching at start on Monday. I don't know if I'll be able to use it during my apprenticeship, but when I eventually get my own classroom I plan to use it and share it with any other teachers that want to use it as well. My Github for the project is [here](https://github.com/thomaskellough/Personal-Projects/tree/master/grades-analyzer). I'll also take advice on how I set up my Github if anyone wants to offer anything. [https://tkellough.shinyapps.io/grades/](https://tkellough.shinyapps.io/grades/) is a direct link to my project, but you will need a CSV/Excel file to run it (I've included some in the Github).

​

Thank you in advance!",Would someone be willing to review my code and give me advice/suggestions? RShiny Project,99zbzl,top
"I want to write a function that finds comparison text between User Generated Text and The Office TV show lines that have been said. The program would allow for anyone to type in any text and the R program could find Office lines with similar words. 

Solution:
User Generated Text:
 ""I'm interested in buying a paper shredder from the Steam Town Mall"" 

Output:
 ""Let's go to the Steam Town Mall to see if there is a sale, anyone interested?""  -Michael Scott, Season 4 Episode 5 (as an example)

The data: 
https://docs.google.com/spreadsheets/d/18wS5AAwOh8QO95RwHLS95POmSNKA2jjzdt0phrxeAE0/edit#gid=747974534 


This is the code I have so far. 

    library(plyr)
    library(dplyr)
    library(tidytext)
    library(googlesheets)
    library(bindrcpp)
    library(stringr)



    # get key for data sheet
    sheet_key <- gs_ls(""the-office-lines"") %>% 
      pull(sheet_key)

    # register sheet to access it
    reg <- sheet_key %>%
      gs_key()

    # read sheet data into R
    raw_data <- reg %>%
      gs_read(ws = ""scripts"")

    #removing funky stuff fixing typos
    mod_data <- raw_data %>% 
      filter(deleted == ""FALSE"") %>% 
      mutate(actions = str_extract_all(line_text, ""\\[.*?\\]""),
         line_text_mod = str_trim(str_replace_all(line_text, ""\\[.*?\\]"", """"))) %>% 
      mutate_at(vars(line_text_mod), funs(str_replace_all(., ""���"",""'""))) %>% 
      mutate_at(vars(speaker), funs(tolower)) %>% 
      mutate_at(vars(speaker), funs(str_trim(str_replace_all(., ""\\[.*?\\]"", """")))) %>% 
      mutate_at(vars(speaker), funs(str_replace_all(., ""micheal|michel|michae$"", ""michael"")))


    # Creating the comparison function between sentences
    compareSentences <- function(sentence1, sentence2) {
 
       # split everything on ""not a word"" and put all to lowercase
       x1 <- tolower(unlist(strsplit(sentence1, ""\\W"")))
       x2 <- tolower(unlist(strsplit(sentence2, ""\\W"")))
  
      commonWords <- intersect(x1, x2)
      #add word beginning and ending and put words between ()
      # to allow for match referencing in gsub
      commonWords <- paste(""\\<("",commonWords,"")\\>"",sep="""")
  
  
      for(x in commonWords){ 
        # replace the match by the match with star added
        sentence1 <- gsub(x, ""\\1*"", sentence1,ignore.case=TRUE)
        sentence2 <- gsub(x, ""\\1*"", sentence2,ignore.case=TRUE)
      }
  
     numberofwordsmatch <- str_count(sentence1,coll(""*""))
  
 
     return(list(sentence1,sentence2, numberofwordsmatch))     
     }

        # Getting a specific The Office quote
        TheOfficeLine<- mod_data %>%
                filter(id ==1, 
                   episode ==1, 
                   scene ==1, 
                   season ==1 )%>%
             select(line_text_mod)


    UserDefinedText <- ""all right Jim so this quarter look good""

    compareSentences(TheOfficeLine$line_text_mod, UserDefinedText )


If we run the function `compareSentences` we will see that five words match between the two different texts -- This is awesome. What I want to do next is loop through the entire series and see how many words match with my User Defined Text. 

I decided to make a loop to try and complete the next step:

    scenerange <- 1:100 # just pick the first 100 lines 
    for ( i in scenerange){
  
      TheOfficeLine <- mod_data %>%
        filter(id ==i)%>%
        select(line_text_mod)
    
    print(TheOfficeLine)
      }
  
This will work printing first 100 lines. The next bit is when I have trouble. I cannot seem to understand how to combine a loop and a function. 

This does not work: 
    
     for ( i in scenerange){
  
      TheOfficeLine<- mod_data %>%
        filter(id ==i)%>%
        select(line_text_mod)
  
      UserDefineText<- ""all right Jim so this quarter look good""
  
     compareSentences(TheOfficeLine$line_text_mod, UserDefineText)
 
    }

And I'm not sure why -- the loop works and the function works as well. I've used loops before but I have a hunch this has something to do with global environment not existing inside the function? maybe... 

Does anyone have an idea on what I should try next? 

",Requesting Help - Working Code -- Data is publicly available. Comparing between different text strings,98env2,top
"#SOLVED

Hi friends,

I created a package of R functions and thing I've found on the internet and a few I've written myself. I've done a package before and had no issues. Typically, what I do is create the package in RStudio then load it into github, then use `devtools::install\_github("""")` to install the package (it just keeps everything up to date and consistent across computers). 

today, though, I went through and added documentation for my personal package for future me. After installing the package, I've had all kinds of errors. Rstudio couldn't create a folder for my package so I had to make one by hand and install it there; it won't download from github; it won't install itself; file is corrupted; etc. 

I'm at a point now where the package is installed and will successfully download itself from github. 

however. 

None of the functions work. I load the package and call any of the functions and rstudio and R console both act as if they've never heard of them. There's gotta be something wrong with the namespace? or something else? 

Does anyone else wanna give it a shot? 

    devtools::install_github(""McCartneyAC/mccrr"")

    library(mccrr)

    coinflips()","trouble with a package not loading functions, et al.",97ywf5,top
" I just started using RMarkdown (have been working with R for a year now, so familiar with basic code writing in R); it's really handy but my documents don't look nice and structured. For example:

\- How can you change the color/thickness of line page breaks?

\- How can you change color of certain text pieces (to emphasize a word/sentence)

Any other tips are also welcome :)",Tips for a RMarkdown newby? Especially commands to make the document look nice?,97t1mn,top
"x-post from r/statistics

i have 12 independent events occuring, and need to figure the probabilities of X number of events. This is for a sports schedule, so basically after 5 games the probability of being 0-5, 1-4, 2-3, 3-2, etc.

What would be the quickest way to calculate this with some type of loop to figure this out without manually doing all 4095 possibilities by the time I get to week 12.

Thanks!",I need to find a loop to find the probability exactly X independent events occur,94cd5x,top
"Machine learning is one of the most searched keyword on any search engine at this point of time. The reason is quite clear; the benefits of utilising it in any industry is beyond imagination. Machine learning is making computers learn from data to find patterns & generate business insights. In e-commerce, machine learning is even far more relevant because of digitally generated user-specific data points. Daily, we read so much about big companies using machine learning in their business decisions. With the technological advancement, machine learning is very much accessible for any small to medium enterprise. However, still thousands of companies are not capitalising the value generated from machine learning. We will briefly discuss most useful cases of machine learning in e-commerce.

>*With the technological advancement, machine learning is very much accessible for any small to medium enterprise*

* User churn prediction: By using customer transactional historic data and other behavioural traits, user churn probability can be predicted. Engaging a customer at right time can help reduce the churn if we know specific customers are about to churn, machine learning plays a pivotal role.
* [Recommendation engine](https://www.datatobiz.com/2017/09/15/product-recommenders/): Up-selling & cross-selling based on machine learning basket analytics can boost revenue. Everyone know about amazon product recommendations. It has been surfaced in one of the report that 27% of Amazon revenue comes from recommendations only. The power of recommender engine can be estimated from these numbers itself.
* [Customer Life Time value v/s Customer acquisition cost](https://www.datatobiz.com/2017/10/29/machine-learning-trasactional-analytics/) : Understanding customer LTV can be very crucial for any business. Using RFM (recency, frequency & monetary), machine learning can figure out the customer LTV to make strategic decisions on acquisition channels & cost of acquisitions.
* Customer segmentation: With statistical segmentations, users can be defined in the specific type of users to better understand of your customer base. Which type of users are more profitable, who buys more stuff. These types of answers will create a solid foundation for strategic business decisions.
* Marketing Campaign optimisation: Every marketing campaign has its cost. To better manage marketing budget, one need to analyse which campaign doing well and why. Machine learning can work quite well in figuring this out.
* Spatial analytics: Matching demand supply spatially & timely can be very productive in any business. Using machine learning, demand & supply can be predicted to take business actions to reduce this gap.
* Product inventory optimisation: Another use case of machine learning is inventory management, with the demand prediction, a business can be lean enough to reduce storage & waiting for costs for various products.

The above mentioned key areas where any e-commerce firm can make better business decisions using machine learning. In addition, fraud detection, customer service, voice analytics, web page & content selection analytics, image recognition and lot more can make managers better at business decisions.

This blog has been published originally at [DataToBiz](https://datatobiz.com/blog) official blog page.",7 Ways to use machine learning in E-commerce​,91h0qf,top
"Hi! I'm a beginner R user and working on an interesting exercise: I have to predict which service will be degraded by an incident based on some categorical data (IDs of machines where the incident happened). I have like thousands of these ids and in an incident one or more of them is affected. I'm not sure that using dummy variables is the best method... I can convert the IDs to unique numbers, but won't that affect the precision of the model? (Like one service is degraded when ID 12 and 5 are down, and another service is degraded when ID 10 and 7 is down...) I plan to use knn or random forest for the solution. Many thanks in advance for your ideas!",Best way to handle categorical variables for classification?,90dexy,top
"Ive used rstudio in windows and tried to put it on Mint. I have R-base installed and can use it from the command line, and I also have rstudio installed. It will not open though. If I try to open it either from the gui or command line nothing happens, no message is returned to me. Not sure what is going on. ",Rstudio wont open in Mint,8zht12,top
"Hi all, 

Can anyone recommend any packages or tools that would count and tag the number of words in a paragraph? So for instance: 

Pre-processing a paragraph might look like this. 

And another like this. 

*But post-processing*

Pre-processing a paragraph might look like this (7). 

And another like this (4).

Or similar. 
",Any packages for counting and tagging paragraph lengths?,8zh57h,top
"As far as I understood CRAN doesn't allow them, but what about Bioconductor?

Thanks",Are C shared libraries (.so) allowed on Bioconductor ?,8zbvu2,top
"Hi everybody, I'm trying to run a log-log model linking the price of the houses with the age:

logprice <- log(hp$price)

logage <- log(hp$age)

hp\_loglog <- lm(logprice \~ logage, data=hp)

but I encounter an error due to the fact that the result of some log transformations is -Inf. Is there a way to exclude those values or anything else to make the model run smoothly?",Log Transformation problem (log-log model),8ylplc,top
"I have a list of 452 data frames. Each data frame has row names for a column on integers. However, these row names are time stamps, and I want to plot them. 

This adequately extracts the rownames and puts them into a separate list of data.frames:

df.rownames <- lapply(X = df.original[1:452], FUN = 'rownames')

df.rownames <- lapply(X = df.rownames[1:452], FUN = 'data.frame')

But now I can't figure out how to bind them across the lists of 1:452 *and* get rid of the row names in df.original.

Any ideas?",I have a list of data frames and want the row names for each to become a new column in each.,9d8q51,new
"I need some help. I am away from my desk and can't reproduce my error messages right now. Here's what my code looks like right now:

depvar <- ""foo"" 

transformedvars[1] <- ""mean(bar)"" 

dataset %>% mutate(paste0(""t"", depvar) = transformedvars[1])

I want to use mutate() to create a column called 'tfoo' and have it take as values the result of calling up mean(bar). This code isnt working, and I don't know why. Help!

EDIT: For some clarification, 'bar' is another column of my data 'dataset'. Its a bunch of numbers that I want to perform a function on, then drop into a column called 'tfoo'.

The error I get is:

Error: unexpected '=' in:

""dataset %>% mutate(paste0(""t"", depvar) =""

UPDATE: Problem solved! I needed to do this... 

dataset %>% mutate(!!paste0(""t"", depvar) := !!parse_quosure(transformedvars[1]))",Help with dplyr and expressions inside mutate(),9d683y,new
"Hi

I have two values, f.x.

    from = XY05*
    to     = XY55*

Then I have a `tbl_dff` that contains a lot of strings.

    Codes = [""XY05A"", ""XY56"", ""XY555"", ""AT003""
                  ""GA003A"", ""XY36"", ""XY100"", ""XY03"",...]

So I want to use my variables `from` and `to` to see if any of these are in my `Codes` variable.

From the example, I wish to have a match on 

    ""XY05A""
    ""XY555""
    ""XY36""

Since it is between `XY05* - XY55*`. The `*` just says, that I do not care what is after.

Hope this makes sense.
",match wildcard with interval,9d4zco,new
"I am referring the econometrics textbook by Jeffery Woolridge for studying time series. The book has a bunch of practical exercises but the data sets can only be accessed in STATA.

There's an R package (""woolridge"") that has collected and compiled all the data sets from the book. However, I am unable to install it on RStudio. Whenever I try, it returns  the message: package ‘woolridge’ is not available (for R version 3.4.3).

 Can anyone help in figuring this out? Thanks. 

&#x200B;",Need help with installing the woolridge package,9d43qu,new
"Below is what this list structure looks like. I would to extract each of the listed data frames out. Please help before I lose mind. (mods, sorry for so many questions; I'm in over my head but learning a lot)

str(unholy.list)
List of 452
 $ : 'data.frame':           11 obs of 2 variables
   ..$  X[[i]]:  int [1:4] 2  1  8  25
   ..$  time :   chr [1:4 ""2018-08-29T19:00:00-06:00""",List of data frames is crushing soul. Please help me extract and name them.,9dbnwi,new
"Hi all I'm new to R and would love your help. I have a data frame where I would like to recode some values. Here's an example data frame:

    df <- data.frame(age = sample(100, size = 6),
                     gender = c(""boy"", ""girl"")
    print(x)
          age gender
        1  58    boy
        2  41   girl
        3  31    boy
        4  96   girl
        5  93    boy
        6  60   girl

Let's say I want to recode *boy* to *man* and *girl* to *woman* in a new column called *new.gender* . I tried using the `ifelse` function (to no avail):

    df$new.gender <- NA
    ifelse(x$gender == ""boy"", x$new.gender <- ""man"", x$new.gender <- ""woman"")
    print(x)
      age gender new.gender
    1  96    boy      woman
    2  46   girl      woman
    3  68    boy      woman
    4   6   girl      woman
    5  26    boy      woman
    6  55   girl      woman

After some thinking, I changed the syntax a bit and got it to work:

    x$new.gender <- NA
    x$new.gender <- ifelse(x$gender == ""boy"", ""man"", ""woman"")
    print(x)
      age gender new.gender
    1  96    boy        man
    2  46   girl      woman
    3  68    boy        man
    4   6   girl      woman
    5  26    boy        man
    6  55   girl      woman

Can someone help me understand why my first attempt resulted in all values changing to *woman*, while my second attempt worked? Thanks!",understanding how ifelse works,9dcmfm,new
